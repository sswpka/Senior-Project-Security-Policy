[
    {
        "project_name": "awslabs/autogluon",
        "project_url": "https://github.com/awslabs/autogluon",
        "SSF": {
            "date": "2024-10-30T01:24:37+07:00",
            "repo": {
                "name": "github.com/awslabs/autogluon",
                "commit": "1555ef5851606d4633a5af6c7c165fa1ebe26857"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.4,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch '0.8.3'",
                        "Warn: branch protection not enabled for branch '0.5.3'",
                        "Warn: branch protection not enabled for branch '0.5.2'",
                        "Warn: branch protection not enabled for branch '0.4.3'",
                        "Warn: branch protection not enabled for branch '0.4.2'",
                        "Warn: branch protection not enabled for branch '0.0.15'",
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Warn: no status checks found to merge onto branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 out of 30 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: amazon aws ai contributor org/company found, university of freiburg contributor org/company found, aws @autogluon @d2l-ai contributor org/company found, aws ai contributor org/company found, aws contributor org/company found, DS3Lab contributor org/company found, amazon contributor org/company found, arcadelab contributor org/company found, scipy contributor org/company found, aws @awslabs contributor org/company found, ms cs @ nyu 2023 contributor org/company found, aws-samples contributor org/company found, cleanlab contributor org/company found, brainnetome contributor org/company found, dsgiitr contributor org/company found, amazon ai contributor org/company found, dyweb contributor org/company found, ML-HK contributor org/company found, awslabs contributor org/company found, d2l-ai contributor org/company found, apachecn contributor org/company found, MentorsWithoutBorders contributor org/company found, apache contributor org/company found, dmlc contributor org/company found, amazon web services contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 25 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 5 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/build_latest_image.yml:41"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark-command.yml:80: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark-command.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark-command.yml:95: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark-command.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark-command.yml:99: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark-command.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark-command.yml:125: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark-command.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark-command.yml:136: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark-command.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark-command.yml:141: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark-command.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark-command.yml:143: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark-command.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark-command.yml:147: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark-command.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark-command.yml:151: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark-command.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark-command.yml:171: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark-command.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark-command.yml:176: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark-command.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark-command.yml:189: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark-command.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark-command.yml:198: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark-command.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark-command.yml:205: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark-command.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark-command.yml:214: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark-command.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:231: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:241: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:243: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:247: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:251: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:263: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:47: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:57: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:59: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:63: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:67: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:79: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:93: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:103: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:105: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:109: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:113: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:125: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:139: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:149: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:151: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:155: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:159: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:171: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:185: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:195: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:197: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:201: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:205: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark_master.yml:217: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/benchmark_master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_latest_image.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/build_latest_image.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build_latest_image.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/build_latest_image.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build_latest_image.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/build_latest_image.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_latest_image.yml:44: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/build_latest_image.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build_latest_image.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/build_latest_image.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build_latest_image.yml:53: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/build_latest_image.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_latest_image.yml:72: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/build_latest_image.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build_latest_image.yml:74: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/build_latest_image.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build_latest_image.yml:81: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/build_latest_image.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build_latest_image.yml:100: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/build_latest_image.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build_latest_image.yml:102: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/build_latest_image.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build_latest_image.yml:109: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/build_latest_image.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/codeguru-reviewer.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/codeguru-reviewer.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeguru-reviewer.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/codeguru-reviewer.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/codeguru-reviewer.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/codeguru-reviewer.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeguru-reviewer.yml:42: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/codeguru-reviewer.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:47: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codespell.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/codespell.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/codespell.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/codespell.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:272: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:274: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:294: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:296: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:365: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:124: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:126: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:421: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:425: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:444: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:334: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:379: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:104: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:106: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:314: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:316: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:228: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:230: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:250: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:252: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:351: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:407: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:144: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:146: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:164: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/continuous_integration.yml:166: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/continuous_integration_multigpu.yaml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration_multigpu.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/continuous_integration_multigpu.yaml:47: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration_multigpu.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/continuous_integration_multigpu.yaml:65: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration_multigpu.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/continuous_integration_multigpu.yaml:67: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration_multigpu.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/continuous_integration_multigpu.yaml:85: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration_multigpu.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/continuous_integration_multigpu.yaml:87: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration_multigpu.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/continuous_integration_multigpu.yaml:105: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration_multigpu.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/continuous_integration_multigpu.yaml:107: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/continuous_integration_multigpu.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/platform_tests-command.yml:91: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/platform_tests-command.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/platform_tests-command.yml:96: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/platform_tests-command.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/platform_tests-command.yml:98: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/platform_tests-command.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/platform_tests-command.yml:124: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/platform_tests-command.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/platform_tests-command.yml:129: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/platform_tests-command.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/platform_tests-command.yml:131: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/platform_tests-command.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/platform_tests-command.yml:190: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/platform_tests-command.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/platform_tests-command.yml:195: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/platform_tests-command.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/platform_tests-command.yml:197: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/platform_tests-command.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/platform_tests-command.yml:235: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/platform_tests-command.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/platform_tests-command.yml:240: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/platform_tests-command.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/platform_tests-command.yml:242: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/platform_tests-command.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/platform_tests-command.yml:279: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/platform_tests-command.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/platform_tests-command.yml:284: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/platform_tests-command.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/platform_tests-command.yml:286: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/platform_tests-command.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/platform_tests-command.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/platform_tests-command.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/platform_tests-command.yml:58: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/platform_tests-command.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/platform_tests-command.yml:63: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/platform_tests-command.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/platform_tests-command.yml:65: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/platform_tests-command.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi_release.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/pypi_release.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi_release.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/pypi_release.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pythonpublish.yml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/pythonpublish.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pythonpublish.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/pythonpublish.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pythonpublish_testpypi.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/pythonpublish_testpypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pythonpublish_testpypi.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/pythonpublish_testpypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/slash_command_dispatch.yml:12: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/slash_command_dispatch.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/slash_command_dispatch.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/slash_command_dispatch.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/slash_command_dispatch.yml:47: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/slash_command_dispatch.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/slash_command_dispatch.yml:63: update your workflow using https://app.stepsecurity.io/secureworkflow/autogluon/autogluon/slash_command_dispatch.yml/master?enable=pin",
                        "Warn: containerImage not pinned by hash: CI/batch/docker/Dockerfile.cpu:1",
                        "Warn: containerImage not pinned by hash: CI/batch/docker/Dockerfile.gpu:1",
                        "Warn: containerImage not pinned by hash: CI/batch/docker/Dockerfile.pyodide:1: pin your Docker image by updating pyodide/pyodide-env:20221102-chrome107-firefox106 to pyodide/pyodide-env:20221102-chrome107-firefox106@sha256:384f7b3325b8cb152e56ce59fc23f2146435141c1307b4c0d10cdfd9f2829c55",
                        "Warn: containerImage not pinned by hash: CI/docker/Dockerfile.cpu-inference:1",
                        "Warn: containerImage not pinned by hash: CI/docker/Dockerfile.cpu-training:1",
                        "Warn: containerImage not pinned by hash: CI/docker/Dockerfile.gpu-inference:1",
                        "Warn: containerImage not pinned by hash: CI/docker/Dockerfile.gpu-training:1",
                        "Warn: containerImage not pinned by hash: CI/hf_mirror/Dockerfile:1: pin your Docker image by updating python:3.8 to python:3.8@sha256:d411270700143fa2683cc8264d9fa5d3279fd3b6afff62ae81ea2f9d070e390c",
                        "Warn: pipCommand not pinned by hash: CI/batch/docker/Dockerfile.pyodide:5-12",
                        "Warn: pipCommand not pinned by hash: CI/batch/docker/Dockerfile.pyodide:5-12",
                        "Warn: pipCommand not pinned by hash: CI/batch/docker/Dockerfile.pyodide:5-12",
                        "Warn: pipCommand not pinned by hash: CI/batch/docker/Dockerfile.pyodide:19",
                        "Warn: pipCommand not pinned by hash: CI/docker/Dockerfile.cpu-inference:9",
                        "Warn: pipCommand not pinned by hash: CI/docker/Dockerfile.cpu-inference:10",
                        "Warn: pipCommand not pinned by hash: CI/docker/Dockerfile.cpu-inference:11",
                        "Warn: pipCommand not pinned by hash: CI/docker/Dockerfile.cpu-training:11",
                        "Warn: pipCommand not pinned by hash: CI/docker/Dockerfile.cpu-training:12",
                        "Warn: pipCommand not pinned by hash: CI/docker/Dockerfile.gpu-inference:9",
                        "Warn: pipCommand not pinned by hash: CI/docker/Dockerfile.gpu-inference:10",
                        "Warn: pipCommand not pinned by hash: CI/docker/Dockerfile.gpu-inference:11",
                        "Warn: pipCommand not pinned by hash: CI/docker/Dockerfile.gpu-training:11",
                        "Warn: pipCommand not pinned by hash: CI/docker/Dockerfile.gpu-training:12",
                        "Warn: pipCommand not pinned by hash: .github/workflow_scripts/env_setup.sh:2",
                        "Warn: pipCommand not pinned by hash: .github/workflow_scripts/env_setup.sh:3",
                        "Warn: pipCommand not pinned by hash: .github/workflow_scripts/env_setup.sh:4",
                        "Warn: pipCommand not pinned by hash: .github/workflow_scripts/env_setup.sh:5",
                        "Warn: pipCommand not pinned by hash: .github/workflow_scripts/env_setup.sh:6",
                        "Warn: pipCommand not pinned by hash: .github/workflow_scripts/env_setup.sh:7",
                        "Warn: pipCommand not pinned by hash: .github/workflow_scripts/env_setup.sh:11",
                        "Warn: pipCommand not pinned by hash: .github/workflow_scripts/env_setup.sh:12",
                        "Warn: pipCommand not pinned by hash: .github/workflow_scripts/env_setup.sh:18",
                        "Warn: pipCommand not pinned by hash: .github/workflow_scripts/env_setup.sh:19",
                        "Warn: pipCommand not pinned by hash: .github/workflow_scripts/env_setup.sh:21",
                        "Warn: pipCommand not pinned by hash: .github/workflow_scripts/env_setup.sh:22",
                        "Warn: pipCommand not pinned by hash: .github/workflow_scripts/env_setup.sh:26",
                        "Warn: pipCommand not pinned by hash: .github/workflow_scripts/env_setup.sh:33",
                        "Warn: pipCommand not pinned by hash: .github/workflow_scripts/env_setup.sh:39",
                        "Warn: pipCommand not pinned by hash: .github/workflow_scripts/env_setup.sh:52",
                        "Warn: pipCommand not pinned by hash: .github/workflow_scripts/env_setup.sh:77",
                        "Warn: pipCommand not pinned by hash: .github/workflow_scripts/setup_mmcv.sh:3",
                        "Warn: pipCommand not pinned by hash: CI/docker/full_install_image.sh:4",
                        "Warn: pipCommand not pinned by hash: CI/docker/full_install_image.sh:5",
                        "Warn: pipCommand not pinned by hash: CI/docker/full_install_image.sh:6",
                        "Warn: pipCommand not pinned by hash: CI/docker/full_install_image.sh:7",
                        "Warn: pipCommand not pinned by hash: CI/docker/full_install_image.sh:8",
                        "Warn: pipCommand not pinned by hash: CI/docker/full_install_image.sh:9",
                        "Warn: pipCommand not pinned by hash: CI/docker/full_install_image.sh:10",
                        "Warn: pipCommand not pinned by hash: CI/docker/full_install_image.sh:13",
                        "Warn: pipCommand not pinned by hash: docs/build_pip_install.sh:13",
                        "Warn: pipCommand not pinned by hash: docs/build_pip_install.sh:17",
                        "Warn: pipCommand not pinned by hash: docs/build_pip_install.sh:21",
                        "Warn: pipCommand not pinned by hash: docs/build_pip_install.sh:27",
                        "Warn: pipCommand not pinned by hash: docs/build_pip_install.sh:31",
                        "Warn: pipCommand not pinned by hash: docs/build_pip_install.sh:35",
                        "Warn: pipCommand not pinned by hash: docs/build_pip_install.sh:39",
                        "Warn: pipCommand not pinned by hash: docs/build_pip_install.sh:41",
                        "Warn: pipCommand not pinned by hash: docs/build_pip_install.sh:45",
                        "Warn: pipCommand not pinned by hash: full_install.sh:20",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pypi_release.yml:25",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pypi_release.yml:26",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pythonpublish.yml:26",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pythonpublish.yml:27",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pythonpublish_testpypi.yml:22",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pythonpublish_testpypi.yml:23",
                        "Info:   0 out of  81 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of  53 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   8 containerImage dependencies pinned",
                        "Info:   0 out of  56 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: all commits (30) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/benchmark-command.yml:67",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/benchmark_master.yml:15",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/build_latest_image.yml:10",
                        "Warn: no topLevel permission defined: .github/workflows/check_hf_model_list.yml:1",
                        "Warn: topLevel 'security-events' permission set to 'write': .github/workflows/codeguru-reviewer.yml:12",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/codeguru-reviewer.yml:11",
                        "Warn: no topLevel permission defined: .github/workflows/codeql.yml:1",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/codespell.yml:11",
                        "Warn: no topLevel permission defined: .github/workflows/platform_tests-command.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/pypi_release.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/pythonpublish.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/pythonpublish_testpypi.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/slash_command_dispatch.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/awslabs/autogluon/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\n| Version       | Supported          |\n| ------------- | ------------------ |\n| 1.1.1         | :white_check_mark: |\n| < 1.1.1       | :x:                |\n\n## How we do security\n\n\nAs much as possible, AutoGluon relies on automated tools to do security scanning. In particular, we support:\n\n1. Dependency Analysis: Using Dependabot\n2. Docker Scanning: Using Snyk\n3. Code Analysis: Using CodeGuru\n\n\n## Reporting a Vulnerability\n\nReport any security vulnerabilities to `autogluon-security@amazon.com`. This email directly links to the Autogluon security maintenance team. Once the security vulnerability is confirmed, we will work privately on a patch, aiming to produce a dedicated bugfix release as swiftly as complexity allows.",
        "project_all_labels": [
            "API & Doc",
            "breaking",
            "bug",
            "bug: unconfirmed",
            "code cleanup",
            "dependency",
            "discussion",
            "duplicate",
            "enhancement",
            "enhancement: new task",
            "env: colab",
            "env: kaggle",
            "env: new",
            "env: sagemaker",
            "feature request",
            "feature: distributed",
            "feature: hpo",
            "good first issue",
            "help wanted",
            "install",
            "invalid",
            "model list checked",
            "module: cloud",
            "module: common",
            "module: eda",
            "module: features",
            "module: multimodal",
            "module: tabular",
            "module: timeseries",
            "Needs Triage",
            "needs: benchmark",
            "OS: Mac",
            "OS: Windows",
            "priority: 0",
            "priority: 1",
            "priority: 2",
            "question",
            "resource: ARM",
            "resource: GPU",
            "run-multi-gpu",
            "stale",
            "todo",
            "urgent",
            "wontfix"
        ],
        "README_content": "\n\n<div align=\"center\">\n<img src=\"https://user-images.githubusercontent.com/16392542/77208906-224aa500-6aba-11ea-96bd-e81806074030.png\" width=\"350\">\n\n## Fast and Accurate ML in 3 Lines of Code\n\n[![Latest Release](https://img.shields.io/github/v/release/autogluon/autogluon)](https://github.com/autogluon/autogluon/releases)\n[![Conda Forge](https://img.shields.io/conda/vn/conda-forge/autogluon.svg)](https://anaconda.org/conda-forge/autogluon)\n[![Python Versions](https://img.shields.io/badge/python-3.8%20%7C%203.9%20%7C%203.10%20%7C%203.11-blue)](https://pypi.org/project/autogluon/)\n[![Downloads](https://pepy.tech/badge/autogluon/month)](https://pepy.tech/project/autogluon)\n[![GitHub license](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](./LICENSE)\n[![Discord](https://img.shields.io/discord/1043248669505368144?logo=discord&style=flat)](https://discord.gg/wjUmjqAc2N)\n[![Twitter](https://img.shields.io/twitter/follow/autogluon?style=social)](https://twitter.com/autogluon)\n[![Continuous Integration](https://github.com/autogluon/autogluon/actions/workflows/continuous_integration.yml/badge.svg)](https://github.com/autogluon/autogluon/actions/workflows/continuous_integration.yml)\n[![Platform Tests](https://github.com/autogluon/autogluon/actions/workflows/platform_tests-command.yml/badge.svg?event=schedule)](https://github.com/autogluon/autogluon/actions/workflows/platform_tests-command.yml)\n\n[Installation](https://auto.gluon.ai/stable/install.html) | [Documentation](https://auto.gluon.ai/stable/index.html) | [Release Notes](https://auto.gluon.ai/stable/whats_new/index.html)\n\nAutoGluon automates machine learning tasks enabling you to easily achieve strong predictive performance in your applications.  With just a few lines of code, you can train and deploy high-accuracy machine learning and deep learning models on image, text, time series, and tabular data.\n</div>\n\n##  Installation\n\nAutoGluon is supported on Python 3.8 - 3.11 and is available on Linux, MacOS, and Windows.\n\nYou can install AutoGluon with:\n\n```python\npip install autogluon\n```\n\nVisit our [Installation Guide](https://auto.gluon.ai/stable/install.html) for detailed instructions, including GPU support, Conda installs, and optional dependencies.\n\n## :zap: Quickstart\n\nBuild accurate end-to-end ML models in just 3 lines of code!\n\n```python\nfrom autogluon.tabular import TabularPredictor\npredictor = TabularPredictor(label=\"class\").fit(\"train.csv\")\npredictions = predictor.predict(\"test.csv\")\n```\n\n| AutoGluon Task      |                                                                                Quickstart                                                                                |                                                                                API                                                                                |\n|:--------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------:|\n| TabularPredictor    | [![Quick Start](https://img.shields.io/static/v1?label=&message=tutorial&color=grey)](https://auto.gluon.ai/stable/tutorials/tabular/tabular-quick-start.html) |                 [![API](https://img.shields.io/badge/api-reference-blue.svg)](https://auto.gluon.ai/stable/api/autogluon.tabular.TabularPredictor.html)                 |\n| MultiModalPredictor | [![Quick Start](https://img.shields.io/static/v1?label=&message=tutorial&color=grey)](https://auto.gluon.ai/stable/tutorials/multimodal/multimodal_prediction/multimodal-quick-start.html)            | [![API](https://img.shields.io/badge/api-reference-blue.svg)](https://auto.gluon.ai/stable/api/autogluon.multimodal.MultiModalPredictor.html) |\n| TimeSeriesPredictor | [![Quick Start](https://img.shields.io/static/v1?label=&message=tutorial&color=grey)](https://auto.gluon.ai/stable/tutorials/timeseries/forecasting-quick-start.html)            | [![API](https://img.shields.io/badge/api-reference-blue.svg)](https://auto.gluon.ai/stable/api/autogluon.timeseries.TimeSeriesPredictor.html) |\n\n## :mag: Resources\n\n### Hands-on Tutorials / Talks\n\nBelow is a curated list of recent tutorials and talks on AutoGluon. A comprehensive list is available [here](AWESOME.md#videos--tutorials).\n\n| Title                                                                                                                    | Format   | Location                                                                         | Date       |\n|--------------------------------------------------------------------------------------------------------------------------|----------|----------------------------------------------------------------------------------|------------|\n| :tv: [AutoGluon 1.0: Shattering the AutoML Ceiling with Zero Lines of Code](https://www.youtube.com/watch?v=5tvp_Ihgnuk) | Tutorial | [AutoML Conf 2023](https://2023.automl.cc/)                                      | 2023/09/12 |\n| :sound: [AutoGluon: The Story](https://automlpodcast.com/episode/autogluon-the-story)                                    | Podcast  | [The AutoML Podcast](https://automlpodcast.com/)                                 | 2023/09/05 |\n| :tv: [AutoGluon: AutoML for Tabular, Multimodal, and Time Series Data](https://youtu.be/Lwu15m5mmbs?si=jSaFJDqkTU27C0fa) | Tutorial | PyData Berlin                                                                    | 2023/06/20 | \n| :tv: [Solving Complex ML Problems in a few Lines of Code with AutoGluon](https://www.youtube.com/watch?v=J1UQUCPB88I)    | Tutorial | PyData Seattle                                                                   | 2023/06/20 | \n| :tv: [The AutoML Revolution](https://www.youtube.com/watch?v=VAAITEds-28)                                                | Tutorial | [Fall AutoML School 2022](https://sites.google.com/view/automl-fall-school-2022) | 2022/10/18 |\n\n### Scientific Publications\n- [AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data](https://arxiv.org/pdf/2003.06505.pdf) (*Arxiv*, 2020) ([BibTeX](CITING.md#general-usage--autogluontabular))\n- [Fast, Accurate, and Simple Models for Tabular Data via Augmented Distillation](https://proceedings.neurips.cc/paper/2020/hash/62d75fb2e3075506e8837d8f55021ab1-Abstract.html) (*NeurIPS*, 2020) ([BibTeX](CITING.md#tabular-distillation))\n- [Benchmarking Multimodal AutoML for Tabular Data with Text Fields](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/9bf31c7ff062936a96d3c8bd1f8f2ff3-Paper-round2.pdf) (*NeurIPS*, 2021) ([BibTeX](CITING.md#autogluonmultimodal))\n- [XTab: Cross-table Pretraining for Tabular Transformers](https://proceedings.mlr.press/v202/zhu23k/zhu23k.pdf) (*ICML*, 2023)\n- [AutoGluon-TimeSeries: AutoML for Probabilistic Time Series Forecasting](https://arxiv.org/abs/2308.05566) (*AutoML Conf*, 2023) ([BibTeX](CITING.md#autogluontimeseries))\n- [TabRepo: A Large Scale Repository of Tabular Model Evaluations and its AutoML Applications](https://arxiv.org/pdf/2311.02971.pdf) (*Under Review*, 2024)\n\n### Articles\n- [AutoGluon-TimeSeries: Every Time Series Forecasting Model In One Library](https://towardsdatascience.com/autogluon-timeseries-every-time-series-forecasting-model-in-one-library-29a3bf6879db) (*Towards Data Science*, Jan 2024)\n- [AutoGluon for tabular data: 3 lines of code to achieve top 1% in Kaggle competitions](https://aws.amazon.com/blogs/opensource/machine-learning-with-autogluon-an-open-source-automl-library/) (*AWS Open Source Blog*, Mar 2020)\n- [AutoGluon overview & example applications](https://towardsdatascience.com/autogluon-deep-learning-automl-5cdb4e2388ec?source=friends_link&sk=e3d17d06880ac714e47f07f39178fdf2) (*Towards Data Science*, Dec 2019)\n\n### Train/Deploy AutoGluon in the Cloud\n- [AutoGluon Cloud](https://auto.gluon.ai/cloud/stable/index.html) (Recommended)\n- [AutoGluon on SageMaker AutoPilot](https://auto.gluon.ai/stable/tutorials/cloud_fit_deploy/autopilot-autogluon.html)\n- [AutoGluon on Amazon SageMaker](https://auto.gluon.ai/stable/tutorials/cloud_fit_deploy/cloud-aws-sagemaker-train-deploy.html)\n- [AutoGluon Deep Learning Containers](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#autogluon-training-containers) (Security certified & maintained by the AutoGluon developers)\n- [AutoGluon Official Docker Container](https://hub.docker.com/r/autogluon/autogluon)\n- [AutoGluon-Tabular on AWS Marketplace](https://aws.amazon.com/marketplace/pp/prodview-n4zf5pmjt7ism) (Not maintained by us)\n\n## :pencil: Citing AutoGluon\n\nIf you use AutoGluon in a scientific publication, please refer to our [citation guide](CITING.md).\n\n## :wave: How to get involved\n\nWe are actively accepting code contributions to the AutoGluon project. If you are interested in contributing to AutoGluon, please read the [Contributing Guide](https://github.com/autogluon/autogluon/blob/master/CONTRIBUTING.md) to get started.\n\n## :classical_building: License\n\nThis library is licensed under the Apache 2.0 License.\n",
        "num_commits": 2350,
        "project_age_days": 1919,
        "project_created_at": "2019-07-29",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 115,
        "num_pull": 2658,
        "num_issues": 4105,
        "num_opening_issue": 380,
        "project_size(kB)": 20998,
        "num_stargazers": 7976,
        "num_watchers": 7976,
        "num_forks": 925,
        "num_subscribers": 97,
        "SecurityPolicy_created_at": "2024-06-27 16:57:09",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "a6dcbcb8d5723275d05fe8baf0f23edf0745d6b0",
                "url": "https://github.com/autogluon/autogluon/commit/a6dcbcb8d5723275d05fe8baf0f23edf0745d6b0",
                "date": "2024-06-27 16:57:09"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "User guideline",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "web2py/web2py",
        "project_url": "https://github.com/web2py/web2py",
        "SSF": {
            "date": "2024-10-29T21:49:00+07:00",
            "repo": {
                "name": "github.com/web2py/web2py",
                "commit": "301999fa743b05f6019b9a472f2444c35fbd9981"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 4.3,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'master'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "3 out of 3 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 1,
                    "reason": "Found 3/27 approved changesets -- score normalized to 1",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: gooborgstudios contributor org/company found, luizalabs contributor org/company found, KMUGradeServerProject contributor org/company found, KMUGradeServer contributor org/company found, dendra contributor org/company found, wxWidgets contributor org/company found, SistemasAgiles contributor org/company found, gobelohorizonte contributor org/company found, UniversidadDelEste contributor org/company found, pythonbrasil contributor org/company found, python contributor org/company found, kivy contributor org/company found, tigim contributor org/company found, getsentry contributor org/company found, openwebdocs contributor org/company found, pythonmg contributor org/company found, UCIUROP2015 contributor org/company found, sqlcollaborative @web2py contributor org/company found, growthpath contributor org/company found, pythonhub contributor org/company found, editor-bootstrap contributor org/company found, InstitutoPascal contributor org/company found, sahana contributor org/company found, naver contributor org/company found, web2py contributor org/company found, emmett-framework contributor org/company found, pysimplesoap contributor org/company found, PyAr contributor org/company found, onapsis contributor org/company found, socit contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 30 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no workflows found",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "14 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Info: Possibly incomplete results: error parsing shell code: \"select\" must be followed by a literal: scripts/drop-pgsql-tables.sh:0",
                        "Warn: containerImage not pinned by hash: docker/alpine/web2py-gevent/Dockerfile:1: pin your Docker image by updating alpine:latest to alpine:latest@sha256:beefdbd8a1da6d2915566fde36db9db0b524eb737fc57cd1367effd16dc0d06d",
                        "Warn: containerImage not pinned by hash: docker/alpine/web2py-gunicorn/Dockerfile:1: pin your Docker image by updating alpine:latest to alpine:latest@sha256:beefdbd8a1da6d2915566fde36db9db0b524eb737fc57cd1367effd16dc0d06d",
                        "Warn: containerImage not pinned by hash: docker/alpine/web2py-paste/Dockerfile:1: pin your Docker image by updating alpine:latest to alpine:latest@sha256:beefdbd8a1da6d2915566fde36db9db0b524eb737fc57cd1367effd16dc0d06d",
                        "Warn: containerImage not pinned by hash: docker/alpine/web2py-rocket-ssl/Dockerfile:1: pin your Docker image by updating alpine:latest to alpine:latest@sha256:beefdbd8a1da6d2915566fde36db9db0b524eb737fc57cd1367effd16dc0d06d",
                        "Warn: containerImage not pinned by hash: docker/alpine/web2py-rocket/Dockerfile:1: pin your Docker image by updating alpine:latest to alpine:latest@sha256:beefdbd8a1da6d2915566fde36db9db0b524eb737fc57cd1367effd16dc0d06d",
                        "Warn: containerImage not pinned by hash: docker/alpine/web2py-tornado/Dockerfile:1: pin your Docker image by updating alpine:latest to alpine:latest@sha256:beefdbd8a1da6d2915566fde36db9db0b524eb737fc57cd1367effd16dc0d06d",
                        "Warn: containerImage not pinned by hash: docker/alpine/web2py-waitress/Dockerfile:1: pin your Docker image by updating alpine:latest to alpine:latest@sha256:beefdbd8a1da6d2915566fde36db9db0b524eb737fc57cd1367effd16dc0d06d",
                        "Warn: containerImage not pinned by hash: docker/alpine/web2py-wsgiref/Dockerfile:1: pin your Docker image by updating alpine:latest to alpine:latest@sha256:beefdbd8a1da6d2915566fde36db9db0b524eb737fc57cd1367effd16dc0d06d",
                        "Warn: containerImage not pinned by hash: docker/centos/web2py-eventlet/Dockerfile:1: pin your Docker image by updating centos:latest to centos:latest@sha256:a27fd8080b517143cbbbab9dfb7c8571c40d67d534bbdee55bd6c473f432b177",
                        "Warn: containerImage not pinned by hash: docker/centos/web2py-gevent/Dockerfile:1: pin your Docker image by updating centos:latest to centos:latest@sha256:a27fd8080b517143cbbbab9dfb7c8571c40d67d534bbdee55bd6c473f432b177",
                        "Warn: containerImage not pinned by hash: docker/centos/web2py-gunicorn/Dockerfile:1: pin your Docker image by updating centos:latest to centos:latest@sha256:a27fd8080b517143cbbbab9dfb7c8571c40d67d534bbdee55bd6c473f432b177",
                        "Warn: containerImage not pinned by hash: docker/centos/web2py-paste/Dockerfile:1: pin your Docker image by updating centos:latest to centos:latest@sha256:a27fd8080b517143cbbbab9dfb7c8571c40d67d534bbdee55bd6c473f432b177",
                        "Warn: containerImage not pinned by hash: docker/centos/web2py-rocket/Dockerfile:1: pin your Docker image by updating centos:latest to centos:latest@sha256:a27fd8080b517143cbbbab9dfb7c8571c40d67d534bbdee55bd6c473f432b177",
                        "Warn: containerImage not pinned by hash: docker/centos/web2py-tornado/Dockerfile:1: pin your Docker image by updating centos:latest to centos:latest@sha256:a27fd8080b517143cbbbab9dfb7c8571c40d67d534bbdee55bd6c473f432b177",
                        "Warn: containerImage not pinned by hash: docker/centos/web2py-twisted/Dockerfile:1: pin your Docker image by updating centos:latest to centos:latest@sha256:a27fd8080b517143cbbbab9dfb7c8571c40d67d534bbdee55bd6c473f432b177",
                        "Warn: containerImage not pinned by hash: docker/centos/web2py-waitress/Dockerfile:1: pin your Docker image by updating centos:latest to centos:latest@sha256:a27fd8080b517143cbbbab9dfb7c8571c40d67d534bbdee55bd6c473f432b177",
                        "Warn: containerImage not pinned by hash: docker/centos/web2py-wsgiref/Dockerfile:1: pin your Docker image by updating centos:latest to centos:latest@sha256:a27fd8080b517143cbbbab9dfb7c8571c40d67d534bbdee55bd6c473f432b177",
                        "Warn: containerImage not pinned by hash: docker/debian/web2py-diesel/Dockerfile:1: pin your Docker image by updating debian:latest to debian:latest@sha256:e11072c1614c08bf88b543fcfe09d75a0426d90896408e926454e88078274fcb",
                        "Warn: containerImage not pinned by hash: docker/debian/web2py-eventlet/Dockerfile:1: pin your Docker image by updating debian:latest to debian:latest@sha256:e11072c1614c08bf88b543fcfe09d75a0426d90896408e926454e88078274fcb",
                        "Warn: containerImage not pinned by hash: docker/debian/web2py-gevent/Dockerfile:1: pin your Docker image by updating debian:latest to debian:latest@sha256:e11072c1614c08bf88b543fcfe09d75a0426d90896408e926454e88078274fcb",
                        "Warn: containerImage not pinned by hash: docker/debian/web2py-gunicorn/Dockerfile:1: pin your Docker image by updating debian:latest to debian:latest@sha256:e11072c1614c08bf88b543fcfe09d75a0426d90896408e926454e88078274fcb",
                        "Warn: containerImage not pinned by hash: docker/debian/web2py-paste/Dockerfile:1: pin your Docker image by updating debian:latest to debian:latest@sha256:e11072c1614c08bf88b543fcfe09d75a0426d90896408e926454e88078274fcb",
                        "Warn: containerImage not pinned by hash: docker/debian/web2py-rocket/Dockerfile:1: pin your Docker image by updating debian:latest to debian:latest@sha256:e11072c1614c08bf88b543fcfe09d75a0426d90896408e926454e88078274fcb",
                        "Warn: containerImage not pinned by hash: docker/debian/web2py-tornado/Dockerfile:1: pin your Docker image by updating debian:latest to debian:latest@sha256:e11072c1614c08bf88b543fcfe09d75a0426d90896408e926454e88078274fcb",
                        "Warn: containerImage not pinned by hash: docker/debian/web2py-twisted/Dockerfile:1: pin your Docker image by updating debian:latest to debian:latest@sha256:e11072c1614c08bf88b543fcfe09d75a0426d90896408e926454e88078274fcb",
                        "Warn: containerImage not pinned by hash: docker/debian/web2py-waitress/Dockerfile:1: pin your Docker image by updating debian:latest to debian:latest@sha256:e11072c1614c08bf88b543fcfe09d75a0426d90896408e926454e88078274fcb",
                        "Warn: containerImage not pinned by hash: docker/debian/web2py-wsgiref/Dockerfile:1: pin your Docker image by updating debian:latest to debian:latest@sha256:e11072c1614c08bf88b543fcfe09d75a0426d90896408e926454e88078274fcb",
                        "Warn: containerImage not pinned by hash: docker/fedora/web2py-eventlet/Dockerfile:1: pin your Docker image by updating fedora:latest to fedora:latest@sha256:d0207dbb078ee261852590b9a8f1ab1f8320547be79a2f39af9f3d23db33735e",
                        "Warn: containerImage not pinned by hash: docker/fedora/web2py-gevent/Dockerfile:1: pin your Docker image by updating fedora:latest to fedora:latest@sha256:d0207dbb078ee261852590b9a8f1ab1f8320547be79a2f39af9f3d23db33735e",
                        "Warn: containerImage not pinned by hash: docker/fedora/web2py-gunicorn/Dockerfile:1: pin your Docker image by updating fedora:latest to fedora:latest@sha256:d0207dbb078ee261852590b9a8f1ab1f8320547be79a2f39af9f3d23db33735e",
                        "Warn: containerImage not pinned by hash: docker/fedora/web2py-paste/Dockerfile:1: pin your Docker image by updating fedora:latest to fedora:latest@sha256:d0207dbb078ee261852590b9a8f1ab1f8320547be79a2f39af9f3d23db33735e",
                        "Warn: containerImage not pinned by hash: docker/fedora/web2py-rocket/Dockerfile:1: pin your Docker image by updating fedora:latest to fedora:latest@sha256:d0207dbb078ee261852590b9a8f1ab1f8320547be79a2f39af9f3d23db33735e",
                        "Warn: containerImage not pinned by hash: docker/fedora/web2py-tornado/Dockerfile:1: pin your Docker image by updating fedora:latest to fedora:latest@sha256:d0207dbb078ee261852590b9a8f1ab1f8320547be79a2f39af9f3d23db33735e",
                        "Warn: containerImage not pinned by hash: docker/fedora/web2py-twisted/Dockerfile:1: pin your Docker image by updating fedora:latest to fedora:latest@sha256:d0207dbb078ee261852590b9a8f1ab1f8320547be79a2f39af9f3d23db33735e",
                        "Warn: containerImage not pinned by hash: docker/fedora/web2py-waitress/Dockerfile:1: pin your Docker image by updating fedora:latest to fedora:latest@sha256:d0207dbb078ee261852590b9a8f1ab1f8320547be79a2f39af9f3d23db33735e",
                        "Warn: containerImage not pinned by hash: docker/fedora/web2py-wsgiref/Dockerfile:1: pin your Docker image by updating fedora:latest to fedora:latest@sha256:d0207dbb078ee261852590b9a8f1ab1f8320547be79a2f39af9f3d23db33735e",
                        "Warn: containerImage not pinned by hash: docker/opensuse/web2py-eventlet/Dockerfile:1",
                        "Warn: containerImage not pinned by hash: docker/opensuse/web2py-gevent/Dockerfile:1",
                        "Warn: containerImage not pinned by hash: docker/opensuse/web2py-gunicorn/Dockerfile:1",
                        "Warn: containerImage not pinned by hash: docker/opensuse/web2py-paste/Dockerfile:1",
                        "Warn: containerImage not pinned by hash: docker/opensuse/web2py-rocket/Dockerfile:1",
                        "Warn: containerImage not pinned by hash: docker/opensuse/web2py-tornado/Dockerfile:1",
                        "Warn: containerImage not pinned by hash: docker/opensuse/web2py-twisted/Dockerfile:1",
                        "Warn: containerImage not pinned by hash: docker/opensuse/web2py-waitress/Dockerfile:1",
                        "Warn: containerImage not pinned by hash: docker/opensuse/web2py-wsgiref/Dockerfile:1",
                        "Warn: containerImage not pinned by hash: docker/python/web2py-diesel/Dockerfile:1: pin your Docker image by updating python:2.7 to python:2.7@sha256:cfa62318c459b1fde9e0841c619906d15ada5910d625176e24bf692cf8a2601d",
                        "Warn: containerImage not pinned by hash: docker/python/web2py-gevent/Dockerfile:1: pin your Docker image by updating python:2.7 to python:2.7@sha256:cfa62318c459b1fde9e0841c619906d15ada5910d625176e24bf692cf8a2601d",
                        "Warn: containerImage not pinned by hash: docker/python/web2py-gunicorn/Dockerfile:1: pin your Docker image by updating python:2.7 to python:2.7@sha256:cfa62318c459b1fde9e0841c619906d15ada5910d625176e24bf692cf8a2601d",
                        "Warn: containerImage not pinned by hash: docker/python/web2py-paste/Dockerfile:1: pin your Docker image by updating python:2.7 to python:2.7@sha256:cfa62318c459b1fde9e0841c619906d15ada5910d625176e24bf692cf8a2601d",
                        "Warn: containerImage not pinned by hash: docker/python/web2py-rocket-ssl/Dockerfile:1: pin your Docker image by updating python:2.7 to python:2.7@sha256:cfa62318c459b1fde9e0841c619906d15ada5910d625176e24bf692cf8a2601d",
                        "Warn: containerImage not pinned by hash: docker/python/web2py-rocket/Dockerfile:1: pin your Docker image by updating python:2.7 to python:2.7@sha256:cfa62318c459b1fde9e0841c619906d15ada5910d625176e24bf692cf8a2601d",
                        "Warn: containerImage not pinned by hash: docker/python/web2py-tornado/Dockerfile:1: pin your Docker image by updating python:2.7 to python:2.7@sha256:cfa62318c459b1fde9e0841c619906d15ada5910d625176e24bf692cf8a2601d",
                        "Warn: containerImage not pinned by hash: docker/python/web2py-twisted/Dockerfile:1: pin your Docker image by updating python:2.7 to python:2.7@sha256:cfa62318c459b1fde9e0841c619906d15ada5910d625176e24bf692cf8a2601d",
                        "Warn: containerImage not pinned by hash: docker/python/web2py-waitress/Dockerfile:1: pin your Docker image by updating python:2.7 to python:2.7@sha256:cfa62318c459b1fde9e0841c619906d15ada5910d625176e24bf692cf8a2601d",
                        "Warn: containerImage not pinned by hash: docker/python/web2py-wsgiref/Dockerfile:1: pin your Docker image by updating python:2.7 to python:2.7@sha256:cfa62318c459b1fde9e0841c619906d15ada5910d625176e24bf692cf8a2601d",
                        "Warn: containerImage not pinned by hash: docker/ubuntu/web2py-diesel/Dockerfile:1: pin your Docker image by updating ubuntu:latest to ubuntu:latest@sha256:99c35190e22d294cdace2783ac55effc69d32896daaa265f0bbedbcde4fbe3e5",
                        "Warn: containerImage not pinned by hash: docker/ubuntu/web2py-eventlet/Dockerfile:1: pin your Docker image by updating ubuntu:latest to ubuntu:latest@sha256:99c35190e22d294cdace2783ac55effc69d32896daaa265f0bbedbcde4fbe3e5",
                        "Warn: containerImage not pinned by hash: docker/ubuntu/web2py-gevent/Dockerfile:1: pin your Docker image by updating ubuntu:latest to ubuntu:latest@sha256:99c35190e22d294cdace2783ac55effc69d32896daaa265f0bbedbcde4fbe3e5",
                        "Warn: containerImage not pinned by hash: docker/ubuntu/web2py-gunicorn/Dockerfile:1: pin your Docker image by updating ubuntu:latest to ubuntu:latest@sha256:99c35190e22d294cdace2783ac55effc69d32896daaa265f0bbedbcde4fbe3e5",
                        "Warn: containerImage not pinned by hash: docker/ubuntu/web2py-paste/Dockerfile:1: pin your Docker image by updating ubuntu:latest to ubuntu:latest@sha256:99c35190e22d294cdace2783ac55effc69d32896daaa265f0bbedbcde4fbe3e5",
                        "Warn: containerImage not pinned by hash: docker/ubuntu/web2py-rocket/Dockerfile:1: pin your Docker image by updating ubuntu:latest to ubuntu:latest@sha256:99c35190e22d294cdace2783ac55effc69d32896daaa265f0bbedbcde4fbe3e5",
                        "Warn: containerImage not pinned by hash: docker/ubuntu/web2py-tornado/Dockerfile:1: pin your Docker image by updating ubuntu:latest to ubuntu:latest@sha256:99c35190e22d294cdace2783ac55effc69d32896daaa265f0bbedbcde4fbe3e5",
                        "Warn: containerImage not pinned by hash: docker/ubuntu/web2py-twisted/Dockerfile:1: pin your Docker image by updating ubuntu:latest to ubuntu:latest@sha256:99c35190e22d294cdace2783ac55effc69d32896daaa265f0bbedbcde4fbe3e5",
                        "Warn: containerImage not pinned by hash: docker/ubuntu/web2py-waitress/Dockerfile:1: pin your Docker image by updating ubuntu:latest to ubuntu:latest@sha256:99c35190e22d294cdace2783ac55effc69d32896daaa265f0bbedbcde4fbe3e5",
                        "Warn: containerImage not pinned by hash: docker/ubuntu/web2py-wsgiref/Dockerfile:1: pin your Docker image by updating ubuntu:latest to ubuntu:latest@sha256:99c35190e22d294cdace2783ac55effc69d32896daaa265f0bbedbcde4fbe3e5",
                        "Warn: pipCommand not pinned by hash: docker/alpine/web2py-gevent/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/alpine/web2py-gevent/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/alpine/web2py-gunicorn/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/alpine/web2py-gunicorn/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/alpine/web2py-paste/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/alpine/web2py-paste/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/alpine/web2py-rocket-ssl/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/alpine/web2py-rocket-ssl/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/alpine/web2py-rocket/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/alpine/web2py-rocket/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/alpine/web2py-tornado/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/alpine/web2py-tornado/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/alpine/web2py-waitress/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/alpine/web2py-waitress/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/alpine/web2py-wsgiref/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/alpine/web2py-wsgiref/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/centos/web2py-eventlet/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/centos/web2py-eventlet/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/centos/web2py-gevent/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/centos/web2py-gevent/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/centos/web2py-gunicorn/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/centos/web2py-gunicorn/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/centos/web2py-paste/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/centos/web2py-paste/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/centos/web2py-rocket/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/centos/web2py-rocket/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/centos/web2py-tornado/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/centos/web2py-tornado/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/centos/web2py-twisted/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/centos/web2py-twisted/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/centos/web2py-waitress/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/centos/web2py-waitress/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/centos/web2py-wsgiref/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/centos/web2py-wsgiref/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/debian/web2py-diesel/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/debian/web2py-eventlet/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/debian/web2py-gevent/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/debian/web2py-gunicorn/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/debian/web2py-paste/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/debian/web2py-rocket/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/debian/web2py-rocket/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/debian/web2py-tornado/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/debian/web2py-twisted/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/debian/web2py-waitress/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/debian/web2py-wsgiref/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/fedora/web2py-eventlet/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/fedora/web2py-eventlet/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/fedora/web2py-gevent/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/fedora/web2py-gevent/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/fedora/web2py-gunicorn/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/fedora/web2py-gunicorn/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/fedora/web2py-paste/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/fedora/web2py-paste/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/fedora/web2py-rocket/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/fedora/web2py-rocket/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/fedora/web2py-tornado/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/fedora/web2py-tornado/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/fedora/web2py-twisted/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/fedora/web2py-twisted/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/fedora/web2py-waitress/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/fedora/web2py-waitress/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/fedora/web2py-wsgiref/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/fedora/web2py-wsgiref/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/opensuse/web2py-eventlet/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/opensuse/web2py-eventlet/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/opensuse/web2py-gevent/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/opensuse/web2py-gevent/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/opensuse/web2py-gunicorn/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/opensuse/web2py-gunicorn/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/opensuse/web2py-paste/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/opensuse/web2py-paste/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/opensuse/web2py-rocket/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/opensuse/web2py-rocket/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/opensuse/web2py-tornado/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/opensuse/web2py-tornado/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/opensuse/web2py-twisted/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/opensuse/web2py-twisted/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/opensuse/web2py-waitress/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/opensuse/web2py-waitress/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/opensuse/web2py-wsgiref/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/opensuse/web2py-wsgiref/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/python/web2py-diesel/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/python/web2py-diesel/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/python/web2py-gevent/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/python/web2py-gevent/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/python/web2py-gunicorn/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/python/web2py-gunicorn/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/python/web2py-paste/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/python/web2py-paste/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/python/web2py-tornado/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/python/web2py-tornado/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/python/web2py-twisted/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/python/web2py-twisted/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/python/web2py-waitress/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/python/web2py-waitress/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/python/web2py-wsgiref/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/python/web2py-wsgiref/Dockerfile:5-8",
                        "Warn: pipCommand not pinned by hash: docker/ubuntu/web2py-diesel/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/ubuntu/web2py-eventlet/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/ubuntu/web2py-gevent/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/ubuntu/web2py-gunicorn/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/ubuntu/web2py-paste/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/ubuntu/web2py-rocket/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/ubuntu/web2py-tornado/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/ubuntu/web2py-twisted/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/ubuntu/web2py-waitress/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: docker/ubuntu/web2py-wsgiref/Dockerfile:5-7",
                        "Warn: pipCommand not pinned by hash: scripts/setup-web2py-cloudfoundry.sh:4",
                        "Warn: pipCommand not pinned by hash: scripts/setup-web2py-heroku.sh:2",
                        "Warn: pipCommand not pinned by hash: scripts/setup-web2py-heroku.sh:5",
                        "Warn: pipCommand not pinned by hash: scripts/setup-web2py-nginx-uwsgi-centos7.sh:63",
                        "Warn: pipCommand not pinned by hash: scripts/setup-web2py-nginx-uwsgi-centos8.sh:90",
                        "Warn: pipCommand not pinned by hash: scripts/setup-web2py-nginx-uwsgi-opensuse.sh:13",
                        "Warn: pipCommand not pinned by hash: scripts/setup-web2py-nginx-uwsgi-ubuntu-focal.sh:33",
                        "Warn: pipCommand not pinned by hash: scripts/setup-web2py-nginx-uwsgi-ubuntu.sh:32",
                        "Info:   0 out of 115 pipCommand dependencies pinned",
                        "Info:   0 out of  65 containerImage dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 6 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Warn: no linked content found",
                        "Warn: One or no descriptive hints of disclosure, vulnerability, and/or timelines in security policy",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 3,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "No tokens found",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/web2py/web2py/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Reporting a Vulnerability\n\nPlease report security issues to <email>\n",
        "project_all_labels": [
            "bug",
            "DAL",
            "docs",
            "enhancement",
            "imported",
            "in progress",
            "Priority-Critical",
            "Priority-High",
            "Priority-Low",
            "Priority-Medium",
            "tests"
        ],
        "README_content": "## Readme\n\nweb2py is a free open source full-stack framework for rapid development of fast, scalable, secure and portable database-driven web-based applications.\n\nIt is written and programmable in Python. LGPLv3 License\n\nLearn more at http://web2py.com\n\n## Google App Engine deployment\n\n    cp examples/app.yaml ./\n    cp handlers/gaehandler.py ./\n\nThen edit ./app.yaml and replace \"yourappname\" with yourappname.\n\n## Important reminder about this GIT repo\n\nAn important part of web2py is the Database Abstraction Layer (DAL). In early 2015 this was decoupled into a separate code-base ([PyDAL](https://github.com/web2py/pydal)). In terms of git, it is a sub-module of the main repository.\n\nThe use of a sub-module requires a one-time use of the --recursive flag for git clone if you are cloning web2py from scratch.\n\n    git clone --recursive https://github.com/web2py/web2py.git\n\nIf you have an existing repository, the commands below need to be executed at least once:\n\n    git submodule update --init --recursive\n\nPyDAL uses a separate stable release cycle to the rest of web2py. PyDAL releases will use a date-naming scheme similar to Ubuntu. Issues related to PyDAL should be reported to its separate repository.\n\n\n## Documentation (readthedocs.org)\n\n[![Docs Status](https://readthedocs.org/projects/web2py/badge/?version=latest&style=flat-square)](http://web2py.rtfd.org/)\n\n## Tests\n\n[![Build Status](https://img.shields.io/travis/web2py/web2py/master.svg?style=flat-square&label=Travis-CI)](https://app.travis-ci.com/github/web2py/web2py)\n[![MS Build Status](https://img.shields.io/appveyor/ci/web2py/web2py/master.svg?style=flat-square&label=Appveyor-CI)](https://ci.appveyor.com/project/web2py/web2py)\n[![Coverage Status](https://img.shields.io/codecov/c/github/web2py/web2py.svg?style=flat-square)](https://codecov.io/github/web2py/web2py)\n\n\n## Installation Instructions\n\nTo start web2py there is NO NEED to install it. Just unzip and do:\n\n    python web2py.py\n\nThat's it!!!\n\n## web2py directory structure\n\n    project/\n        README\n        LICENSE\n        VERSION                    > this web2py version\n        web2py.py                  > the startup script\n        anyserver.py               > to run with third party servers\n        ...                        > other handlers and example files\n        gluon/                     > the core libraries\n            packages/              > web2py submodules\n              dal/\n            contrib/               > third party libraries\n            tests/                 > unittests\n        applications/              > are the apps\n            admin/                 > web based IDE\n                ...\n            examples/              > examples, docs, links\n                ...\n            welcome/               > the scaffolding app (they all copy it)\n                ABOUT\n                LICENSE\n                models/\n                views/\n                controllers/\n                sessions/\n                errors/\n                cache/\n                static/\n                uploads/\n                modules/\n                cron/\n                tests/\n            ...                    > your own apps\n        examples/                  > example config files, mv .. and customize\n        extras/                    > other files which are required for building web2py\n        scripts/                   > utility and installation scripts\n        handlers/\n            wsgihandler.py         > handler to connect to WSGI\n            ...                    > handlers for Fast-CGI, SCGI, Gevent, etc\n        site-packages/             > additional optional modules\n        logs/                      > log files will go in there\n        deposit/                   > a place where web2py stores apps temporarily\n\n## Issues?\n\nReport issues at https://github.com/web2py/web2py/issues\n",
        "num_commits": 8304,
        "project_age_days": 5835,
        "project_created_at": "2008-11-07",
        "latest_updated_at": "2024-10-28",
        "latest_pushed_at": "2024-10-28",
        "num_contributors": 192,
        "num_pull": 1434,
        "num_issues": 2496,
        "num_opening_issue": 382,
        "project_size(kB)": 43162,
        "num_stargazers": 2117,
        "num_watchers": 2117,
        "num_forks": 907,
        "num_subscribers": 223,
        "SecurityPolicy_created_at": "2021-10-26 17:21:34",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "40292d6b17d92585bbf15854c2421d3fd7c013f6",
                "url": "https://github.com/web2py/web2py/commit/40292d6b17d92585bbf15854c2421d3fd7c013f6",
                "date": "2021-11-10 16:09:15"
            },
            {
                "commit_id": "87bce4e1eb1a9ad50e391f8ed93cb37ccd1258d1",
                "url": "https://github.com/web2py/web2py/commit/87bce4e1eb1a9ad50e391f8ed93cb37ccd1258d1",
                "date": "2021-10-26 17:21:34"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "not_mentioned",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "weblateorg/weblate",
        "project_url": "https://github.com/weblateorg/weblate",
        "SSF": {
            "date": "2024-10-29T23:53:32+07:00",
            "repo": {
                "name": "github.com/weblateorg/weblate",
                "commit": "6def83484690dcf0a6791b4ca56c6b7fbe1d6788"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.4,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: branch 'main' does not require approvers",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Info: status check found to merge onto on branch 'main'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "14 out of 14 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 4,
                    "reason": "Found 7/17 approved changesets -- score normalized to 4",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: Hamakor contributor org/company found, freelance contributor org/company found, grupo de amigos de gnu/linux de pontevedra - galpon contributor org/company found, WeblateOrg contributor org/company found, unknown-horizons contributor org/company found, sdaps contributor org/company found, spiral-project contributor org/company found, CaptainFact contributor org/company found, code-charity contributor org/company found, ddterm contributor org/company found, GnuCash-Pocket contributor org/company found, gammu contributor org/company found, translate contributor org/company found, python-social-auth contributor org/company found, weblateorg contributor org/company found, phpmyadmin contributor org/company found, another agency contributor org/company found, dataprev contributor org/company found, FossifyOrg contributor org/company found, osmandapp contributor org/company found, Pext contributor org/company found, ifntuog contributor org/company found, freeplane contributor org/company found, osmno contributor org/company found, open source contributor org/company found, s.p. timoshenko institute of mechanics contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 26 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no workflows found",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: :0"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: COPYING:0",
                        "Info: FSF or OSI recognized license: GNU General Public License v3.0: COPYING:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 24 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: containerImage not pinned by hash: dev-docker/weblate-dev/Dockerfile:5: pin your Docker image by updating weblate/weblate:bleeding to weblate/weblate:bleeding@sha256:6a6f9a0ad7ff20434fb5b28fe55c0beab64f66f5df8a487d7b9f1640bb6e5ca4",
                        "Info:   0 out of   1 containerImage dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: all commits (27) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact weblate-5.8.1 not signed: https://api.github.com/repos/WeblateOrg/weblate/releases/179955802",
                        "Warn: release artifact weblate-5.8 not signed: https://api.github.com/repos/WeblateOrg/weblate/releases/179948863",
                        "Warn: release artifact weblate-5.7.2 not signed: https://api.github.com/repos/WeblateOrg/weblate/releases/173604801",
                        "Warn: release artifact weblate-5.7.1 not signed: https://api.github.com/repos/WeblateOrg/weblate/releases/172798174",
                        "Warn: release artifact weblate-5.7 not signed: https://api.github.com/repos/WeblateOrg/weblate/releases/170323571",
                        "Warn: release artifact weblate-5.8.1 does not have provenance: https://api.github.com/repos/WeblateOrg/weblate/releases/179955802",
                        "Warn: release artifact weblate-5.8 does not have provenance: https://api.github.com/repos/WeblateOrg/weblate/releases/179948863",
                        "Warn: release artifact weblate-5.7.2 does not have provenance: https://api.github.com/repos/WeblateOrg/weblate/releases/173604801",
                        "Warn: release artifact weblate-5.7.1 does not have provenance: https://api.github.com/repos/WeblateOrg/weblate/releases/172798174",
                        "Warn: release artifact weblate-5.7 does not have provenance: https://api.github.com/repos/WeblateOrg/weblate/releases/170323571"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "No tokens found",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/weblateorg/weblate/contents/SECURITY.md",
        "SecurityPolicy_content": "<!--\nCopyright  Michal iha <michal@weblate.org>\n\nSPDX-License-Identifier: CC0-1.0\n\nThis file is maintained in https://github.com/WeblateOrg/meta/\n-->\n\n# Weblate security\n\nThe Weblate team takes security and related transparency very seriously.\nWe welcome any peer review of our 100% open-source code to ensure nobody's Weblate\nis ever compromised or hacked.\n\nInformation about practices for reporting and fixing security issues is described\nin [our documentation][1] and on [our page at HackerOne][2]. This ensures all\nvulnerabilities are solved securely, quickly, and transparently.\n\n[1]: https://docs.weblate.org/en/latest/contributing/issues.html#security\n[2]: https://hackerone.com/weblate\n",
        "project_all_labels": [
            "automerge",
            "backlog",
            "bug",
            "dependencies",
            "documentation",
            "duplicate",
            "enhancement",
            "good first issue",
            "hacktoberfest",
            "help wanted",
            "hosted",
            "invalid",
            "naming",
            "needinfo",
            "question",
            "translate-toolkit",
            "undecided",
            "ux",
            "wontfix"
        ],
        "README_content": ".. image:: https://s.weblate.org/cdn/Logo-Darktext-borders.png\n   :alt: Weblate\n   :target: https://weblate.org/\n   :height: 80px\n\n**Weblate is libre software web-based continuous localization system,\nused by over 2500 libre projects and companies in more than 165 countries.**\n\nInstall it, or use the Hosted Weblate service at `weblate.org`_.\n\n.. image:: https://img.shields.io/badge/website-weblate.org-blue.svg\n    :alt: Website\n    :target: https://weblate.org/\n\n.. image:: https://hosted.weblate.org/widget/weblate/svg-badge.svg\n    :alt: Translation status\n    :target: https://hosted.weblate.org/engage/weblate/\n\n.. image:: https://www.bestpractices.dev/projects/552/badge\n    :alt: CII Best Practices\n    :target: https://www.bestpractices.dev/en/projects/552\n\n.. image:: https://api.reuse.software/badge/github.com/WeblateOrg/weblate\n    :alt: REUSE status\n    :target: https://api.reuse.software/info/github.com/WeblateOrg/weblate\n\n.. image:: https://img.shields.io/pypi/v/weblate.svg\n    :target: https://pypi.org/project/Weblate/\n\n.. image:: https://readthedocs.org/projects/weblate/badge/\n    :target: https://docs.weblate.org/\n\n.. image:: https://img.shields.io/github/license/WeblateOrg/weblate.svg\n    :alt: License\n    :target: https://github.com/WeblateOrg/weblate/blob/main/COPYING\n\nSupport\n-------\n\nWeblate is libre software with optional professional support and cloud\nhosting offerings. Check out https://weblate.org/hosting/ for more information.\n\nDocumentation\n-------------\n\nTo be found in the ``docs`` directory of the source code, or\nviewed online on https://docs.weblate.org/\n\nInstallation\n------------\n\nSetup instructions:\n\nhttps://docs.weblate.org/en/latest/admin/install.html\n\nBugs\n----\n\nPlease report feature requests and problems to:\n\nhttps://github.com/WeblateOrg/weblate/issues\n\n\nLive chat\n---------\n\nLive chat about Weblate is available at `Libera.Chat <https://libera.chat/>`_ IRC network. The channel name is ``#weblate``. This can be accessed by, for example, https://web.libera.chat/#weblate or an IRC client installed on your computer.\n\nStats\n-----\n\n.. image:: https://repobeats.axiom.co/api/embed/e0cfcc1b19f13f78669d3a93ca26b59974faaa22.svg\n   :alt: Repobeats analytics image\n\nLicense\n-------\n\nCopyright  Michal iha michal@weblate.org\n\nThis program is free software: you can redistribute it and/or modify it under\nthe terms of the GNU General Public License as published by the Free Software\nFoundation, either version 3 of the License, or (at your option) any later\nversion.\n\nThis program is distributed in the hope that it will be useful, but WITHOUT ANY\nWARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A\nPARTICULAR PURPOSE. See the `GNU General Public License\n<https://www.gnu.org/licenses/gpl-3.0.html>`_ for more details.\n\n.. _weblate.org: https://weblate.org/\n",
        "num_commits": 68192,
        "project_age_days": 4628,
        "project_created_at": "2012-02-27",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-30",
        "num_contributors": 313,
        "num_pull": 6611,
        "num_issues": 12045,
        "num_opening_issue": 442,
        "project_size(kB)": 3080414,
        "num_stargazers": 4582,
        "num_watchers": 4582,
        "num_forks": 1016,
        "num_subscribers": 96,
        "SecurityPolicy_created_at": "2017-03-21 12:42:39",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "ef935d31d8b1646217a46bb1d854065cb8b12c0f",
                "url": "https://github.com/WeblateOrg/weblate/commit/ef935d31d8b1646217a46bb1d854065cb8b12c0f",
                "date": "2023-07-14 12:57:44"
            },
            {
                "commit_id": "42104e330142b796952e3b4e6b55e4d077bfac13",
                "url": "https://github.com/WeblateOrg/weblate/commit/42104e330142b796952e3b4e6b55e4d077bfac13",
                "date": "2023-01-10 10:25:30"
            },
            {
                "commit_id": "2d008391e3718c6c168414d1421dbdaf4d908421",
                "url": "https://github.com/WeblateOrg/weblate/commit/2d008391e3718c6c168414d1421dbdaf4d908421",
                "date": "2023-01-10 08:50:17"
            },
            {
                "commit_id": "43c27c73cd5dcb1ec69bae8c820ee748b0032d74",
                "url": "https://github.com/WeblateOrg/weblate/commit/43c27c73cd5dcb1ec69bae8c820ee748b0032d74",
                "date": "2020-10-21 07:51:18"
            },
            {
                "commit_id": "1a1851ad59a2eb4b95124fc0d2ecd0605ac12a0b",
                "url": "https://github.com/WeblateOrg/weblate/commit/1a1851ad59a2eb4b95124fc0d2ecd0605ac12a0b",
                "date": "2020-09-14 11:49:12"
            },
            {
                "commit_id": "582f2bc0e8ce497b47756db2f76a1faa155f44b1",
                "url": "https://github.com/WeblateOrg/weblate/commit/582f2bc0e8ce497b47756db2f76a1faa155f44b1",
                "date": "2017-04-24 08:42:42"
            },
            {
                "commit_id": "0c26554b94bfcbe04152b2bebd2f957f95b4c03a",
                "url": "https://github.com/WeblateOrg/weblate/commit/0c26554b94bfcbe04152b2bebd2f957f95b4c03a",
                "date": "2017-03-21 12:42:39"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": false
    },
    {
        "project_name": "dask/distributed",
        "project_url": "https://github.com/dask/distributed",
        "SSF": {
            "date": "2024-10-29T23:37:32+07:00",
            "repo": {
                "name": "github.com/dask/distributed",
                "commit": "29530909fecedeead25b98198ed3ab28d185f6cc"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.2,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'main'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 9,
                    "reason": "27 out of 28 merged PRs checked by a CI test -- score normalized to 9",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 7,
                    "reason": "Found 21/27 approved changesets -- score normalized to 7",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: python-compilers-workshop contributor org/company found, arrayfire contributor org/company found, dask contributor org/company found, element84 contributor org/company found, pypy contributor org/company found, pycondor contributor org/company found, pandas-dev contributor org/company found, data-engineering-collective contributor org/company found, holoviz contributor org/company found, light-field-microscopy contributor org/company found, hackforla contributor org/company found, hits contributor org/company found, anaconda contributor org/company found, JuliaControl contributor org/company found, Parietal-INRIA contributor org/company found, SHTOOLS contributor org/company found, visionworkbench contributor org/company found, twisted contributor org/company found, logpy contributor org/company found, TU-Berlin-DIMA contributor org/company found, geopandas contributor org/company found, nvidia contributor org/company found, intake contributor org/company found, ProjectPythia contributor org/company found, overholser contributor org/company found, scisprints contributor org/company found, asnible contributor org/company found, apache contributor org/company found, ibis-project contributor org/company found, aspp-apac contributor org/company found, geodynamics contributor org/company found, google contributor org/company found, drdoctr contributor org/company found, conda-tools contributor org/company found, zarr-developers contributor org/company found, jazzband contributor org/company found, Element84 contributor org/company found, jupyterlab contributor org/company found, willowsierra contributor org/company found, googlers contributor org/company found, pydata contributor org/company found, DudLab contributor org/company found, python contributor org/company found, canvg contributor org/company found, jupyterhub contributor org/company found, UofTCoders contributor org/company found, sympy contributor org/company found, pyFFTW contributor org/company found, noetic as contributor org/company found, conda-forge contributor org/company found, conda-incubator contributor org/company found, sqlalchemy-redshift contributor org/company found, paris-swc contributor org/company found, voltron data contributor org/company found, pytoolz contributor org/company found, stac-utils contributor org/company found, jean-zay-users contributor org/company found, obspy contributor org/company found, pyviz contributor org/company found, azavea contributor org/company found, asv-runner contributor org/company found, nanshe-org contributor org/company found, rapidsai contributor org/company found, looking for work contributor org/company found, i-for-change @catley-lakeman contributor org/company found, EmoryUniversityTheoreticalBiophysics contributor org/company found, madison-python contributor org/company found, cupy contributor org/company found, blaze contributor org/company found, opsdroid contributor org/company found, mesonbuild contributor org/company found, ilastik contributor org/company found, kr8s-org contributor org/company found, hex-inc contributor org/company found, SeismicData contributor org/company found, barbagroup contributor org/company found, encode contributor org/company found, knime-ip contributor org/company found, sphinx-gallery contributor org/company found, dask-contrib contributor org/company found, llvm contributor org/company found, matplotlib contributor org/company found, mara contributor org/company found, jupyter contributor org/company found, pytest-dev contributor org/company found, python-trio contributor org/company found, pangeo-forge contributor org/company found, open-source engineer @probabl-ai contributor org/company found, hydepark contributor org/company found, WIPACrepo contributor org/company found, data-apis contributor org/company found, stactools-packages contributor org/company found, PyDataAnnArbor contributor org/company found, UTCompSeismo contributor org/company found, coiled contributor org/company found, numpy contributor org/company found, cagov contributor org/company found, numfocus contributor org/company found, SciTools contributor org/company found, mypaint contributor org/company found, pangeo-data contributor org/company found, InsightSoftwareConsortium contributor org/company found, PyCQA contributor org/company found, NVIDIA contributor org/company found, NVIDIA-Genomics-Research contributor org/company found, pydy contributor org/company found, cphvb contributor org/company found, fsspec contributor org/company found, cloudpipe contributor org/company found, GoogleCloudPlatform contributor org/company found, scikit-learn contributor org/company found, didcot-data contributor org/company found, nationalparkservice contributor org/company found, joblib contributor org/company found, python-streamz contributor org/company found, substrait-io contributor org/company found, conda contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 117 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.txt:0",
                        "Info: FSF or OSI recognized license: BSD 3-Clause \"New\" or \"Revised\" License: LICENSE.txt:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 16 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-pre-commit.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/ci-pre-commit.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-pre-commit.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/ci-pre-commit.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci-pre-commit.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/ci-pre-commit.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/conda.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/conda.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/conda.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/conda.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/label-all.yml:11: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/label-all.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-test-results.yaml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/publish-test-results.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-drafter.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/release-drafter.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-drafter.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/release-drafter.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-publish.yml:23: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/release-publish.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test-report.yaml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/test-report.yaml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test-report.yaml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/test-report.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test-report.yaml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/test-report.yaml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test-report.yaml:56: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/test-report.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yaml:121: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/tests.yaml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yaml:126: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/tests.yaml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yaml:138: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/tests.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yaml:156: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/tests.yaml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yaml:286: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/tests.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yaml:297: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/tests.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yaml:307: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/tests.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yaml:321: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/tests.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/update-gpuci.yaml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/update-gpuci.yaml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/update-gpuci.yaml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/update-gpuci.yaml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/update-gpuci.yaml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/update-gpuci.yaml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/update-gpuci.yaml:32: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/update-gpuci.yaml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/update-gpuci.yaml:49: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/update-gpuci.yaml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/update-gpuci.yaml:57: update your workflow using https://app.stepsecurity.io/secureworkflow/dask/distributed/update-gpuci.yaml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: continuous_integration/gpuci/build.sh:44",
                        "Warn: pipCommand not pinned by hash: continuous_integration/gpuci/build.sh:47",
                        "Info:   0 out of  12 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of  16 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   2 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 28 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/dask/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/dask/.github/SECURITY.md:1",
                        "Warn: One or no descriptive hints of disclosure, vulnerability, and/or timelines in security policy",
                        "Info: Found text in security policy: github.com/dask/.github/SECURITY.md:1"
                    ],
                    "score": 9,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: jobLevel 'checks' permission set to 'write': .github/workflows/publish-test-results.yaml:20",
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/release-drafter.yml:16",
                        "Info: jobLevel 'pull-requests' permission set to 'read': .github/workflows/release-drafter.yml:17",
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/release-publish.yml:16",
                        "Info: jobLevel 'pull-requests' permission set to 'read': .github/workflows/release-publish.yml:17",
                        "Warn: no topLevel permission defined: .github/workflows/ci-pre-commit.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/conda.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/label-all.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish-test-results.yaml:1",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/release-drafter.yml:9",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/release-publish.yml:9",
                        "Warn: no topLevel permission defined: .github/workflows/test-report.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/tests.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/update-gpuci.yaml:1"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/dask/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "To report a security vulnerability to Dask, please go to https://tidelift.com/security and follow the instructions there.\n",
        "project_all_labels": [
            "adaptive",
            "asyncio",
            "bug",
            "config",
            "core",
            "dashboard",
            "deadlock",
            "dependencies",
            "deprecation",
            "diagnostics",
            "discussion",
            "do not merge",
            "documentation",
            "enhancement",
            "feature",
            "flaky test",
            "good expert issue",
            "good first issue",
            "good second issue",
            "gpu",
            "help wanted",
            "hygiene",
            "io",
            "memory",
            "needs attention",
            "needs info",
            "needs reproducer",
            "needs review",
            "needs triage",
            "networking",
            "p1",
            "p2",
            "p3",
            "packaging",
            "performance",
            "regression",
            "scheduler",
            "scheduling",
            "shuffle",
            "skip-caching",
            "stability",
            "stealing",
            "tests"
        ],
        "README_content": "Distributed\n===========\n\n|Test Status| |Longitudinal Report (full)| |Longitudinal Report (short)| |Coverage| |Doc Status| |Discourse| |Version Status| |NumFOCUS|\n\nA library for distributed computation.  See documentation_ for more details.\n\n.. _documentation: https://distributed.dask.org\n.. |Test Status| image:: https://github.com/dask/distributed/workflows/Tests/badge.svg?branch=main\n   :target: https://github.com/dask/distributed/actions?query=workflow%3ATests+branch%3Amain\n.. |Longitudinal Report (full)| image:: https://github.com/dask/distributed/workflows/Test%20Report/badge.svg?branch=main\n   :target: https://dask.github.io/distributed/test_report.html\n   :alt: Longitudinal test report (full version)\n.. |Longitudinal Report (short)| image:: https://github.com/dask/distributed/workflows/Test%20Report/badge.svg?branch=main\n   :target: https://dask.github.io/distributed/test_short_report.html\n   :alt: Longitudinal test report (short version)\n.. |Coverage| image:: https://codecov.io/gh/dask/distributed/branch/main/graph/badge.svg\n   :target: https://codecov.io/gh/dask/distributed/branch/main\n   :alt: Coverage status\n.. |Doc Status| image:: https://readthedocs.org/projects/distributed/badge/?version=latest\n   :target: https://distributed.dask.org\n   :alt: Documentation Status\n.. |Discourse| image:: https://img.shields.io/discourse/users?logo=discourse&server=https%3A%2F%2Fdask.discourse.group\n   :alt: Discuss Dask-related things and ask for help\n   :target: https://dask.discourse.group\n.. |Version Status| image:: https://img.shields.io/pypi/v/distributed.svg\n   :target: https://pypi.python.org/pypi/distributed/\n.. |NumFOCUS| image:: https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A\n   :target: https://www.numfocus.org/\n",
        "num_commits": 5918,
        "project_age_days": 3334,
        "project_created_at": "2015-09-13",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 305,
        "num_pull": 5177,
        "num_issues": 8812,
        "num_opening_issue": 1570,
        "project_size(kB)": 273824,
        "num_stargazers": 1576,
        "num_watchers": 1576,
        "num_forks": 719,
        "num_subscribers": 57,
        "SecurityPolicy_created_at": "2020-08-26 13:42:16",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "fc97b65a6481fff2f11ac8eca09e0180b2b0ed25",
                "url": "https://github.com/dask/.github/commit/fc97b65a6481fff2f11ac8eca09e0180b2b0ed25",
                "date": "2020-08-26 13:42:16"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": false
    },
    {
        "project_name": "archivy/archivy",
        "project_url": "https://github.com/archivy/archivy",
        "SSF": {
            "date": "2024-10-30T00:24:51+07:00",
            "repo": {
                "name": "github.com/archivy/archivy",
                "commit": "bdcdd39ac6cf9f7b3709b984d8be2f0fa898139e"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 3.9,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'master'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "0 out of 5 merged PRs checked by a CI test -- score normalized to 0",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 1/30 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: sugarlabs contributor org/company found, fossasia contributor org/company found, guiscrcpy contributor org/company found, archivy contributor org/company found, sugarlabs-infra contributor org/company found, sugarlabs-appstore contributor org/company found, sugaroidbot contributor org/company found, lugvitc contributor org/company found, magicproduct contributor org/company found, publiclab contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 10 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: :0"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "0 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 0",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/build-docker-on-push-master.yml:13"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/black.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/archivy/archivy/black.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/black.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/archivy/archivy/black.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build-docker-on-push-master.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/archivy/archivy/build-docker-on-push-master.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build-docker-on-push-master.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/archivy/archivy/build-docker-on-push-master.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build-docker-on-release.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/archivy/archivy/build-docker-on-release.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build-docker-on-release.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/archivy/archivy/build-docker-on-release.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build-docker-specific-version.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/archivy/archivy/build-docker-specific-version.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build-docker-specific-version.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/archivy/archivy/build-docker-specific-version.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codecov.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/archivy/archivy/codecov.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codecov.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/archivy/archivy/codecov.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/codecov.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/archivy/archivy/codecov.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/deploy-docs.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/archivy/archivy/deploy-docs.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/deploy-docs.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/archivy/archivy/deploy-docs.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/deploy-docs.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/archivy/archivy/deploy-docs.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi-auto-deploy.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/archivy/archivy/pypi-auto-deploy.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi-auto-deploy.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/archivy/archivy/pypi-auto-deploy.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pypi-auto-deploy.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/archivy/archivy/pypi-auto-deploy.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pypi-auto-deploy.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/archivy/archivy/pypi-auto-deploy.yml/master?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/black.yml:32",
                        "Warn: pipCommand not pinned by hash: .github/workflows/black.yml:33",
                        "Warn: pipCommand not pinned by hash: .github/workflows/black.yml:34",
                        "Warn: pipCommand not pinned by hash: .github/workflows/black.yml:37",
                        "Warn: pipCommand not pinned by hash: .github/workflows/codecov.yml:35",
                        "Warn: pipCommand not pinned by hash: .github/workflows/codecov.yml:36",
                        "Warn: pipCommand not pinned by hash: .github/workflows/codecov.yml:37",
                        "Warn: pipCommand not pinned by hash: .github/workflows/deploy-docs.yml:22",
                        "Warn: pipCommand not pinned by hash: .github/workflows/deploy-docs.yml:25",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pypi-auto-deploy.yml:20",
                        "Info:   0 out of  12 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   6 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of  10 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 5 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Warn: One or no descriptive hints of disclosure, vulnerability, and/or timelines in security policy",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 9,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact v1.7.4 not signed: https://api.github.com/repos/archivy/archivy/releases/89260182",
                        "Warn: release artifact v1.7.3 not signed: https://api.github.com/repos/archivy/archivy/releases/65511687",
                        "Warn: release artifact v1.7.2 not signed: https://api.github.com/repos/archivy/archivy/releases/61406059",
                        "Warn: release artifact v1.7.1 not signed: https://api.github.com/repos/archivy/archivy/releases/60534817",
                        "Warn: release artifact v1.7.0 not signed: https://api.github.com/repos/archivy/archivy/releases/58236739",
                        "Warn: release artifact v1.7.4 does not have provenance: https://api.github.com/repos/archivy/archivy/releases/89260182",
                        "Warn: release artifact v1.7.3 does not have provenance: https://api.github.com/repos/archivy/archivy/releases/65511687",
                        "Warn: release artifact v1.7.2 does not have provenance: https://api.github.com/repos/archivy/archivy/releases/61406059",
                        "Warn: release artifact v1.7.1 does not have provenance: https://api.github.com/repos/archivy/archivy/releases/60534817",
                        "Warn: release artifact v1.7.0 does not have provenance: https://api.github.com/repos/archivy/archivy/releases/58236739"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/black.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build-docker-on-push-master.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build-docker-on-release.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/build-docker-specific-version.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/codecov.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/deploy-docs.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/pypi-auto-deploy.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-h5c8-rqwp-cp95",
                        "Warn: Project is vulnerable to: GHSA-h75v-3vvj-5mfj",
                        "Warn: Project is vulnerable to: GHSA-9wx4-h78v-vm56",
                        "Warn: Project is vulnerable to: GHSA-j8r2-6x86-q33q / PYSEC-2023-74",
                        "Warn: Project is vulnerable to: GHSA-2g68-c3qc-8985",
                        "Warn: Project is vulnerable to: GHSA-f9vj-2wh5-fj8j",
                        "Warn: Project is vulnerable to: GHSA-hrfv-mqp8-q5rw / PYSEC-2023-221",
                        "Warn: Project is vulnerable to: GHSA-q34m-jh98-gwm2"
                    ],
                    "score": 2,
                    "reason": "8 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/archivy/archivy/contents/SECURITY.md",
        "SecurityPolicy_content": "If you think you've found a security issue in Archivy, please contact halcyon@disroot.org before disclosing anything publicly.\n",
        "project_all_labels": [
            "bug",
            "dependencies",
            "design",
            "documentation",
            "duplicate",
            "enhancement",
            "good first issue",
            "hacktoberfest",
            "help wanted",
            "high-priority",
            "invalid",
            "question",
            "wontfix"
        ],
        "README_content": "![logo](docs/img/logo.png)\n\n# Archivy\n\nArchivy is a self-hostable knowledge repository that allows you to learn and retain information in your own personal and extensible wiki.\n\nFeatures:\n\n- If you add bookmarks, their web-pages contents' will be saved to ensure that you will **always** have access to it, following the idea of [digital preservation](https://jeffhuang.com/designed_to_last/). Archivy is also easily integrated with other services and your online accounts.\n- Knowledge base organization with bidirectional links between notes, and embedded tags.\n- Everything is a file! For ease of access and editing, all the content is stored in extended markdown files with yaml front matter. This format supports footnotes, LaTeX math rendering, syntax highlighting and more. \n- Extensible plugin system and API for power users to take control of their knowledge process\n- [syncing options](https://github.com/archivy/archivy-git)\n- Powerful and advanced search. \n- Image upload\n\n\n[demo video](https://www.uzpg.me/assets/images/archivy.mov)\n\n[Roadmap](https://github.com/archivy/archivy/issues/74#issuecomment-764828063)\n\nUpcoming:\n\n- Annotations\n- Multi User System with permission setup.\n\n## Quickstart\n\n\nInstall archivy with `pip install archivy`. Other installations methods are listed [here](https://archivy.github.io/install), including Docker.\n\nRun the `archivy init` command to setup you installation.\n\nThen run this and enter a password to create a new user:\n\n```bash\n$ archivy create-admin <username>\n```\n\nFinally, execute `archivy run` to serve the app. You can open it at https://localhost:5000 and login with the credentials you entered before.\n\nYou can then use archivy to create notes, bookmarks and then organize and store information.\n\nSee the [official docs](https://archivy.github.io) for information on other installation methods.\n\n## Community\n\nArchivy is dedicated to building **open and quality knowledge base software** through collaboration and community discussion.\n\nTo get news and updates on Archivy and its development, you can [watch the archivy repository](https://github.com/archivy/archivy) or follow [@uzpg_ on Twitter](https://twitter.com/uzpg_).\n\nYou can interact with us through the [issue board](https://github.com/archivy/archivy/issues) and the more casual [discord server](https://discord.gg/uQsqyxB).\n\nNote: If you're interested in the applications of AI to knowledge management, we're also working on this with [Espial](https://github.com/Uzay-G/espial).\n",
        "num_commits": 561,
        "project_age_days": 1608,
        "project_created_at": "2020-06-04",
        "latest_updated_at": "2024-10-21",
        "latest_pushed_at": "2023-07-25",
        "num_contributors": 23,
        "num_pull": 157,
        "num_issues": 309,
        "num_opening_issue": 43,
        "project_size(kB)": 1212,
        "num_stargazers": 3208,
        "num_watchers": 3208,
        "num_forks": 114,
        "num_subscribers": 49,
        "SecurityPolicy_created_at": "2021-12-23 09:49:30",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "ea353cd20a2892149ecdda3bb86a32e0974ba098",
                "url": "https://github.com/archivy/archivy/commit/ea353cd20a2892149ecdda3bb86a32e0974ba098",
                "date": "2021-12-23 09:49:30"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": false
    },
    {
        "project_name": "jquery/jquery",
        "project_url": "https://github.com/jquery/jquery",
        "SSF": {
            "date": "2024-10-29T20:20:34+07:00",
            "repo": {
                "name": "github.com/jquery/jquery",
                "commit": "19716254877870ecd649272cadd00a0d0ff8be01"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 8.0,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: required approving review count is 1 on branch 'main'",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Info: status check found to merge onto on branch 'main'",
                        "Info: PRs are required in order to make changes on branch 'main'"
                    ],
                    "score": 8,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "25 out of 25 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 9,
                    "reason": "Found 19/21 approved changesets -- score normalized to 9",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: jshint contributor org/company found, rubyftw contributor org/company found, apps4good contributor org/company found, avajs contributor org/company found, khan contributor org/company found, eslint contributor org/company found, jscs-dev contributor org/company found, getbpm contributor org/company found, w3c contributor org/company found, Agoric contributor org/company found, bocoup contributor org/company found, lyonjs contributor org/company found, xojs contributor org/company found, emberjs-addons contributor org/company found, components contributor org/company found, starbeamjs contributor org/company found, rubinius contributor org/company found, quickcue contributor org/company found, snowflake jquery contributor org/company found, rails contributor org/company found, nemikor-solutions contributor org/company found, Khan contributor org/company found, gruntjs contributor org/company found, theintern contributor org/company found, bpm contributor org/company found, wikimedia contributor org/company found, chalk contributor org/company found, pylon contributor org/company found, https://www.innovalabs.fr contributor org/company found, feedback-assistant contributor org/company found, ot-crew contributor org/company found, freshcodes contributor org/company found, dojo contributor org/company found, trac-hacks contributor org/company found, guard contributor org/company found, w3ctag contributor org/company found, h5bp contributor org/company found, jquery @spokestack contributor org/company found, alohaeditor contributor org/company found, blazing-edge-labs contributor org/company found, bower contributor org/company found, saskjavascript contributor org/company found, agoric contributor org/company found, spokestack contributor org/company found, tokaido contributor org/company found, whatwg contributor org/company found, planview contributor org/company found, concordancejs contributor org/company found, jquery contributor org/company found, carlhuda contributor org/company found, angular contributor org/company found, scummvm contributor org/company found, TypeStrong contributor org/company found, yeoman contributor org/company found, cst contributor org/company found, wikimedia foundation contributor org/company found, aspect-build contributor org/company found, dept contributor org/company found, node-task contributor org/company found, jsbin contributor org/company found, yarnpkg contributor org/company found, editorconfig contributor org/company found, tastejs contributor org/company found, awesome-lists contributor org/company found, erikhuda contributor org/company found, tildeio contributor org/company found, purple scout ab contributor org/company found, istanbuljs contributor org/company found, yargs contributor org/company found, us center for medicare and medicaid contributor org/company found, danger contributor org/company found, emberjs contributor org/company found, bamf-health contributor org/company found, babel contributor org/company found, refined-github contributor org/company found, qunitjs contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 76 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.txt:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE.txt:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "18 commit(s) and 16 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: npmCommand not pinned by hash: .github/workflows/browserstack.yml:56",
                        "Warn: npmCommand not pinned by hash: .github/workflows/filestash.yml:39",
                        "Warn: npmCommand not pinned by hash: .github/workflows/node.js.yml:82",
                        "Warn: npmCommand not pinned by hash: .github/workflows/node.js.yml:142",
                        "Info:  23 out of  23 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   3 out of   7 npmCommand dependencies pinned"
                    ],
                    "score": 8,
                    "reason": "dependency not pinned by hash detected -- score normalized to 8",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: all commits (28) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql-analysis.yml:16",
                        "Warn: no topLevel permission defined: .github/workflows/browserstack-dispatch.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/browserstack.yml:1",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/codeql-analysis.yml:11",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/filestash.yml:9",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/node.js.yml:9",
                        "Warn: no topLevel permission defined: .github/workflows/verify-release.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/jquery/jquery/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nThe [latest released version](https://github.com/jquery/jquery/releases) of jQuery is supported.\n\n## Reporting a Vulnerability\n\nPlease email security@jquery.com, and we will respond as quickly as possible.\n\nIf the vulnerability is considered valid and accepted, a patch will be made for the latest jQuery version.\nIf the vulnerability is deemed invalid, no further action is required.\n",
        "project_all_labels": [
            "1.x-only",
            "2.x-only",
            "3.x-only",
            "4.x-only",
            "Ajax",
            "Attributes",
            "Awaiting Sizzle Update",
            "Behavior Change",
            "Blocker",
            "Bug",
            "Build",
            "Callbacks",
            "CLA: Error",
            "CLA: Valid",
            "Core",
            "CSS",
            "Data",
            "Deferred",
            "dependencies",
            "Deprecated",
            "Dimensions",
            "Discuss in Meeting",
            "Discussion",
            "Docs",
            "duplicate",
            "Effects",
            "Event",
            "Feature",
            "github_actions",
            "Has Pull Request",
            "help wanted",
            "javascript",
            "Manipulation",
            "Needs info",
            "Needs review",
            "Offset",
            "Patch Welcome",
            "Release",
            "Selector",
            "Serialize",
            "Support",
            "Tests",
            "Traversing",
            "Web Standards",
            "wontfix",
            "Works For Me",
            "Wrap"
        ],
        "README_content": "# [jQuery](https://jquery.com/)  New Wave JavaScript\n\nMeetings are currently held on the [matrix.org platform](https://matrix.to/#/#jquery_meeting:gitter.im).\n\nMeeting minutes can be found at [meetings.jquery.org](https://meetings.jquery.org/category/core/).\n\nThe latest version of jQuery is available at [https://jquery.com/download/](https://jquery.com/download/).\n\n## Version support\n\n| Version | Branch     | Status   |\n| ------- | ---------- | -------- |\n| 4.x     | main       | Beta     |\n| 3.x     | 3.x-stable | Active   |\n| 2.x     | 2.x-stable | Inactive |\n| 1.x     | 1.x-stable | Inactive |\n\nOnce 4.0.0 final is released, the 3.x branch will continue to receive updates for a limited time. The 2.x and 1.x branches are no longer supported.\n\nCommercial support for inactive versions is available from [HeroDevs](https://herodevs.com/nes).\n\nLearn more about our [version support](https://jquery.com/support/).\n\n## Contribution Guides\n\nIn the spirit of open source software development, jQuery always encourages community code contribution. To help you get started and before you jump into writing code, be sure to read these important contribution guidelines thoroughly:\n\n1. [Getting Involved](https://contribute.jquery.org/)\n2. [Core Style Guide](https://contribute.jquery.org/style-guide/js/)\n3. [Writing Code for jQuery Projects](https://contribute.jquery.org/code/)\n\n### References to issues/PRs\n\nGitHub issues/PRs are usually referenced via `gh-NUMBER`, where `NUMBER` is the numerical ID of the issue/PR. You can find such an issue/PR under `https://github.com/jquery/jquery/issues/NUMBER`.\n\njQuery has used a different bug tracker - based on Trac - in the past, available under [bugs.jquery.com](https://bugs.jquery.com/). It is being kept in read only mode so that referring to past discussions is possible. When jQuery source references one of those issues, it uses the pattern `trac-NUMBER`, where `NUMBER` is the numerical ID of the issue. You can find such an issue under `https://bugs.jquery.com/ticket/NUMBER`.\n\n## Environments in which to use jQuery\n\n- [Browser support](https://jquery.com/browser-support/)\n- jQuery also supports Node, browser extensions, and other non-browser environments.\n\n## What you need to build your own jQuery\n\nTo build jQuery, you need to have the latest Node.js/npm and git 1.7 or later. Earlier versions might work, but are not supported.\n\nFor Windows, you have to download and install [git](https://git-scm.com/downloads) and [Node.js](https://nodejs.org/en/download/).\n\nmacOS users should install [Homebrew](https://brew.sh/). Once Homebrew is installed, run `brew install git` to install git,\nand `brew install node` to install Node.js.\n\nLinux/BSD users should use their appropriate package managers to install git and Node.js, or build from source\nif you swing that way. Easy-peasy.\n\n## How to build your own jQuery\n\nFirst, [clone the jQuery git repo](https://help.github.com/en/github/creating-cloning-and-archiving-repositories/cloning-a-repository).\n\nThen, enter the jquery directory, install dependencies, and run the build script:\n\n```bash\ncd jquery\nnpm install\nnpm run build\n```\n\nThe built version of jQuery will be placed in the `dist/` directory, along with a minified copy and associated map file.\n\n## Build all jQuery release files\n\nTo build all variants of jQuery, run the following command:\n\n```bash\nnpm run build:all\n```\n\nThis will create all of the variants that jQuery includes in a release, including `jquery.js`, `jquery.slim.js`, `jquery.module.js`, and `jquery.slim.module.js` along their associated minified files and sourcemaps.\n\n`jquery.module.js` and `jquery.slim.module.js` are [ECMAScript modules](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Modules) that export `jQuery` and `$` as named exports are placed in the `dist-module/` directory rather than the `dist/` directory.\n\n## Building a Custom jQuery\n\nThe build script can be used to create a custom version of jQuery that includes only the modules you need.\n\nAny module may be excluded except for `core`. When excluding `selector`, it is not removed but replaced with a small wrapper around native `querySelectorAll` (see below for more information).\n\n### Build Script Help\n\nTo see the full list of available options for the build script, run the following:\n\n```bash\nnpm run build -- --help\n```\n\n### Modules\n\nTo exclude a module, pass its path relative to the `src` folder (without the `.js` extension) to the `--exclude` option. When using the `--include` option, the default includes are dropped and a build is created with only those modules.\n\nSome example modules that can be excluded or included are:\n\n- **ajax**: All AJAX functionality: `$.ajax()`, `$.get()`, `$.post()`, `$.ajaxSetup()`, `.load()`, transports, and ajax event shorthands such as `.ajaxStart()`.\n- **ajax/xhr**: The XMLHTTPRequest AJAX transport only.\n- **ajax/script**: The `<script>` AJAX transport only; used to retrieve scripts.\n- **ajax/jsonp**: The JSONP AJAX transport only; depends on the ajax/script transport.\n- **css**: The `.css()` method. Also removes **all** modules depending on css (including **effects**, **dimensions**, and **offset**).\n- **css/showHide**: Non-animated `.show()`, `.hide()` and `.toggle()`; can be excluded if you use classes or explicit `.css()` calls to set the `display` property. Also removes the **effects** module.\n- **deprecated**: Methods documented as deprecated but not yet removed.\n- **dimensions**: The `.width()` and `.height()` methods, including `inner-` and `outer-` variations.\n- **effects**: The `.animate()` method and its shorthands such as `.slideUp()` or `.hide(\"slow\")`.\n- **event**: The `.on()` and `.off()` methods and all event functionality.\n- **event/trigger**: The `.trigger()` and `.triggerHandler()` methods.\n- **offset**: The `.offset()`, `.position()`, `.offsetParent()`, `.scrollLeft()`, and `.scrollTop()` methods.\n- **wrap**: The `.wrap()`, `.wrapAll()`, `.wrapInner()`, and `.unwrap()` methods.\n- **core/ready**: Exclude the ready module if you place your scripts at the end of the body. Any ready callbacks bound with `jQuery()` will simply be called immediately. However, `jQuery(document).ready()` will not be a function and `.on(\"ready\", ...)` or similar will not be triggered.\n- **deferred**: Exclude jQuery.Deferred. This also excludes all modules that rely on Deferred, including **ajax**, **effects**, and **queue**, but replaces **core/ready** with **core/ready-no-deferred**.\n- **exports/global**: Exclude the attachment of global jQuery variables ($ and jQuery) to the window.\n- **exports/amd**: Exclude the AMD definition.\n\n- **selector**: The full jQuery selector engine. When this module is excluded, it is replaced with a rudimentary selector engine based on the browser's `querySelectorAll` method that does not support jQuery selector extensions or enhanced semantics. See the [selector-native.js](https://github.com/jquery/jquery/blob/main/src/selector-native.js) file for details.\n\n*Note*: Excluding the full `selector` module will also exclude all jQuery selector extensions (such as `effects/animatedSelector` and `css/hiddenVisibleSelectors`).\n\n##### AMD name\n\nYou can set the module name for jQuery's AMD definition. By default, it is set to \"jquery\", which plays nicely with plugins and third-party libraries, but there may be cases where you'd like to change this. Pass it to the `--amd` parameter:\n\n```bash\nnpm run build -- --amd=\"custom-name\"\n```\n\nOr, to define anonymously, leave the name blank.\n\n```bash\nnpm run build -- --amd\n```\n\n##### File name and directory\n\nThe default name for the built jQuery file is `jquery.js`; it is placed under the `dist/` directory. It's possible to change the file name using `--filename` and the directory using `--dir`. `--dir` is relative to the project root.\n\n```bash\nnpm run build -- --slim --filename=\"jquery.slim.js\" --dir=\"/tmp\"\n```\n\nThis would create a slim version of jQuery and place it under `tmp/jquery.slim.js`.\n\n##### ECMAScript Module (ESM) mode\n\nBy default, jQuery generates a regular script JavaScript file. You can also generate an ECMAScript module exporting `jQuery` as the default export using the `--esm` parameter:\n\n```bash\nnpm run build -- --filename=jquery.module.js --esm\n```\n\n##### Factory mode\n\nBy default, jQuery depends on a global `window`. For environments that don't have one, you can generate a factory build that exposes a function accepting `window` as a parameter that you can provide externally (see [`README` of the published package](build/fixtures/README.md) for usage instructions). You can generate such a factory using the `--factory` parameter:\n\n```bash\nnpm run build -- --filename=jquery.factory.js --factory\n```\n\nThis option can be mixed with others like `--esm` or `--slim`:\n\n```bash\nnpm run build -- --filename=jquery.factory.slim.module.js --factory --esm --slim --dir=\"/dist-module\"\n```\n\n#### Custom Build Examples\n\nCreate a custom build using `npm run build`, listing the modules to be excluded. Excluding a top-level module also excludes its corresponding directory of modules.\n\nExclude all **ajax** functionality:\n\n```bash\nnpm run build -- --exclude=ajax\n```\n\nExcluding **css** removes modules depending on CSS: **effects**, **offset**, **dimensions**.\n\n```bash\nnpm run build -- --exclude=css\n```\n\nExclude a bunch of modules (`-e` is an alias for `--exclude`):\n\n```bash\nnpm run build -- -e ajax/jsonp -e css -e deprecated -e dimensions -e effects -e offset -e wrap\n```\n\nThere is a special alias to generate a build with the same configuration as the official jQuery Slim build:\n\n```bash\nnpm run build -- --filename=jquery.slim.js --slim\n```\n\nOr, to create the slim build as an esm module:\n\n```bash\nnpm run build -- --filename=jquery.slim.module.js --slim --esm\n```\n\n*Non-official custom builds are not regularly tested. Use them at your own risk.*\n\n## Running the Unit Tests\n\nMake sure you have the necessary dependencies:\n\n```bash\nnpm install\n```\n\nStart `npm start` to auto-build jQuery as you work:\n\n```bash\nnpm start\n```\n\nRun the unit tests with a local server that supports PHP. Ensure that you run the site from the root directory, not the \"test\" directory. No database is required. Pre-configured php local servers are available for Windows and Mac. Here are some options:\n\n- Windows: [WAMP download](https://www.wampserver.com/en/)\n- Mac: [MAMP download](https://www.mamp.info/en/downloads/)\n- Linux: [Setting up LAMP](https://www.linux.com/training-tutorials/easy-lamp-server-installation/)\n- [Mongoose (most platforms)](https://code.google.com/p/mongoose/)\n\n## Essential Git\n\nAs the source code is handled by the Git version control system, it's useful to know some features used.\n\n### Cleaning\n\nIf you want to purge your working directory back to the status of upstream, the following commands can be used (remember everything you've worked on is gone after these):\n\n```bash\ngit reset --hard upstream/main\ngit clean -fdx\n```\n\n### Rebasing\n\nFor feature/topic branches, you should always use the `--rebase` flag to `git pull`, or if you are usually handling many temporary \"to be in a github pull request\" branches, run the following to automate this:\n\n```bash\ngit config branch.autosetuprebase local\n```\n\n(see `man git-config` for more information)\n\n### Handling merge conflicts\n\nIf you're getting merge conflicts when merging, instead of editing the conflicted files manually, you can use the feature\n`git mergetool`. Even though the default tool `xxdiff` looks awful/old, it's rather useful.\n\nThe following are some commands that can be used there:\n\n- `Ctrl + Alt + M` - automerge as much as possible\n- `b` - jump to next merge conflict\n- `s` - change the order of the conflicted lines\n- `u` - undo a merge\n- `left mouse button` - mark a block to be the winner\n- `middle mouse button` - mark a line to be the winner\n- `Ctrl + S` - save\n- `Ctrl + Q` - quit\n\n## [QUnit](https://api.qunitjs.com) Reference\n\n### Test methods\n\n```js\nexpect( numAssertions );\nstop();\nstart();\n```\n\n*Note*: QUnit's eventual addition of an argument to stop/start is ignored in this test suite so that start and stop can be passed as callbacks without worrying about their parameters.\n\n### Test assertions\n\n```js\nok( value, [message] );\nequal( actual, expected, [message] );\nnotEqual( actual, expected, [message] );\ndeepEqual( actual, expected, [message] );\nnotDeepEqual( actual, expected, [message] );\nstrictEqual( actual, expected, [message] );\nnotStrictEqual( actual, expected, [message] );\nthrows( block, [expected], [message] );\n```\n\n## Test Suite Convenience Methods Reference\n\nSee [test/data/testinit.js](https://github.com/jquery/jquery/blob/main/test/data/testinit.js).\n\n### Returns an array of elements with the given IDs\n\n```js\nq( ... );\n```\n\nExample:\n\n```js\nq( \"main\", \"foo\", \"bar\" );\n\n=> [ div#main, span#foo, input#bar ]\n```\n\n### Asserts that a selection matches the given IDs\n\n```js\nt( testName, selector, [ \"array\", \"of\", \"ids\" ] );\n```\n\nExample:\n\n```js\nt(\"Check for something\", \"//[a]\", [\"foo\", \"bar\"]);\n```\n\n### Fires a native DOM event without going through jQuery\n\n```js\nfireNative( node, eventType );\n```\n\nExample:\n\n```js\nfireNative( jQuery( \"#elem\" )[ 0 ], \"click\" );\n```\n\n### Add random number to url to stop caching\n\n```js\nurl( \"some/url\" );\n```\n\nExample:\n\n```js\nurl( \"index.html\" );\n\n=> \"data/index.html?10538358428943\"\n\n\nurl( \"mock.php?foo=bar\" );\n\n=> \"data/mock.php?foo=bar&10538358345554\"\n```\n\n### Run tests in an iframe\n\nSome tests may require a document other than the standard test fixture, and\nthese can be run in a separate iframe. The actual test code and assertions\nremain in jQuery's main test files; only the minimal test fixture markup\nand setup code should be placed in the iframe file.\n\n```js\ntestIframe( testName, fileName,\n  function testCallback(\n      assert, jQuery, window, document,\n\t  [ additional args ] ) {\n\t...\n  } );\n```\n\nThis loads a page, constructing a url with fileName `\"./data/\" + fileName`.\nThe iframed page determines when the callback occurs in the test by\nincluding the \"/test/data/iframeTest.js\" script and calling\n`startIframeTest( [ additional args ] )` when appropriate. Often this\nwill be after either document ready or `window.onload` fires.\n\nThe `testCallback` receives the QUnit `assert` object created by `testIframe`\nfor this test, followed by the global `jQuery`, `window`, and `document` from\nthe iframe. If the iframe code passes any arguments to `startIframeTest`,\nthey follow the `document` argument.\n\n## Questions?\n\nIf you have any questions, please feel free to ask on the\n[Developing jQuery Core forum](https://forum.jquery.com/developing-jquery-core) or in #jquery on [libera](https://web.libera.chat/).\n",
        "num_commits": 6736,
        "project_age_days": 5688,
        "project_created_at": "2009-04-03",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-21",
        "num_contributors": 294,
        "num_pull": 3045,
        "num_issues": 5383,
        "num_opening_issue": 93,
        "project_size(kB)": 34436,
        "num_stargazers": 59212,
        "num_watchers": 59212,
        "num_forks": 20589,
        "num_subscribers": 3170,
        "SecurityPolicy_created_at": "2020-05-12 18:33:45",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "2ffe54ca53b4ba2de2012f83c3faf262c1003af9",
                "url": "https://github.com/jquery/jquery/commit/2ffe54ca53b4ba2de2012f83c3faf262c1003af9",
                "date": "2020-05-12 18:33:45"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "facebookresearch/parlai",
        "project_url": "https://github.com/facebookresearch/parlai",
        "SSF": {
            "date": "2024-10-30T00:09:42+07:00",
            "repo": {
                "name": "github.com/facebookresearch/parlai",
                "commit": "6c802418e93a51cbb746b011439ab783dd136de8"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.1,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: required approving review count is 1 on branch 'main'",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Warn: no status checks found to merge onto branch 'main'",
                        "Info: PRs are required in order to make changes on branch 'main'"
                    ],
                    "score": 6,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 2,
                    "reason": "7 out of 30 merged PRs checked by a CI test -- score normalized to 2",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: ml-mipt contributor org/company found, venue contributor org/company found, meta platforms contributor org/company found, klaviyo contributor org/company found, DeepLearningCourse contributor org/company found, facebookresearch contributor org/company found, facebook ai research contributor org/company found, nabla contributor org/company found, fairinternal @facebookresearch contributor org/company found, mitnlp contributor org/company found, global strategic solutions contributor org/company found, meta contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 12 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: :0"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": [
                        "Warn: Repository is archived."
                    ],
                    "score": 0,
                    "reason": "project is archived",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:129: update your workflow using https://app.stepsecurity.io/secureworkflow/facebookresearch/ParlAI/lint.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/lint.yml:156: update your workflow using https://app.stepsecurity.io/secureworkflow/facebookresearch/ParlAI/lint.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/facebookresearch/ParlAI/lint.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/facebookresearch/ParlAI/lint.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/lint.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/facebookresearch/ParlAI/lint.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/facebookresearch/ParlAI/lint.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:26: update your workflow using https://app.stepsecurity.io/secureworkflow/facebookresearch/ParlAI/lint.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/lint.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/facebookresearch/ParlAI/lint.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:65: update your workflow using https://app.stepsecurity.io/secureworkflow/facebookresearch/ParlAI/lint.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:70: update your workflow using https://app.stepsecurity.io/secureworkflow/facebookresearch/ParlAI/lint.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:92: update your workflow using https://app.stepsecurity.io/secureworkflow/facebookresearch/ParlAI/lint.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/lint.yml:113: update your workflow using https://app.stepsecurity.io/secureworkflow/facebookresearch/ParlAI/lint.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/stale.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/facebookresearch/ParlAI/stale.yml/main?enable=pin",
                        "Warn: containerImage not pinned by hash: Dockerfile:4: pin your Docker image by updating nvidia/cuda:11.1.1-cudnn8-devel-ubuntu18.04 to nvidia/cuda:11.1.1-cudnn8-devel-ubuntu18.04@sha256:1f181384de58303eb71b70854033fa0774a3212ac6824ad07859c96f91e98fac",
                        "Warn: pipCommand not pinned by hash: Dockerfile:18",
                        "Warn: pipCommand not pinned by hash: Dockerfile:29-31",
                        "Warn: npmCommand not pinned by hash: parlai/crowdsourcing/tasks/dialcrowd/config.sh:8",
                        "Warn: npmCommand not pinned by hash: parlai/crowdsourcing/tasks/dialcrowd/configquality.sh:8",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint.yml:40",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint.yml:99",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint.yml:100",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint.yml:101",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint.yml:102",
                        "Warn: npmCommand not pinned by hash: .github/workflows/lint.yml:146",
                        "Warn: npmCommand not pinned by hash: .github/workflows/lint.yml:147",
                        "Info:   0 out of   9 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   4 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   7 pipCommand dependencies pinned",
                        "Info:   0 out of   4 npmCommand dependencies pinned",
                        "Info:   0 out of   1 containerImage dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/facebookresearch/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/facebookresearch/.github/SECURITY.md:1",
                        "Warn: One or no descriptive hints of disclosure, vulnerability, and/or timelines in security policy",
                        "Info: Found text in security policy: github.com/facebookresearch/.github/SECURITY.md:1"
                    ],
                    "score": 9,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/lint.yml:1",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/stale.yml:7",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-wf5p-g6vw-rhxx",
                        "Warn: Project is vulnerable to: GHSA-vc8w-jr9v-vj7f",
                        "Warn: Project is vulnerable to: GHSA-grv7-fg5c-xmjg",
                        "Warn: Project is vulnerable to: GHSA-jchw-25xp-jwwc",
                        "Warn: Project is vulnerable to: GHSA-cxjh-pqwp-8mfp",
                        "Warn: Project is vulnerable to: GHSA-c2qf-rxjj-qqgw",
                        "Warn: Project is vulnerable to: GHSA-4vvj-4cpr-p986",
                        "Warn: Project is vulnerable to: GHSA-2mqj-m65w-jghx / PYSEC-2024-4",
                        "Warn: Project is vulnerable to: GHSA-29gw-9793-fvw7",
                        "Warn: Project is vulnerable to: GHSA-h5c8-rqwp-cp95",
                        "Warn: Project is vulnerable to: GHSA-h75v-3vvj-5mfj",
                        "Warn: Project is vulnerable to: GHSA-3xr8-qfvj-9p9j",
                        "Warn: Project is vulnerable to: GHSA-46cm-pfwv-cgf8",
                        "Warn: Project is vulnerable to: GHSA-7ggm-4rjg-594w",
                        "Warn: Project is vulnerable to: GHSA-8j42-pcfm-3467",
                        "Warn: Project is vulnerable to: GHSA-g26j-5385-hhw3",
                        "Warn: Project is vulnerable to: GHSA-gppg-gqw8-wh9g",
                        "Warn: Project is vulnerable to: GHSA-h6m6-jj8v-94jj",
                        "Warn: Project is vulnerable to: GHSA-qqcv-vg9f-5rr3",
                        "Warn: Project is vulnerable to: GHSA-cgvx-9447-vcch",
                        "Warn: Project is vulnerable to: GHSA-3f63-hfp8-52jq",
                        "Warn: Project is vulnerable to: GHSA-44wm-f244-xhp3",
                        "Warn: Project is vulnerable to: GHSA-5pcm-hx3q-hm94",
                        "Warn: Project is vulnerable to: GHSA-pg7h-5qx3-wjr3",
                        "Warn: Project is vulnerable to: GHSA-753j-mpmx-qq6g",
                        "Warn: Project is vulnerable to: GHSA-qppv-j76h-2rpx",
                        "Warn: Project is vulnerable to: GHSA-w235-7p84-xx57",
                        "Warn: Project is vulnerable to: GHSA-g7vv-2v7x-gj9p"
                    ],
                    "score": 0,
                    "reason": "28 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/facebookresearch/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "# Reporting and Fixing Security Issues\n\nPlease do not open GitHub issues or pull requests - this makes the problem immediately visible to everyone, including malicious actors. Security issues in this open source project can be safely reported via the Meta Bug Bounty program:\n\nhttps://www.facebook.com/whitehat\n\nMeta's security team will triage your report and determine whether or not is it eligible for a bounty under our program.\n",
        "project_all_labels": [
            "Agents",
            "bb3",
            "Bug",
            "CLA Signed",
            "Code Quality",
            "CS5152",
            "dependencies",
            "Docs",
            "donotreap",
            "Enhancement",
            "Grand",
            "H1 2020",
            "H2 2020",
            "Help Wanted",
            "javascript",
            "Large",
            "low-pri",
            "Medium",
            "Metrics",
            "Minor",
            "MTurk",
            "never-stale",
            "P0",
            "P1",
            "P2",
            "P3",
            "python",
            "RFC",
            "Small",
            "stale",
            "stale-issue",
            "stale-pr",
            "Tests",
            "windows"
        ],
        "README_content": "<p align=\"center\">\n <img width=\"70%\" src=\"docs/source/\\_static/img/parlai.png\" />\n</p>\n\n<p align=\"center\">\n   <a href=\"https://github.com/facebookresearch/ParlAI/blob/main/LICENSE\">\n    <img src=\"https://img.shields.io/badge/license-MIT-blue.svg\" alt=\"CircleCI\" />\n  </a>\n   <a href=\"https://pypi.org/project/parlai/\">\n    <img src=\"https://img.shields.io/pypi/v/parlai?color=blue&label=release\" alt=\"CircleCI\" />\n  </a>\n    <a href=\"https://circleci.com/gh/facebookresearch/ParlAI/tree/main\">\n    <img src=\"https://img.shields.io/circleci/build/github/facebookresearch/ParlAI/main\" alt=\"Coverage\" />\n  </a>\n    <a href=\"https://codecov.io/gh/facebookresearch/ParlAI\">\n    <img src=\"https://img.shields.io/codecov/c/github/facebookresearch/ParlAI\" alt=\"GitHub contributors\" />\n  </a>\n    <a href=\"https://img.shields.io/github/contributors/facebookresearch/ParlAI\">\n    <img src=\"https://img.shields.io/github/contributors/facebookresearch/ParlAI\"/>\n  </a>\n    <a href=\"https://twitter.com/parlai_parley\">\n    <img src=\"https://img.shields.io/twitter/follow/parlai_parley?label=Twitter&style=social\" alt=\"Twitter\" />\n  </a>\n </p>\n\n-------------------------------------------------------------------------------------------------------------------------------------------------------\n\n[ParlAI](http://parl.ai) (pronounced par-lay) is a python framework for\nsharing, training and testing dialogue models, from open-domain chitchat, to\ntask-oriented dialogue, to visual question answering.\n\nIts goal is to provide researchers:\n\n- **100+ popular datasets available all in one place, with the same API**, among them [PersonaChat](https://arxiv.org/abs/1801.07243), [DailyDialog](https://arxiv.org/abs/1710.03957), [Wizard of Wikipedia](https://openreview.net/forum?id=r1l73iRqKm), [Empathetic Dialogues](https://arxiv.org/abs/1811.00207), [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/), [MS MARCO](http://www.msmarco.org/), [QuAC](https://www.aclweb.org/anthology/D18-1241), [HotpotQA](https://hotpotqa.github.io/), [QACNN & QADailyMail](https://arxiv.org/abs/1506.03340), [CBT](https://arxiv.org/abs/1511.02301), [BookTest](https://arxiv.org/abs/1610.00956), [bAbI Dialogue tasks](https://arxiv.org/abs/1605.07683), [Ubuntu Dialogue](https://arxiv.org/abs/1506.08909), [OpenSubtitles](http://opus.lingfil.uu.se/OpenSubtitles.php),  [Image Chat](https://arxiv.org/abs/1811.00945), [VQA](http://visualqa.org/), [VisDial](https://arxiv.org/abs/1611.08669) and [CLEVR](http://cs.stanford.edu/people/jcjohns/clevr/). See the complete list [here](https://github.com/facebookresearch/ParlAI/blob/main/parlai/tasks/task_list.py).\n- a wide set of [**reference models**](https://parl.ai/docs/agents_list.html) -- from retrieval baselines to Transformers.\n- a large [zoo of **pretrained models**](https://parl.ai/docs/zoo.html) ready to use off-the-shelf\n- seamless **integration of [Amazon Mechanical Turk](https://www.mturk.com/mturk/welcome)** for data collection and human evaluation\n- **integration with [Facebook Messenger](https://parl.ai/docs/tutorial_chat_service.html)** to connect agents with humans in a chat interface\n- a large range of **helpers to create your own agents** and train on several tasks with **multitasking**\n- **multimodality**, some tasks use text and images\n\n\nParlAI is described in the following paper:\n[ParlAI: A Dialog Research Software Platform\", arXiv:1705.06476](https://arxiv.org/abs/1705.06476)\nor see these [more up-to-date slides](https://drive.google.com/file/d/1JfUW4AVrjSp8X8Fp0_rTTRoLxUfW0aUm/view?usp=sharing).\n\nFollow us on [Twitter](https://twitter.com/parlai_parley) and check out our [Release\nnotes](https://github.com/facebookresearch/ParlAI/releases) to see the latest\ninformation about new features & updates, and the website\n[http://parl.ai](http://parl.ai) for further docs. For an archived list of updates,\ncheck out [NEWS.md](https://github.com/facebookresearch/ParlAI/blob/main/NEWS.md).\n\n<p align=\"center\"><img width=\"90%\" src=\"https://raw.githubusercontent.com/facebookresearch/ParlAI/main/docs/source/_static/img/parlai_example.png\" /></p>\n\n## Interactive Tutorial\n\nFor those who want to start with ParlAI now, you can try our [Colab Tutorial](https://colab.research.google.com/drive/1bRMvN0lGXaTF5fuTidgvlAl-Lb41F7AD#scrollTo=KtVz5dCUmFkN).\n\n## Installing ParlAI\n\n### Operating System\n\nParlAI should work as inteded under Linux or macOS. We do not support Windows at this time, but many users [report success on Windows using Python 3.8](https://github.com/facebookresearch/ParlAI/issues/3989) and issues with Python 3.9. We are happy to accept patches that improve Windows support.\n\n### Python Interpreter\n\nParlAI currently requires Python3.8+.\n\n### Requirements\n\nParlAI supports [Pytorch](https://pytorch.org) 1.6 or higher.\nAll requirements of the core modules are listed in [`requirements.txt`](https://github.com/facebookresearch/ParlAI/blob/main/requirements.txt). However, some models included (in [`parlai/agents`](https://github.com/facebookresearch/ParlAI/tree/main/parlai/agents)) have additional requirements.\n\n## Virtual Environment\n\nWe *strongly* recommend you install ParlAI in a virtual environment using [venv](https://docs.python.org/3/library/venv.html) or [conda](https://www.anaconda.com/).\n\n### End User Installation\n\nIf you want to use ParlAI without modifications, you can install it with:\n\n```bash\ncd /path/to/your/parlai-app\npython3.8 -m venv venv\nvenv/bin/pip install --upgrade pip setuptools wheel\nvenv/bin/pip install parlai\n```\n\n### Developer Installation\n\nMany users will want to modify some parts of ParlAI. To set up a development\nenvironment, run the following commands to clone the repository and install\nParlAI:\n\n```bash\ngit clone https://github.com/facebookresearch/ParlAI.git ~/ParlAI\ncd ~/ParlAI\npython3.8 -m venv venv\nvenv/bin/pip install --upgrade pip setuptools wheel\nvenv/bin/python setup.py develop\n```\n\n> **Note**\n> Sometimes the install from source maynot work due to dependencies (specially in PyTorch related packaged).\n> In that case try building a fresh conda environment and running the similar to the following:\n> `conda install pytorch==2.0.0 torchvision torchaudio torchtext pytorch-cuda=11.8 -c pytorch -c nvidia`.\n> Check torch setup documentation for your CUDA and OS versions.\n\nAll needed data will be downloaded to `~/ParlAI/data`. If you need to clear out\nthe space used by these files, you can safely delete these directories and any\nfiles needed will be downloaded again.\n\n## Documentation\n\n - [Quick Start](https://parl.ai/docs/tutorial_quick.html)\n - [Basics: world, agents, teachers, action and observations](https://parl.ai/docs/tutorial_basic.html)\n - [Creating a new dataset/task](http://parl.ai/docs/tutorial_task.html)\n - [List of available tasks/datasets](https://parl.ai/docs/tasks.html)\n - [Creating a seq2seq agent](https://parl.ai/docs/tutorial_torch_generator_agent.html)\n - [List of available agents](https://parl.ai/docs/agents_list.html)\n - [Model zoo (list pretrained models)](https://parl.ai/docs/zoo.html)\n - [Running crowdsourcing tasks](http://parl.ai/docs/tutorial_crowdsourcing.html)\n - [Plug into Facebook Messenger](https://parl.ai/docs/tutorial_chat_service.html)\n\n\n## Examples\n\nA large set of scripts can be found in [`parlai/scripts`](https://github.com/facebookresearch/ParlAI/tree/main/parlai/scripts). Here are a few of them.\nNote: If any of these examples fail, check the [installation section](#installing-parlai) to see if you have missed something.\n\nDisplay 10 random examples from the SQuAD task\n```bash\nparlai display_data -t squad\n```\n\nEvaluate an IR baseline model on the validation set of the Personachat task:\n```bash\nparlai eval_model -m ir_baseline -t personachat -dt valid\n```\n\nTrain a single layer transformer on PersonaChat (requires pytorch and torchtext).\nDetail: embedding size 300, 4 attention heads,  2 epochs using batchsize 64, word vectors are initialized with fasttext and the other elements of the batch are used as negative during training.\n```bash\nparlai train_model -t personachat -m transformer/ranker -mf /tmp/model_tr6 --n-layers 1 --embedding-size 300 --ffn-size 600 --n-heads 4 --num-epochs 2 -veps 0.25 -bs 64 -lr 0.001 --dropout 0.1 --embedding-type fasttext_cc --candidates batch\n```\n\n## Code Organization\n\nThe code is set up into several main directories:\n\n- [**core**](https://github.com/facebookresearch/ParlAI/tree/main/parlai/core): contains the primary code for the framework\n- [**agents**](https://github.com/facebookresearch/ParlAI/tree/main/parlai/agents): contains agents which can interact with the different tasks (e.g. machine learning models)\n- [**scripts**](https://github.com/facebookresearch/ParlAI/tree/main/parlai/scripts): contains a number of useful scripts, like training, evaluating, interactive chatting, ...\n- [**tasks**](https://github.com/facebookresearch/ParlAI/tree/main/parlai/tasks): contains code for the different tasks available from within ParlAI\n- [**mturk**](https://github.com/facebookresearch/ParlAI/tree/main/parlai/mturk): contains code for setting up Mechanical Turk, as well as sample MTurk tasks\n- [**messenger**](https://github.com/facebookresearch/ParlAI/tree/main/parlai/chat_service/services/messenger): contains code for interfacing with Facebook Messenger\n- [**utils**](https://github.com/facebookresearch/ParlAI/tree/main/parlai/utils): contains a wide number of frequently used utility methods\n- [**crowdsourcing**](https://github.com/facebookresearch/ParlAI/tree/main/parlai/crowdsourcing): contains code for running crowdsourcing tasks, such as on Amazon Mechanical Turk\n- [**chat_service**](https://github.com/facebookresearch/ParlAI/tree/main/parlai/chat_service/services/messenger): contains code for interfacing with services such as Facebook Messenger\n- [**zoo**](https://github.com/facebookresearch/ParlAI/tree/main/parlai/zoo): contains code to directly download and use pretrained models from our model zoo\n\n## Support\nIf you have any questions, bug reports or feature requests, please don't hesitate to post on our [Github Issues page](https://github.com/facebookresearch/ParlAI/issues).\nYou may also be interested in checking out our [FAQ](https://parl.ai/docs/faq.html) and\nour [Tips n Tricks](https://parl.ai/docs/tutorial_tipsntricks.html).\n\nPlease remember to follow our [Code of Conduct](https://github.com/facebookresearch/ParlAI/blob/main/CODE_OF_CONDUCT.md).\n\n## Contributing\nWe welcome PRs from the community!\n\nYou can find information about contributing to ParlAI in our\n[Contributing](https://github.com/facebookresearch/ParlAI/blob/main/CONTRIBUTING.md)\ndocument.\n\n\n## The Team\nParlAI is currently maintained by Moya Chen, Emily Dinan, Dexter Ju, Mojtaba\nKomeili, Spencer Poff, Pratik Ringshia, Stephen Roller, Kurt Shuster,\nEric Michael Smith, Megan Ung, Jack Urbanek, Jason Weston, Mary Williamson,\nand Jing Xu. Kurt Shuster is the current Tech Lead.\n\nFormer major contributors and maintainers include Alexander H. Miller, Margaret\nLi, Will Feng, Adam Fisch, Jiasen Lu, Antoine Bordes, Devi Parikh, Dhruv Batra,\nFilipe de Avila Belbute Peres, Chao Pan, and Vedant Puri.\n\n## Citation\n\nPlease cite the [arXiv paper](https://arxiv.org/abs/1705.06476) if you use ParlAI in your work:\n\n```\n@article{miller2017parlai,\n  title={ParlAI: A Dialog Research Software Platform},\n  author={{Miller}, A.~H. and {Feng}, W. and {Fisch}, A. and {Lu}, J. and {Batra}, D. and {Bordes}, A. and {Parikh}, D. and {Weston}, J.},\n  journal={arXiv preprint arXiv:{1705.06476}},\n  year={2017}\n}\n```\n\n## License\nParlAI is MIT licensed. See the **[LICENSE](https://github.com/facebookresearch/ParlAI/blob/main/LICENSE)** file for details.\n",
        "num_commits": 4358,
        "project_age_days": 2745,
        "project_created_at": "2017-04-24",
        "latest_updated_at": "2024-10-27",
        "latest_pushed_at": "2023-11-03",
        "num_contributors": 192,
        "num_pull": 3401,
        "num_issues": 4945,
        "num_opening_issue": 51,
        "project_size(kB)": 149271,
        "num_stargazers": 10483,
        "num_watchers": 10483,
        "num_forks": 2095,
        "num_subscribers": 283,
        "SecurityPolicy_created_at": "2020-09-21 22:57:11",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "d725f134079dbce13782a2ea1519bae4447c876f",
                "url": "https://github.com/facebookresearch/.github/commit/d725f134079dbce13782a2ea1519bae4447c876f",
                "date": "2022-01-20 20:25:35"
            },
            {
                "commit_id": "dbea5eae758446a83e3723ba5b9548ac29775fda",
                "url": "https://github.com/facebookresearch/.github/commit/dbea5eae758446a83e3723ba5b9548ac29775fda",
                "date": "2020-09-21 22:57:11"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "apragacz/django-rest-registration",
        "project_url": "https://github.com/apragacz/django-rest-registration",
        "SSF": {
            "date": "2024-10-29T22:55:37+07:00",
            "repo": {
                "name": "github.com/apragacz/django-rest-registration",
                "commit": "c8bc12d110b62fa3919315cbab3f52f76f1b86a9"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.9,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: branch 'master' does not require approvers",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Warn: no status checks found to merge onto branch 'master'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "19 out of 19 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 0/11 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: fajnie-ze-wiesz contributor org/company found, saucelabs contributor org/company found, edukaton contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 3 contributing companies or organizations -- score normalized to 10",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "17 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:42: update your workflow using https://app.stepsecurity.io/secureworkflow/apragacz/django-rest-registration/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/apragacz/django-rest-registration/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:57: update your workflow using https://app.stepsecurity.io/secureworkflow/apragacz/django-rest-registration/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:71: update your workflow using https://app.stepsecurity.io/secureworkflow/apragacz/django-rest-registration/codeql-analysis.yml/master?enable=pin",
                        "Info:   0 out of   4 GitHub-owned GitHubAction dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: all commits (19) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact v0.9.0 not signed: https://api.github.com/repos/apragacz/django-rest-registration/releases/172908646",
                        "Warn: release artifact v0.8.3 not signed: https://api.github.com/repos/apragacz/django-rest-registration/releases/132584814",
                        "Warn: release artifact v0.8.2 not signed: https://api.github.com/repos/apragacz/django-rest-registration/releases/104320406",
                        "Warn: release artifact v0.8.1 not signed: https://api.github.com/repos/apragacz/django-rest-registration/releases/101847327",
                        "Warn: release artifact v0.8.0 not signed: https://api.github.com/repos/apragacz/django-rest-registration/releases/97610302",
                        "Warn: release artifact v0.9.0 does not have provenance: https://api.github.com/repos/apragacz/django-rest-registration/releases/172908646",
                        "Warn: release artifact v0.8.3 does not have provenance: https://api.github.com/repos/apragacz/django-rest-registration/releases/132584814",
                        "Warn: release artifact v0.8.2 does not have provenance: https://api.github.com/repos/apragacz/django-rest-registration/releases/104320406",
                        "Warn: release artifact v0.8.1 does not have provenance: https://api.github.com/repos/apragacz/django-rest-registration/releases/101847327",
                        "Warn: release artifact v0.8.0 does not have provenance: https://api.github.com/repos/apragacz/django-rest-registration/releases/97610302"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql-analysis.yml:28",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql-analysis.yml:29",
                        "Warn: no topLevel permission defined: .github/workflows/codeql-analysis.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 9,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-5hgc-2vfp-mqvc / PYSEC-2024-102",
                        "Warn: Project is vulnerable to: GHSA-795c-9xpc-xw6g / PYSEC-2024-68",
                        "Warn: Project is vulnerable to: GHSA-9jmf-237g-qf46 / PYSEC-2024-58",
                        "Warn: Project is vulnerable to: GHSA-f6f8-9mx6-9mx2 / PYSEC-2024-59",
                        "Warn: Project is vulnerable to: GHSA-jh75-99hh-qvx9 / PYSEC-2024-67",
                        "Warn: Project is vulnerable to: GHSA-pv4p-cwwg-4rph / PYSEC-2024-70",
                        "Warn: Project is vulnerable to: GHSA-qg2p-9jwr-mmqf / PYSEC-2024-56",
                        "Warn: Project is vulnerable to: GHSA-r836-hh6v-rg5g / PYSEC-2024-69",
                        "Warn: Project is vulnerable to: GHSA-rrqc-c2jx-6jgv",
                        "Warn: Project is vulnerable to: GHSA-x7q2-wr7g-xqmf / PYSEC-2024-57",
                        "Warn: Project is vulnerable to: GHSA-h75v-3vvj-5mfj",
                        "Warn: Project is vulnerable to: GHSA-r683-j2x4-v87g",
                        "Warn: Project is vulnerable to: GHSA-rp65-9cf3-cjxr",
                        "Warn: Project is vulnerable to: GHSA-7fh5-64p2-3v2j"
                    ],
                    "score": 0,
                    "reason": "14 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/apragacz/django-rest-registration/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nThese versions of Django-REST-Registration are\ncurrently being supported with security updates:\n\n| Version | Supported          |\n| ------- | ------------------ |\n| 0.9.x   | :white_check_mark: |\n| 0.8.x   | :white_check_mark: |\n| < 0.8.0 | :x:                |\n\n## Reporting a Vulnerability\n\nIf you think that you found a security issue (especially one with high severity),\nplease do not share it publicly; instead do one of these:\n\n*   [Report a security vulnerability](https://github.com/apragacz/django-rest-registration/security/advisories/new)\n    via GitHub (preferred)\n*   Write a [direct e-mail](mailto:apragacz@o2.pl) to the author.\n",
        "project_all_labels": [
            "closed-as:duplicate",
            "closed-as:wontfix",
            "dependencies",
            "help wanted",
            "javascript",
            "language:javascript",
            "language:python",
            "priority:high",
            "priority:low",
            "priority:middle",
            "python",
            "release:next-major-version",
            "state:design",
            "state:needs-answer",
            "state:research",
            "type:bug",
            "type:cleanup",
            "type:feature-request",
            "type:question"
        ],
        "README_content": "# Django REST Registration\n\n[![CircleCI Build Status](https://circleci.com/gh/apragacz/django-rest-registration.svg?style=shield)](https://circleci.com/gh/apragacz/django-rest-registration)\n[![Codecov Coverage](https://codecov.io/gh/apragacz/django-rest-registration/branch/master/graphs/badge.svg?branch=master)](https://codecov.io/github/apragacz/django-rest-registration?branch=master)\n[![PyPi Version](https://badge.fury.io/py/django-rest-registration.svg)](https://pypi.python.org/pypi/django-rest-registration/)\n[![Documentation Status](https://readthedocs.org/projects/django-rest-registration/badge/?version=latest)](https://django-rest-registration.readthedocs.io/en/latest/?badge=latest)\n\nUser registration REST API, based on Django REST Framework.\n\n## Documentation\n\nFull documentation for the project is available at [https://django-rest-registration.readthedocs.io/](https://django-rest-registration.readthedocs.io/).\n\n## Requirements\n\n* Django (2.0+, 3.0+, 4.0+, 5.0+) and Django-REST-Framework (3.3+)\n* Python 3.7 or higher (no Python 2 support!)\n\n## Features\n\n* Supported views:\n    * registration (sign-up) with verification\n    * login/logout (sign-in), session- or token-based\n    * user profile (retrieving / updating)\n    * reset password\n    * change password\n    * register (change) e-mail\n* Views are compatible with [django-rest-swagger](https://github.com/marcgibbons/django-rest-swagger)\n* Views can be authenticated via session or auth token\n* Modeless (uses the user defined by `settings.AUTH_USER_MODEL` and also uses [cryptographic signing](https://docs.djangoproject.com/en/dev/topics/signing/) instead of profile models)\n* Uses [password validation](https://docs.djangoproject.com/en/dev/topics/auth/passwords/#password-validation)\n* Heavily tested (Above 98% code coverage)\n\n\n## Current limitations\n\n*   Supports only one email per user (as model field)\n*   No JWT support (but you can easily\n    [implement one](https://django-rest-registration.readthedocs.io/en/latest/cookbook/jwt.html)\n    or use Django REST Registration along libraries like\n    [django-rest-framework-simplejwt](https://github.com/davesque/django-rest-framework-simplejwt))\n\n\n## Installation & Configuration\n\nYou can [install](https://django-rest-registration.readthedocs.io/en/latest/install.html)\nDjango REST Registration latest version via pip:\n\n    pip install django-rest-registration\n\nThen, you should add it to the `INSTALLED_APPS` so the app templates\nfor notification emails can be accessed:\n\n```python\nINSTALLED_APPS=(\n    ...\n\n    'rest_registration',\n)\n```\nAfter that, you can use the urls in your urlconfig, for instance:\n\n```python\napi_urlpatterns = [\n    ...\n\n    path('accounts/', include('rest_registration.api.urls')),\n]\n\n\nurlpatterns = [\n    ...\n\n    path('api/v1/', include(api_urlpatterns)),\n]\n```\n\nYou can configure Django REST Registration using the `REST_REGISTRATION`\nsetting in your Django settings (similarly to Django REST Framework).\n\nBelow is sample, minimal config you can provide in your django settings which will satisfy the system checks:\n\n```python\nREST_REGISTRATION = {\n    'REGISTER_VERIFICATION_ENABLED': False,\n    'RESET_PASSWORD_VERIFICATION_ENABLED': False,\n    'REGISTER_EMAIL_VERIFICATION_ENABLED': False,\n}\n```\n\nHowever, the preferred base configuration would be:\n\n```python\nREST_REGISTRATION = {\n    'REGISTER_VERIFICATION_URL': 'https://frontend-host/verify-user/',\n    'RESET_PASSWORD_VERIFICATION_URL': 'https://frontend-host/reset-password/',\n    'REGISTER_EMAIL_VERIFICATION_URL': 'https://frontend-host/verify-email/',\n\n    'VERIFICATION_FROM_EMAIL': 'no-reply@example.com',\n}\n```\n\nThe frontend urls are not provided by the library but should be provided\nby the user of the library, because Django REST Registration is frontend-agnostic.\nThe frontend urls will receive parameters as GET query and should pass\nthem to corresponding REST API views via HTTP POST request.\n\nIn case when any verification is enabled (which is the default!),\nyour Django application needs to be\n[properly configured so it can send e-mails](https://docs.djangoproject.com/en/dev/topics/email/).\n\nYou can read more about basic configuration\n[here](https://django-rest-registration.readthedocs.io/en/latest/quickstart.html).\n\nYou can read more about detailed configuration\n[here](https://django-rest-registration.readthedocs.io/en/latest/detailed_configuration/).\n\n## Configuration options\n\nYou can find all `REST_REGISTRATION` configuration options\n[here](https://django-rest-registration.readthedocs.io/en/latest/detailed_configuration/all_settings.html).\n\n## Contributing\n\nIf you want to contribute, please refer to separate document [CONTRIBUTING.md](CONTRIBUTING.md).\n",
        "num_commits": 688,
        "project_age_days": 3229,
        "project_created_at": "2015-12-27",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 23,
        "num_pull": 185,
        "num_issues": 308,
        "num_opening_issue": 14,
        "project_size(kB)": 3459,
        "num_stargazers": 542,
        "num_watchers": 542,
        "num_forks": 84,
        "num_subscribers": 17,
        "SecurityPolicy_created_at": "2020-05-03 11:00:38",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "1263134e1735e664e12bf65c6062743dd994e7c5",
                "url": "https://github.com/apragacz/django-rest-registration/commit/1263134e1735e664e12bf65c6062743dd994e7c5",
                "date": "2024-08-31 22:13:29"
            },
            {
                "commit_id": "4a837783794ce69813fbc2be72a2360a4cc810ac",
                "url": "https://github.com/apragacz/django-rest-registration/commit/4a837783794ce69813fbc2be72a2360a4cc810ac",
                "date": "2023-05-19 21:21:48"
            },
            {
                "commit_id": "dcf8387c43a0820ba7fa7eaef8771e0fef99d1c8",
                "url": "https://github.com/apragacz/django-rest-registration/commit/dcf8387c43a0820ba7fa7eaef8771e0fef99d1c8",
                "date": "2022-03-09 12:29:27"
            },
            {
                "commit_id": "011293b793ec7b20edf222a7b9d84cf736907e1a",
                "url": "https://github.com/apragacz/django-rest-registration/commit/011293b793ec7b20edf222a7b9d84cf736907e1a",
                "date": "2021-05-04 22:20:58"
            },
            {
                "commit_id": "fe1ab5a1914930bd1de22cf628bb8aef53d40487",
                "url": "https://github.com/apragacz/django-rest-registration/commit/fe1ab5a1914930bd1de22cf628bb8aef53d40487",
                "date": "2020-05-03 11:00:38"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email_advisory",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "ericsson/codechecker",
        "project_url": "https://github.com/ericsson/codechecker",
        "SSF": {
            "date": "2024-10-30T00:21:52+07:00",
            "repo": {
                "name": "github.com/ericsson/codechecker",
                "commit": "1e9f8f040b83550a7fa4ba2a565c472c88ef4d9f"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.4,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Warn: 'allow deletion' enabled on branch 'release-v6.24.4'",
                        "Warn: 'allow deletion' enabled on branch 'release-v6.24.3'",
                        "Warn: 'allow deletion' enabled on branch 'release-v6.24.2'",
                        "Warn: 'allow deletion' enabled on branch 'release-v6.24.1'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'release-v6.24.4'",
                        "Info: 'force pushes' disabled on branch 'release-v6.24.3'",
                        "Info: 'force pushes' disabled on branch 'release-v6.24.2'",
                        "Info: 'force pushes' disabled on branch 'release-v6.24.1'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: branch 'release-v6.24.4' does not require approvers",
                        "Warn: branch 'release-v6.24.3' does not require approvers",
                        "Warn: branch 'release-v6.24.2' does not require approvers",
                        "Warn: branch 'release-v6.24.1' does not require approvers",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Warn: codeowners review is not required on branch 'release-v6.24.4'",
                        "Warn: codeowners review is not required on branch 'release-v6.24.3'",
                        "Warn: codeowners review is not required on branch 'release-v6.24.2'",
                        "Warn: codeowners review is not required on branch 'release-v6.24.1'",
                        "Info: status check found to merge onto on branch 'master'",
                        "Warn: no status checks found to merge onto branch 'release-v6.24.4'",
                        "Warn: no status checks found to merge onto branch 'release-v6.24.3'",
                        "Warn: no status checks found to merge onto branch 'release-v6.24.2'",
                        "Warn: no status checks found to merge onto branch 'release-v6.24.1'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 1,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 4,
                    "reason": "6 out of 13 merged PRs checked by a CI test -- score normalized to 4",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 7,
                    "reason": "Found 12/16 approved changesets -- score normalized to 7",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: apple contributor org/company found, fossasia contributor org/company found, stony brook university contributor org/company found, sonarsource contributor org/company found, contour-terminal contributor org/company found, Ericsson contributor org/company found, llvm contributor org/company found, flow-computing contributor org/company found, flow-computing oy contributor org/company found, mozilla contributor org/company found, ericsson contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 11 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: :0"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.TXT:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE.TXT:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 6 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/docker.yml:11"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/config_coverage.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/config_coverage.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/config_coverage.yml:32: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/config_coverage.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/config_coverage.yml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/config_coverage.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docker.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/docker.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docker.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/docker.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docker.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/docker.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docker.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/docker.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi.yml:47: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi.yml:64: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi.yml:68: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/snap.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/snap.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/snap.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/snap.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/snap.yml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/snap.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:35: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/test.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:91: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:92: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:117: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:118: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:153: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:154: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:198: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:199: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:202: update your workflow using https://app.stepsecurity.io/secureworkflow/Ericsson/codechecker/test.yml/master?enable=pin",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.test.sqlite.clang11.bionic:1: pin your Docker image by updating ubuntu:18.04 to ubuntu:18.04@sha256:152dc042452c496007f07ca9127571cb9c29697f42acbfad72324b2bb2e43c98",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.test.sqlite.clang11.xenial:1: pin your Docker image by updating ubuntu:16.04 to ubuntu:16.04@sha256:1f1a2d56de1d604801a9671f301190704c25d604a416f59e03c04f5c6ffee0d6",
                        "Warn: containerImage not pinned by hash: web/docker/Dockerfile:5",
                        "Warn: containerImage not pinned by hash: web/docker/Dockerfile:43: pin your Docker image by updating python:3.9.7-slim-buster to python:3.9.7-slim-buster@sha256:76eaa9e5bd357d6983a88ddc9c4545ef4ad64c50f84f081ba952c7ed08e3bdd6",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.test.sqlite.clang11.bionic:3-29",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.test.sqlite.clang11.bionic:3-29",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.test.sqlite.clang11.xenial:3-33",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.test.sqlite.clang11.xenial:3-33",
                        "Warn: downloadThenRun not pinned by hash: web/docker/Dockerfile:16-23",
                        "Warn: pipCommand not pinned by hash: web/docker/Dockerfile:90-118",
                        "Warn: pipCommand not pinned by hash: web/docker/Dockerfile:90-118",
                        "Warn: pipCommand not pinned by hash: web/docker/Dockerfile:90-118",
                        "Warn: pipCommand not pinned by hash: web/docker/Dockerfile:90-118",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pypi.yml:103",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pypi.yml:104",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:26",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:51",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:58",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:64",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:70",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:77",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:83",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:125",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:177",
                        "Info:   0 out of  24 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   6 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   4 containerImage dependencies pinned",
                        "Info:   0 out of  19 pipCommand dependencies pinned",
                        "Info:   0 out of   1 downloadThenRun dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 26 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: topLevel permissions set to 'read-all': .github/workflows/config_coverage.yml:24",
                        "Info: topLevel permissions set to 'read-all': .github/workflows/docker.yml:8",
                        "Info: topLevel permissions set to 'read-all': .github/workflows/pypi.yml:9",
                        "Info: topLevel permissions set to 'read-all': .github/workflows/snap.yml:8",
                        "Info: topLevel permissions set to 'read-all': .github/workflows/test.yml:6",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 10,
                    "reason": "GitHub workflow tokens follow principle of least privilege",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-3ww4-gg4f-jr7f",
                        "Warn: Project is vulnerable to: GHSA-6vqw-3v5j-54x4",
                        "Warn: Project is vulnerable to: GHSA-9v9h-cgj8-h64p",
                        "Warn: Project is vulnerable to: GHSA-h4gh-qq45-vh27",
                        "Warn: Project is vulnerable to: GHSA-jfhm-5ghh-2f97 / PYSEC-2023-254",
                        "Warn: Project is vulnerable to: GHSA-8hc4-vh64-cxmj",
                        "Warn: Project is vulnerable to: GHSA-qwcr-r2fm-qrc7",
                        "Warn: Project is vulnerable to: GHSA-grv7-fg5c-xmjg",
                        "Warn: Project is vulnerable to: GHSA-pxg6-pf52-xh8x",
                        "Warn: Project is vulnerable to: GHSA-gxpj-cx7g-858c",
                        "Warn: Project is vulnerable to: GHSA-qw6h-vgh9-j6wx",
                        "Warn: Project is vulnerable to: GHSA-2j2x-2gpw-g8fm",
                        "Warn: Project is vulnerable to: GHSA-c7qv-q95q-8v27",
                        "Warn: Project is vulnerable to: GHSA-2p57-rm9w-gvfp",
                        "Warn: Project is vulnerable to: GHSA-952p-6rrq-rcjv",
                        "Warn: Project is vulnerable to: GHSA-f8q6-p94x-37v3",
                        "Warn: Project is vulnerable to: GHSA-9wv6-86v2-598j",
                        "Warn: Project is vulnerable to: GHSA-7fh5-64p2-3v2j",
                        "Warn: Project is vulnerable to: GHSA-p8p7-x288-28g6",
                        "Warn: Project is vulnerable to: GHSA-m6fv-jmcg-4jfg",
                        "Warn: Project is vulnerable to: GHSA-cm22-4g7w-348p",
                        "Warn: Project is vulnerable to: GHSA-f5x3-32g6-xq36",
                        "Warn: Project is vulnerable to: GHSA-72xf-g2v4-qvf3",
                        "Warn: Project is vulnerable to: GHSA-cchq-frgv-rjh5",
                        "Warn: Project is vulnerable to: GHSA-g644-9gfx-q4q4",
                        "Warn: Project is vulnerable to: GHSA-5j4c-8p2g-v4jx",
                        "Warn: Project is vulnerable to: GHSA-g3ch-rx76-35fx",
                        "Warn: Project is vulnerable to: GHSA-3h5v-q93c-6h6q"
                    ],
                    "score": 0,
                    "reason": "28 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/ericsson/codechecker/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nOnly the latest release version of _CodeChecker_ is supported by security updates.\n\n| Version            | Supported          |\n| ------------------ | ------------------ |\n| Latest Release     | :white_check_mark: |\n| Earlier Releases   | :x:                |\n\n## Reporting a Vulnerability\n\nIf you find a vulnerability in _CodeChecker_, please report it as a security vulnerability on GitHub\nhttps://github.com/Ericsson/codechecker/security/advisories/new\n",
        "project_all_labels": [
            "analyzer :chart_with_upwards_trend:",
            "API change :page_facing_up:",
            "bug :bug:",
            "bugfix :hammer:",
            "CI :package:",
            "clang sa :dragon:",
            "clang-tidy :dragon:",
            "CLI :computer:",
            "config :gear:",
            "cppcheck ",
            "database :file_cabinet:",
            "dependencies :package:",
            "deprecate :hourglass_flowing_sand:",
            "dev env :rescue_worker_helmet:",
            "discussion :bulb:",
            "documentation :book:",
            "duplicate :busts_in_silhouette:",
            "enhancement :star2:",
            "garbage collection ",
            "gcc :water_buffalo:",
            "good first issue",
            "GUI :art:",
            "help wanted",
            "javascript",
            "label-tool ",
            "ld-logger :page_with_curl:",
            "new feature :+1:",
            "other-analyzer :speech_balloon:",
            "package-Docker ",
            "package-Python ",
            "performance :runner:",
            "platform-macOS ",
            "platform-Windows ",
            "plist2html :earth_asia:",
            "python",
            "question :grey_question:",
            "RDY-OnHold :stop_sign:",
            "refactoring   ",
            "report-converter ",
            "RFC :black_nib:",
            "server :desktop_computer:",
            "style :memo:",
            "test :ballot_box_with_check:",
            "tools :hammer_and_wrench:",
            "tu_collector :page_with_curl:",
            "usability :+1:",
            "version :tada:",
            "WARN :warning:: Backward compatibility breaker!",
            "web :earth_africa:",
            "WIP :bomb:",
            "Won't fix :-1:"
        ],
        "README_content": "<h1 align=\"center\">\n  <br>\n  <img src=\"https://github.com/Ericsson/codechecker/raw/master/docs/logo/logo_blue.png\" alt=\"CodeChecker\" width=\"200\">\n  <br>\n  CodeChecker\n  <br>\n</h1>\n\n<p align=\"center\">\n  <a href=\"https://github.com/Ericsson/codechecker/actions\">\n    <img src=\"https://github.com/Ericsson/codechecker/workflows/codechecker-tests/badge.svg\"\n         alt=\"Github Action\">\n  </a>\n  <a href=\"https://gitter.im/codecheckerHQ/Lobby?utm_source=share-link&utm_medium=link&utm_campaign=share-link\">\n    <img src=\"https://badges.gitter.im/codecheckerHQ/Lobby.svg\"\n         alt=\"Gitter\">\n  </a>\n  <a href=\"https://codechecker.readthedocs.io/en/latest/?badge=latest\">\n    <img src=\"https://readthedocs.org/projects/codechecker/badge/?version=latest\"\n         alt=\"Documentation Status\">\n  </a>\n  <a href=\"https://securityscorecards.dev/viewer/?uri=github.com/Ericsson/codechecker\">\n    <img src=\"https://api.securityscorecards.dev/projects/github.com/Ericsson/codechecker/badge\"\n         alt=\"OpenSSF Scorecard Score\">\n  </a>\n</p>\n\n**CodeChecker** is a static analysis infrastructure built on the [LLVM/Clang\nStatic Analyzer](http://clang-analyzer.llvm.org) toolchain, replacing\n[`scan-build`](http://clang-analyzer.llvm.org/scan-build.html) in a Linux or\nmacOS (OS X) development environment.\n\n![Web interface showing list of analysed projects and bugs](images/demo.gif)\n\n**:bulb: Check out our [DEMO](https://codechecker-demo.eastus.cloudapp.azure.com) showing some analysis results of open-source projects!**\n\n# Main features\n## Command line C/C++ Analysis\n  * Executes [_Clang-Tidy_](http://clang.llvm.org/extra/clang-tidy/), [_Clang Static Analyzer_](http://clang-analyzer.llvm.org/) with Cross-Translation Unit analysis, Statistical Analysis (when checkers are available), [_Cppcheck_](https://cppcheck.sourceforge.io/), [_GCC Static Analyzer_](https://gcc.gnu.org/wiki/StaticAnalyzer) and the [_Facebook Infer Analyzer_](https://fbinfer.com).\n  * Creates the JSON compilation database by wiretapping any build process (e.g., `CodeChecker log -b \"make\"`).\n  * Automatically analyzes GCC cross-compiled projects: detecting GCC or Clang compiler configuration and forming the corresponding clang analyzer invocations.\n  * Incremental analysis: Only the changed files and its dependencies need to be reanalyzed.\n  * False positive suppression with a possibility to add review comments.\n  * Result visualization in command line or in static HTML.\n\n## Web-based report storage\n  * **You can store & visualize thousands of analysis reports** of many analyzers like\n    Clang Static Analyzer (C/C++), Clang Tidy (C/C++), Facebook Infer (C/C++, Java), Clang Sanitizers (C/C++), Spotbugs (Java), Pylint (Python), Eslint (Javascript) ...  \n    For a complete list see [Supported Analyzers](supported_code_analyzers.md)\n  * **Web application** for viewing discovered code defects with a streamlined,\n    easy experience (with PostgreSQL, or SQLite backend).\n  * **Gerrit and GitLab integration** Shows analysis results as [GitLab](gitlab_integration.md) or [Gerrit](jenkins_gerrit_integration.md) reviews.\n  * **Filterable** (defect checker name, severity, source paths, ...) and\n    **comparable** (calculates difference between two analyses of the project,\n    showing which bugs have been fixed and which are newly introduced) result\n    viewing.\n  * **Diff mode:** This shows the list of bugs that have been introduced since your last analyzer\n    execution.\n  * Results can be shared with fellow developers, the **comments** and\n    **review** system helps communication of code defects.\n  * Easily implementable [Thrift](http://thrift.apache.org)-based\n    server-client communication used for storing and querying of discovered\n    defects.\n  * Support for multiple bug visualization frontends, such as the web\n    application, a [command-line tool](usage.md) and an\n    [Eclipse plugin](http://github.com/Ericsson/CodeCheckerEclipsePlugin).\n\n## Command line features\n`CodeChecker` command has many subcommands which can be used for example to\nlog and analyze your projects, print the results or start a web server. For\nfull list see the following table or check the help message of this command\n(`CodeChecker --help`):\n\n| `CodeChecker` subcommand | Description                                                                                   |\n|--------------------------|-----------------------------------------------------------------------------------------------|\n| `analyze`                | Execute the supported code analyzers for the files recorded in a JSON Compilation Database.   |\n| `analyzer-version`       | Print the version of CodeChecker analyzer package that is being used.                         |\n| `analyzers`              | List supported and available analyzers.                                                       |\n| `check`                  | Perform analysis on a project and print results to standard output.                           |\n| `checkers`               | List the checkers available for code analysis.                                                |\n| `cmd`                    | View analysis results on a running server from the command line.                              |\n| `fixit`                  | Apply automatic fixes based on the suggestions of the analyzers.                              |\n| `log`                    | Run a build command, collect the executed compilation commands and store them in a JSON file. |\n| `parse`                  | Print analysis summary and results in a human-readable format.                                |\n| `server`                 | Start and manage the CodeChecker Web server.                                                  |\n| `store`                  | Save analysis results to a database.                                                          |\n| `version`                | Print the version of CodeChecker package that is being used.                                  |\n| `web-version`            | Print the version of CodeChecker server package that is being used.                           |\n\n\n`CodeChecker cmd` subcommand also has many other subcommands which can be used\nto get data (products, runs, results, statistics) from a running CodeChecker\nserver. For full list see the following table or check the help message of this\nsubcommand (`CodeChecker cmd --help`):\n\n| `CodeChecker cmd` subcommand | Description                                                                                       |\n|------------------------------|---------------------------------------------------------------------------------------------------|\n| `runs`                       | List the available analysis runs.                                                                 |\n| `history`                    | Show run history of multiple runs.                                                                |\n| `results`                    | List analysis result (finding) summary for a given run.                                           |\n| `diff`                       | Compare two analysis runs and show the difference.                                                |\n| `sum`                        | Show statistics of checkers.                                                                      |\n| `token`                      | Access subcommands related to configuring personal access tokens managed by a CodeChecker server. |\n| `del`                        | Delete analysis runs.                                                                             |\n| `update`                     | Update an analysis run.                                                                           |\n| `suppress`                   | Manage and import suppressions of reports on a CodeChecker server.                                |\n| `products`                   | Access subcommands related to configuring the products managed by a CodeChecker server.           |\n| `components`                 | Access subcommands related to configuring the source components managed by a CodeChecker server.  |\n| `login`                      | Authenticate into CodeChecker servers that require privileges.                                    |\n| `export`                     | Export comments and review statuses from CodeChecker.                                             |\n| `import`                     | Import comments and review statuses into CodeChecker.                                             |\n\n\n# Usage flow\n![Usage diagram](images/usage_flow.png)\n\n- *Step 1*: `CodeChecker log` runs the given build command and records the\nexecuted compilation steps. These steps are written to an output file\n(Compilation Database) in a JSON format.\n- *Step 2*: `CodeChecker analyze` uses the previously created JSON Compilation\nDatabase to perform an analysis on the project, outputting analysis results in\na machine-readable (plist) format.\n- *Step 3*: In this step, you can do multiple things:\n    - Parse and pretty-print the summary and results from analysis result files\n    (`CodeChecker parse`).\n    - Store the results to a running CodeChecker server (`CodeChecker store`).\n    - Compare two analysis results/runs to show the results that differ between\n    the two (`CodeChecker cmd diff`).\n    - etc.\n\nFor more information how to use CodeChecker see our [user guide](usage.md).\n\n# User documentation\n\n* [Getting started (How-To with examples)](usage.md)\n\n## C/C++ Analysis\n* [Analyzer User guide](analyzer/user_guide.md)\n* [Avoiding or suppressing false positives](analyzer/false_positives.md)\n* [Checker and Static Analyzer configuration](analyzer/checker_and_analyzer_configuration.md)\n* [GCC incompatibilities](analyzer/gcc_incompatibilities.md)\n* [Suppressing false positives](analyzer/user_guide.md#source-code-comments)\n\n## Web based report management\n* [Webserver User Guide](web/user_guide.md)\n* [WEB GUI User Guide](/web/server/vue-cli/src/assets/userguide/userguide.md)\n* [Command line and WEB UI Feature overview](feature_comparison.md)\n* Security configuration \n  * [Configuring Authentication](web/authentication.md)\n  * [Configuring Authorization](web/permissions.md)\n* Deployment\n  * [Deploy server using docker](web/docker.md#deployment)\n* Server Configuration\n  * [Configuring Server Logging](logging.md)\n  * [Setting up multiple CodeChecker repositories in one server](web/products.md)\n* Continuous Integration (CI)\n  * [CodeChecker as a GitHub Action](http://github.com/marketplace/actions/codechecker-static-analysis)\n  * [Setting up CI gating with Gerrit and Jenkins](jenkins_gerrit_integration.md)\n* Database Configuration\n  * [PostgreSQL database backend setup guide](web/postgresql_setup.md)\n  * [CodeChecker server and database schema upgrade guide](web/db_schema_guide.md)\n\n### Storage of reports from analyzer tools\nCodeChecker can be used as a generic tool for visualizing analyzer results.\n\nThe following tools are supported:\n\n| Language       | Analyzer                                                                     |\n|----------------|------------------------------------------------------------------------------|\n| **C/C++**      | [Clang Static Analyzer](https://clang-analyzer.llvm.org/)                    |\n|                | [Clang Tidy](https://clang.llvm.org/extra/clang-tidy/)                       |\n|                | [Clang Sanitizers](supported_code_analyzers.md#clang-sanitizers)             |\n|                | [Cppcheck](/docs/tools/report-converter.md#cppcheck)                         |\n|                | [Facebook Infer](/docs/tools/report-converter.md#facebook-infer)             |\n|                | [Coccinelle](/docs/tools/report-converter.md#coccinelle)                     |\n|                | [Smatch](/docs/tools/report-converter.md#smatch)                             |\n|                | [Kernel-Doc](/docs/tools/report-converter.md#kernel-doc)                     |\n|                | [Sparse](/docs/tools/report-converter.md#sparse)                             |\n|                | [cpplint](/docs/tools/report-converter.md#cpplint)                           |\n| **C#**         | [Roslynator.DotNet.Cli](/docs/tools/report-converter.md#roslynatordotnetcli) |\n| **Java**       | [SpotBugs](/docs/tools/report-converter.md#spotbugs)                         |\n|                | [Facebook Infer](/docs/tools/report-converter.md#facebook-infer)                    |\n| **Python**     | [Pylint](/docs/tools/report-converter.md#pylint)                             |\n|                | [Pyflakes](/docs/tools/report-converter.md#pyflakes)                         |\n| **JavaScript** | [ESLint](/docs/tools/report-converter.md#eslint)                             |\n| **TypeScript** | [TSLint](/docs/tools/report-converter.md#tslint)                             |\n| **Go**         | [Golint](/docs/tools/report-converter.md#golint)                             |\n| **Markdown**   | [Markdownlint](/docs/tools/report-converter.md#markdownlint)                 |\n|                | [Sphinx](/docs/tools/report-converter.md#sphinx)                             |\n\n\nFor details see \n[supported code analyzers](supported_code_analyzers.md) documentation and the \n[Report Converter Tool](/docs/tools/report-converter.md).\n\n## Common Tools\nUseful tools that can also be used outside CodeChecker.\n\n* [Build Logger (to generate JSON Compilation Database from your builds)](/analyzer/tools/build-logger/README.md)\n* [Plist/Sarif to HTML converter (to generate HTML files from the given plist or sarif files)](/docs/tools/report-converter.md#plist-to-html-tool)\n* [Report Converter Tool (to convert analysis results from other analyzers to the codechecker report directory format))](/docs/tools/report-converter.md)\n* [Translation Unit Collector (to collect source files of a translation unit or to get source files which depend on the given header files)](/docs/tools/tu_collector.md)\n* [Report Hash generator (to generate unique hash identifiers for reports)](/docs/tools/report-converter.md#report-hash-generation-module)\n\n## Helper Scripts\n* [Helper Scripts for daily analysis](script_daily.md)\n\n# Install guide\n\n## Install CodeChecker via `pip`\nCodeChecker is available on the [pypi](https://pypi.org/project/codechecker/)\nand can be installed with the following command:\n```sh\npip3 install codechecker\n```\n\n**Note:** this package can be installed on `Linux`, `OSX` and `Windows`\nsystems where `pip3` command is available. On `OSX`, `intercept-build` must be\ninstalled for logging (`CodeChecker log`). On `Windows`, logging is not\navailable.\n\n## Installing CodeChecker via the `snap` package manager\nCodeChecker is available on the [Snap Store](https://snapcraft.io/codechecker)\nand can be installed with the following command:\n```sh\nsudo snap install codechecker --classic\n```\n\n**Note:** Unfortunately, the snap package supports only lower-case command names.\nFor this reason, you need to use `codechecker` command instead of `CodeChecker`\neverywhere. For a full list of available commands in the _codechecker_ snap\npackage, run `snap info codechecker`.\n\n## Linux\n\nFor a detailed dependency list, and for instructions on how to install newer\nClang and Clang-Tidy versions, please see [Requirements](deps.md).\nThe following commands are used to bootstrap CodeChecker on Ubuntu 20.04 LTS:\n\n```sh\n# Install mandatory dependencies for a development and analysis environment.\n# NOTE: clang or clang-tidy can be any sufficiently fresh version, and need not\n#       come from package manager!\n#       In case of Cppcheck, the minimal supported version is 1.80.\n#       In case of gcc, the minimal supported version is 13.0.0.\n#       Infer: https://fbinfer.com/docs/getting-started\nsudo apt-get install clang clang-tidy cppcheck g++ build-essential curl\n      gcc-multilib git python3-dev python3-venv python3-setuptools\n\n# In case of venv_dev target and Ubuntu 23 Linux, install an additional library:\nsudo apt-get install libpq-dev\n\n# Install nodejs dependency for web. In case of Debian/Ubuntu you can use the\n# following commands. For more information see the official docs:\n# https://nodejs.org/en/download/package-manager/\ncurl -sL https://deb.nodesource.com/setup_16.x | sudo -E bash -\nsudo apt-get install -y nodejs\n\n# Check out CodeChecker source code.\ngit clone https://github.com/Ericsson/CodeChecker.git --depth 1 ~/codechecker\ncd ~/codechecker\n\n# Create a Python virtualenv and set it as your environment.\n# NOTE: if you want to develop CodeChecker, use the `venv_dev` target instead\n# of `venv`.\nmake venv\nsource $PWD/venv/bin/activate\n\n# [Optional] If you want to use external authentication methods (LDAP / PAM)\n# follow the instructions in\n# docs/web/authentication.md#external-authentication-methods\n\n# Build and install a CodeChecker package.\nmake package\n\n# For ease of access, add the build directory to PATH.\nexport PATH=\"$PWD/build/CodeChecker/bin:$PATH\"\n\ncd ..\n```\n\n**Notes**:\n- By default, `make package` will build ldlogger shared objects for\n`32bit` and `64bit` too. If you would like to build and package `64 bit only`\nshared objects and ldlogger binary you can set `BUILD_LOGGER_64_BIT_ONLY`\nenvironment variable to `YES` before the package build:\n`BUILD_LOGGER_64_BIT_ONLY=YES make package`.\n- By default, the `make package` will build the UI code if it's not built yet\nor the UI code is changed. If you wouldn't like to build the UI code you can\nset the `BUILD_UI_DIST` environment variable to `NO` before the package build:\n`BUILD_UI_DIST=NO make package`.\n- Use `make standalone_package` instead of `make package` to avoid\nhaving to manually activate the environment before running CodeChecker.\n\n### Upgrading environment after system or Python upgrade\n\nIf you have upgraded your system's Python to a newer version (e.g., from\n`3.8` to `3.11` &ndash; this is the case when upgrading Ubuntu from\n20.04 LTS to 22.04 LTS), the installed environment will not work\nout-of-the-box. To fix this issue, run the following command to upgrade your\n`checker_env` too:\n\n```sh\ncd ~/codechecker/venv\npython3 -m venv .\n```\n\n## Mac OS X\nFor installation instructions for Mac OS X see [Mac OS X Installation Guide](install_macosx.md) documentation.\n\n## Docker\nTo run the CodeChecker server in Docker see the [Docker](web/docker.md) documentation.\nYou can find the CodeChecker web-server container at the [Docker Hub](https://hub.docker.com/r/codechecker/codechecker-web).\n\n<img src=\"https://raw.githubusercontent.com/Ericsson/codechecker/master/docs/images/docker.jpg\" width=\"100\">\n\n## Visual Studio Code plugin\n<img src=\"https://raw.githubusercontent.com/Ericsson/codechecker/master/docs/images/vscode.png\" width=\"100\">\n\nYou can install and use CodeChecker VSCode extension from the\n[Visual Studio Marketplace](http://marketplace.visualstudio.com/items?itemName=codechecker.vscode-codechecker)\nor from [Open VSX](http://open-vsx.org/extension/codechecker/codechecker).\n\nMain features:\n- Run CodeChecker analysis from the editor and see the results automatically.\n- Re-analyze the current file when saved.\n- Commands and build tasks for running CodeChecker as part of a build system.\n- Browse through the found reports and show the reproduction steps directly in the code.\n- Navigate between the reproduction steps.\n\n![VSCode plugin](images/vscode.gif)\n\nFor more information how to install and use this plugin see the\n[repository](https://github.com/Ericsson/codecheckervsCodePlugin/) of this\nextension.\n\n## GitHub Actions CI\n\n![CodeChecker executed in GitHub Actions](images/github-actions.png)\n\nCodeChecker can be executed via a reusable GitHub action for your project!\nYou need only specify the build command, as if you would run the analysis\nlocally.\n\nFor more information, check out the\n[CodeChecker Static Analysis](http://github.com/marketplace/actions/codechecker-static-analysis)\naction on the GitHub Actions Marketplace.\n\n# Analyze your first project\n\n## Setting up the environment in your Terminal\n\nThese steps must always be taken in a new command prompt you wish to execute\nanalysis in.\n\n```sh\nsource ~/codechecker/venv/bin/activate\n\n# Path of CodeChecker package\n# NOTE: SKIP this line if you want to always specify CodeChecker's full path.\nexport PATH=~/codechecker/build/CodeChecker/bin:$PATH\n\n# Path of the built LLVM/Clang\n# NOTE: SKIP this line if clang is available in your PATH as an installed Linux package.\nexport PATH=~/<user path>/build/bin:$PATH\n```\n## Execute analysis\n\nAnalyze your project with the `check` command:\n\n    CodeChecker check -b \"cd ~/your-project && make clean && make\" -o ./results\n\n`check` will print an overview of the issues found in your project by the\nanalyzers. The reports will be stored in the `./results` directory in `plist` \nXML format.\n\n## Export the reports as static HTML files\nYou can visualize the results as static HTML by executing\n\n`CodeChecker parse -e html ./results -o ./reports_html`\n\nAn index page will be generated with a list of all repors in \n`./reports_html/index.html` \n\n\n## Optionally store the results in Web server & view the results\n\nIf you have hundreds of results, you may want to store them on the web\nserver with a database backend.\n\nStart a CodeChecker web and storage server in another terminal or as a\nbackground process. By default, it will listen on `localhost:8001`.\n\nThe SQLite database containing the reports will be placed in your workspace\ndirectory (`~/.codechecker` by default), which can be provided via the `-w`\nflag.\n\n    CodeChecker server\n\nStore your analysis reports onto the server to be able to use the Web Viewer.\n\n    CodeChecker store ./results -n my-project\n\nOpen the [CodeChecker Web Viewer](http://localhost:8001) in your browser, and\nyou should be greeted with a web application showing you the analysis results.\n\n\n## Developer documentations\n* [Architecture](architecture.md)\n* [Package layout](package_layout.md)\n* [Dependencies](deps.md)\n* [Thrift interface](web/api/README.md)\n* [Package and integration tests](tests.md)\n\n## Conference papers, presentations\n* An overview about the CodeChecker infrastructure was given at [PLDI 2020](http://pldi20.sigplan.org).<br />\n  **Mrton, Gbor and Krupp, Dniel**:<br />\n  [_Tool Talk: CodeChecker_](http://youtube.com/watch?v=bVqrhaoxHlc)\n* A high-level overview about the infrastructure is available amongst the\n  [2015 Euro LLVM Conference](http://llvm.org/devmtg/2015-04) presentations.<br/>\n  **Krupp, Dniel and Orbn, Gyrgy and Horvth, Gbor and Babati, Bence**:<br/>\n  [_Industrial Experiences with the Clang Static Analysis Toolset_](http://llvm.org/devmtg/2015-04/slides/Clang_static_analysis_toolset_final.pdf)\n",
        "num_commits": 6344,
        "project_age_days": 3424,
        "project_created_at": "2015-06-15",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-27",
        "num_contributors": 94,
        "num_pull": 2918,
        "num_issues": 4302,
        "num_opening_issue": 422,
        "project_size(kB)": 40816,
        "num_stargazers": 2252,
        "num_watchers": 2252,
        "num_forks": 377,
        "num_subscribers": 53,
        "SecurityPolicy_created_at": "2023-08-22 11:56:25",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "9b934a6a93cf7a91147f74a48af2f5ad4bd32b5c",
                "url": "https://github.com/Ericsson/codechecker/commit/9b934a6a93cf7a91147f74a48af2f5ad4bd32b5c",
                "date": "2023-08-29 06:11:28"
            },
            {
                "commit_id": "0178a7295ce144272516ffbfb7e9d26ad175cbf0",
                "url": "https://github.com/Ericsson/codechecker/commit/0178a7295ce144272516ffbfb7e9d26ad175cbf0",
                "date": "2023-08-29 06:11:16"
            },
            {
                "commit_id": "faa0b279e385cb17f113b1b9aa7d8d14bbb46f4b",
                "url": "https://github.com/Ericsson/codechecker/commit/faa0b279e385cb17f113b1b9aa7d8d14bbb46f4b",
                "date": "2023-08-29 06:10:46"
            },
            {
                "commit_id": "0020da733f466522b5a999ff278a1feb46dc1e55",
                "url": "https://github.com/Ericsson/codechecker/commit/0020da733f466522b5a999ff278a1feb46dc1e55",
                "date": "2023-08-23 12:01:20"
            },
            {
                "commit_id": "713ab9468b8bd5523adee58fcb9435dd84d1cfb6",
                "url": "https://github.com/Ericsson/codechecker/commit/713ab9468b8bd5523adee58fcb9435dd84d1cfb6",
                "date": "2023-08-22 11:56:25"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "advisory",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "zopefoundation/products.pluggableauthservice",
        "project_url": "https://github.com/zopefoundation/products.pluggableauthservice",
        "SSF": {
            "date": "2024-10-30T00:52:23+07:00",
            "repo": {
                "name": "github.com/zopefoundation/products.pluggableauthservice",
                "commit": "681919f5fa2051e7e59fc03af04abc9555578e0d"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 4.9,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Info: status check found to merge onto on branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 8,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 3,
                    "reason": "4 out of 11 merged PRs checked by a CI test -- score normalized to 3",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 5,
                    "reason": "Found 11/22 approved changesets -- score normalized to 5",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: repoze contributor org/company found, py76 contributor org/company found, imio communesplone go4web.be contributor org/company found, IMIO contributor org/company found, freelancer contributor org/company found, plone contributor org/company found, zestsoftware contributor org/company found, PloneGov contributor org/company found, vlaamsemilieumaatschappij contributor org/company found, morepath contributor org/company found, FlaskCon contributor org/company found, plone-de contributor org/company found, zopefoundation contributor org/company found, Pylons contributor org/company found, collective contributor org/company found, buildout contributor org/company found, mxstack contributor org/company found, simplon b.v. contributor org/company found, starzel contributor org/company found, covid-tracker-group contributor org/company found, agendaless consulting contributor org/company found, tox-dev contributor org/company found, canonical contributor org/company found, flaskcwg contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 24 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.txt:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "1 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 0",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/zopefoundation/Products.PluggableAuthService/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/zopefoundation/Products.PluggableAuthService/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:44: update your workflow using https://app.stepsecurity.io/secureworkflow/zopefoundation/Products.PluggableAuthService/tests.yml/master?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:53",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:54",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:64",
                        "Info:   0 out of   3 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   3 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 19 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/zopefoundation/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/zopefoundation/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/zopefoundation/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/zopefoundation/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/tests.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/zopefoundation/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\nThe Zope developer community uses the same security policy as the Plone developer community. The most up to date information about Plone security is on https://plone.org/security\n\n## Supported Versions\nFor supported versions, see the [Zope development roadmap](https://www.zope.dev/developer/roadmap.html).\n\n## Reporting a Vulnerability\nPlease do **NOT** create a public bug report if you think this may be a security issue.\nInstead, please contact the Plone and Zope Security Team via email: security@plone.org. See also https://plone.org/security/report\n\nOnly bug reports submitted directly to the security team email will be treated as responsible disclosure. Any offered for sale to third parties or submitted to public bug bounty programmes will be treated as irresponsible public disclosure. We will not confirm any submissions on third party platforms such as \"huntr\" or \"hackerone\" and do not give permission for those systems to accept reports on our behalf or to represent themselves as a conduit for vulnerability reports.\n",
        "project_all_labels": [
            "bug",
            "do not merge",
            "documentation",
            "duplicate",
            "enhancement",
            "help wanted",
            "invalid",
            "question",
            "wontfix"
        ],
        "README_content": "Products.PluggableAuthService\n=============================\n\n.. image:: https://github.com/zopefoundation/Products.PluggableAuthService/actions/workflows/tests.yml/badge.svg\n        :target: https://github.com/zopefoundation/Products.PluggableAuthService/actions/workflows/tests.yml\n\n.. image:: https://coveralls.io/repos/github/zopefoundation/Products.PluggableAuthService/badge.svg\n        :target: https://coveralls.io/github/zopefoundation/Products.PluggableAuthService\n\n.. image:: https://readthedocs.org/projects/productspluggableauthservice/badge/?version=latest\n        :target: https://productspluggableauthservice.readthedocs.io/\n        :alt: Documentation Status\n\n.. image:: https://img.shields.io/pypi/v/Products.PluggableAuthService.svg\n        :target: https://pypi.org/project/Products.PluggableAuthService/\n        :alt: Latest stable release on PyPI\n\n.. image:: https://img.shields.io/pypi/pyversions/Products.PluggableAuthService.svg\n        :target: https://pypi.org/project/Products.PluggableAuthService/\n        :alt: Stable release supported Python versions`\n\nThis product defines a fully-pluggable user folder, intended for\nuse in all Zope sites.\n\nInstallation\n------------\n\nThe normal way it install this package is via ``setuptools``, either\nvia ``pip`` into a virtual environment::\n\n  $ cd /path/to/virtualenv\n  $ bin/pip install Products.PluggableAuthService\n\nor by including the package in the configuration for a ``zc.buildout``-based\ndeployment::\n\n  $ cd /path/to/buildout\n  $ grep \"eggs =\" buildout.cfg\n  ...\n  eggs = Products.PluggableAuthService\n  ...\n\nThe product can also be installed as a dependency of another distribution.\n\nDocumentation\n-------------\n\nPlease see the files under ``doc/`` in the packaged software for more\ninformation, and consult the interfaces files under ``interfaces/`` in\nthe software package for PluggableAuthService and plugin APIs.\n\nThe documentation is also online available at https://productspluggableauthservice.readthedocs.io/.\n\n",
        "num_commits": 434,
        "project_age_days": 3550,
        "project_created_at": "2015-02-10",
        "latest_updated_at": "2024-09-19",
        "latest_pushed_at": "2024-09-19",
        "num_contributors": 31,
        "num_pull": 71,
        "num_issues": 120,
        "num_opening_issue": 1,
        "project_size(kB)": 1167,
        "num_stargazers": 9,
        "num_watchers": 9,
        "num_forks": 18,
        "num_subscribers": 70,
        "SecurityPolicy_created_at": "2020-10-01 12:54:56",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "73354a406601b5b932ed67429b32587d8a57cfa6",
                "url": "https://github.com/zopefoundation/.github/commit/73354a406601b5b932ed67429b32587d8a57cfa6",
                "date": "2022-02-02 06:58:30"
            },
            {
                "commit_id": "230a2bb9798705353da2e1a5178b4dfab52fc7f5",
                "url": "https://github.com/zopefoundation/.github/commit/230a2bb9798705353da2e1a5178b4dfab52fc7f5",
                "date": "2021-09-12 08:56:34"
            },
            {
                "commit_id": "7d9f3c84030087ca403d403727d1eaa801dd2fa5",
                "url": "https://github.com/zopefoundation/.github/commit/7d9f3c84030087ca403d403727d1eaa801dd2fa5",
                "date": "2020-10-02 06:43:48"
            },
            {
                "commit_id": "6404e075a3395a32fc186d66934e2677d3a4179e",
                "url": "https://github.com/zopefoundation/.github/commit/6404e075a3395a32fc186d66934e2677d3a4179e",
                "date": "2020-10-01 12:54:56"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "python-ldap/python-ldap",
        "project_url": "https://github.com/python-ldap/python-ldap",
        "SSF": {
            "date": "2024-10-29T23:45:07+07:00",
            "repo": {
                "name": "github.com/python-ldap/python-ldap",
                "commit": "326f8708ca6d6fff36893a38f38b645bed9c5e6f"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.5,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: required approving review count is 1 on branch 'main'",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Info: status check found to merge onto on branch 'main'",
                        "Info: PRs are required in order to make changes on branch 'main'"
                    ],
                    "score": 8,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 4,
                    "reason": "11 out of 27 merged PRs checked by a CI test -- score normalized to 4",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 7,
                    "reason": "Found 21/29 approved changesets -- score normalized to 7",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: python contributor org/company found, freeipa contributor org/company found, 389ds contributor org/company found, authlib contributor org/company found, fedora-python contributor org/company found, PyLadiesCZ contributor org/company found, latchset contributor org/company found, django-mptt contributor org/company found, railsadminteam contributor org/company found, OCA contributor org/company found, pyvec contributor org/company found, dogtagpki contributor org/company found, django-auth-ldap contributor org/company found, plone contributor org/company found, python-ldap contributor org/company found, red hat contributor org/company found, zopefoundation contributor org/company found, redhatofficial contributor org/company found, pytest-dev contributor org/company found, telecoop contributor org/company found, pallets-eco contributor org/company found, FactoryBoy contributor org/company found, pyparsing contributor org/company found, python-distro contributor org/company found, pioneer valley books contributor org/company found, yaal-coop contributor org/company found, supercoopbdx contributor org/company found, univention gmbh contributor org/company found, django contributor org/company found, jazzband contributor org/company found, wtforms contributor org/company found, requests contributor org/company found, urllib3 contributor org/company found, Pioneer-Valley-Books contributor org/company found, Pylons contributor org/company found, denemo contributor org/company found, univention contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 37 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENCE:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 1,
                    "reason": "2 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 1",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/python-ldap/python-ldap/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:48: update your workflow using https://app.stepsecurity.io/secureworkflow/python-ldap/python-ldap/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tox-fedora.yml:12: update your workflow using https://app.stepsecurity.io/secureworkflow/python-ldap/python-ldap/tox-fedora.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tox-fedora.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/python-ldap/python-ldap/tox-fedora.yml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:56",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:57",
                        "Info:   0 out of   3 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   2 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 28 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact python-ldap-3.3.1 not signed: https://api.github.com/repos/python-ldap/python-ldap/releases/28026990",
                        "Warn: release artifact python-ldap-3.3.1 does not have provenance: https://api.github.com/repos/python-ldap/python-ldap/releases/28026990"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/ci.yml:13",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/tox-fedora.yml:6",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 10,
                    "reason": "GitHub workflow tokens follow principle of least privilege",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/python-ldap/python-ldap/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nSecurity updates are applied only to the latest release.\n\n## Reporting a Vulnerability\n\nIf you have discovered a security vulnerability in this project, please report it privately. **Do not disclose it as a public issue.** This gives us time to work with you to fix the issue before public exposure, reducing the chance that the exploit will be used before a patch is released.\n\nPlease disclose it at our [security advisory](https://github.com/python-ldap/python-ldap/security/advisories/new).\n\nThis project is maintained by a team of volunteers on a reasonable-effort basis. As such, vulnerabilities will be disclosed in a best effort base.\n",
        "project_all_labels": [
            "bug",
            "correctness",
            "doc",
            "ease-of-use",
            "enhancement",
            "feature",
            "good first issue",
            "help wanted",
            "infra",
            "needs-docs",
            "needs-tests",
            "on hold",
            "performance",
            "question",
            "spam",
            "tests",
            "wip"
        ],
        "README_content": "README",
        "num_commits": 961,
        "project_age_days": 2532,
        "project_created_at": "2017-11-23",
        "latest_updated_at": "2024-10-18",
        "latest_pushed_at": "2024-10-11",
        "num_contributors": 31,
        "num_pull": 311,
        "num_issues": 578,
        "num_opening_issue": 100,
        "project_size(kB)": 1252,
        "num_stargazers": 401,
        "num_watchers": 401,
        "num_forks": 120,
        "num_subscribers": 21,
        "SecurityPolicy_created_at": "2023-07-27 23:55:14",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "72c1b5e0f37f74b1a68e67b6b5712d395d577bb9",
                "url": "https://github.com/python-ldap/python-ldap/commit/72c1b5e0f37f74b1a68e67b6b5712d395d577bb9",
                "date": "2023-07-27 23:55:14"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "advisory",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "astropy/astropy",
        "project_url": "https://github.com/astropy/astropy",
        "SSF": {
            "date": "2024-10-29T20:50:22+07:00",
            "repo": {
                "name": "github.com/astropy/astropy",
                "commit": "019b0cdddda98cf7f6be4835987bd641a9b2c0c6"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.5,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: 'branch protection settings apply to administrators' is disable on branch 'main'",
                        "Warn: required approving review count is 1 on branch 'main'",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Info: status check found to merge onto on branch 'main'",
                        "Info: PRs are required in order to make changes on branch 'main'"
                    ],
                    "score": 8,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "8 out of 8 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 7,
                    "reason": "Found 8/11 approved changesets -- score normalized to 7",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: openjournals contributor org/company found, glue-viz contributor org/company found, chandra-mta contributor org/company found, IPAC-SW contributor org/company found, nasa-fornax contributor org/company found, institut de physique des 2 infinis (ip2i cnrs) contributor org/company found, gaia-unlimited contributor org/company found, YSOVAR contributor org/company found, KeplerGO contributor org/company found, space telescope science institute contributor org/company found, center for astrophysics | harvard & smithsonian contributor org/company found, gammapy contributor org/company found, scipy-conference contributor org/company found, caltech/ipac contributor org/company found, fot contributor org/company found, minnesota state university moorhead contributor org/company found, Chandra-MARX contributor org/company found, flatironinstitute contributor org/company found, atpy contributor org/company found, astropy contributor org/company found, mprg-sf contributor org/company found, STScI-SSB contributor org/company found, microsoft contributor org/company found, dirac-institute contributor org/company found, AstroHackWeek2020 contributor org/company found, mit contributor org/company found, sot contributor org/company found, matplotlib contributor org/company found, sunpy contributor org/company found, astroML contributor org/company found, spacetelescope contributor org/company found, yt-project contributor org/company found, morgan stanley contributor org/company found, liberfa contributor org/company found, c2corg contributor org/company found, iminuit contributor org/company found, WorldWideTelescope contributor org/company found, Caltech-IPAC contributor org/company found, OpenAstronomy contributor org/company found, pi3challenge contributor org/company found, python-in-astronomy contributor org/company found, aplpy contributor org/company found, stream-team contributor org/company found, SWAT-Sheffield contributor org/company found, DKISTDC contributor org/company found, the-turing-way contributor org/company found, musevlt contributor org/company found, open-gamma-ray-astro contributor org/company found, STScI-JWST contributor org/company found, heidelbergcement contributor org/company found, university of toronto contributor org/company found, numpy contributor org/company found, lund observatory contributor org/company found, AstroHackWeek contributor org/company found, conda-forge contributor org/company found, SciCoder contributor org/company found, university of sheffield contributor org/company found, python4astronomers contributor org/company found, json-schema-org contributor org/company found, numfocus contributor org/company found, pixee contributor org/company found, gsoc-cn contributor org/company found, lightkurve contributor org/company found, convexfi contributor org/company found, scientific-python contributor org/company found, astronomy-commons contributor org/company found, LinuxVoice contributor org/company found, radio-astro-tools contributor org/company found, aperio software contributor org/company found, university of florida contributor org/company found, glowing-waffle contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 71 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": [
                        "Warn: script injection with untrusted input ' github.event.pull_request.head.label ': .github/workflows/ci_benchmark.yml:72"
                    ],
                    "score": 0,
                    "reason": "dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.rst:0",
                        "Info: FSF or OSI recognized license: BSD 3-Clause \"New\" or \"Revised\" License: LICENSE.rst:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 20 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci_cron_daily.yml:74",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci_cron_weekly.yml:191",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci_cron_weekly.yml:93",
                        "Warn: pipCommand not pinned by hash: .github/workflows/codeql-analysis.yml:77",
                        "Warn: pipCommand not pinned by hash: .github/workflows/codeql-analysis.yml:78",
                        "Warn: pipCommand not pinned by hash: .github/workflows/update_astropy_iers_data_pin.yml:33",
                        "Info:  25 out of  25 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   5 out of   5 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   6 pipCommand dependencies pinned"
                    ],
                    "score": 6,
                    "reason": "dependency not pinned by hash detected -- score normalized to 6",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Warn: 0 commits out of 27 are checked with a SAST tool"
                    ],
                    "score": 7,
                    "reason": "SAST tool detected but not run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: found token with 'none' permissions: .github/workflows/ci_workflows.yml:119",
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql-analysis.yml:25",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql-analysis.yml:26",
                        "Info: found token with 'none' permissions: .github/workflows/publish.yml:28",
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/update_astropy_iers_data_pin.yml:19",
                        "Warn: no topLevel permission defined: .github/workflows/CFF-test.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/check_changelog.yml:1",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/check_milestone.yml:12",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/ci_benchmark.yml:14",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/ci_cron_daily.yml:33",
                        "Warn: no topLevel permission defined: .github/workflows/ci_cron_weekly.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/ci_workflows.yml:1",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/codeql-analysis.yml:20",
                        "Warn: no topLevel permission defined: .github/workflows/open_actions.yml:1",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/publish.yml:17",
                        "Warn: no topLevel permission defined: .github/workflows/stalebot.yml:1",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/update_astropy_iers_data_pin.yml:13"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/astropy/astropy/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nThe table below indicates which versions of `astropy` are\ncurrently being supported with security updates.\n\n| Version | Supported          |\n| ------- | ------------------ |\n| 7.0.x (main)   | :white_check_mark: |\n| 6.1.x   | :white_check_mark: |\n| < 6.1   | :x:                |\n\n## Reporting a Vulnerability\n\n[GitHub private security vulnerability reporting](https://docs.github.com/en/code-security/security-advisories/guidance-on-reporting-and-writing/privately-reporting-a-security-vulnerability)\nshould be enabled for `astropy`. But if that does not work for whatever reason, please report to the\n[@astropy/security-team](https://github.com/orgs/astropy/teams/security-team) that is also listed on the [Astropy Team listing](https://www.astropy.org/team).\n\nWe will respond as soon as we are able. If vulnerability is accepted, we will work on a hotfix.\nThe timing depends on the available resources and the severity/risk of the vulnerability.\nIf a vulnerability is declined, we will take no further action as far as code is concerned. Either way, we will communicate back to you.\n\nThank you for your help!\n",
        "project_all_labels": [
            "\\_()_/",
            ":fire:",
            ":zzz: analytic_functions",
            ":zzz: astropy-helpers",
            ":zzz: astropy-helpers-removal",
            ":zzz: backport-v4.0.x",
            ":zzz: backport-v4.3.x",
            ":zzz: backport-v5.0.x",
            ":zzz: backport-v5.1.x",
            ":zzz: backport-v5.2.x",
            ":zzz: backport-v5.3.x",
            ":zzz: backport-v6.0.x",
            ":zzz: io.misc.asdf",
            ":zzz: merge-when-ci-passes",
            ":zzz: Python2",
            ":zzz: Python2.6",
            ":zzz: Python3",
            ":zzz: Python3.7",
            ":zzz: Python3.8",
            ":zzz: Python3.9",
            ":zzz: Python4",
            "Affects-dev",
            "API change",
            "backport-main",
            "backport-v6.1.x",
            "backport-v7.0.x",
            "benchmark",
            "black",
            "Bug",
            "build",
            "Build all wheels",
            "Close?",
            "closed-by-bot",
            "config",
            "constants",
            "convolution",
            "coordinates",
            "cosmology",
            "dependencies",
            "dev-automation",
            "Docs",
            "Downstream Fix Required",
            "Duplicate",
            "Effort-high",
            "Effort-low",
            "Effort-medium",
            "Enhancement",
            "erfa",
            "Experimental",
            "external",
            "Extra CI",
            "Feature Request",
            "good first issue",
            "Hacktoberfest",
            "hacktoberfest-accepted",
            "installation",
            "invalid",
            "io.ascii",
            "io.fits",
            "io.misc",
            "io.registry",
            "io.votable",
            "keep-open",
            "Last-before-release",
            "logging",
            "Mac OSX",
            "Manual Backport",
            "modeling",
            "multi-threading",
            "nddata",
            "Needs-clarification",
            "needs-copyediting",
            "needs-discussion",
            "needs-downstream-testing",
            "no-changelog-entry-needed",
            "numpy-dev",
            "Package-expert",
            "Package-intermediate",
            "Package-novice",
            "Performance",
            "platform-i386",
            "platform-mips",
            "platform-ppc",
            "precision",
            "Python 3.11",
            "Python 3.12",
            "Python 3.13",
            "Python3.10",
            "question",
            "Ready-for-final-review",
            "Refactoring",
            "Release",
            "samp",
            "skip-basebranch-check",
            "skip-changelog-checks",
            "sprint",
            "stats",
            "Still Needs Manual Backport",
            "table",
            "testing",
            "time",
            "timeseries",
            "typing",
            "uncertainty",
            "unified-io",
            "units",
            "unusual-merge-dealt-with",
            "Upstream Fix Required",
            "utils",
            "utils.iers",
            "utils.masked",
            "visualization",
            "visualization.wcsaxes",
            "vo",
            "vo.conesearch",
            "wcs",
            "wcs.wcsapi",
            "whatsnew-needed",
            "Windows",
            "wont-fix"
        ],
        "README_content": "|Astropy Logo|\n\n----\n\n|Actions Status| |CircleCI Status| |Coverage Status| |PyPI Status| |Documentation Status| |Pre-Commit| |Ruff| |Zenodo|\n----\nThe Astropy Project is a community effort to develop a\nsingle core package for astronomy in Python and foster interoperability between\npackages used in the field. This repository contains the core library.\n\n* `Website <https://astropy.org/>`_\n* `Documentation <https://docs.astropy.org/>`_\n* `Slack <https://astropy.slack.com/>`_\n* `Open Astronomy Discourse <https://community.openastronomy.org/c/astropy/8>`_\n* `Astropy users mailing list <https://mail.python.org/mailman/listinfo/astropy>`_\n* `Astropy developers mailing list <https://groups.google.com/g/astropy-dev>`_\n\nInstallation\n============\n\nTo install `astropy` from PyPI, use:\n\n.. code-block:: bash\n\n    pip install astropy\n\nFor more detailed instructions, see the `install guide\n<https://docs.astropy.org/en/stable/install.html>`_ in the docs.\n\nContributing\n============\n\n.. raw:: html\n\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/astropy/repo_stats/blob/cache/cache/astropy_user_stats_dark.png?raw=true\">\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"https://github.com/astropy/repo_stats/blob/cache/cache/astropy_user_stats_light.png?raw=true\">\n      <img alt=\"Astropy user statistics\" src=\"https://github.com/astropy/repo_stats/blob/cache/cache/astropy_user_stats_light.png?raw=true\">\n    </picture>\n\nThe Astropy Project is made both by and for its users, so we welcome and\nencourage contributions of many kinds. Our goal is to keep this a positive,\ninclusive, successful, and growing community that abides by the\n`Astropy Community Code of Conduct\n<https://www.astropy.org/about.html#codeofconduct>`_.\n\nFor guidance on contributing to or submitting feedback for the Astropy Project,\nsee the `contributions page <https://www.astropy.org/contribute.html>`_.\nFor contributing code specifically, the developer docs have a\n`guide <https://docs.astropy.org/en/latest/index_dev.html>`_ with a quickstart.\nThere's also a `summary of contribution guidelines <CONTRIBUTING.md>`_.\n\nDeveloping with Codespaces\n==========================\n\nGitHub Codespaces is a cloud development environment using Visual Studio Code\nin your browser. This is a convenient way to start developing Astropy, using\nour `dev container <.devcontainer/devcontainer.json>`_ configured\nwith the required packages. For help, see the `GitHub Codespaces\ndocs <https://docs.github.com/en/codespaces>`_.\n\n|Codespaces|\n\nAcknowledging and Citing\n========================\nSee the `acknowledgement and citation guide\n<https://www.astropy.org/acknowledging.html>`_ and the `CITATION\n<https://github.com/astropy/astropy/blob/main/astropy/CITATION>`_ file.\n\nSupporting the Project\n======================\n\n|NumFOCUS| |Donate|\n\nThe Astropy Project is sponsored by NumFOCUS, a 501(c)(3) nonprofit in the\nUnited States. You can donate to the project by using the link above, and this\ndonation will support our mission to promote sustainable, high-level code base\nfor the astronomy community, open code development, educational materials, and\nreproducible scientific research.\n\nLicense\n=======\n\nAstropy is licensed under a 3-clause BSD style license - see the\n`LICENSE.rst <LICENSE.rst>`_ file.\n\n\n.. |Astropy Logo| image:: https://github.com/astropy/repo_stats/blob/main/dashboard_template/astropy_banner_gray.svg\n    :target: https://www.astropy.org/\n    :alt: Astropy\n\n.. |Actions Status| image:: https://github.com/astropy/astropy/actions/workflows/ci_workflows.yml/badge.svg\n    :target: https://github.com/astropy/astropy/actions\n    :alt: Astropy's GitHub Actions CI Status\n\n.. |CircleCI Status| image::  https://img.shields.io/circleci/build/github/astropy/astropy/main?logo=circleci&label=CircleCI\n    :target: https://circleci.com/gh/astropy/astropy\n    :alt: Astropy's CircleCI Status\n\n.. |Coverage Status| image:: https://codecov.io/gh/astropy/astropy/branch/main/graph/badge.svg\n    :target: https://codecov.io/gh/astropy/astropy\n    :alt: Astropy's Coverage Status\n\n.. |PyPI Status| image:: https://img.shields.io/pypi/v/astropy.svg\n    :target: https://pypi.org/project/astropy\n    :alt: Astropy's PyPI Status\n\n.. |Zenodo| image:: https://zenodo.org/badge/DOI/10.5281/zenodo.4670728.svg\n    :target: https://doi.org/10.5281/zenodo.4670728\n    :alt: Zenodo DOI\n\n.. |Documentation Status| image:: https://img.shields.io/readthedocs/astropy/latest.svg?logo=read%20the%20docs&logoColor=white&label=Docs&version=stable\n    :target: https://docs.astropy.org/en/stable/?badge=stable\n    :alt: Documentation Status\n\n.. |Pre-Commit| image:: https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white\n    :target: https://github.com/pre-commit/pre-commit\n    :alt: pre-commit\n\n.. |Ruff| image:: https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json\n    :target: https://github.com/astral-sh/ruff\n    :alt: Ruff\n\n.. |NumFOCUS| image:: https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A\n    :target: https://numfocus.org\n    :alt: Powered by NumFOCUS\n\n.. |Donate| image:: https://img.shields.io/badge/Donate-to%20Astropy-brightgreen.svg\n    :target: https://numfocus.org/donate-to-astropy\n\n.. |Codespaces| image:: https://github.com/codespaces/badge.svg\n    :target: https://github.com/codespaces/new?hide_repo_select=true&ref=main&repo=2081289\n    :alt: Open in GitHub Codespaces\n",
        "num_commits": 38578,
        "project_age_days": 4850,
        "project_created_at": "2011-07-21",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 433,
        "num_pull": 11081,
        "num_issues": 17256,
        "num_opening_issue": 1310,
        "project_size(kB)": 166036,
        "num_stargazers": 4422,
        "num_watchers": 4422,
        "num_forks": 1771,
        "num_subscribers": 141,
        "SecurityPolicy_created_at": "2023-08-21 13:56:05",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "72aa0b60ef556e66f62187b0f8e59595864c2c9a",
                "url": "https://github.com/astropy/astropy/commit/72aa0b60ef556e66f62187b0f8e59595864c2c9a",
                "date": "2024-05-05 21:35:03"
            },
            {
                "commit_id": "1b9e70451bcf8c29259e9e8727a298057ec1c467",
                "url": "https://github.com/astropy/astropy/commit/1b9e70451bcf8c29259e9e8727a298057ec1c467",
                "date": "2023-11-27 20:38:11"
            },
            {
                "commit_id": "b296e4d2a4a9dffae7faf7a12c648d492ded9a60",
                "url": "https://github.com/astropy/astropy/commit/b296e4d2a4a9dffae7faf7a12c648d492ded9a60",
                "date": "2023-11-14 19:16:35"
            },
            {
                "commit_id": "ef31fb0b0eecf42113a0f822c380cc1417cc2372",
                "url": "https://github.com/astropy/astropy/commit/ef31fb0b0eecf42113a0f822c380cc1417cc2372",
                "date": "2023-08-21 14:25:54"
            },
            {
                "commit_id": "dce55cd3250e66e80f3fa6b0fbf4ecb58d1c287c",
                "url": "https://github.com/astropy/astropy/commit/dce55cd3250e66e80f3fa6b0fbf4ecb58d1c287c",
                "date": "2023-08-21 13:56:05"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email_advisory",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "scikit-learn/scikit-learn",
        "project_url": "https://github.com/scikit-learn/scikit-learn",
        "SSF": {
            "date": "2024-10-30T03:57:33+07:00",
            "repo": {
                "name": "github.com/scikit-learn/scikit-learn",
                "commit": "221b209ba9d4d413ce3082d3409e7d2a3063af75"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 8.9,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'allow deletion' disabled on branch '1.5.X'",
                        "Info: 'allow deletion' disabled on branch '1.4.X'",
                        "Info: 'allow deletion' disabled on branch '1.3.X'",
                        "Info: 'allow deletion' disabled on branch '1.1.X'",
                        "Info: 'allow deletion' disabled on branch '1.0.X'",
                        "Info: 'allow deletion' disabled on branch '0.24.X'",
                        "Info: 'allow deletion' disabled on branch '0.23.X'",
                        "Info: 'allow deletion' disabled on branch '0.22.X'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch '1.5.X'",
                        "Info: 'force pushes' disabled on branch '1.4.X'",
                        "Info: 'force pushes' disabled on branch '1.3.X'",
                        "Info: 'force pushes' disabled on branch '1.1.X'",
                        "Info: 'force pushes' disabled on branch '1.0.X'",
                        "Info: 'force pushes' disabled on branch '0.24.X'",
                        "Info: 'force pushes' disabled on branch '0.23.X'",
                        "Info: 'force pushes' disabled on branch '0.22.X'",
                        "Warn: required approving review count is 1 on branch 'main'",
                        "Warn: branch '1.5.X' does not require approvers",
                        "Warn: branch '1.4.X' does not require approvers",
                        "Warn: branch '1.3.X' does not require approvers",
                        "Warn: branch '1.1.X' does not require approvers",
                        "Warn: branch '1.0.X' does not require approvers",
                        "Warn: branch '0.24.X' does not require approvers",
                        "Warn: branch '0.23.X' does not require approvers",
                        "Warn: branch '0.22.X' does not require approvers",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Warn: codeowners review is not required on branch '1.5.X'",
                        "Warn: codeowners review is not required on branch '1.4.X'",
                        "Warn: codeowners review is not required on branch '1.3.X'",
                        "Warn: codeowners review is not required on branch '1.1.X'",
                        "Warn: codeowners review is not required on branch '1.0.X'",
                        "Warn: codeowners review is not required on branch '0.24.X'",
                        "Warn: codeowners review is not required on branch '0.23.X'",
                        "Warn: codeowners review is not required on branch '0.22.X'",
                        "Info: status check found to merge onto on branch 'main'",
                        "Warn: no status checks found to merge onto branch '1.5.X'",
                        "Warn: no status checks found to merge onto branch '1.4.X'",
                        "Warn: no status checks found to merge onto branch '1.3.X'",
                        "Warn: no status checks found to merge onto branch '1.1.X'",
                        "Warn: no status checks found to merge onto branch '1.0.X'",
                        "Warn: no status checks found to merge onto branch '0.24.X'",
                        "Warn: no status checks found to merge onto branch '0.23.X'",
                        "Warn: no status checks found to merge onto branch '0.22.X'",
                        "Info: PRs are required in order to make changes on branch 'main'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 out of 30 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: ramp-kits contributor org/company found, conda-forge contributor org/company found, google contributor org/company found, probabl.ai contributor org/company found, canva contributor org/company found, open-source engineer @probabl-ai contributor org/company found, jean-zay-users contributor org/company found, PySurfer contributor org/company found, matplotlib contributor org/company found, mamba-org contributor org/company found, tlcom paristech contributor org/company found, NYU-MSDSE-SWG contributor org/company found, Parietal-INRIA contributor org/company found, pydataberlin contributor org/company found, fairlearn contributor org/company found, pyarff contributor org/company found, scikit-learn contributor org/company found, scientific-python contributor org/company found, willowsierra contributor org/company found, altair-viz contributor org/company found, microsoft newsbreak facebook google contributor org/company found, fairinternal contributor org/company found, AFPy contributor org/company found, QuantStack contributor org/company found, pystruct contributor org/company found, probabilists contributor org/company found, google deepmind contributor org/company found, scikit-learn-inria-fondation contributor org/company found, open-source engineer @ :probabl. contributor org/company found, quantstack contributor org/company found, pyodide contributor org/company found, pydata contributor org/company found, mne-tools contributor org/company found, flyteorg contributor org/company found, skrub-data contributor org/company found, sphinx-gallery contributor org/company found, unionai contributor org/company found, astroML contributor org/company found, pyRiemann contributor org/company found, clusterlib contributor org/company found, opt-out-tools contributor org/company found, skops-dev contributor org/company found, timc contributor org/company found, wikilinks contributor org/company found, MarkUsProject contributor org/company found, datapipeline contributor org/company found, sup-e-educ contributor org/company found, scikit-learn-contrib contributor org/company found, neurospin contributor org/company found, ulige contributor org/company found, numfocus contributor org/company found, tegaki contributor org/company found, scipy-japan contributor org/company found, paris-swc contributor org/company found, pytorch contributor org/company found, compatible contributor org/company found, scipy contributor org/company found, uwescience contributor org/company found, mavmap contributor org/company found, pactools contributor org/company found, xtensor-stack contributor org/company found, symerio contributor org/company found, microsoft contributor org/company found, meta contributor org/company found, numpy contributor org/company found, soda-inria contributor org/company found, probabl-ai contributor org/company found, BIDS contributor org/company found, openai contributor org/company found, uva language technology lab @ltl-uva contributor org/company found, TopSBM contributor org/company found, joblib contributor org/company found, dask contributor org/company found, UWSEDS contributor org/company found, NYCPython contributor org/company found, pyOpenSci contributor org/company found, skorch-dev contributor org/company found, BinPy contributor org/company found, mlbench contributor org/company found, tencent contributor org/company found, scikit-image contributor org/company found, scikit-optimize contributor org/company found, euroscipy contributor org/company found, scikit-garden contributor org/company found, google brain contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 85 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no workflows found",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: :0"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Info: OSSFuzz integration found"
                    ],
                    "score": 10,
                    "reason": "project is fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: COPYING:0",
                        "Info: FSF or OSI recognized license: BSD 3-Clause \"New\" or \"Revised\" License: COPYING:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 15 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no dependencies found",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: all commits (30) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "No tokens found",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/scikit-learn/scikit-learn/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\n| Version       | Supported          |\n| ------------- | ------------------ |\n| 1.5.2         | :white_check_mark: |\n| < 1.5.2       | :x:                |\n\n## Reporting a Vulnerability\n\nPlease report security vulnerabilities by email to `security@scikit-learn.org`.\nThis email is an alias to a subset of the scikit-learn maintainers' team.\n\nIf the security vulnerability is accepted, a patch will be crafted privately\nin order to prepare a dedicated bugfix release as timely as possible (depending\non the complexity of the fix).\n\nIn addition to sending the report by email, you can also report security\nvulnerabilities to [tidelift](https://tidelift.com/security).\n",
        "project_all_labels": [
            "API",
            "arch:arm",
            "Array API",
            "Blocker",
            "Breaking Change",
            "Bug",
            "Build / CI",
            "C/C++",
            "CUDA CI",
            "cython",
            "dependencies",
            "Developer API",
            "Documentation",
            "Easy",
            "Enhancement",
            "float32",
            "free-threading",
            "frontend",
            "good first issue",
            "good first PR to review",
            "hacktoberfest",
            "hacktoberfest-accepted",
            "Hard",
            "help wanted",
            "High Priority",
            "Large Scale",
            "Lock files",
            "Low Priority",
            "Meta-issue",
            "Metadata Routing",
            "Moderate",
            "module:base",
            "module:calibration",
            "module:cluster",
            "module:common",
            "module:compose",
            "module:covariance",
            "module:cross_decomposition",
            "module:datasets",
            "module:decomposition",
            "module:discriminant_analysis",
            "module:ensemble",
            "module:feature_extraction",
            "module:feature_selection",
            "module:gaussian_process",
            "module:impute",
            "module:inspection",
            "module:isotonic",
            "module:kernel_approximation",
            "module:linear_model",
            "module:manifold",
            "module:metrics",
            "module:mixture",
            "module:model_selection",
            "module:multiclass",
            "module:multioutput",
            "module:naive_bayes",
            "module:neighbors",
            "module:neural_network",
            "module:pipeline",
            "module:preprocessing",
            "module:random_projection",
            "module:semi_supervised",
            "module:svm",
            "module:test-suite",
            "module:tree",
            "module:utils",
            "Move to scikit-learn-extra",
            "Needs Benchmarks",
            "Needs Decision",
            "Needs Decision - Close",
            "Needs Decision - Include Feature",
            "Needs Info",
            "Needs Investigation",
            "Needs Reproducible Code",
            "Needs Triage",
            "Needs work",
            "New Feature",
            "No Changelog Needed",
            "Numerical Stability",
            "OS:Linux",
            "OS:macOS",
            "OS:Windows",
            "Packaging",
            "Pandas compatibility",
            "Performance",
            "pypy",
            "Question",
            "Quick Review",
            "Refactor",
            "Regression",
            "RFC",
            "segfault",
            "spam",
            "Sprint",
            "Stalled",
            "Superseded",
            "To backport",
            "upstream bug",
            "Validation",
            "Waiting for Reviewer",
            "Waiting for Second Reviewer",
            "wontfix",
            "workflow"
        ],
        "README_content": ".. -*- mode: rst -*-\n\n|Azure| |CirrusCI| |Codecov| |CircleCI| |Nightly wheels| |Black| |PythonVersion| |PyPi| |DOI| |Benchmark|\n\n.. |Azure| image:: https://dev.azure.com/scikit-learn/scikit-learn/_apis/build/status/scikit-learn.scikit-learn?branchName=main\n   :target: https://dev.azure.com/scikit-learn/scikit-learn/_build/latest?definitionId=1&branchName=main\n\n.. |CircleCI| image:: https://circleci.com/gh/scikit-learn/scikit-learn/tree/main.svg?style=shield\n   :target: https://circleci.com/gh/scikit-learn/scikit-learn\n\n.. |CirrusCI| image:: https://img.shields.io/cirrus/github/scikit-learn/scikit-learn/main?label=Cirrus%20CI\n   :target: https://cirrus-ci.com/github/scikit-learn/scikit-learn/main\n\n.. |Codecov| image:: https://codecov.io/gh/scikit-learn/scikit-learn/branch/main/graph/badge.svg?token=Pk8G9gg3y9\n   :target: https://codecov.io/gh/scikit-learn/scikit-learn\n\n.. |Nightly wheels| image:: https://github.com/scikit-learn/scikit-learn/workflows/Wheel%20builder/badge.svg?event=schedule\n   :target: https://github.com/scikit-learn/scikit-learn/actions?query=workflow%3A%22Wheel+builder%22+event%3Aschedule\n\n.. |PythonVersion| image:: https://img.shields.io/pypi/pyversions/scikit-learn.svg\n   :target: https://pypi.org/project/scikit-learn/\n\n.. |PyPi| image:: https://img.shields.io/pypi/v/scikit-learn\n   :target: https://pypi.org/project/scikit-learn\n\n.. |Black| image:: https://img.shields.io/badge/code%20style-black-000000.svg\n   :target: https://github.com/psf/black\n\n.. |DOI| image:: https://zenodo.org/badge/21369/scikit-learn/scikit-learn.svg\n   :target: https://zenodo.org/badge/latestdoi/21369/scikit-learn/scikit-learn\n\n.. |Benchmark| image:: https://img.shields.io/badge/Benchmarked%20by-asv-blue\n   :target: https://scikit-learn.org/scikit-learn-benchmarks\n\n.. |PythonMinVersion| replace:: 3.9\n.. |NumPyMinVersion| replace:: 1.19.5\n.. |SciPyMinVersion| replace:: 1.6.0\n.. |JoblibMinVersion| replace:: 1.2.0\n.. |ThreadpoolctlMinVersion| replace:: 3.1.0\n.. |MatplotlibMinVersion| replace:: 3.3.4\n.. |Scikit-ImageMinVersion| replace:: 0.17.2\n.. |PandasMinVersion| replace:: 1.1.5\n.. |SeabornMinVersion| replace:: 0.9.0\n.. |PytestMinVersion| replace:: 7.1.2\n.. |PlotlyMinVersion| replace:: 5.14.0\n\n.. image:: https://raw.githubusercontent.com/scikit-learn/scikit-learn/main/doc/logos/scikit-learn-logo.png\n  :target: https://scikit-learn.org/\n\n**scikit-learn** is a Python module for machine learning built on top of\nSciPy and is distributed under the 3-Clause BSD license.\n\nThe project was started in 2007 by David Cournapeau as a Google Summer\nof Code project, and since then many volunteers have contributed. See\nthe `About us <https://scikit-learn.org/dev/about.html#authors>`__ page\nfor a list of core contributors.\n\nIt is currently maintained by a team of volunteers.\n\nWebsite: https://scikit-learn.org\n\nInstallation\n------------\n\nDependencies\n~~~~~~~~~~~~\n\nscikit-learn requires:\n\n- Python (>= |PythonMinVersion|)\n- NumPy (>= |NumPyMinVersion|)\n- SciPy (>= |SciPyMinVersion|)\n- joblib (>= |JoblibMinVersion|)\n- threadpoolctl (>= |ThreadpoolctlMinVersion|)\n\n=======\n\n**Scikit-learn 0.20 was the last version to support Python 2.7 and Python 3.4.**\nscikit-learn 1.0 and later require Python 3.7 or newer.\nscikit-learn 1.1 and later require Python 3.8 or newer.\n\nScikit-learn plotting capabilities (i.e., functions start with ``plot_`` and\nclasses end with ``Display``) require Matplotlib (>= |MatplotlibMinVersion|).\nFor running the examples Matplotlib >= |MatplotlibMinVersion| is required.\nA few examples require scikit-image >= |Scikit-ImageMinVersion|, a few examples\nrequire pandas >= |PandasMinVersion|, some examples require seaborn >=\n|SeabornMinVersion| and plotly >= |PlotlyMinVersion|.\n\nUser installation\n~~~~~~~~~~~~~~~~~\n\nIf you already have a working installation of NumPy and SciPy,\nthe easiest way to install scikit-learn is using ``pip``::\n\n    pip install -U scikit-learn\n\nor ``conda``::\n\n    conda install -c conda-forge scikit-learn\n\nThe documentation includes more detailed `installation instructions <https://scikit-learn.org/stable/install.html>`_.\n\n\nChangelog\n---------\n\nSee the `changelog <https://scikit-learn.org/dev/whats_new.html>`__\nfor a history of notable changes to scikit-learn.\n\nDevelopment\n-----------\n\nWe welcome new contributors of all experience levels. The scikit-learn\ncommunity goals are to be helpful, welcoming, and effective. The\n`Development Guide <https://scikit-learn.org/stable/developers/index.html>`_\nhas detailed information about contributing code, documentation, tests, and\nmore. We've included some basic information in this README.\n\nImportant links\n~~~~~~~~~~~~~~~\n\n- Official source code repo: https://github.com/scikit-learn/scikit-learn\n- Download releases: https://pypi.org/project/scikit-learn/\n- Issue tracker: https://github.com/scikit-learn/scikit-learn/issues\n\nSource code\n~~~~~~~~~~~\n\nYou can check the latest sources with the command::\n\n    git clone https://github.com/scikit-learn/scikit-learn.git\n\nContributing\n~~~~~~~~~~~~\n\nTo learn more about making a contribution to scikit-learn, please see our\n`Contributing guide\n<https://scikit-learn.org/dev/developers/contributing.html>`_.\n\nTesting\n~~~~~~~\n\nAfter installation, you can launch the test suite from outside the source\ndirectory (you will need to have ``pytest`` >= |PyTestMinVersion| installed)::\n\n    pytest sklearn\n\nSee the web page https://scikit-learn.org/dev/developers/contributing.html#testing-and-improving-test-coverage\nfor more information.\n\n    Random number generation can be controlled during testing by setting\n    the ``SKLEARN_SEED`` environment variable.\n\nSubmitting a Pull Request\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\nBefore opening a Pull Request, have a look at the\nfull Contributing page to make sure your code complies\nwith our guidelines: https://scikit-learn.org/stable/developers/index.html\n\nProject History\n---------------\n\nThe project was started in 2007 by David Cournapeau as a Google Summer\nof Code project, and since then many volunteers have contributed. See\nthe `About us <https://scikit-learn.org/dev/about.html#authors>`__ page\nfor a list of core contributors.\n\nThe project is currently maintained by a team of volunteers.\n\n**Note**: `scikit-learn` was previously referred to as `scikits.learn`.\n\nHelp and Support\n----------------\n\nDocumentation\n~~~~~~~~~~~~~\n\n- HTML documentation (stable release): https://scikit-learn.org\n- HTML documentation (development version): https://scikit-learn.org/dev/\n- FAQ: https://scikit-learn.org/stable/faq.html\n\nCommunication\n~~~~~~~~~~~~~\n\n- Mailing list: https://mail.python.org/mailman/listinfo/scikit-learn\n- Logos & Branding: https://github.com/scikit-learn/scikit-learn/tree/main/doc/logos\n- Blog: https://blog.scikit-learn.org\n- Calendar: https://blog.scikit-learn.org/calendar/\n- Twitter: https://twitter.com/scikit_learn\n- Stack Overflow: https://stackoverflow.com/questions/tagged/scikit-learn\n- GitHub Discussions: https://github.com/scikit-learn/scikit-learn/discussions\n- Website: https://scikit-learn.org\n- LinkedIn: https://www.linkedin.com/company/scikit-learn\n- YouTube: https://www.youtube.com/channel/UCJosFjYm0ZYVUARxuOZqnnw/playlists\n- Facebook: https://www.facebook.com/scikitlearnofficial/\n- Instagram: https://www.instagram.com/scikitlearnofficial/\n- TikTok: https://www.tiktok.com/@scikit.learn\n- Mastodon: https://mastodon.social/@sklearn@fosstodon.org\n- Discord: https://discord.gg/h9qyrK8Jc8\n\n\nCitation\n~~~~~~~~\n\nIf you use scikit-learn in a scientific publication, we would appreciate citations: https://scikit-learn.org/stable/about.html#citing-scikit-learn\n",
        "num_commits": 31864,
        "project_age_days": 5187,
        "project_created_at": "2010-08-17",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 409,
        "num_pull": 17936,
        "num_issues": 29135,
        "num_opening_issue": 2057,
        "project_size(kB)": 164451,
        "num_stargazers": 59926,
        "num_watchers": 59926,
        "num_forks": 25373,
        "num_subscribers": 2141,
        "SecurityPolicy_created_at": "2021-10-25 16:27:08",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "35164b3e8b605bc990eaf42a8a170082036dff59",
                "url": "https://github.com/scikit-learn/scikit-learn/commit/35164b3e8b605bc990eaf42a8a170082036dff59",
                "date": "2024-09-13 15:50:51"
            },
            {
                "commit_id": "ecdc9570953f21d702e3e96394133abdad8e3b6a",
                "url": "https://github.com/scikit-learn/scikit-learn/commit/ecdc9570953f21d702e3e96394133abdad8e3b6a",
                "date": "2024-07-03 12:51:04"
            },
            {
                "commit_id": "6a18882c3965a6844ecc9bcd12feda64b0a004f0",
                "url": "https://github.com/scikit-learn/scikit-learn/commit/6a18882c3965a6844ecc9bcd12feda64b0a004f0",
                "date": "2024-05-22 14:24:48"
            },
            {
                "commit_id": "180fd177b09bccfbdc8f0e61ecd6bc8bfb692a33",
                "url": "https://github.com/scikit-learn/scikit-learn/commit/180fd177b09bccfbdc8f0e61ecd6bc8bfb692a33",
                "date": "2024-04-10 05:39:47"
            },
            {
                "commit_id": "5f93a1dda0e4514887ce676537c80af4a420a7cd",
                "url": "https://github.com/scikit-learn/scikit-learn/commit/5f93a1dda0e4514887ce676537c80af4a420a7cd",
                "date": "2024-02-16 09:46:14"
            },
            {
                "commit_id": "a3c8da18af46da0d0e32027dacb20501647b078a",
                "url": "https://github.com/scikit-learn/scikit-learn/commit/a3c8da18af46da0d0e32027dacb20501647b078a",
                "date": "2024-01-19 12:01:11"
            },
            {
                "commit_id": "5c85b581b858c5c99b9f90c6a5fd049f0ad85a4b",
                "url": "https://github.com/scikit-learn/scikit-learn/commit/5c85b581b858c5c99b9f90c6a5fd049f0ad85a4b",
                "date": "2023-10-25 11:57:29"
            },
            {
                "commit_id": "3f6bc8e8153fec8e6d3ffcf4b5a61abc98a96b3c",
                "url": "https://github.com/scikit-learn/scikit-learn/commit/3f6bc8e8153fec8e6d3ffcf4b5a61abc98a96b3c",
                "date": "2023-09-21 09:22:35"
            },
            {
                "commit_id": "d5d2364b897858947bab53dc3959a446e391c92c",
                "url": "https://github.com/scikit-learn/scikit-learn/commit/d5d2364b897858947bab53dc3959a446e391c92c",
                "date": "2023-06-30 12:05:39"
            },
            {
                "commit_id": "a994afbbfc95b31e917a09d4edb1b1699a3131d5",
                "url": "https://github.com/scikit-learn/scikit-learn/commit/a994afbbfc95b31e917a09d4edb1b1699a3131d5",
                "date": "2023-03-09 11:29:35"
            },
            {
                "commit_id": "daa84491b7bf4d59a3c127103ea073248fbd1699",
                "url": "https://github.com/scikit-learn/scikit-learn/commit/daa84491b7bf4d59a3c127103ea073248fbd1699",
                "date": "2023-01-25 13:47:56"
            },
            {
                "commit_id": "005711801654d65785cef1f1d58a96b4cc0629a6",
                "url": "https://github.com/scikit-learn/scikit-learn/commit/005711801654d65785cef1f1d58a96b4cc0629a6",
                "date": "2022-12-08 15:44:48"
            },
            {
                "commit_id": "e49293e252ed601084e03629498877b4e6d67772",
                "url": "https://github.com/scikit-learn/scikit-learn/commit/e49293e252ed601084e03629498877b4e6d67772",
                "date": "2022-10-31 09:12:42"
            },
            {
                "commit_id": "355ec7ef58f4168af61de08da8cc29bbc6c589a1",
                "url": "https://github.com/scikit-learn/scikit-learn/commit/355ec7ef58f4168af61de08da8cc29bbc6c589a1",
                "date": "2022-09-30 14:31:56"
            },
            {
                "commit_id": "8955057049c5c8cc5a7d8380e236f6a5efcf1c05",
                "url": "https://github.com/scikit-learn/scikit-learn/commit/8955057049c5c8cc5a7d8380e236f6a5efcf1c05",
                "date": "2021-10-25 16:27:08"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "jaraco/keyring",
        "project_url": "https://github.com/jaraco/keyring",
        "SSF": {
            "date": "2024-10-29T23:33:04+07:00",
            "repo": {
                "name": "github.com/jaraco/keyring",
                "commit": "999a2f945a6449a914f192a2fad5805183a6f09d"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.5,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'main'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 5,
                    "reason": "2 out of 4 merged PRs checked by a CI test -- score normalized to 5",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 2,
                    "reason": "Found 4/14 approved changesets -- score normalized to 2",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: cycle148hki contributor org/company found, python-humanize contributor org/company found, python-twitter-tools contributor org/company found, flake8-implicit-str-concat contributor org/company found, ansible contributor org/company found, kpi-web-guild contributor org/company found, ansible-collections contributor org/company found, AFPy contributor org/company found, UpCloudLtd contributor org/company found, cawemo contributor org/company found, kyiv-team-hacktbilisi contributor org/company found, ukrainian-github contributor org/company found, python-attrs contributor org/company found, sanitizers contributor org/company found, ansible-collection-migration contributor org/company found, quicksilver contributor org/company found, retext-project contributor org/company found, upcloudltd contributor org/company found, pytest-dev contributor org/company found, whyaretheflagsup contributor org/company found, deadsetbit contributor org/company found, itkpi contributor org/company found, shenv contributor org/company found, tahoe-lafs contributor org/company found, cherrypy contributor org/company found, jazzband contributor org/company found, git-skeletons contributor org/company found, python contributor org/company found, fatiando contributor org/company found, mobbler contributor org/company found, github-actions-playground contributor org/company found, open-craft-guild contributor org/company found, sphinx-contrib contributor org/company found, neurospin contributor org/company found, imagen2 contributor org/company found, pypa contributor org/company found, python-pillow contributor org/company found, WahKazoo contributor org/company found, microsoft contributor org/company found, pypi contributor org/company found, coherent-oss contributor org/company found, termcolor contributor org/company found, fitness-buddies contributor org/company found, douhack contributor org/company found, libwww-perl contributor org/company found, home-assistant contributor org/company found, camunda contributor org/company found, hairybearsocialclub contributor org/company found, camunda-cloud contributor org/company found, helsinki-python contributor org/company found, rpm-software-management contributor org/company found, rlink7 contributor org/company found, cribl contributor org/company found, citybikes contributor org/company found, nordsoftware contributor org/company found, pyba contributor org/company found, SalaryCalc contributor org/company found, twisted contributor org/company found, UWARG contributor org/company found, E-waste-manager contributor org/company found, university of waterloo contributor org/company found, python-trio contributor org/company found, endoflife-date contributor org/company found, uw-midsun contributor org/company found, lvov-douhack contributor org/company found, re-actors contributor org/company found, faitmain contributor org/company found, NaPoGenMo contributor org/company found, ultrajson contributor org/company found, reStructuredText contributor org/company found, beslogic contributor org/company found, pylast contributor org/company found, unitedstates contributor org/company found, NaNoGenMo contributor org/company found, Azure contributor org/company found, aio-libs contributor org/company found, ansible-community contributor org/company found, ansible core engineering team @ @redhatofficial contributor org/company found, cveda contributor org/company found, mozilla contributor org/company found, circus-tent contributor org/company found, sigma-project-program contributor org/company found, OSS-NORUS contributor org/company found, n8henrie.com contributor org/company found, cea contributor org/company found, the interface financial group contributor org/company found, GDG-Ukraine contributor org/company found, gajim contributor org/company found, polifactory-polimi contributor org/company found, pmxbot contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 90 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 9 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:60: update your workflow using https://app.stepsecurity.io/secureworkflow/jaraco/keyring/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:62: update your workflow using https://app.stepsecurity.io/secureworkflow/jaraco/keyring/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:80: update your workflow using https://app.stepsecurity.io/secureworkflow/jaraco/keyring/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:84: update your workflow using https://app.stepsecurity.io/secureworkflow/jaraco/keyring/main.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/main.yml:103: update your workflow using https://app.stepsecurity.io/secureworkflow/jaraco/keyring/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:116: update your workflow using https://app.stepsecurity.io/secureworkflow/jaraco/keyring/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:118: update your workflow using https://app.stepsecurity.io/secureworkflow/jaraco/keyring/main.yml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:123",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:68",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:89",
                        "Info:   0 out of   6 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   3 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 20 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/main.yml:109",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/main.yml:16"
                    ],
                    "score": 10,
                    "reason": "GitHub workflow tokens follow principle of least privilege",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/jaraco/keyring/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Contact\n\nTo report a security vulnerability, please use the [Tidelift security contact](https://tidelift.com/security). Tidelift will coordinate the fix and disclosure.\n",
        "project_all_labels": [
            "bug",
            "documentation",
            "duplicate",
            "enhancement",
            "good-first-issue",
            "help wanted",
            "invalid",
            "languishing",
            "Linux",
            "macOS",
            "needs-reproducer",
            "question",
            "tests",
            "Windows",
            "wontfix"
        ],
        "README_content": ".. image:: https://img.shields.io/pypi/v/keyring.svg\n   :target: https://pypi.org/project/keyring\n\n.. image:: https://img.shields.io/pypi/pyversions/keyring.svg\n\n.. image:: https://github.com/jaraco/keyring/actions/workflows/main.yml/badge.svg\n   :target: https://github.com/jaraco/keyring/actions?query=workflow%3A%22tests%22\n   :alt: tests\n\n.. image:: https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/charliermarsh/ruff/main/assets/badge/v2.json\n    :target: https://github.com/astral-sh/ruff\n    :alt: Ruff\n\n.. image:: https://readthedocs.org/projects/keyring/badge/?version=latest\n   :target: https://keyring.readthedocs.io/en/latest/?badge=latest\n\n.. image:: https://img.shields.io/badge/skeleton-2024-informational\n   :target: https://blog.jaraco.com/skeleton\n\n.. image:: https://tidelift.com/badges/package/pypi/keyring\n   :target: https://tidelift.com/subscription/pkg/pypi-keyring?utm_source=pypi-keyring&utm_medium=readme\n\n.. image:: https://badges.gitter.im/jaraco/keyring.svg\n   :alt: Join the chat at https://gitter.im/jaraco/keyring\n   :target: https://gitter.im/jaraco/keyring?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge\n\nThe Python keyring library provides an easy way to access the\nsystem keyring service from python. It can be used in any\napplication that needs safe password storage.\n\nThese recommended keyring backends are supported:\n\n* macOS `Keychain\n  <https://en.wikipedia.org/wiki/Keychain_%28software%29>`_\n* Freedesktop `Secret Service\n  <http://standards.freedesktop.org/secret-service/>`_ supports many DE including\n  GNOME (requires `secretstorage <https://pypi.python.org/pypi/secretstorage>`_)\n* KDE4 & KDE5 `KWallet <https://en.wikipedia.org/wiki/KWallet>`_\n  (requires `dbus <https://pypi.python.org/pypi/dbus-python>`_)\n* `Windows Credential Locker\n  <https://docs.microsoft.com/en-us/windows/uwp/security/credential-locker>`_\n\nOther keyring implementations are available through `Third-Party Backends`_.\n\nInstallation - Linux\n====================\n\nOn Linux, the KWallet backend relies on dbus-python_, which does not always\ninstall correctly when using pip (compilation is needed). For best results,\ninstall dbus-python as a system package.\n\n.. _dbus-python: https://gitlab.freedesktop.org/dbus/dbus-python\n\nCompatibility - macOS\n=====================\n\nmacOS keychain supports macOS 11 (Big Sur) and later requires Python 3.8.7\nor later with the \"universal2\" binary. See\n`#525 <https://github.com/jaraco/keyring/issues/525>`_ for details.\n\nUsing Keyring\n=============\n\nThe basic usage of keyring is pretty simple: just call\n``keyring.set_password`` and ``keyring.get_password``::\n\n    >>> import keyring\n    >>> keyring.set_password(\"system\", \"username\", \"password\")\n    >>> keyring.get_password(\"system\", \"username\")\n    'password'\n\nCommand-line Utility\n--------------------\n\nKeyring supplies a ``keyring`` command which is installed with the\npackage. After installing keyring in most environments, the\ncommand should be available for setting, getting, and deleting\npasswords. For more usage information, invoke with no arguments\nor with ``--help`` as so::\n\n    $ keyring --help\n    $ keyring set system username\n    Password for 'username' in 'system':\n    $ keyring get system username\n    password\n\nThe command-line functionality is also exposed as an executable\npackage, suitable for invoking from Python like so::\n\n    $ python -m keyring --help\n    $ python -m keyring set system username\n    Password for 'username' in 'system':\n    $ python -m keyring get system username\n    password\n\nTab Completion\n--------------\n\nIf installed via a package manager (apt, pacman, nix, homebrew, etc),\nthese shell completions may already have been distributed with the package\n(no action required).\n\nKeyring provides tab completion if the ``completion`` extra is installed::\n\n    $ pip install 'keyring[completion]'\n\nThen, generate shell completions, something like::\n\n    $ keyring --print-completion bash | sudo tee /usr/share/bash-completion/completions/keyring\n    $ keyring --print-completion zsh | sudo tee /usr/share/zsh/site-functions/_keyring\n    $ keyring --print-completion tcsh | sudo tee /etc/profile.d/keyring.csh\n\n**Note**: the path of `/usr/share` is mainly for GNU/Linux. For other OSs,\nconsider:\n\n- macOS (Homebrew x86): /usr/local/share\n- macOS (Homebrew ARM): /opt/homebrew/share\n- Android (Termux): /data/data/com.termux/files/usr/share\n- Windows (mingw64 of msys2): /mingw64/share\n- ...\n\nAfter installing the shell completions, enable them following your shell's\nrecommended instructions. e.g.:\n\n- bash: install `bash-completion <https://github.com/scop/bash-completion>`_,\n  and ensure ``. /usr/share/bash-completion/bash_completion`` in ``~/.bashrc``.\n- zsh: ensure ``autoload -Uz compinit && compinit`` appears in ``~/.zshrc``,\n  then ``grep -w keyring ~/.zcompdump`` to verify keyring appears, indicating\n  it was installed correctly.\n\nConfiguring\n===========\n\nThe python keyring lib contains implementations for several backends. The\nlibrary will attempt to\nautomatically choose the most suitable backend for the current\nenvironment. Users may also specify the preferred keyring in a\nconfig file or by calling the ``set_keyring()`` function.\n\nConfig file path\n----------------\n\nThe configuration is stored in a file named \"keyringrc.cfg\"\nfound in a platform-specific location. To determine\nwhere the config file is stored, run ``keyring diagnose``.\n\nConfig file content\n-------------------\n\nTo specify a keyring backend, set the **default-keyring** option to the\nfull path of the class for that backend, such as\n``keyring.backends.macOS.Keyring``.\n\nIf **keyring-path** is indicated, keyring will add that path to the Python\nmodule search path before loading the backend.\n\nFor example, this config might be used to load the\n``SimpleKeyring`` from the ``simplekeyring`` module in\nthe ``./demo`` directory (not implemented)::\n\n    [backend]\n    default-keyring=simplekeyring.SimpleKeyring\n    keyring-path=demo\n\nThird-Party Backends\n====================\n\nIn addition to the backends provided by the core keyring package for\nthe most common and secure use cases, there\nare additional keyring backend implementations available for other\nuse cases. Simply install them to make them available:\n\n- `keyrings.cryptfile <https://pypi.org/project/keyrings.cryptfile>`_\n  - Encrypted text file storage.\n- `keyrings.alt <https://pypi.org/project/keyrings.alt>`_ - \"alternate\",\n  possibly-insecure backends, originally part of the core package, but\n  available for opt-in.\n- `gsheet-keyring <https://pypi.org/project/gsheet-keyring>`_\n  - a backend that stores secrets in a Google Sheet. For use with\n  `ipython-secrets <https://pypi.org/project/ipython-secrets>`_.\n- `bitwarden-keyring <https://pypi.org/project/bitwarden-keyring/>`_\n  - a backend that stores secrets in the `BitWarden <https://bitwarden.com/>`_\n  password manager.\n- `onepassword-keyring <https://pypi.org/project/onepassword-keyring/>`_\n  - a backend that stores secrets in the `1Password <https://1password.com/>`_ password manager.\n- `sagecipher <https://pypi.org/project/sagecipher>`_ - an encryption\n  backend which uses the ssh agent protocol's signature operation to\n  derive the cipher key.\n- `keyrings.osx_keychain_keys <https://pypi.org/project/keyrings.osx-keychain-keys>`_\n  - OSX keychain key-management, for private, public, and symmetric keys.\n- `keyring_pass.PasswordStoreBackend <https://github.com/nazarewk/keyring_pass>`_\n   - Password Store (pass) backend for python's keyring \n- `keyring_jeepney <https://pypi.org/project/keyring_jeepney>`__ - a\n  pure Python backend using the secret service DBus API for desktop\n  Linux (requires ``keyring<24``).\n\n\nWrite your own keyring backend\n==============================\n\nThe interface for the backend is defined by ``keyring.backend.KeyringBackend``.\nEvery backend should derive from that base class and define a ``priority``\nattribute and three functions: ``get_password()``, ``set_password()``, and\n``delete_password()``. The ``get_credential()`` function may be defined if\ndesired.\n\nSee the ``backend`` module for more detail on the interface of this class.\n\nKeyring employs entry points to allow any third-party package to implement\nbackends without any modification to the keyring itself. Those interested in\ncreating new backends are encouraged to create new, third-party packages\nin the ``keyrings`` namespace, in a manner modeled by the `keyrings.alt\npackage <https://github.com/jaraco/keyrings.alt>`_. See the\n``setup.cfg`` file\nin that project for hints on how to create the requisite entry points.\nBackends that prove essential may be considered for inclusion in the core\nlibrary, although the ease of installing these third-party packages should\nmean that extensions may be readily available.\n\nTo create an extension for Keyring, please submit a pull request to\nhave your extension mentioned as an available extension.\n\nRuntime Configuration\n=====================\n\nKeyring additionally allows programmatic configuration of the\nbackend calling the api ``set_keyring()``. The indicated backend\nwill subsequently be used to store and retrieve passwords.\n\nTo invoke ``set_keyring``::\n\n    # define a new keyring class which extends the KeyringBackend\n    import keyring.backend\n\n    class TestKeyring(keyring.backend.KeyringBackend):\n        \"\"\"A test keyring which always outputs the same password\n        \"\"\"\n        priority = 1\n\n        def set_password(self, servicename, username, password):\n            pass\n\n        def get_password(self, servicename, username):\n            return \"password from TestKeyring\"\n\n        def delete_password(self, servicename, username):\n            pass\n\n    # set the keyring for keyring lib\n    keyring.set_keyring(TestKeyring())\n\n    # invoke the keyring lib\n    try:\n        keyring.set_password(\"demo-service\", \"tarek\", \"passexample\")\n        print(\"password stored successfully\")\n    except keyring.errors.PasswordSetError:\n        print(\"failed to store password\")\n    print(\"password\", keyring.get_password(\"demo-service\", \"tarek\"))\n\n\nDisabling Keyring\n=================\n\nIn many cases, uninstalling keyring will never be necessary.\nEspecially on Windows and macOS, the behavior of keyring is\nusually degenerate, meaning it will return empty values to\nthe caller, allowing the caller to fall back to some other\nbehavior.\n\nIn some cases, the default behavior of keyring is undesirable and\nit would be preferable to disable the keyring behavior altogether.\nThere are several mechanisms to disable keyring:\n\n- Uninstall keyring. Most applications are tolerant to keyring\n  not being installed. Uninstalling keyring should cause those\n  applications to fall back to the behavior without keyring.\n  This approach affects the Python environment where keyring\n  would otherwise have been installed.\n\n- Configure the Null keyring in the environment. Set\n  ``PYTHON_KEYRING_BACKEND=keyring.backends.null.Keyring``\n  in the environment, and the ``Null`` (degenerate) backend\n  will be used. This approach affects all uses of Keyring where\n  that variable is set.\n\n- Permanently configure the Null keyring for the user by running\n  ``keyring --disable`` or ``python -m keyring --disable``.\n  This approach affects all uses of keyring for that user.\n\n\nAltering Keyring Behavior\n=========================\n\nKeyring provides a mechanism to alter the keyring's behavior through\nenvironment variables. Each backend implements a\n``KeyringBackend.set_properties_from_env``, which\nwhen invoked will find all environment variables beginning with\n``KEYRING_PROPERTY_{NAME}`` and will set a property for each\n``{NAME.lower()}`` on the keyring. This method is invoked during\ninitialization for the default/configured keyring.\n\nThis mechanism may be used to set some useful values on various\nkeyrings, including:\n\n- keychain; macOS, path to an alternate keychain file\n- appid; Linux/SecretService, alternate ID for the application\n\n\nUsing Keyring on Ubuntu 16.04\n=============================\n\nThe following is a complete transcript for installing keyring in a\nvirtual environment on Ubuntu 16.04.  No config file was used::\n\n  $ sudo apt install python3-venv libdbus-glib-1-dev\n  $ cd /tmp\n  $ pyvenv py3\n  $ source py3/bin/activate\n  $ pip install -U pip\n  $ pip install secretstorage dbus-python\n  $ pip install keyring\n  $ python\n  >>> import keyring\n  >>> keyring.get_keyring()\n  <keyring.backends.SecretService.Keyring object at 0x7f9b9c971ba8>\n  >>> keyring.set_password(\"system\", \"username\", \"password\")\n  >>> keyring.get_password(\"system\", \"username\")\n  'password'\n\n\nUsing Keyring on headless Linux systems\n=======================================\n\nIt is possible to use the SecretService backend on Linux systems without\nX11 server available (only D-Bus is required). In this case:\n\n* Install the `GNOME Keyring`_ daemon.\n* Start a D-Bus session, e.g. run ``dbus-run-session -- sh`` and run\n  the following commands inside that shell.\n* Run ``gnome-keyring-daemon`` with ``--unlock`` option. The description of\n  that option says:\n\n      Read a password from stdin, and use it to unlock the login keyring\n      or create it if the login keyring does not exist.\n\n  When that command is started, enter a password into stdin and\n  press Ctrl+D (end of data). After that, the daemon will fork into\n  the background (use ``--foreground`` option to block).\n* Now you can use the SecretService backend of Keyring. Remember to\n  run your application in the same D-Bus session as the daemon.\n\n.. _GNOME Keyring: https://wiki.gnome.org/Projects/GnomeKeyring\n\nUsing Keyring on headless Linux systems in a Docker container\n=============================================================\n\nIt is possible to use keyring with the SecretService backend in Docker containers as well.\nAll you need to do is install the necessary dependencies and add the `--privileged` flag\nto avoid any `Operation not permitted` errors when attempting to unlock the system's keyring.\n\nThe following is a complete transcript for installing keyring on a Ubuntu 18:04 container::\n\n  docker run -it -d --privileged ubuntu:18.04\n\n  $ apt-get update\n  $ apt install -y gnome-keyring python3-venv python3-dev\n  $ python3 -m venv venv\n  $ source venv/bin/activate # source a virtual environment to avoid polluting your system\n  $ pip3 install --upgrade pip\n  $ pip3 install keyring\n  $ dbus-run-session -- sh # this will drop you into a new D-bus shell\n  $ echo 'somecredstorepass' | gnome-keyring-daemon --unlock # unlock the system's keyring\n\n  $ python\n  >>> import keyring\n  >>> keyring.get_keyring()\n  <keyring.backends.SecretService.Keyring object at 0x7f9b9c971ba8>\n  >>> keyring.set_password(\"system\", \"username\", \"password\")\n  >>> keyring.get_password(\"system\", \"username\")\n  'password'\n\nIntegration\n===========\n\nAPI\n---\n\nThe keyring lib has a few functions:\n\n* ``get_keyring()``: Return the currently-loaded keyring implementation.\n* ``get_password(service, username)``: Returns the password stored in the\n  active keyring. If the password does not exist, it will return None.\n* ``get_credential(service, username)``: Return a credential object stored\n  in the active keyring. This object contains at least ``username`` and\n  ``password`` attributes for the specified service, where the returned\n  ``username`` may be different from the argument.\n* ``set_password(service, username, password)``: Store the password in the\n  keyring.\n* ``delete_password(service, username)``: Delete the password stored in\n  keyring. If the password does not exist, it will raise an exception.\n\nIn all cases, the parameters (``service``, ``username``, ``password``)\nshould be Unicode text.\n\n\nExceptions\n----------\n\nThe keyring lib raises the following exceptions:\n\n* ``keyring.errors.KeyringError``: Base Error class for all exceptions in keyring lib.\n* ``keyring.errors.InitError``: Raised when the keyring cannot be initialized.\n* ``keyring.errors.PasswordSetError``: Raised when the password cannot be set in the keyring.\n* ``keyring.errors.PasswordDeleteError``: Raised when the password cannot be deleted in the keyring.\n\nGet Involved\n============\n\nPython keyring lib is an open community project and eagerly\nwelcomes contributors.\n\n* Repository: https://github.com/jaraco/keyring/\n* Bug Tracker: https://github.com/jaraco/keyring/issues/\n* Mailing list: http://groups.google.com/group/python-keyring\n\nSecurity Considerations\n=======================\n\nEach built-in backend may have security considerations to understand\nbefore using this library. Authors of tools or libraries utilizing\n``keyring`` are encouraged to consider these concerns.\n\nAs with any list of known security concerns, this list is not exhaustive.\nAdditional issues can be added as needed.\n\n- macOS Keychain\n    - Any Python script or application can access secrets created by\n      ``keyring`` from that same Python executable without the operating\n      system prompting the user for a password. To cause any specific\n      secret to prompt for a password every time it is accessed, locate\n      the credential using the ``Keychain Access`` application, and in\n      the ``Access Control`` settings, remove ``Python`` from the list\n      of allowed applications.\n\n- Freedesktop Secret Service\n    - No analysis has been performed\n\n- KDE4 & KDE5 KWallet\n    - No analysis has been performed\n\n- Windows Credential Locker\n    - No analysis has been performed\n\nMaking Releases\n===============\n\nThis project makes use of automated releases and continuous\nintegration. The\nsimple workflow is to tag a commit and push it to Github. If it\npasses tests in CI, it will be automatically deployed to PyPI.\n\nOther things to consider when making a release:\n\n- Check that the changelog is current for the intended release.\n\nRunning Tests\n=============\n\nTests are continuously run in Github Actions.\n\nTo run the tests locally, install and invoke\n`tox <https://pypi.org/project/tox>`_.\n\nBackground\n==========\n\nThe project was based on Tarek Ziade's idea in `this post`_. Kang Zhang\ninitially carried it out as a `Google Summer of Code`_ project, and Tarek\nmentored Kang on this project.\n\n.. _this post: http://tarekziade.wordpress.com/2009/03/27/pycon-hallway-session-1-a-keyring-library-for-python/\n.. _Google Summer of Code: http://socghop.appspot.com/\n\nFor Enterprise\n==============\n\nAvailable as part of the Tidelift Subscription.\n\nThis project and the maintainers of thousands of other packages are working with Tidelift to deliver one enterprise subscription that covers all of the open source you use.\n\n`Learn more <https://tidelift.com/subscription/pkg/pypi-keyring?utm_source=pypi-keyring&utm_medium=referral&utm_campaign=github>`_.\n",
        "num_commits": 2249,
        "project_age_days": 3535,
        "project_created_at": "2015-02-24",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 101,
        "num_pull": 176,
        "num_issues": 697,
        "num_opening_issue": 65,
        "project_size(kB)": 3979,
        "num_stargazers": 1257,
        "num_watchers": 1257,
        "num_forks": 159,
        "num_subscribers": 21,
        "SecurityPolicy_created_at": "2023-07-08 01:48:23",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "a7310562fad7a8834c9810c1edd8e00b03e1394b",
                "url": "https://github.com/jaraco/keyring/commit/a7310562fad7a8834c9810c1edd8e00b03e1394b",
                "date": "2023-07-08 01:48:23"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "encode/django-rest-framework",
        "project_url": "https://github.com/encode/django-rest-framework",
        "SSF": {
            "date": "2024-10-29T23:27:30+07:00",
            "repo": {
                "name": "github.com/encode/django-rest-framework",
                "commit": "9016efe3fc412488df92912c619f8f24fed2937c"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.9,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Warn: no status checks found to merge onto branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 6,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 out of 30 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 9,
                    "reason": "Found 29/30 approved changesets -- score normalized to 9",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: peek traffic contributor org/company found, railsadminteam contributor org/company found, awesomeWM contributor org/company found, LeChtiAsso contributor org/company found, requests contributor org/company found, djangolondon contributor org/company found, openplans contributor org/company found, encode oss contributor org/company found, filepreviews contributor org/company found, celery contributor org/company found, python-glasgow contributor org/company found, django-mptt contributor org/company found, Pioneer-Valley-Books contributor org/company found, testbed contributor org/company found, django @djangolondon contributor org/company found, testsuite contributor org/company found, dabapps contributor org/company found, MouvementY contributor org/company found, pytest-dev contributor org/company found, auth0 contributor org/company found, jazzband contributor org/company found, fullstacknights contributor org/company found, openfga contributor org/company found, python-edinburgh contributor org/company found, nose-devs contributor org/company found, django-sme contributor org/company found, Midburn contributor org/company found, appenguin contributor org/company found, capitalone contributor org/company found, yprez contributor org/company found, freelancer up for hire contributor org/company found, greaterhartfordpython contributor org/company found, SixiemeEtage contributor org/company found, stepwise contributor org/company found, inboundli contributor org/company found, lare-team contributor org/company found, FactoryBoy contributor org/company found, django-auth-ldap contributor org/company found, Vimjas contributor org/company found, CodeForPhilly contributor org/company found, pylola contributor org/company found, tox-dev contributor org/company found, pioneer valley books contributor org/company found, google contributor org/company found, building @btnapp contributor org/company found, tempdrop contributor org/company found, django contributor org/company found, TrendBreaker contributor org/company found, dataline contributor org/company found, python-scotland contributor org/company found, whissip contributor org/company found, celery @psf @apache @encode contributor org/company found, python-ldap contributor org/company found, python-distro contributor org/company found, koordinates contributor org/company found, python-attrs contributor org/company found, select2 contributor org/company found, zorg contributor org/company found, encode contributor org/company found, linovia contributor org/company found, pyparsing contributor org/company found, yourlabs contributor org/company found, neomake contributor org/company found, codeforamerica contributor org/company found, pyimgui contributor org/company found, opera software contributor org/company found, lawprct contributor org/company found, mkdocs contributor org/company found, urllib3 contributor org/company found, spotify contributor org/company found, pallets contributor org/company found, katz-consulting-group contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 72 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.md:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "17 commit(s) and 5 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/encode/django-rest-framework/main.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/encode/django-rest-framework/main.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:55: update your workflow using https://app.stepsecurity.io/secureworkflow/encode/django-rest-framework/main.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:57: update your workflow using https://app.stepsecurity.io/secureworkflow/encode/django-rest-framework/main.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pre-commit.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/encode/django-rest-framework/pre-commit.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pre-commit.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/encode/django-rest-framework/pre-commit.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pre-commit.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/encode/django-rest-framework/pre-commit.yml/master?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:35",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:38",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:63",
                        "Info:   0 out of   6 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   3 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/main.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/pre-commit.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/encode/django-rest-framework/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Reporting a Vulnerability\n\nSecurity issues are handled under the supervision of the [Django security team](https://www.djangoproject.com/foundation/teams/#security-team).\n\n **Please report security issues by emailing security@djangoproject.com**.\n\n The project maintainers will then work with you to resolve any issues where required, prior to any public disclosure.\n",
        "project_all_labels": [
            "3.15.1",
            "breaking change",
            "Bug",
            "Cleanup",
            "dependencies",
            "Deprecation",
            "Documentation",
            "Enhancement",
            "Extension eligible",
            "good first issue",
            "help wanted",
            "Interactive API Documentation",
            "Needs confirmation",
            "Needs design decision",
            "Needs further review",
            "Needs information",
            "Needs re-base",
            "Priority",
            "Process",
            "python",
            "Release",
            "Schema Generation",
            "spam",
            "stale",
            "testcase",
            "Usage"
        ],
        "README_content": "# [Django REST framework][docs]\n\n[![build-status-image]][build-status]\n[![coverage-status-image]][codecov]\n[![pypi-version]][pypi]\n\n**Awesome web-browsable Web APIs.**\n\nFull documentation for the project is available at [https://www.django-rest-framework.org/][docs].\n\n---\n\n# Funding\n\nREST framework is a *collaboratively funded project*. If you use\nREST framework commercially we strongly encourage you to invest in its\ncontinued development by [signing up for a paid plan][funding].\n\nThe initial aim is to provide a single full-time position on REST framework.\n*Every single sign-up makes a significant impact towards making that possible.*\n\n[![][sentry-img]][sentry-url]\n[![][stream-img]][stream-url]\n[![][spacinov-img]][spacinov-url]\n[![][retool-img]][retool-url]\n[![][bitio-img]][bitio-url]\n[![][posthog-img]][posthog-url]\n[![][cryptapi-img]][cryptapi-url]\n[![][fezto-img]][fezto-url]\n[![][svix-img]][svix-url]\n[![][zuplo-img]][zuplo-url]\n\nMany thanks to all our [wonderful sponsors][sponsors], and in particular to our premium backers, [Sentry][sentry-url], [Stream][stream-url], [Spacinov][spacinov-url], [Retool][retool-url], [bit.io][bitio-url], [PostHog][posthog-url], [CryptAPI][cryptapi-url], [FEZTO][fezto-url], [Svix][svix-url], and [Zuplo][zuplo-url].\n\n---\n\n# Overview\n\nDjango REST framework is a powerful and flexible toolkit for building Web APIs.\n\nSome reasons you might want to use REST framework:\n\n* The Web browsable API is a huge usability win for your developers.\n* [Authentication policies][authentication] including optional packages for [OAuth1a][oauth1-section] and [OAuth2][oauth2-section].\n* [Serialization][serializers] that supports both [ORM][modelserializer-section] and [non-ORM][serializer-section] data sources.\n* Customizable all the way down - just use [regular function-based views][functionview-section] if you don't need the [more][generic-views] [powerful][viewsets] [features][routers].\n* [Extensive documentation][docs], and [great community support][group].\n\n**Below**: *Screenshot from the browsable API*\n\n![Screenshot][image]\n\n----\n\n# Requirements\n\n* Python 3.8+\n* Django 4.2, 5.0, 5.1\n\nWe **highly recommend** and only officially support the latest patch release of\neach Python and Django series.\n\n# Installation\n\nInstall using `pip`...\n\n    pip install djangorestframework\n\nAdd `'rest_framework'` to your `INSTALLED_APPS` setting.\n```python\nINSTALLED_APPS = [\n    ...\n    'rest_framework',\n]\n```\n\n# Example\n\nLet's take a look at a quick example of using REST framework to build a simple model-backed API for accessing users and groups.\n\nStartup up a new project like so...\n\n    pip install django\n    pip install djangorestframework\n    django-admin startproject example .\n    ./manage.py migrate\n    ./manage.py createsuperuser\n\n\nNow edit the `example/urls.py` module in your project:\n\n```python\nfrom django.contrib.auth.models import User\nfrom django.urls import include, path\nfrom rest_framework import routers, serializers, viewsets\n\n\n# Serializers define the API representation.\nclass UserSerializer(serializers.HyperlinkedModelSerializer):\n    class Meta:\n        model = User\n        fields = ['url', 'username', 'email', 'is_staff']\n\n\n# ViewSets define the view behavior.\nclass UserViewSet(viewsets.ModelViewSet):\n    queryset = User.objects.all()\n    serializer_class = UserSerializer\n\n\n# Routers provide a way of automatically determining the URL conf.\nrouter = routers.DefaultRouter()\nrouter.register(r'users', UserViewSet)\n\n# Wire up our API using automatic URL routing.\n# Additionally, we include login URLs for the browsable API.\nurlpatterns = [\n    path('', include(router.urls)),\n    path('api-auth/', include('rest_framework.urls', namespace='rest_framework')),\n]\n```\n\nWe'd also like to configure a couple of settings for our API.\n\nAdd the following to your `settings.py` module:\n\n```python\nINSTALLED_APPS = [\n    ...  # Make sure to include the default installed apps here.\n    'rest_framework',\n]\n\nREST_FRAMEWORK = {\n    # Use Django's standard `django.contrib.auth` permissions,\n    # or allow read-only access for unauthenticated users.\n    'DEFAULT_PERMISSION_CLASSES': [\n        'rest_framework.permissions.DjangoModelPermissionsOrAnonReadOnly',\n    ]\n}\n```\n\nThat's it, we're done!\n\n    ./manage.py runserver\n\nYou can now open the API in your browser at `http://127.0.0.1:8000/`, and view your new 'users' API. If you use the `Login` control in the top right corner you'll also be able to add, create and delete users from the system.\n\nYou can also interact with the API using command line tools such as [`curl`](https://curl.haxx.se/). For example, to list the users endpoint:\n\n    $ curl -H 'Accept: application/json; indent=4' -u admin:password http://127.0.0.1:8000/users/\n    [\n        {\n            \"url\": \"http://127.0.0.1:8000/users/1/\",\n            \"username\": \"admin\",\n            \"email\": \"admin@example.com\",\n            \"is_staff\": true,\n        }\n    ]\n\nOr to create a new user:\n\n    $ curl -X POST -d username=new -d email=new@example.com -d is_staff=false -H 'Accept: application/json; indent=4' -u admin:password http://127.0.0.1:8000/users/\n    {\n        \"url\": \"http://127.0.0.1:8000/users/2/\",\n        \"username\": \"new\",\n        \"email\": \"new@example.com\",\n        \"is_staff\": false,\n    }\n\n# Documentation & Support\n\nFull documentation for the project is available at [https://www.django-rest-framework.org/][docs].\n\nFor questions and support, use the [REST framework discussion group][group], or `#restframework` on libera.chat IRC.\n\n# Security\n\nPlease see the [security policy][security-policy].\n\n[build-status-image]: https://github.com/encode/django-rest-framework/actions/workflows/main.yml/badge.svg\n[build-status]: https://github.com/encode/django-rest-framework/actions/workflows/main.yml\n[coverage-status-image]: https://img.shields.io/codecov/c/github/encode/django-rest-framework/master.svg\n[codecov]: https://codecov.io/github/encode/django-rest-framework?branch=master\n[pypi-version]: https://img.shields.io/pypi/v/djangorestframework.svg\n[pypi]: https://pypi.org/project/djangorestframework/\n[group]: https://groups.google.com/forum/?fromgroups#!forum/django-rest-framework\n\n[funding]: https://fund.django-rest-framework.org/topics/funding/\n[sponsors]: https://fund.django-rest-framework.org/topics/funding/#our-sponsors\n\n[sentry-img]: https://raw.githubusercontent.com/encode/django-rest-framework/master/docs/img/premium/sentry-readme.png\n[stream-img]: https://raw.githubusercontent.com/encode/django-rest-framework/master/docs/img/premium/stream-readme.png\n[spacinov-img]: https://raw.githubusercontent.com/encode/django-rest-framework/master/docs/img/premium/spacinov-readme.png\n[retool-img]: https://raw.githubusercontent.com/encode/django-rest-framework/master/docs/img/premium/retool-readme.png\n[bitio-img]: https://raw.githubusercontent.com/encode/django-rest-framework/master/docs/img/premium/bitio-readme.png\n[posthog-img]: https://raw.githubusercontent.com/encode/django-rest-framework/master/docs/img/premium/posthog-readme.png\n[cryptapi-img]: https://raw.githubusercontent.com/encode/django-rest-framework/master/docs/img/premium/cryptapi-readme.png\n[fezto-img]: https://raw.githubusercontent.com/encode/django-rest-framework/master/docs/img/premium/fezto-readme.png\n[svix-img]: https://raw.githubusercontent.com/encode/django-rest-framework/master/docs/img/premium/svix-premium.png\n[zuplo-img]: https://raw.githubusercontent.com/encode/django-rest-framework/master/docs/img/premium/zuplo-readme.png\n\n[sentry-url]: https://getsentry.com/welcome/\n[stream-url]: https://getstream.io/?utm_source=DjangoRESTFramework&utm_medium=Webpage_Logo_Ad&utm_content=Developer&utm_campaign=DjangoRESTFramework_Jan2022_HomePage\n[spacinov-url]: https://www.spacinov.com/\n[retool-url]: https://retool.com/?utm_source=djangorest&utm_medium=sponsorship\n[bitio-url]: https://bit.io/jobs?utm_source=DRF&utm_medium=sponsor&utm_campaign=DRF_sponsorship\n[posthog-url]: https://posthog.com?utm_source=drf&utm_medium=sponsorship&utm_campaign=open-source-sponsorship\n[cryptapi-url]: https://cryptapi.io\n[fezto-url]: https://www.fezto.xyz/?utm_source=DjangoRESTFramework\n[svix-url]: https://www.svix.com/?utm_source=django-REST&utm_medium=sponsorship\n[zuplo-url]: https://zuplo.link/django-gh\n\n[oauth1-section]: https://www.django-rest-framework.org/api-guide/authentication/#django-rest-framework-oauth\n[oauth2-section]: https://www.django-rest-framework.org/api-guide/authentication/#django-oauth-toolkit\n[serializer-section]: https://www.django-rest-framework.org/api-guide/serializers/#serializers\n[modelserializer-section]: https://www.django-rest-framework.org/api-guide/serializers/#modelserializer\n[functionview-section]: https://www.django-rest-framework.org/api-guide/views/#function-based-views\n[generic-views]: https://www.django-rest-framework.org/api-guide/generic-views/\n[viewsets]: https://www.django-rest-framework.org/api-guide/viewsets/\n[routers]: https://www.django-rest-framework.org/api-guide/routers/\n[serializers]: https://www.django-rest-framework.org/api-guide/serializers/\n[authentication]: https://www.django-rest-framework.org/api-guide/authentication/\n[image]: https://www.django-rest-framework.org/img/quickstart.png\n\n[docs]: https://www.django-rest-framework.org/\n[security-policy]: https://github.com/encode/django-rest-framework/security/policy\n",
        "num_commits": 8827,
        "project_age_days": 4990,
        "project_created_at": "2011-03-02",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-23",
        "num_contributors": 387,
        "num_pull": 4759,
        "num_issues": 8682,
        "num_opening_issue": 103,
        "project_size(kB)": 53634,
        "num_stargazers": 28354,
        "num_watchers": 28354,
        "num_forks": 6839,
        "num_subscribers": 627,
        "SecurityPolicy_created_at": "2019-05-29 08:57:07",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "070c32f4a62ef0544f58de404c87d86db36fd825",
                "url": "https://github.com/encode/django-rest-framework/commit/070c32f4a62ef0544f58de404c87d86db36fd825",
                "date": "2022-03-16 12:12:25"
            },
            {
                "commit_id": "063f0de949650ee98a4c795d6bcdf994dadbfe4a",
                "url": "https://github.com/encode/django-rest-framework/commit/063f0de949650ee98a4c795d6bcdf994dadbfe4a",
                "date": "2019-05-29 08:57:07"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "zenml-io/zenml",
        "project_url": "https://github.com/zenml-io/zenml",
        "SSF": {
            "date": "2024-10-29T20:27:38+07:00",
            "repo": {
                "name": "github.com/zenml-io/zenml",
                "commit": "5948af2cc94cb0eb6947d244ffa3ae8afb8c0a24"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.4,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: 'branch protection settings apply to administrators' is disable on branch 'main'",
                        "Warn: branch 'main' does not require approvers",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Warn: no status checks found to merge onto branch 'main'",
                        "Warn: PRs are not required to make changes on branch 'main'; or we don't have data to detect it.If you think it might be the latter, make sure to run Scorecard with a PAT or use Repo Rules (that are always public) instead of Branch Protection settings"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "29 out of 29 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 9,
                    "reason": "Found 28/29 approved changesets -- score normalized to 9",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: ekko-realtime contributor org/company found, maiot gmbh contributor org/company found, assetworx contributor org/company found, argilla-io @huggingface contributor org/company found, zenml contributor org/company found, zenml-io contributor org/company found, zenml-io ex @hellofresh ex @alefeducation  ex @sap contributor org/company found, maiot-io contributor org/company found, riverbank contributor org/company found, argilla-io contributor org/company found, adeo contributor org/company found, fuseml contributor org/company found, minfytech contributor org/company found, infoplaza b.v. contributor org/company found, huggingface contributor org/company found, astuto contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 16 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": [
                        "Warn: script injection with untrusted input ' github.event.pull_request.head.ref ': .github/workflows/update-templates-to-examples.yml:72",
                        "Warn: script injection with untrusted input ' github.event.pull_request.head.ref ': .github/workflows/update-templates-to-examples.yml:72",
                        "Warn: script injection with untrusted input ' github.event.pull_request.head.ref ': .github/workflows/update-templates-to-examples.yml:83",
                        "Warn: script injection with untrusted input ' github.event.pull_request.head.ref ': .github/workflows/update-templates-to-examples.yml:143",
                        "Warn: script injection with untrusted input ' github.event.pull_request.head.ref ': .github/workflows/update-templates-to-examples.yml:143",
                        "Warn: script injection with untrusted input ' github.event.pull_request.head.ref ': .github/workflows/update-templates-to-examples.yml:154",
                        "Warn: script injection with untrusted input ' github.event.pull_request.head.ref ': .github/workflows/update-templates-to-examples.yml:216",
                        "Warn: script injection with untrusted input ' github.event.pull_request.head.ref ': .github/workflows/update-templates-to-examples.yml:216",
                        "Warn: script injection with untrusted input ' github.event.pull_request.head.ref ': .github/workflows/update-templates-to-examples.yml:227",
                        "Warn: script injection with untrusted input ' github.event.pull_request.head.ref ': .github/workflows/update-templates-to-examples.yml:287",
                        "Warn: script injection with untrusted input ' github.event.pull_request.head.ref ': .github/workflows/update-templates-to-examples.yml:287",
                        "Warn: script injection with untrusted input ' github.event.pull_request.head.ref ': .github/workflows/update-templates-to-examples.yml:298"
                    ],
                    "score": 0,
                    "reason": "dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/publish_docker_image.yml:17"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-fast.yml:68: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-fast.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-fast.yml:70: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-fast.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-fast.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-fast.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-fast.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-fast.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-fast.yml:43: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-fast.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-fast.yml:47: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-fast.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-fast.yml:57: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-fast.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci-fast.yml:59: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-fast.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-slow.yml:114: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-slow.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-slow.yml:118: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-slow.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-slow.yml:67: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-slow.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-slow.yml:71: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-slow.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci-slow.yml:75: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-slow.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-slow.yml:90: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-slow.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-slow.yml:94: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-slow.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci-slow.yml:98: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-slow.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-slow.yml:131: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-slow.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-slow.yml:135: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-slow.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci-slow.yml:139: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-slow.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-slow.yml:151: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-slow.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-slow.yml:153: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-slow.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci-slow.yml:168: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-slow.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-slow.yml:26: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-slow.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-slow.yml:47: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-slow.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-slow.yml:49: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/ci-slow.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:26: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/codeql.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/codeql.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/codeql.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/generate-test-duration.yml:26: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/generate-test-duration.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/image-optimiser.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/image-optimiser.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/image-optimiser.yml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/image-optimiser.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/integration-test-fast.yml:105: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/integration-test-fast.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/integration-test-fast.yml:121: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/integration-test-fast.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/integration-test-fast.yml:123: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/integration-test-fast.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/integration-test-fast.yml:129: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/integration-test-fast.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/integration-test-fast.yml:134: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/integration-test-fast.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/integration-test-fast.yml:139: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/integration-test-fast.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/integration-test-fast.yml:225: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/integration-test-fast.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/integration-test-fast.yml:233: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/integration-test-fast.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/integration-test-fast.yml:242: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/integration-test-fast.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/integration-test-slow.yml:105: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/integration-test-slow.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/integration-test-slow.yml:122: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/integration-test-slow.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/integration-test-slow.yml:129: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/integration-test-slow.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/integration-test-slow.yml:131: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/integration-test-slow.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/integration-test-slow.yml:137: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/integration-test-slow.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/integration-test-slow.yml:142: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/integration-test-slow.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/integration-test-slow.yml:225: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/integration-test-slow.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/integration-test-slow.yml:233: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/integration-test-slow.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/integration-test-slow.yml:240: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/integration-test-slow.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pr_labeler.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/pr_labeler.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pr_labeler.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/pr_labeler.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_api_docs.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/publish_api_docs.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_api_docs.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/publish_api_docs.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_api_docs.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/publish_api_docs.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_docker_image.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/publish_docker_image.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish_docker_image.yml:44: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/publish_docker_image.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish_docker_image.yml:59: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/publish_docker_image.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_helm_chart.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/publish_helm_chart.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish_helm_chart.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/publish_helm_chart.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish_helm_chart.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/publish_helm_chart.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish_helm_chart.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/publish_helm_chart.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_stack_templates.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/publish_stack_templates.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish_stack_templates.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/publish_stack_templates.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_to_pypi.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/publish_to_pypi.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_to_pypi.yml:23: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/publish_to_pypi.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish_to_pypi.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/publish_to_pypi.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish_to_pypi.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/publish_to_pypi.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_to_pypi_nightly.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/publish_to_pypi_nightly.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_to_pypi_nightly.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/publish_to_pypi_nightly.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish_to_pypi_nightly.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/publish_to_pypi_nightly.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish_to_pypi_nightly.yml:62: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/publish_to_pypi_nightly.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:122: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:57: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:61: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release.yml:65: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release_finalize.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release_finalize.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release_finalize.yml:49: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release_finalize.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release_finalize.yml:69: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release_finalize.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release_finalize.yml:83: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release_finalize.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release_finalize.yml:88: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release_finalize.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release_finalize.yml:118: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release_finalize.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release_prepare.yml:224: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release_prepare.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release_prepare.yml:227: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release_prepare.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release_prepare.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release_prepare.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release_prepare.yml:50: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release_prepare.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release_prepare.yml:64: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release_prepare.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release_prepare.yml:145: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release_prepare.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release_prepare.yml:147: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release_prepare.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release_prepare.yml:161: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release_prepare.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release_prepare.yml:186: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release_prepare.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release_prepare.yml:189: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/release_prepare.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/spellcheck.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/spellcheck.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/spellcheck.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/spellcheck.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/templates-test.yml:52: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/templates-test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/trivy-zenml-core.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/trivy-zenml-core.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/trivy-zenml-core.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/trivy-zenml-core.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/trivy-zenml-core.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/trivy-zenml-core.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/trivy-zenserver.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/trivy-zenserver.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/trivy-zenserver.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/trivy-zenserver.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/trivy-zenserver.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/trivy-zenserver.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/unit-test.yml:76: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/unit-test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/unit-test.yml:95: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/unit-test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/unit-test.yml:109: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/unit-test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/update-templates-to-examples.yml:187: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/update-templates-to-examples.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/update-templates-to-examples.yml:204: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/update-templates-to-examples.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/update-templates-to-examples.yml:235: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/update-templates-to-examples.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/update-templates-to-examples.yml:260: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/update-templates-to-examples.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/update-templates-to-examples.yml:275: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/update-templates-to-examples.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/update-templates-to-examples.yml:306: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/update-templates-to-examples.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/update-templates-to-examples.yml:44: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/update-templates-to-examples.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/update-templates-to-examples.yml:60: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/update-templates-to-examples.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/update-templates-to-examples.yml:91: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/update-templates-to-examples.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/update-templates-to-examples.yml:116: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/update-templates-to-examples.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/update-templates-to-examples.yml:132: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/update-templates-to-examples.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/update-templates-to-examples.yml:162: update your workflow using https://app.stepsecurity.io/secureworkflow/zenml-io/zenml/update-templates-to-examples.yml/main?enable=pin",
                        "Warn: containerImage not pinned by hash: docker/base.Dockerfile:6",
                        "Warn: containerImage not pinned by hash: docker/base.Dockerfile:21",
                        "Warn: containerImage not pinned by hash: docker/base.Dockerfile:44",
                        "Warn: containerImage not pinned by hash: docker/base.Dockerfile:63",
                        "Warn: containerImage not pinned by hash: docker/base.Dockerfile:82",
                        "Warn: containerImage not pinned by hash: docker/base.Dockerfile:124",
                        "Warn: containerImage not pinned by hash: docker/zenml-dev.Dockerfile:4",
                        "Warn: containerImage not pinned by hash: docker/zenml-dev.Dockerfile:19",
                        "Warn: containerImage not pinned by hash: docker/zenml-dev.Dockerfile:65",
                        "Warn: containerImage not pinned by hash: docker/zenml-quickstart-dev.Dockerfile:3",
                        "Warn: containerImage not pinned by hash: docker/zenml-quickstart.Dockerfile:4",
                        "Warn: containerImage not pinned by hash: docker/zenml-server-dev.Dockerfile:4",
                        "Warn: containerImage not pinned by hash: docker/zenml-server-dev.Dockerfile:19",
                        "Warn: containerImage not pinned by hash: docker/zenml-server-dev.Dockerfile:67",
                        "Warn: containerImage not pinned by hash: docker/zenml-server-hf-spaces.Dockerfile:1: pin your Docker image by updating zenmldocker/zenml-server:latest to zenmldocker/zenml-server:latest@sha256:4d6b6414a7194bae5436dabe68a65bcd8c7b726aaa371545b4039f4ace8e42af",
                        "Warn: containerImage not pinned by hash: examples/e2e_nlp/gradio/Dockerfile:4: pin your Docker image by updating python:3.9 to python:3.9@sha256:ed8b9dd4e9f89c111f4bdb85a55f8c9f0e22796a298449380b15f627d9914095",
                        "Warn: pipCommand not pinned by hash: docker/base.Dockerfile:54-61",
                        "Warn: pipCommand not pinned by hash: docker/base.Dockerfile:54-61",
                        "Warn: pipCommand not pinned by hash: docker/base.Dockerfile:73-80",
                        "Warn: pipCommand not pinned by hash: docker/base.Dockerfile:73-80",
                        "Warn: pipCommand not pinned by hash: docker/zenml-dev.Dockerfile:53-55",
                        "Warn: pipCommand not pinned by hash: docker/zenml-dev.Dockerfile:53-55",
                        "Warn: pipCommand not pinned by hash: docker/zenml-dev.Dockerfile:61",
                        "Warn: pipCommand not pinned by hash: docker/zenml-quickstart-dev.Dockerfile:12",
                        "Warn: pipCommand not pinned by hash: docker/zenml-quickstart.Dockerfile:15",
                        "Warn: pipCommand not pinned by hash: docker/zenml-server-dev.Dockerfile:55-57",
                        "Warn: pipCommand not pinned by hash: docker/zenml-server-dev.Dockerfile:55-57",
                        "Warn: pipCommand not pinned by hash: docker/zenml-server-dev.Dockerfile:63",
                        "Warn: pipCommand not pinned by hash: examples/e2e_nlp/gradio/Dockerfile:10",
                        "Warn: pipCommand not pinned by hash: scripts/format.sh:37",
                        "Warn: pipCommand not pinned by hash: scripts/generate-docs.sh:54",
                        "Warn: pipCommand not pinned by hash: scripts/install-zenml-dev.sh:83",
                        "Warn: pipCommand not pinned by hash: scripts/test-migrations.sh:329",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/ci-fast.yml:29",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/ci-slow.yml:158",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/ci-slow.yml:54",
                        "Warn: pipCommand not pinned by hash: .github/workflows/integration-test-fast.yml:158",
                        "Warn: chocoCommand not pinned by hash: .github/workflows/integration-test-fast.yml:171",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/integration-test-fast.yml:208",
                        "Warn: pipCommand not pinned by hash: .github/workflows/integration-test-slow.yml:158",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/integration-test-slow.yml:208",
                        "Warn: npmCommand not pinned by hash: .github/workflows/publish_api_docs.yml:28",
                        "Warn: npmCommand not pinned by hash: .github/workflows/publish_api_docs.yml:29",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release_finalize.yml:94",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release_finalize.yml:95",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release_prepare.yml:195",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release_prepare.yml:196",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release_prepare.yml:241",
                        "Warn: pipCommand not pinned by hash: .github/workflows/update-templates-to-examples.yml:68",
                        "Warn: pipCommand not pinned by hash: .github/workflows/update-templates-to-examples.yml:139",
                        "Warn: pipCommand not pinned by hash: .github/workflows/update-templates-to-examples.yml:212",
                        "Warn: pipCommand not pinned by hash: .github/workflows/update-templates-to-examples.yml:283",
                        "Info:   0 out of  72 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of  48 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of  16 containerImage dependencies pinned",
                        "Info:   0 out of  28 pipCommand dependencies pinned",
                        "Info:   0 out of   5 downloadThenRun dependencies pinned",
                        "Info:   0 out of   1 chocoCommand dependencies pinned",
                        "Info:   0 out of   2 npmCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Warn: 17 commits out of 29 are checked with a SAST tool"
                    ],
                    "score": 8,
                    "reason": "SAST tool detected but not run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql.yml:17",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql.yml:18",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/nightly_build.yml:20",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/publish_docker_image.yml:21",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/publish_helm_chart.yml:12",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/publish_stack_templates.yml:11",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/publish_to_pypi.yml:12",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/release_prepare.yml:140",
                        "Warn: no topLevel permission defined: .github/workflows/ci-fast.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/ci-slow.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/codeql.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/generate-test-duration.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/image-optimiser.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/integration-test-fast.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/integration-test-slow.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/nightly_build.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/pr_labeler.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish_api_docs.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish_docker_image.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish_helm_chart.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish_stack_templates.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish_to_pypi.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish_to_pypi_nightly.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release_finalize.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release_prepare.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/spellcheck.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/templates-test.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/trivy-zenml-core.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/trivy-zenserver.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/unit-test.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/update-templates-to-examples.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-29gw-9793-fvw7",
                        "Warn: Project is vulnerable to: GHSA-282v-666c-3fvg",
                        "Warn: Project is vulnerable to: GHSA-37q5-v5qm-c9v8",
                        "Warn: Project is vulnerable to: GHSA-3863-2447-669p",
                        "Warn: Project is vulnerable to: GHSA-v68g-wm8c-6x7j",
                        "Warn: Project is vulnerable to: GHSA-7gjr-hcc3-xfr4",
                        "Warn: Project is vulnerable to: GHSA-99hm-86h7-gr3g",
                        "Warn: Project is vulnerable to: GHSA-3p4q-x8f3-p7vq / PYSEC-2018-18",
                        "Warn: Project is vulnerable to: GHSA-4952-p58q-6crx",
                        "Warn: Project is vulnerable to: GHSA-49qr-xh3w-h436 / PYSEC-2018-17",
                        "Warn: Project is vulnerable to: GHSA-6cwv-x26c-w2q4 / PYSEC-2018-57",
                        "Warn: Project is vulnerable to: GHSA-c7vm-f5p4-8fqh / PYSEC-2020-215",
                        "Warn: Project is vulnerable to: GHSA-hhx8-cr55-qcxx / PYSEC-2019-159",
                        "Warn: Project is vulnerable to: GHSA-hwvq-6gjx-j797",
                        "Warn: Project is vulnerable to: GHSA-jqwc-jm56-wcwj / PYSEC-2019-157",
                        "Warn: Project is vulnerable to: GHSA-m87f-39q9-6f55 / PYSEC-2022-180",
                        "Warn: Project is vulnerable to: GHSA-rcx2-m7jp-p9wj / PYSEC-2019-158",
                        "Warn: Project is vulnerable to: GHSA-rv62-4pmj-xw6h",
                        "Warn: Project is vulnerable to: GHSA-v7vq-3x77-87vg / PYSEC-2022-212",
                        "Warn: Project is vulnerable to: GHSA-6h3f-43vq-53hj",
                        "Warn: Project is vulnerable to: GHSA-9x88-4jg8-4vf7",
                        "Warn: Project is vulnerable to: GHSA-c546-8jmq-hprj / PYSEC-2024-105",
                        "Warn: Project is vulnerable to: GHSA-g3r5-72hf-p7p2",
                        "Warn: Project is vulnerable to: GHSA-j527-v579-m98h",
                        "Warn: Project is vulnerable to: GHSA-mq73-g4qr-fgcq",
                        "Warn: Project is vulnerable to: GHSA-vwgf-7f9h-h499"
                    ],
                    "score": 0,
                    "reason": "26 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/zenml-io/zenml/contents/SECURITY.md",
        "SecurityPolicy_content": "#  Reporting a Vulnerability\n\nIf you think you have found a vulnerability, and even if you are not sure about it,\nplease report it right away by sending an\nemail to: [security@zenml.io](mailto:security@zenml.io?subject=Security%20Vulnerability%20Found). Please try to be as explicit as possible,\ndescribing all the steps and example code to\nreproduce the security issue.\n\nWe will review it thoroughly and get back to you.\n\nPlease refrain from publicly discussing a potential security vulnerability as\nthis could potentially put our users at\nrisk! It's better to discuss privately and give us a chance to find a solution\nfirst, to limit the potential impact\nas much as possible.\n",
        "project_all_labels": [
            "backport",
            "breaking-change",
            "bug",
            "cache-miss",
            "CI",
            "dependencies",
            "documentation",
            "duplicate",
            "enhancement",
            "fix",
            "good first issue",
            "good-second-issue",
            "hacktoberfest",
            "hacktoberfest-accepted",
            "help wanted",
            "internal",
            "invalid",
            "P0",
            "P1",
            "P2",
            "P3",
            "python",
            "question",
            "requires-frontend-changes",
            "run-slow-ci",
            "security",
            "tests",
            "wontfix"
        ],
        "README_content": "<div align=\"center\">\n  <img referrerpolicy=\"no-referrer-when-downgrade\" src=\"https://static.scarf.sh/a.png?x-pxid=0fcbab94-8fbe-4a38-93e8-c2348450a42e\" />\n  <h1 align=\"center\">Connecting data science teams seamlessly to cloud infrastructure.\n</h1>\n</div>\n\n<!-- PROJECT SHIELDS -->\n<!--\n*** I'm using markdown \"reference style\" links for readability.\n*** Reference links are enclosed in brackets [ ] instead of parentheses ( ).\n*** See the bottom of this document for the declaration of the reference variables\n*** for contributors-url, forks-url, etc. This is an optional, concise syntax you may use.\n*** https://www.markdownguide.org/basic-syntax/#reference-style-links\n-->\n\n<div align=\"center\">\n\n  <!-- PROJECT LOGO -->\n  <br />\n    <a href=\"https://zenml.io\">\n      <img alt=\"ZenML Logo\" src=\"docs/book/.gitbook/assets/header.png\" alt=\"ZenML Logo\">\n    </a>\n  <br />\n\n  [![PyPi][pypi-shield]][pypi-url]\n  [![PyPi][pypiversion-shield]][pypi-url]\n  [![PyPi][downloads-shield]][downloads-url]\n  [![Contributors][contributors-shield]][contributors-url]\n  [![License][license-shield]][license-url]\n  <!-- [![Build][build-shield]][build-url] -->\n  <!-- [![CodeCov][codecov-shield]][codecov-url] -->\n\n</div>\n\n<!-- MARKDOWN LINKS & IMAGES -->\n<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->\n\n[pypi-shield]: https://img.shields.io/pypi/pyversions/zenml?color=281158\n\n[pypi-url]: https://pypi.org/project/zenml/\n\n[pypiversion-shield]: https://img.shields.io/pypi/v/zenml?color=361776\n\n[downloads-shield]: https://img.shields.io/pypi/dm/zenml?color=431D93\n\n[downloads-url]: https://pypi.org/project/zenml/\n\n[codecov-shield]: https://img.shields.io/codecov/c/gh/zenml-io/zenml?color=7A3EF4\n\n[codecov-url]: https://codecov.io/gh/zenml-io/zenml\n\n[contributors-shield]: https://img.shields.io/github/contributors/zenml-io/zenml?color=7A3EF4\n\n[contributors-url]: https://github.com/zenml-io/zenml/graphs/contributors\n\n[license-shield]: https://img.shields.io/github/license/zenml-io/zenml?color=9565F6\n\n[license-url]: https://github.com/zenml-io/zenml/blob/main/LICENSE\n\n[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&logo=linkedin&colorB=555\n\n[linkedin-url]: https://www.linkedin.com/company/zenml/\n\n[twitter-shield]: https://img.shields.io/twitter/follow/zenml_io?style=for-the-badge\n\n[twitter-url]: https://twitter.com/zenml_io\n\n[slack-shield]: https://img.shields.io/badge/-Slack-black.svg?style=for-the-badge&logo=linkedin&colorB=555\n\n[slack-url]: https://zenml.io/slack-invite\n\n[build-shield]: https://img.shields.io/github/workflow/status/zenml-io/zenml/Build,%20Lint,%20Unit%20&%20Integration%20Test/develop?logo=github&style=for-the-badge\n\n[build-url]: https://github.com/zenml-io/zenml/actions/workflows/ci.yml\n\n---\n\n##  Show Your Support\n\nIf you find ZenML helpful or interesting, please consider giving us a star on GitHub. Your support helps promote the project and lets others know that it's worth checking out. \n\nThank you for your support! \n\n[![Star this project](https://img.shields.io/github/stars/zenml-io/zenml?style=social)](https://github.com/zenml-io/zenml/stargazers)\n\n##  Quickstart\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zenml-io/zenml/blob/main/examples/quickstart/quickstart.ipynb)\n\n[Install ZenML](https://docs.zenml.io/getting-started/installation) via [PyPI](https://pypi.org/project/zenml/). Python 3.9 - 3.12 is required:\n\n```bash\npip install \"zenml[server]\" notebook\n```\n\nTake a tour with the guided quickstart by running:\n\n```bash\nzenml go\n```\n\n##  Simple, integrated, End-to-end MLOps \n\n### Create machine learning pipelines with minimal code changes\n\nZenML is a MLOps framework intended for data scientists or ML engineers looking to standardize machine learning practices. Just add `@step` and `@pipeline` to your existing Python functions to get going. Here is a toy example:\n\n```python\nfrom zenml import pipeline, step\n\n@step  # Just add this decorator\ndef load_data() -> dict:\n    training_data = [[1, 2], [3, 4], [5, 6]]\n    labels = [0, 1, 0]\n    return {'features': training_data, 'labels': labels}\n\n@step\ndef train_model(data: dict) -> None:\n    total_features = sum(map(sum, data['features']))\n    total_labels = sum(data['labels'])\n    \n    print(f\"Trained model using {len(data['features'])} data points. \"\n          f\"Feature sum is {total_features}, label sum is {total_labels}\")\n\n@pipeline  # This function combines steps together \ndef simple_ml_pipeline():\n    dataset = load_data()\n    train_model(dataset)\n\nif __name__ == \"__main__\":\n    run = simple_ml_pipeline()  # call this to run the pipeline\n   \n```\n\n![Running a ZenML pipeline](/docs/book/.gitbook/assets/readme_basic_pipeline.gif)\n\n### Easily provision an MLOps stack or reuse your existing infrastructure\n\nThe framework is a gentle entry point for practitioners to build complex ML pipelines with little knowledge required of the underlying infrastructure complexity. ZenML pipelines can be run on AWS, GCP, Azure, Airflow, Kubeflow and even on Kubernetes without having to change any code or know underlying internals. \n\nZenML provides different features to aid people to get started quickly on a remote setting as well. If you want to deploy a remote stack from scratch on your selected cloud provider, you can use the 1-click deployment feature either through the dashboard:\n\n![Running a ZenML pipeline](/docs/book/.gitbook/assets/one-click-deployment.gif)\n\nOr, through our CLI command:\n\n```bash\nzenml stack deploy --provider aws\n```\n\nAlternatively, if the necessary pieces of infrastructure is already deployed, you can register a cloud stack seamlessly through the stack wizard:\n\n```bash\nzenml stack register <STACK_NAME> --provider aws\n```\n\nRead more about [ZenML stacks](https://docs.zenml.io/user-guide/production-guide/understand-stacks).\n\n### Run workloads easily on your production infrastructure\n\nOnce you have your MLOps stack configured, you can easily run workloads on it:\n\n```bash\nzenml stack set <STACK_NAME>\npython run.py\n```\n\n```python\nfrom zenml.config import ResourceSettings, DockerSettings\n\n@step(\n  settings={\n    \"resources\": ResourceSettings(memory=\"16GB\", gpu_count=\"1\", cpu_count=\"8\"),\n    \"docker\": DockerSettings(parent_image=\"pytorch/pytorch:1.12.1-cuda11.3-cudnn8-runtime\")\n  }\n)\ndef training(...):\n\t...\n```\n\n![Workloads with ZenML](/docs/book/.gitbook/assets/readme_compute.gif)\n\n### Track models, pipeline, and artifacts\n\nCreate a complete lineage of who, where, and what data and models are produced.\n\nYoull be able to find out who produced which model, at what time, with which data, and on which version of the code. This guarantees full reproducibility and auditability.\n\n```python\nfrom zenml import Model\n\n@step(model=Model(name=\"classification\"))\ndef trainer(training_df: pd.DataFrame) -> Annotated[\"model\", torch.nn.Module]:\n\t...\n```\n\n![Exploring ZenML Models](/docs/book/.gitbook/assets/readme_mcp.gif)\n\n### Purpose built for machine learning with integration to you favorite tools\n\nWhile ZenML brings a lot of value of the box, it also integrates into your existing tooling and infrastructure without you having to be locked in.\n\n```python\nfrom bentoml._internal.bento import bento\n\n@step(on_failure=alert_slack, experiment_tracker=\"mlflow\")\ndef train_and_deploy(training_df: pd.DataFrame) -> bento.Bento\n\tmlflow.autolog()\n\t...\n\treturn bento\n```\n\n![Exploring ZenML Integrations](/docs/book/.gitbook/assets/readme_integrations.gif)\n\n##  Learning\n\nThe best way to learn about ZenML is the [docs](https://docs.zenml.io/). We recommend beginning with the [Starter Guide](https://docs.zenml.io/user-guide/starter-guide) to get up and running quickly.\n\nIf you are a visual learner, this 11-minute video tutorial is also a great start:\n\n[![Introductory Youtube Video](docs/book/.gitbook/assets/readme_youtube_thumbnail.png)](https://www.youtube.com/watch?v=wEVwIkDvUPs)\n\nAnd finally, here are some other examples and use cases for inspiration:\n\n1. [E2E Batch Inference](examples/e2e/): Feature engineering, training, and inference pipelines for tabular machine learning.\n2. [Basic NLP with BERT](examples/e2e_nlp/): Feature engineering, training, and inference focused on NLP.\n3. [LLM RAG Pipeline with Langchain and OpenAI](https://github.com/zenml-io/zenml-projects/tree/main/llm-agents): Using Langchain to create a simple RAG pipeline.\n4. [Huggingface Model to Sagemaker Endpoint](https://github.com/zenml-io/zenml-projects/tree/main/huggingface-sagemaker): Automated MLOps on Amazon Sagemaker and HuggingFace\n5. [LLMops](https://github.com/zenml-io/zenml-projects/tree/main/llm-complete-guide): Complete guide to do LLM with ZenML\n\n\n##  Deploy ZenML\n\nFor full functionality ZenML should be deployed on the cloud to\nenable collaborative features as the central MLOps interface for teams.\n\nCurrently, there are two main ways to deploy ZenML:\n\n- **ZenML Pro**: [ZenML Pro](cloud.zenml.io/?utm_source=readme&utm_medium=referral_link&utm_campaign=cloud_promotion&utm_content=signup_link),\noffers a SaaS version which comes with a control plane to create and manage multiple ZenML servers.\nThese servers are managed and maintained by ZenMLs dedicated team, alleviating\nthe burden of server management from your end. They also come with additional features like RBAC, a Model Control Plane\nand [much more](https://zenml-io.gitbook.io/zenml-documentation/getting-started/zenml-pro.\n- **Self-hosted deployment**: Alternatively, you have the flexibility to [deploy\nZenML on your own self-hosted environment](https://docs.zenml.io/getting-started/deploying-zenml#deploying-a-zenml-server).\nThis can be achieved through various methods, including using our CLI, Docker,\nHelm, or HuggingFace Spaces.\n\n## Use ZenML with VS Code\n\nZenML has a [VS Code extension](https://marketplace.visualstudio.com/items?itemName=ZenML.zenml-vscode) that allows you to inspect your stacks and pipeline runs directly from your editor. The extension also allows you to switch your stacks without needing to type any CLI commands.\n\n<details>\n  <summary> VS Code Extension in Action!</summary>\n  <div align=\"center\">\n  <img width=\"60%\" src=\"/docs/book/.gitbook/assets/zenml-extension-shortened.gif\" alt=\"ZenML Extension\">\n</div>\n</details>\n\n##  Roadmap\n\nZenML is being built in public. The [roadmap](https://zenml.io/roadmap) is a regularly updated source of truth for the ZenML community to understand where the product is going in the short, medium, and long term.\n\nZenML is managed by a [core team](https://zenml.io/company) of developers that are responsible for making key decisions and incorporating feedback from the community. The team oversees feedback via various channels,\nand you can directly influence the roadmap as follows:\n\n- Vote on your most wanted feature on our [Discussion\nboard](https://zenml.io/discussion).\n- Start a thread in our [Slack channel](https://zenml.io/slack).\n- [Create an issue](https://github.com/zenml-io/zenml/issues/new/choose) on our GitHub repo.\n\n##  Contributing and Community\n\nWe would love to develop ZenML together with our community! The best way to get\nstarted is to select any issue from the `[good-first-issue`\nlabel](https://github.com/issues?q=is%3Aopen+is%3Aissue+archived%3Afalse+user%3Azenml-io+label%3A%22good+first+issue%22)\nand open up a Pull Request! \n\nIf you\nwould like to contribute, please review our [Contributing\nGuide](CONTRIBUTING.md) for all relevant details.\n\n##  Getting Help\n\nThe first point of call should\nbe [our Slack group](https://zenml.io/slack-invite/).\nAsk your questions about bugs or specific use cases, and someone from\nthe [core team](https://zenml.io/company) will respond.\nOr, if you\nprefer, [open an issue](https://github.com/zenml-io/zenml/issues/new/choose) on\nour GitHub repo.\n\n##  Show Your Support\n\nIf you find ZenML helpful or interesting, please consider giving us a star on GitHub. Your support helps promote the project and lets others know that it's worth checking out. \n\nThank you for your support! \n\n[![Star this project](https://img.shields.io/github/stars/zenml-io/zenml?style=social)](https://github.com/zenml-io/zenml/stargazers)\n\n##  License\n\nZenML is distributed under the terms of the Apache License Version 2.0.\nA complete version of the license is available in the [LICENSE](LICENSE) file in\nthis repository. Any contribution made to this project will be licensed under\nthe Apache License Version 2.0.\n\n<div>\n<p align=\"left\">\n    <div align=\"left\">\n      Join our <a href=\"https://zenml.io/slack\" target=\"_blank\">\n      <img width=\"18\" src=\"https://cdn3.iconfinder.com/data/icons/logos-and-brands-adobe/512/306_Slack-512.png\" alt=\"Slack\"/>\n    <b>Slack Community</b> </a> and be part of the ZenML family.\n    </div>\n    <br />\n    <a href=\"https://zenml.io/features\">Features</a>\n    \n    <a href=\"https://zenml.io/roadmap\">Roadmap</a>\n    \n    <a href=\"https://github.com/zenml-io/zenml/issues\">Report Bug</a>\n    \n    <a href=\"https://zenml.io/pro\">Sign up for ZenML Pro</a>\n    \n    <a href=\"https://www.zenml.io/blog\">Read Blog</a>\n    \n    <a href=\"https://github.com/issues?q=is%3Aopen+is%3Aissue+archived%3Afalse+user%3Azenml-io+label%3A%22good+first+issue%22\">Contribute to Open Source</a>\n    \n    <a href=\"https://github.com/zenml-io/zenml-projects\">Projects Showcase</a>\n    <br />\n    <br />\n     Version 0.68.0 is out. Check out the release notes\n    <a href=\"https://github.com/zenml-io/zenml/releases\">here</a>.\n    <br />\n     Download our VS Code Extension <a href=\"https://marketplace.visualstudio.com/items?itemName=ZenML.zenml-vscode\">here</a>.\n    <br />\n  </p>\n</div>\n",
        "num_commits": 6838,
        "project_age_days": 1440,
        "project_created_at": "2020-11-19",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 97,
        "num_pull": 2837,
        "num_issues": 3136,
        "num_opening_issue": 59,
        "project_size(kB)": 576232,
        "num_stargazers": 4032,
        "num_watchers": 4032,
        "num_forks": 437,
        "num_subscribers": 41,
        "SecurityPolicy_created_at": "2023-09-20 09:25:58",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "a74bfdca3a8cad637c16a2a3eaf090ee3a1430be",
                "url": "https://github.com/zenml-io/zenml/commit/a74bfdca3a8cad637c16a2a3eaf090ee3a1430be",
                "date": "2024-04-22 11:07:56"
            },
            {
                "commit_id": "92d70d3dc153c8634b92b8d2a627eba446f8eca0",
                "url": "https://github.com/zenml-io/zenml/commit/92d70d3dc153c8634b92b8d2a627eba446f8eca0",
                "date": "2023-09-20 09:25:58"
            }
        ],
        "project_security_labels": [
            "security"
        ],
        "security_issues": [
            {
                "url": "https://github.com/zenml-io/zenml/pull/2587",
                "title": "Check old password during password change and add missing CLI commands",
                "labels": [
                    "bug",
                    "internal",
                    "security",
                    "run-slow-ci",
                    "P2"
                ],
                "user": "stefannica",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2587,
                "id": 2226139907,
                "state": "closed",
                "project_created_at": "2024-04-04T17:34:45Z",
                "closed_at": "2024-04-09T07:22:03Z",
                "body": "## Describe changes\r\nAs an extra security measure, this PR always requires that the current password value be supplied during a password change.\r\n\r\nAdditional related changes:\r\n* implement a separate `zenml user change-password` CLI command for changing the password for the current user\r\n* warn about passing passwords using command-line arguments in `zenml user change-password`, `zenml user create` and `zenml user update`\r\n* warn about using username/password to connect to a ZenML server and suggest using the web login flow or a service account API key instead\r\n* allow a user account to be activated and deactivated through `zenml user update`\r\n* implement the `zenml user deactivate` CLI command to be used to reset other user accounts through the CLI (by admins only).\r\n\r\n**IMPORTANT**: this change invalidates the current ZenML Dashboard password change support. A dashboard update is required to pass the current password to the call made to the API (handled with https://github.com/zenml-io/zenml-dashboard/pull/556)\r\n\r\n## Pre-requisites\r\nPlease ensure you have done the following:\r\n- [x] I have read the **CONTRIBUTING.md** document.\r\n- [ ] If my change requires a change to docs, I have updated the documentation accordingly.\r\n- [ ] I have added tests to cover my changes.\r\n- [x] I have based my new branch on `develop` and the open PR is targeting `develop`. If your branch wasn't based on develop read [Contribution guide on rebasing branch to develop](https://github.com/zenml-io/zenml/blob/main/CONTRIBUTING.md#-pull-requests-rebase-your-branch-on-develop).\r\n- [x] If my changes require changes to the dashboard, these changes are communicated/requested.\r\n\r\n## Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Other (add details above)\r\n\r\n",
                "comments": [
                    {
                        "body": "<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- This is an auto-generated comment: skip review by coderabbit.ai -->\n\n> [!IMPORTANT]\n> ## Auto Review Skipped\n> \n> Auto reviews are disabled on this repository.\n> \n> Please check the settings in the CodeRabbit UI or the `.coderabbit.yaml` file in this repository.\n> \n> To trigger a single review, invoke the `@coderabbitai review` command.\n> \n\n<!-- end of auto-generated comment: skip review by coderabbit.ai --><!-- tweet_start -->\n\nThank you for using CodeRabbit. We offer it for free to the OSS community and would appreciate your support in helping us grow. If you find it useful, would you consider giving us a shout-out on your favorite social media?\n\n<details>\n<summary>Share</summary>\n\n- [X](https://twitter.com/intent/tweet?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A&url=https%3A//coderabbit.ai)\n- [Mastodon](https://mastodon.social/share?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A%20https%3A%2F%2Fcoderabbit.ai)\n- [Reddit](https://www.reddit.com/submit?title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&text=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code.%20Check%20it%20out%3A%20https%3A//coderabbit.ai)\n- [LinkedIn](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcoderabbit.ai&mini=true&title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&summary=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code)\n\n</details>\n\n<!-- tweet_end --><!-- tips_start -->\n\n---\n\n<details>\n<summary>Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n- Review comments: Directly reply to a review comment made by CodeRabbit. Example:\n\t- `I pushed a fix in commit <commit_id>.`\n\t- `Generate unit testing code for this file.`\n\t- `Open a follow-up GitHub issue for this discussion.`\n- Files and specific lines of code (under the \"Files changed\" tab): Tag `@coderabbitai` in a new review comment at the desired location with your query. Examples:\n\t- `@coderabbitai generate unit testing code for this file.`\n\t-\t`@coderabbitai modularize this function.`\n- PR comments: Tag `@coderabbitai` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n\t- `@coderabbitai generate interesting stats about this repository and render them as a table.`\n\t- `@coderabbitai show all the console.log statements in this repository.`\n\t- `@coderabbitai read src/utils.ts and generate unit testing code.`\n\t- `@coderabbitai read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (invoked as PR comments)\n\n- `@coderabbitai pause` to pause the reviews on a PR.\n- `@coderabbitai resume` to resume the paused reviews.\n- `@coderabbitai review` to trigger a review. This is useful when automatic reviews are disabled for the repository.\n- `@coderabbitai resolve` resolve all the CodeRabbit review comments.\n- `@coderabbitai help` to get help.\n\n\nAdditionally, you can add `@coderabbitai ignore` anywhere in the PR description to prevent this PR from being reviewed.\n\n### CodeRabbit Configration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](https://discord.com/invite/GsXnASn26c) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-04T17:34:50Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2587#issuecomment-2037799998"
                    },
                    {
                        "body": "> Thanks, nice feature! Do we have dashboard changes ready? If not I would pause merging this, so it is not in the upcoming release, until Dashboard has this. @Cahllagerfeld\r\n\r\n@avishniakov yes, the dashboard changes have already been merged: https://github.com/zenml-io/zenml-dashboard/pull/556",
                        "user": "stefannica",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-08T13:07:51Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2587#issuecomment-2042715991"
                    },
                    {
                        "body": "E2E template updates in `examples/e2e` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-08T13:24:45Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2587#issuecomment-2042753537"
                    },
                    {
                        "body": "LLM Finetuning template updates in `examples/llm_finetuning` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-08T13:33:53Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2587#issuecomment-2042774453"
                    },
                    {
                        "body": "NLP template updates in `examples/e2e_nlp` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-08T13:41:37Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2587#issuecomment-2042794886"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/zenml-io/zenml/pulls/2587",
                    "merged_at": "2024-04-09T07:22:03Z"
                }
            },
            {
                "url": "https://github.com/zenml-io/zenml/pull/2583",
                "title": "Add security headers to the ZenML server",
                "labels": [
                    "security",
                    "run-slow-ci",
                    "P2"
                ],
                "user": "stefannica",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2583,
                "id": 2223918522,
                "state": "closed",
                "project_created_at": "2024-04-03T21:01:47Z",
                "closed_at": "2024-04-06T15:32:36Z",
                "body": "## Describe changes\r\nThere are a set of HTTP headers that can be added to all ZenML server responses for improved security. This PR adds them by using the middleware supplied with the [`secure`](https://secure.readthedocs.io/en/latest/index.html) Python library.\r\n\r\nFor comparison:\r\n* [headers scan for a server without headers](https://securityheaders.com/?q=https%3A%2F%2F1cf18d95-zenml.cloudinfra.zenml.io&followRedirects=on)\r\n* [headers scan for a server with headers](https://securityheaders.com/?q=https%3A%2F%2F9ba52960-zenml.staging.cloudinfra.zenml.io%2F&followRedirects=on)\r\n\r\nNOTE: the content-security-policy security headers are by default set to a \"non-safe\" value because the dashboard code requires special handling to allow its support. More details here: https://content-security-policy.com/examples/allow-inline-script/\r\n\r\n## Pre-requisites\r\nPlease ensure you have done the following:\r\n- [x] I have read the **CONTRIBUTING.md** document.\r\n- [x] If my change requires a change to docs, I have updated the documentation accordingly.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] I have based my new branch on `develop` and the open PR is targeting `develop`. If your branch wasn't based on develop read [Contribution guide on rebasing branch to develop](https://github.com/zenml-io/zenml/blob/main/CONTRIBUTING.md#-pull-requests-rebase-your-branch-on-develop).\r\n- [ ] If my changes require changes to the dashboard, these changes are communicated/requested.\r\n\r\n## Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Other (add details above)\r\n\r\n",
                "comments": [
                    {
                        "body": "<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- This is an auto-generated comment: skip review by coderabbit.ai -->\n\n> [!IMPORTANT]\n> ## Auto Review Skipped\n> \n> Auto reviews are disabled on this repository.\n> \n> Please check the settings in the CodeRabbit UI or the `.coderabbit.yaml` file in this repository.\n> \n> To trigger a single review, invoke the `@coderabbitai review` command.\n> \n\n<!-- end of auto-generated comment: skip review by coderabbit.ai --><!-- tweet_start -->\n\nThank you for using CodeRabbit. We offer it for free to the OSS community and would appreciate your support in helping us grow. If you find it useful, would you consider giving us a shout-out on your favorite social media?\n\n<details>\n<summary>Share</summary>\n\n- [X](https://twitter.com/intent/tweet?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A&url=https%3A//coderabbit.ai)\n- [Mastodon](https://mastodon.social/share?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A%20https%3A%2F%2Fcoderabbit.ai)\n- [Reddit](https://www.reddit.com/submit?title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&text=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code.%20Check%20it%20out%3A%20https%3A//coderabbit.ai)\n- [LinkedIn](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcoderabbit.ai&mini=true&title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&summary=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code)\n\n</details>\n\n<!-- tweet_end --><!-- tips_start -->\n\n---\n\n<details>\n<summary>Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n- Review comments: Directly reply to a review comment made by CodeRabbit. Example:\n\t- `I pushed a fix in commit <commit_id>.`\n\t- `Generate unit testing code for this file.`\n\t- `Open a follow-up GitHub issue for this discussion.`\n- Files and specific lines of code (under the \"Files changed\" tab): Tag `@coderabbitai` in a new review comment at the desired location with your query. Examples:\n\t- `@coderabbitai generate unit testing code for this file.`\n\t-\t`@coderabbitai modularize this function.`\n- PR comments: Tag `@coderabbitai` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n\t- `@coderabbitai generate interesting stats about this repository and render them as a table.`\n\t- `@coderabbitai show all the console.log statements in this repository.`\n\t- `@coderabbitai read src/utils.ts and generate unit testing code.`\n\t- `@coderabbitai read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (invoked as PR comments)\n\n- `@coderabbitai pause` to pause the reviews on a PR.\n- `@coderabbitai resume` to resume the paused reviews.\n- `@coderabbitai review` to trigger a review. This is useful when automatic reviews are disabled for the repository.\n- `@coderabbitai resolve` resolve all the CodeRabbit review comments.\n- `@coderabbitai help` to get help.\n\n\nAdditionally, you can add `@coderabbitai ignore` anywhere in the PR description to prevent this PR from being reviewed.\n\n### CodeRabbit Configration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/coderabbit-overrides.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](https://discord.com/invite/GsXnASn26c) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-03T21:01:51Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2583#issuecomment-2035584344"
                    },
                    {
                        "body": "<!-- overview-comment -->\n**New and removed dependencies detected.** Learn more about [Socket for GitHub ](https://socket.dev?utm_medium=gh)\n\n\n| Package | New capabilities | Transitives | Size | Publisher |\n|:--- |:--- |:--- |:--- |:--- |\n| [pypi/secure@0.3.0](https://socket.dev/pypi/package/secure/overview/0.3.0/py3-none-any-whl) | <a href=\"https://socket.dev?issue=usesEval\">eval</a>, <a href=\"https://socket.dev?issue=filesystemAccess\">filesystem</a>, <a href=\"https://socket.dev?issue=shellAccess\">shell</a> | <a href=\"https://socket.dev\">`0`</a> | 59.6 kB | <a href=\"https://socket.dev/pypi/user/cakinney\">cakinney</a> |\n\n\n[**View full report**](https://socket.dev/dashboard/org/gh/zenml-io/diff/3b9e57a6-aea9-4e5b-b87e-252c43505c22/88e56b20-255e-4855-93f9-293daeb05497)",
                        "user": "socket-security[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-04-03T21:02:34Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2583#issuecomment-2035585311"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/zenml-io/zenml/pulls/2583",
                    "merged_at": "2024-04-06T15:32:36Z"
                }
            },
            {
                "url": "https://github.com/zenml-io/zenml/pull/2494",
                "title": "Add admin users notion",
                "labels": [
                    "bug",
                    "internal",
                    "security",
                    "run-slow-ci",
                    "P1"
                ],
                "user": "avishniakov",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2494,
                "id": 2168644872,
                "state": "closed",
                "project_created_at": "2024-03-05T08:51:45Z",
                "closed_at": "2024-03-12T16:09:59Z",
                "body": "## Describe changes\r\nI implemented the `is_admin` flag for the user accounts and added protection to certain operations performed via the REST interface to ADMIN-allowed only.\r\n\r\n**Only admins can**: list all users, create users, get another user, update another user, deactivate another user, and delete a user.\r\n**All users can**: list self, get self, update self, and activate a user.\r\n\r\nThese checks are only performed if no RBAC is in place, so ZenML Cloud RBAC functionality is not affected.\r\n\r\n## Pre-requisites\r\nPlease ensure you have done the following:\r\n- [x] I have read the **CONTRIBUTING.md** document.\r\n- [x] If my change requires a change to docs, I have updated the documentation accordingly.\r\n- [x] I have added tests to cover my changes.\r\n- [x] I have based my new branch on `develop` and the open PR is targeting `develop`. If your branch wasn't based on develop read [Contribution guide on rebasing branch to develop](https://github.com/zenml-io/zenml/blob/main/CONTRIBUTING.md#-pull-requests-rebase-your-branch-on-develop).\r\n- [x] If my changes require changes to the dashboard, these changes are communicated/requested.\r\n\r\n## Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Other (add details above)\r\n\r\n\n\n<!-- This is an auto-generated comment: release notes by coderabbit.ai -->\n\n## Summary by CodeRabbit\n\n- **New Features**\n\t- Introduced admin user management, including the ability to create users with admin status and update user information with admin privileges.\n- **Documentation**\n\t- Updated the Quickstart guide with correct hyperlinks and improved the community links alignment.\n- **Bug Fixes**\n\t- Ensured that the default user is created with admin privileges and prevented removing admin status from the default user.\n- **Refactor**\n\t- Enhanced various user management functions to support new admin features and improved permission checks across the application.\n- **Tests**\n\t- Added comprehensive tests for new admin user management features, including scenarios for updating user information and admin status.\n\n<!-- end of auto-generated comment: release notes by coderabbit.ai -->",
                "comments": [
                    {
                        "body": "<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- This is an auto-generated comment: skip review by coderabbit.ai -->\n\n> [!IMPORTANT]\n> ## Auto Review Skipped\n> \n> Auto reviews are disabled on this repository.\n> \n> Please check the settings in the CodeRabbit UI or the `.coderabbit.yaml` file in this repository.\n> \n> To trigger a single review, invoke the `@coderabbitai review` command.\n> \n\n<!-- end of auto-generated comment: skip review by coderabbit.ai --><!-- walkthrough_start -->\n\n## Walkthrough\n\nThe recent updates focus on enhancing user management and role-based access control (RBAC) within the application. Key features include the introduction of an `is_admin` flag to distinguish between admin and regular users, updates to user creation and modification functions to handle admin status, and improvements in permission checks and error handling for user actions. These changes aim to provide more granular control over user roles and permissions, ensuring a more secure and customizable environment.\n\n## Changes\n\n| Files                                             | Change Summary                                                                                           |\n|---------------------------------------------------|----------------------------------------------------------------------------------------------------------|\n| `examples/quickstart/README.md`                   | Updated Google Colab badge URL and Slack community link.                                                |\n| `src/zenml/.../user_management.py`, `client.py`   | Added `is_admin` flag to user creation; updated user update functions with admin-related parameters.    |\n| `src/zenml/models/v2/.../service_account.py`, `user.py`, `external_user.py` | Added `is_admin` fields and updated inheritance structures.                                              |\n| `src/zenml/zen_server/...`                        | Enhanced user and admin permission checks, error handling, and RBAC settings in various server modules. |\n| `src/zenml/zen_stores/...`, `tests/...`           | Updated database schema for admin users, added `is_admin` in schemas, and integrated tests.             |\n\n## Poem\n\n> In the world of code, where changes are vast,  \n> A rabbit hopped in, making updates fast.  \n> With a flick of its ear, and a tap of its paw,  \n> Admins and users, it clearly saw.  \n>  \"Let's manage with care, and control with grace,  \n> Permissions and roles, in their right place.\"  \n> In a burrow so deep, with code so neat,  \n> The rabbit's work done, so clever and sweet.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: raw summary by coderabbit.ai -->\n<!--\n\n\nexamples/quickstart/README.md: ## Short summary\n\nThe diff in the `README.md` file updates a hyperlink in the Google Colab badge URL from `run.ipynb` to `quickstart.ipynb`, ensuring users are directed to the correct notebook. Additionally, it adjusts the Slack community link for better alignment.\n\n---\n\nsrc/zenml/cli/user_management.py: ## Short summary\n\n- Added an `is_admin` flag to the `create_user` function to specify if the user should be an admin.\n- Added options to update user information in the `update_user` function, including `updated_password`, `make_admin`, and `make_user`.\n\n---\n\nsrc/zenml/client.py: ## Short summary\n\n- Added a new parameter `is_admin` to the `create_user` function in `client.py`.\n- Added new parameters `updated_password` and `updated_is_admin` to the `update_user` function in `client.py.\n\n---\n\nsrc/zenml/models/v2/core/service_account.py: ## Short summary\n\nAdded the `is_admin` field with a default value of `False` in the `to_user_model` method of the `service_account.py` file.\n\n---\n\nsrc/zenml/models/v2/core/user.py: ## Short summary\n\nIn this change, the `UserRequest` class is refactored to inherit from `UserBase` and `BaseRequest`, introducing new fields like `is_admin` and modifying existing fields like `full_name` and `active`. The `UserUpdate` class now inherits from `UserBase` and `BaseZenModel`, with changes to fields like `name` and `is_admin`. Additionally, `UserResponseBody` gains a new field `is_admin`, and getter methods for `is_admin` and `email` are added.\n\n---\n\nsrc/zenml/models/v2/misc/external_user.py: ## Short summary\n\nAdded a new boolean field `is_admin` with a default value of `False` to the `ExternalUserModel` class.\n\n---\n\nsrc/zenml/zen_server/auth.py: ## Short summary\n\nIn the `authenticate_external_user` function in `auth.py`, the `is_admin` field is now being set based on the `external_user.is_admin` value.\n\n---\n\nsrc/zenml/zen_server/rbac/endpoint_utils.py: ## Short summary\n\nIn the `verify_permissions_and_create_entity` function within `endpoint_utils.py`, the `verify_permission` call has been reformatted to pass arguments on separate lines for `resource_type` and `action`.\n\n---\n\nsrc/zenml/zen_server/rbac/utils.py: ## Short Summary\n\nIn `utils.py`, the `batch_verify_permissions` function's signature was updated to include separate lines for each parameter, `resources` and `action`, instead of having them on a single line.\n\n---\n\nsrc/zenml/zen_server/routers/users_endpoints.py: ## Short summary\n\n- Added `verify_admin_status_if_no_rbac` function for permission checks.\n- Modified logic in `list_users` to handle RBAC settings.\n- Updated `create_user` to verify admin status for non-admin users.\n- Enhanced permission checks in `get_user` and `update_user`.\n- Improved error handling in `update_user` for admin status changes.\n- Enhanced `activate_user` to retain admin status during activation.\n- Added validation in `deactivate_user` to prevent self-deactivation.\n- Strengthened permission checks in `deactivate_user` and `delete_user`.\n- Updated `email_opt_in_response` for email opt-in handling.\n- Enhanced `update_myself` to retain user attributes during update.\n\n---\n\nsrc/zenml/zen_server/utils.py: ## Short summary\n\nIn `utils.py`, the `OAuthError` import is replaced with `IllegalOperationError` and `OAuthError`. Additionally, a new function `verify_admin_status_if_no_rbac` is added to validate admin status for sensitive requests when RBAC is disabled.\n\n---\n\nsrc/zenml/zen_stores/migrations/versions/1a9a9d2a836d_admin_users.py: This file introduces functionality to manage admin users in the database schema. It adds an \"is_admin\" column to the \"user\" table, setting all users as admin during migration for backward compatibility. Admin status can be adjusted by server admins post-upgrade.\n\n---\n\nsrc/zenml/zen_stores/schemas/user_schemas.py: ## Short summary\n\nIn the `UserSchema` class within `user_schemas.py`, a new field `is_admin` of type `bool` with a default value of `False` has been added. This field is now included in various methods like `from_user_request`, `from_service_account_request`, and `to_model`.\n\n---\n\nsrc/zenml/zen_stores/sql_zen_store.py: ## Short summary\n\nIn the `update_user` function of `sql_zen_store.py`, a check has been added to prevent removing admin status from the default user. Additionally, the default user is now created with admin privileges.\n\n---\n\ntests/integration/functional/zen_stores/test_zen_store.py: ## Short summary\n\n- Added `random` and `ascii_lowercase` imports.\n- Added `RestZenStore` import.\n- Added `TestAdminUser` class with various test methods for user management.\n- Updated user creation, listing, getting, updating, deactivating, and deleting logic.\n- Added tests for updating user information and admin status.\n- Added tests for self-update scenarios for admin and non-admin users.\n\n---\n\ntests/integration/functional/zen_stores/utils.py: ## Short summary\n\nIn the `utils.py` file, the `__init__` method of a class now accepts an additional parameter `is_admin`, which is set to `True` by default. The `UserRequest` object creation in the `__enter__` method now includes the `is_admin` attribute. The `create_model` attribute in `user_crud_test_config` now includes the `is_admin` parameter set to `True`.\n\n---\n\ntests/unit/conftest.py: ## Short summary\n\nIn the `tests/unit/conftest.py` file, a change was made to set the `is_admin` attribute to `True` for a user model instance, indicating an update to the user's admin status.\n\n---\n\ntests/unit/models/test_user_models.py: ## Short summary\n\nIn the `test_user_models.py` file, the changes involve modifying the instantiation of `UserRequest` instances by adding the `is_admin=False` parameter to the constructor calls in the test cases `test_user_request_model_fails_with_long_password` and `test_user_request_model_fails_with_long_activation_token`.\n\n-->\n<!-- end of auto-generated comment: raw summary by coderabbit.ai --><!-- This is an auto-generated comment: short summary by coderabbit.ai -->\n<!--\n\n\n### PR Objectives\n\nThe pull request (PR) titled \"Add admin users notion\" introduces the concept of administrative users within a system, enhancing security and user management capabilities. The main changes include the implementation of an `is_admin` flag for user accounts, which distinguishes between admin and non-admin users. This flag is crucial for controlling access to specific operations through the REST interface, ensuring that only admins can perform sensitive actions.\n\nAdmin users are granted exclusive permissions to list all users, create new users, access and modify other users' information, deactivate or delete user accounts. In contrast, regular users are limited to managing their own account details and activating a user account. These restrictions are designed to safeguard the system against unauthorized access and modifications, enhancing overall security.\n\nThe PR also specifies that these new access controls are implemented in a manner that does not interfere with existing Role-Based Access Control (RBAC) functionalities, particularly within the ZenML Cloud environment. This ensures that the new features can coexist with the current RBAC system without causing any disruptions or conflicts.\n\nTo support these changes, the PR includes updates to documentation, the addition of tests to cover the new functionalities, and modifications to various components of the system, including CLI commands, models, and server utilities. The contributor has followed the project's contribution guidelines, ensuring that the new branch is based on `develop` and that all pre-requisites for a successful PR have been met.\n\n### Comments Summary\n\nThe PR received feedback from a reviewer, avishniakov, who suggested improvements for the unit tests and conducted a thorough local test to assess the impact of the changes on the dashboard. The reviewer identified several areas for improvement, particularly regarding the creation and updating of user accounts through the Client/CLI and the dashboard. These include the inability to set or change a user's admin status upon account creation or update, and the need for the dashboard to reflect a user's admin status accurately.\n\nThe reviewer also highlighted a potential vulnerability where a non-admin user could elevate their status to admin during the first login process. This issue was addressed, and the backend points related to user activation and admin status were fixed. However, the dashboard-related enhancements were deferred to a separate task tracked in the project's issue tracking system.\n\nStefannica, the contributor, acknowledged the feedback and incorporated the suggested improvements into the PR. The changes were re-tested and confirmed to work as expected.\n\n### AI-Generated Summary of Generated Summaries\n\nThe PR introduces an `is_admin` flag to distinguish between admin and non-admin users, applying this distinction across various components of the system, including CLI commands, client functions, models, and server utilities. Admin users are granted exclusive permissions for sensitive operations, such as user management tasks, while regular users are limited to managing their own account details.\n\nSignificant changes include the addition of the `is_admin` flag to user creation and update functions, both in the CLI and the client layer, and the introduction of this flag in various user models. The server's authentication and permission verification mechanisms have been updated to accommodate the new admin concept, ensuring that only admins can perform certain actions unless RBAC settings override these restrictions.\n\nThe database schema has been updated to include an `is_admin` column for user management, and tests have been added to cover the new functionalities and ensure that admin and non-admin users are handled correctly. The PR also addresses a potential security vulnerability related to user activation and admin status elevation.\n\nDashboard-related enhancements, such as reflecting a user's admin status and modifying user creation and update functionalities to include admin status settings, have been identified but are to be addressed in a separate task.\n\n-->\n<!-- end of auto-generated comment: short summary by coderabbit.ai --><!-- commit_ids_reviewed_start -->\n\n<!-- 5c4545713838f0b28edfea7c9768339d2d899c2d -->\n\n<!-- commit_ids_reviewed_end --><!-- tweet_start -->\n\nThank you for using CodeRabbit. We offer it for free to the OSS community and would appreciate your support in helping us grow. If you find it useful, would you consider giving us a shout-out on your favorite social media?\n\n<details>\n<summary>Share</summary>\n\n- [X](https://twitter.com/intent/tweet?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A&url=https%3A//coderabbit.ai)\n- [Mastodon](https://mastodon.social/share?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A%20https%3A%2F%2Fcoderabbit.ai)\n- [Reddit](https://www.reddit.com/submit?title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&text=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code.%20Check%20it%20out%3A%20https%3A//coderabbit.ai)\n- [LinkedIn](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcoderabbit.ai&mini=true&title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&summary=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code)\n\n</details>\n\n<!-- tweet_end --><!-- tips_start -->\n\n---\n\n<details>\n<summary>Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with CodeRabbit:\n\n- Review comments: Directly reply to a review comment made by CodeRabbit. Example:\n\t- `I pushed a fix in commit <commit_id>.`\n\t- `Generate unit-tests for this file.`\n\t- `Open a follow-up GitHub issue for this discussion.`\n- Files and specific lines of code (under the \"Files changed\" tab): Tag `@coderabbitai` in a new review comment at the desired location with your query. Examples:\n\t- `@coderabbitai generate unit tests for this file.`\n\t-\t`@coderabbitai modularize this function.`\n- PR comments: Tag `@coderabbitai` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n\t- `@coderabbitai generate interesting stats about this repository and render them as a table.`\n\t- `@coderabbitai show all the console.log statements in this repository.`\n\t- `@coderabbitai read src/utils.ts and generate unit tests.`\n\t- `@coderabbitai read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (invoked as PR comments)\n\n- `@coderabbitai pause` to pause the reviews on a PR.\n- `@coderabbitai resume` to resume the paused reviews.\n- `@coderabbitai review` to trigger a review. This is useful when automatic reviews are disabled for the repository.\n- `@coderabbitai resolve` resolve all the CodeRabbit review comments.\n- `@coderabbitai help` to get help.\n\n\nAdditionally, you can add `@coderabbitai ignore` anywhere in the PR description to prevent this PR from being reviewed.\n\n### CodeRabbit Configration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- The JSON schema for the configuration file is available [here](https://coderabbit.ai/integrations/coderabbit-overrides.v2.json).\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/coderabbit-overrides.v2.json`\n\n### CodeRabbit Discord Community\n\nJoin our [Discord Community](https://discord.com/invite/GsXnASn26c) to get help, request features, and share feedback.\n\n</details>\n\n<!-- tips_end -->",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-05T08:51:52Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2494#issuecomment-1978245381"
                    },
                    {
                        "body": "> Left some improvement suggestions for the unit tests, otherwise looks good.\r\n\r\nThanks for the effort @stefannica ! I will use your suggestions.",
                        "user": "avishniakov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-06T13:57:56Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2494#issuecomment-1980934290"
                    },
                    {
                        "body": "> I gave this a thorough local test, because I wanted to see what impact this has on the dashboard and I found a few things that might need doing:\r\n> \r\n> Client/CLI (we should probably fix these in this PR):\r\n> \r\n> * when creating a new user account, there's no way to decide whether it's admin or not. They are non-admin by default.\r\n> * no way to make an account admin when updating a user\r\n> \r\n> Dashboard:\r\n> \r\n> * should mark users as admins/non-admins in the user list\r\n> * we should disable / remove the option of adding new users for a non-admin user account\r\n> * we should add the ability to decide if a user is admin or not during creation\r\n> \r\n> One new vulnerability that I'll check right away is that a non-admin user invited through an invitation token can elevate their status to admin during the first login.\r\n\r\nBackend points + take over during activation fixed.\r\n\r\nDashboard points shall fall into https://zenml.atlassian.net/browse/PRD-282 (team is aware)",
                        "user": "avishniakov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-07T16:28:22Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2494#issuecomment-1983929981"
                    },
                    {
                        "body": "> \r\n> Backend points + take over during activation fixed.\r\n> \r\n\r\nThank you, I re-tested it, works as expected.",
                        "user": "stefannica",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-07T17:39:44Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2494#issuecomment-1984092095"
                    },
                    {
                        "body": "Quickstart template updates in `examples/quickstart` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-11T16:11:16Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2494#issuecomment-1988814708"
                    },
                    {
                        "body": "Let's blow a bomb of CodeRabbit  \r\n\r\n@coderabbitai review",
                        "user": "avishniakov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-12T14:15:05Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2494#issuecomment-1991753343"
                    },
                    {
                        "body": "<!-- This is an auto-generated reply by CodeRabbit -->\n\n\n@avishniakov, I will review the changes in the PR. \n\n\n<details>\n<summary>Actions performed</summary>\n\nReview triggered.\n\n> Note: CodeRabbit is an incremental review system and does not re-review already reviewed commits. This command is applicable only when automatic reviews are paused.\n\n</details>",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-12T14:15:23Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2494#issuecomment-1991753974"
                    },
                    {
                        "body": "Ok, let's go!",
                        "user": "avishniakov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-12T16:09:52Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2494#issuecomment-1992025044"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/zenml-io/zenml/pulls/2494",
                    "merged_at": "2024-03-12T16:09:59Z"
                }
            },
            {
                "url": "https://github.com/zenml-io/zenml/pull/2491",
                "title": "Don't write the global config to file on server",
                "labels": [
                    "bug",
                    "internal",
                    "security",
                    "run-slow-ci"
                ],
                "user": "stefannica",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2491,
                "id": 2164081952,
                "state": "closed",
                "project_created_at": "2024-03-01T19:58:22Z",
                "closed_at": "2024-03-05T08:04:40Z",
                "body": "## Describe changes\r\nTo prevent accidentally leaking sensitive configuration information by exposing the global configuration file, the ZenML server doesn't dump any of its configuration to disk anymore.\r\n\r\n## Pre-requisites\r\nPlease ensure you have done the following:\r\n- [x] I have read the **CONTRIBUTING.md** document.\r\n- [ ] If my change requires a change to docs, I have updated the documentation accordingly.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] I have based my new branch on `develop` and the open PR is targeting `develop`. If your branch wasn't based on develop read [Contribution guide on rebasing branch to develop](https://github.com/zenml-io/zenml/blob/main/CONTRIBUTING.md#-pull-requests-rebase-your-branch-on-develop).\r\n- [ ] If my changes require changes to the dashboard, these changes are communicated/requested.\r\n\r\n## Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Other (add details above)\r\n\r\n",
                "comments": [
                    {
                        "body": "<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- This is an auto-generated comment: skip review by coderabbit.ai -->\n\n> [!IMPORTANT]\n> ## Auto Review Skipped\n> \n> Auto reviews are disabled on this repository.\n> \n> Please check the settings in the CodeRabbit UI or the `.coderabbit.yaml` file in this repository.\n> \n> To trigger a single review, invoke the `@coderabbitai review` command.\n> \n\n<!-- end of auto-generated comment: skip review by coderabbit.ai --><!-- tweet_start -->\n\nThank you for using CodeRabbit. We offer it for free to the OSS community and would appreciate your support in helping us grow. If you find it useful, would you consider giving us a shout-out on your favorite social media?\n\n<details>\n<summary>Share</summary>\n\n- [X](https://twitter.com/intent/tweet?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A&url=https%3A//coderabbit.ai)\n- [Mastodon](https://mastodon.social/share?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A%20https%3A%2F%2Fcoderabbit.ai)\n- [Reddit](https://www.reddit.com/submit?title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&text=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code.%20Check%20it%20out%3A%20https%3A//coderabbit.ai)\n- [LinkedIn](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcoderabbit.ai&mini=true&title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&summary=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code)\n\n</details>\n\n<!-- tweet_end --><!-- tips_start -->\n\n---\n\n<details>\n<summary>Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with CodeRabbit:\n\n- Review comments: Directly reply to a review comment made by CodeRabbit. Example:\n\t- `I pushed a fix in commit <commit_id>.`\n\t- `Generate unit-tests for this file.`\n- Files and specific lines of code (under the \"Files changed\" tab): Tag `@coderabbitai` in a new review comment at the desired location with your query. Examples:\n\t- `@coderabbitai generate unit tests for this file.`\n\t-\t`@coderabbitai modularize this function.`\n- PR comments: Tag `@coderabbitai` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n\t- `@coderabbitai generate interesting stats about this repository and render them as a table.`\n\t- `@coderabbitai show all the console.log statements in this repository.`\n\t- `@coderabbitai read src/utils.ts and generate unit tests.`\n\t- `@coderabbitai read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (invoked as PR comments)\n\n- `@coderabbitai pause` to pause the reviews on a PR.\n- `@coderabbitai resume` to resume the paused reviews.\n- `@coderabbitai review` to trigger a review. This is useful when automatic reviews are disabled for the repository.\n- `@coderabbitai resolve` resolve all the CodeRabbit review comments.\n- `@coderabbitai help` to get help.\n\n\nAdditionally, you can add `@coderabbitai ignore` anywhere in the PR description to prevent this PR from being reviewed.\n\n### CodeRabbit Configration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- The JSON schema for the configuration file is available [here](https://coderabbit.ai/integrations/coderabbit-overrides.v2.json).\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/coderabbit-overrides.v2.json`\n\n### CodeRabbit Discord Community\n\nJoin our [Discord Community](https://discord.com/invite/GsXnASn26c) to get help, request features, and share feedback.\n\n</details>\n\n<!-- tips_end -->",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-01T19:58:28Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2491#issuecomment-1973827539"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/zenml-io/zenml/pulls/2491",
                    "merged_at": "2024-03-05T08:04:40Z"
                }
            },
            {
                "url": "https://github.com/zenml-io/zenml/pull/2490",
                "title": "Improve Artifact Store isolation",
                "labels": [
                    "bug",
                    "internal",
                    "security",
                    "run-slow-ci"
                ],
                "user": "avishniakov",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2490,
                "id": 2163507127,
                "state": "closed",
                "project_created_at": "2024-03-01T14:15:25Z",
                "closed_at": "2024-03-05T08:02:33Z",
                "body": "## Describe changes\r\nI fixed some isolation issues while using Artifact Stores.\r\n\r\n- `_sanitize_paths` of `BaseArtifactStore` is extended to check that the requested path is not leaving Artifact Store bounds\r\n- various helper methods rerouted to use artifact store methods instead of direct file system\r\n- standard materializers rerouted to use artifact store methods instead of direct file system\r\n\r\nPotential breaking change:\r\n- If unsafe operations were used in user's code - it needs to be revisited to make sure that no objects are created/fetched outside of Artifact Store scopes. Example:\r\n    - Artifact Store is configured as `s3://some_bucket/some_sub_folder`\r\n    - Code is doing `artifact_store.open(\"s3://some_bucket/some_other_folder/dummy.txt\",\"w\")` -> this is not allowed any more\r\n    - Consider using `s3fs` or similar libraries if you need to execute such operations\r\n  \r\n## Pre-requisites\r\nPlease ensure you have done the following:\r\n- [x] I have read the **CONTRIBUTING.md** document.\r\n- [x] If my change requires a change to docs, I have updated the documentation accordingly.\r\n- [x] I have added tests to cover my changes.\r\n- [x] I have based my new branch on `develop` and the open PR is targeting `develop`. If your branch wasn't based on develop read [Contribution guide on rebasing branch to develop](https://github.com/zenml-io/zenml/blob/main/CONTRIBUTING.md#-pull-requests-rebase-your-branch-on-develop).\r\n- [x] If my changes require changes to the dashboard, these changes are communicated/requested.\r\n\r\n## Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Other (add details above)\r\n\r\n\r\n\r\n<!-- This is an auto-generated comment: release notes by coderabbit.ai -->\n## Summary by CodeRabbit\n\n\n## Summary by CodeRabbit\n\n- **New Features**\n\t- Enhanced security with input verification for artifact store operations.\n\t- Improved error handling by raising `IOError` for rejected artifact store requests.\n\n- **Refactor**\n\t- Implemented path verification for abstract method implementations in artifact store initialization.\n\n- **Tests**\n\t- Introduced integration tests to confine artifact store operations within specified bounds.\n\n<!-- end of auto-generated comment: release notes by coderabbit.ai -->",
                "comments": [
                    {
                        "body": "<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- This is an auto-generated comment: skip review by coderabbit.ai -->\n\n> [!IMPORTANT]\n> ## Auto Review Skipped\n> \n> Auto reviews are disabled on this repository.\n> \n> Please check the settings in the CodeRabbit UI or the `.coderabbit.yaml` file in this repository.\n> \n> To trigger a single review, invoke the `@coderabbitai review` command.\n> \n\n<!-- end of auto-generated comment: skip review by coderabbit.ai --><!-- walkthrough_start -->\n\n## Walkthrough\nThe recent updates to ZenML's artifact handling introduce enhanced input verification and path validation within artifact stores. These changes ensure that operations are securely contained within the bounds of the artifact stores, enhancing the robustness and security of data management. Additionally, a specific test suite has been added to validate these improvements, ensuring that artifact operations outside the designated bounds are correctly restricted.\n\n## Changes\n\n| File Path | Change Summary |\n|-----------|----------------|\n| `src/zenml/artifact_stores/base_artifact_store.py`<br>`src/zenml/artifacts/utils.py` | - Introduced input and path verification methods.<br>- Enhanced error handling for rejected requests in artifact store operations. |\n| `tests/integration/functional/artifacts/test_base_artifact_store.py` | - Added tests to verify artifact store boundary operations. |\n| `src/zenml/logging/step_logging.py`<br>`src/zenml/materializers/...materializer.py` | - Updated to use `Client` for artifact store operations instead of direct file I/O, improving integration and compatibility. |\n| `src/zenml/orchestrators/output_utils.py` | - Transitioned to using `Client` for artifact store operations, replacing direct `fileio` calls. |\n\n> <br>\n> In the realm of data, where artifacts dwell,<br>\n> A rabbit hopped, casting a secure spell.<br>\n> Paths verified, inputs checked with care,<br>\n> Ensuring that only safe travels are there.<br>\n> With every hop, a new test case born,<br>\n> Celebrating security from dusk till morn. \n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: raw summary by coderabbit.ai -->\n<!--\n\n\n```\nsrc/zenml/artifact_stores/base_artifact_store.py: ## Short summary\n\n- Added `inspect` and `Path` imports.\n- Modified `_sanitize_potential_path` to handle root path and path type.\n- Added `FileNotFoundError` raise condition.\n- Updated `_sanitize_paths` to handle fixed root path.\n- Added `decorator` function within `_sanitize_paths`.\n- Updated `inner_function` within `decorator` to handle root path and relevant arguments.\n- Added `ValueError` raise condition.\n- Updated `_register` method to use `inspect.getmembers` for method overloads.\n- Added `__init_subclass__` method to wrap abstract method implementations with path sanitizer.\n\n---\n\nsrc/zenml/artifacts/utils.py: ## Short summary\n\nIn `utils.py`, the `_load_file_from_artifact_store` function now raises `IOError` if the artifact store rejects the request.\n\n---\n\ntests/integration/functional/artifacts/test_base_artifact_store.py: This file introduces a test to ensure that operations outside the bounds of the artifact store are not accessible by it. It includes tests for creating, opening, and copying files both inside and outside the artifact store, verifying the expected behavior in each case.\n\n---\n\nsrc/zenml/logging/step_logging.py: ## Short summary\n\nThe functionality in `step_logging.py` has been updated to use `Client` for artifact store operations instead of `fileio`, affecting the preparation and saving of logs.\n\n---\n\nsrc/zenml/materializers/base_materializer.py: ## Short summary\n\nIn the `save_visualizations` method of the `BaseMaterializer` class, the code was updated to use `artifact_store` for file operations instead of `fileio`, enhancing integration with the active stack's artifact store.\n\n---\n\nsrc/zenml/materializers/built_in_materializer.py: ## Short summary\n\n- Added import statement for `Client` from `zenml.client`.\n- Replaced `fileio` references with `artifact_store` accessed through `Client().active_stack.artifact_store`.\n- Updated file operations to use `artifact_store` for reading, writing, existence checks, and directory operations.\n\n---\n\nsrc/zenml/materializers/cloudpickle_materializer.py: ## Short summary\n\nThe functionality of the `CloudpickleMaterializer` in `cloudpickle_materializer.py` has been updated to use the `Client` to access the active stack's artifact store for loading and saving data, replacing direct file I/O operations. This change ensures consistency and compatibility with the current Python environment.\n\n---\n\nsrc/zenml/materializers/numpy_materializer.py: ## Short summary\n\nThe functionality of the `numpy_materializer.py` module has been updated to use the `Client` class from `zenml.client` for artifact store operations instead of `fileio`. This change affects the loading and saving of numpy arrays and visualizations within the materializer.\n\n---\n\nsrc/zenml/materializers/pandas_materializer.py: ## Short summary\n\nThe functionality of the `PandasMaterializer` in the `zenml.materializers.pandas_materializer` module has been updated to use the `Client` to access the active stack's artifact store for loading and saving data. The changes involve replacing direct file I/O operations with interactions through the artifact store, enhancing flexibility and compatibility with different storage mechanisms.\n\n---\n\nsrc/zenml/materializers/service_materializer.py: ## Short summary\n\nThe `service_materializer.py` file in the `src/zenml/materializers` module has been updated to use the `Client` class from `zenml.client` for accessing the active stack's artifact store instead of directly using `fileio`. This change affects the `load` and `save` methods within the `ServiceMaterializer` class.\n\n---\n\nsrc/zenml/materializers/structured_string_materializer.py: ## Short summary\n\nThe functionality of the `structured_string_materializer.py` module has been updated to use the `Client` class from `zenml.client` for accessing the artifact store instead of directly using `fileio`. This change affects the `load` and `save` methods by utilizing the `artifact_store` attribute from the active stack's `Client` instance for file operations.\n\n---\n\nsrc/zenml/orchestrators/output_utils.py: ## Short summary\n\nIn `output_utils.py`, the functionality has been updated to use the `Client` class from `zenml.client` instead of `fileio` for handling artifact store operations. The changes involve replacing `fileio` with `artifact_store` methods for checking existence, creating directories, and removing directories related to artifact URIs.\n```\n\n-->\n<!-- end of auto-generated comment: raw summary by coderabbit.ai --><!-- This is an auto-generated comment: short summary by coderabbit.ai -->\n<!--\n\n\n### PR Objectives\n\nThe pull request titled \"[WIP] Improve Artifact Store isolation\" (PR #2490) aims to enhance the isolation mechanisms within the artifact store component of the ZenML framework. The contributor has implemented and/or fixed certain functionalities to achieve improved isolation. The changes include extending `_sanitize_paths` in `BaseArtifactStore` to enforce boundaries, rerouting helper methods to use artifact store methods, and updating standard materializers to interact with the artifact store directly. A potential breaking change is highlighted, requiring users to ensure operations stay within Artifact Store scopes to maintain security. The contributor has followed the contributing guidelines, including adding tests, updating documentation, and basing the branch on `develop`.\n\n### Comments Summary\n\nThe comments from `avishniakov` are direct requests for `@coderabbitai` to review the pull request, indicating a general review request without specific areas of concern mentioned.\n\n### AI-Generated Summary of Generated Summaries\n\nThe PR introduces key changes to enhance ZenML's artifact store isolation:\n\n1. **Base Artifact Store Enhancements:**\n   - Added imports for `inspect` and `Path`.\n   - Implemented `_verify` for input validation.\n   - Modified `__init_subclass__` for automatic path verification.\n   - Introduced `_inner_verify` for path validation within store bounds.\n\n2. **Artifact Utilities Update (`utils.py`):**\n   - Updated `_load_file_from_artifact_store` to raise `IOError` on rejection, improving error handling.\n\n3. **Integration Test Addition (`test_base_artifact_store.py`):**\n   - Added tests to ensure operations within artifact store bounds, covering file operations.\n\nThese changes collectively strengthen artifact store isolation by enforcing boundaries, enhancing error handling, and ensuring operations are confined within designated scopes.\n\n-->\n<!-- end of auto-generated comment: short summary by coderabbit.ai --><!-- commit_ids_reviewed_start -->\n\n<!-- b265c323bc8fab8cd82470795c5d7ca625f78c65 -->\n<!-- 18b1eb630f150bd7ba6439578f27e20da06b6d46 -->\n\n<!-- commit_ids_reviewed_end --><!-- tweet_start -->\n\nThank you for using CodeRabbit. We offer it for free to the OSS community and would appreciate your support in helping us grow. If you find it useful, would you consider giving us a shout-out on your favorite social media?\n\n<details>\n<summary>Share</summary>\n\n- [X](https://twitter.com/intent/tweet?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A&url=https%3A//coderabbit.ai)\n- [Mastodon](https://mastodon.social/share?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A%20https%3A%2F%2Fcoderabbit.ai)\n- [Reddit](https://www.reddit.com/submit?title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&text=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code.%20Check%20it%20out%3A%20https%3A//coderabbit.ai)\n- [LinkedIn](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcoderabbit.ai&mini=true&title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&summary=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code)\n\n</details>\n\n<!-- tweet_end --><!-- tips_start -->\n\n---\n\n<details>\n<summary>Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with CodeRabbit:\n\n- Review comments: Directly reply to a review comment made by CodeRabbit. Example:\n\t- `I pushed a fix in commit <commit_id>.`\n\t- `Generate unit-tests for this file.`\n- Files and specific lines of code (under the \"Files changed\" tab): Tag `@coderabbitai` in a new review comment at the desired location with your query. Examples:\n\t- `@coderabbitai generate unit tests for this file.`\n\t-\t`@coderabbitai modularize this function.`\n- PR comments: Tag `@coderabbitai` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n\t- `@coderabbitai generate interesting stats about this repository and render them as a table.`\n\t- `@coderabbitai show all the console.log statements in this repository.`\n\t- `@coderabbitai read src/utils.ts and generate unit tests.`\n\t- `@coderabbitai read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (invoked as PR comments)\n\n- `@coderabbitai pause` to pause the reviews on a PR.\n- `@coderabbitai resume` to resume the paused reviews.\n- `@coderabbitai review` to trigger a review. This is useful when automatic reviews are disabled for the repository.\n- `@coderabbitai resolve` resolve all the CodeRabbit review comments.\n- `@coderabbitai help` to get help.\n\n\nAdditionally, you can add `@coderabbitai ignore` anywhere in the PR description to prevent this PR from being reviewed.\n\n### CodeRabbit Configration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- The JSON schema for the configuration file is available [here](https://coderabbit.ai/integrations/coderabbit-overrides.v2.json).\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/coderabbit-overrides.v2.json`\n\n### CodeRabbit Discord Community\n\nJoin our [Discord Community](https://discord.com/invite/GsXnASn26c) to get help, request features, and share feedback.\n\n</details>\n\n<!-- tips_end -->",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-01T14:15:30Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2490#issuecomment-1973281965"
                    },
                    {
                        "body": "@coderabbitai review ",
                        "user": "avishniakov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-01T14:17:18Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2490#issuecomment-1973284908"
                    },
                    {
                        "body": "Quickstart template updates in `examples/quickstart` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-01T14:18:18Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2490#issuecomment-1973286505"
                    },
                    {
                        "body": "NLP template updates in `examples/e2e_nlp` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-01T14:28:35Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2490#issuecomment-1973301830"
                    },
                    {
                        "body": "E2E template updates in `examples/e2e` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-02T10:38:00Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2490#issuecomment-1974759630"
                    },
                    {
                        "body": "@coderabbitai review",
                        "user": "avishniakov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-04T07:59:59Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2490#issuecomment-1975934439"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/zenml-io/zenml/pulls/2490",
                    "merged_at": "2024-03-05T08:02:33Z"
                }
            },
            {
                "url": "https://github.com/zenml-io/zenml/pull/2484",
                "title": "Rate limiting for login API",
                "labels": [
                    "bug",
                    "internal",
                    "security",
                    "run-slow-ci",
                    "P2"
                ],
                "user": "avishniakov",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2484,
                "id": 2161501033,
                "state": "closed",
                "project_created_at": "2024-02-29T15:17:16Z",
                "closed_at": "2024-03-18T11:59:40Z",
                "body": "## Describe changes\r\nI fixed the missing rate limit for login API to prevent misuse and too frequent login attempts.\r\n\r\n## Pre-requisites\r\nPlease ensure you have done the following:\r\n- [x] I have read the **CONTRIBUTING.md** document.\r\n- [x] If my change requires a change to docs, I have updated the documentation accordingly.\r\n- [x] I have added tests to cover my changes.\r\n- [x] I have based my new branch on `develop` and the open PR is targeting `develop`. If your branch wasn't based on develop read [Contribution guide on rebasing branch to develop](https://github.com/zenml-io/zenml/blob/main/CONTRIBUTING.md#-pull-requests-rebase-your-branch-on-develop).\r\n- [x] If my changes require changes to the dashboard, these changes are communicated/requested.\r\n\r\n## Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Other (add details above)\r\n\r\n\n\n<!-- This is an auto-generated comment: release notes by coderabbit.ai -->\n\n## Summary by CodeRabbit\n\n- **New Features**\n\t- Introduced rate limiting on authentication requests to enhance security and manage traffic effectively. Users can now make up to 5 requests per minute and 1000 requests per day.\n\n<!-- end of auto-generated comment: release notes by coderabbit.ai -->",
                "comments": [
                    {
                        "body": "<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- This is an auto-generated comment: skip review by coderabbit.ai -->\n\n> [!IMPORTANT]\n> ## Auto Review Skipped\n> \n> Auto reviews are disabled on this repository.\n> \n> Please check the settings in the CodeRabbit UI or the `.coderabbit.yaml` file in this repository.\n> \n> To trigger a single review, invoke the `@coderabbitai review` command.\n> \n\n<!-- end of auto-generated comment: skip review by coderabbit.ai --><!-- walkthrough_start -->\n\n## Walkthrough\nThe recent update introduces `slowapi` as an optional dependency to enhance the server's resilience against abuse. Specifically, it applies rate limiting to authentication endpoints, ensuring they can only be accessed a certain number of times per minute or day. This measure helps protect the server from potential overload or attack by regulating access frequency.\n\n## Changes\n\n| File Path                        | Change Summary                                         |\n|----------------------------------|--------------------------------------------------------|\n| `pyproject.toml`                 | Added `slowapi` as an optional dependency (`>=0.1.9`). |\n| `.../zen_server/routers/auth_endpoints.py` | Imported `Limiter` and `get_remote_address` from `slowapi`; initialized `limiter` with `Limiter(key_func=get_remote_address)`; added rate limiting (`5/minute;1000/day`) to the `token` function. |\n\n>   \n> In the land of code and might,  \n> A new guard rises, shining bright.  \n> \"Slow and steady,\" it firmly said,  \n> Keeping the server safe, ahead.  \n> With every hop, it sets the pace,  \n> Ensuring all find their rightful place.  \n> \n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: raw summary by coderabbit.ai -->\n<!--\n\n\npyproject.toml: ## Short summary\n\nAdded `slowapi` as an optional dependency with version `>=0.1.9`.\n\nsrc/zenml/zen_server/routers/auth_endpoints.py: ## Short summary\n\nAdded import statements for `Limiter` and `get_remote_address`. Initialized `limiter` with `Limiter(key_func=get_remote_address)`. Decorated the `token` function with rate limiting using `@limiter.limit(\"5/minute;1000/day\")`.\n\n-->\n<!-- end of auto-generated comment: raw summary by coderabbit.ai --><!-- This is an auto-generated comment: short summary by coderabbit.ai -->\n<!--\n\n\n### PR Objectives\n\nThe pull request (PR) titled \"Rate limiting for login API\" (number 2484) introduces a crucial security enhancement to the login API by implementing rate limiting. This change aims to mitigate misuse and excessive login attempts, enhancing the overall security posture of the system. The contributor has completed several preparatory steps to ensure the quality and compatibility of this change, including reading the contributing guidelines, potentially updating documentation, basing their work on the `develop` branch, and communicating necessary changes to the dashboard if required. Although the PR does not include new tests to cover the changes, it marks a significant bug fix by adding rate limiting to an area previously lacking this safeguard. The changes are categorized under bug fixes, indicating an improvement to existing functionality without introducing new features or breaking changes.\n\n### Comments Summary\n\nThe comment from `avishniakov` directly requests a review from `@coderabbitai`. This indicates a need for evaluation and feedback on the implemented changes. There are no further comments providing additional context or raising specific concerns about the PR. Thus, the primary focus from the comments is on obtaining a thorough review of the modifications made to introduce rate limiting to the login API.\n\n### AI-generated Summary of Generated Summaries\n\nThe PR introduces rate limiting to the login API by incorporating `slowapi` as an optional dependency, specified to be version `>=0.1.9` in `pyproject.toml`. In `src/zenml/zen_server/routers/auth_endpoints.py`, the changes involve importing `Limiter` and `get_remote_address` to initialize a `limiter` instance with `Limiter(key_func=get_remote_address)`. The `token` function, responsible for handling login attempts, is now decorated with a rate limit of \"5/minute;1000/day\" to prevent misuse and excessive login attempts. This enhancement is a direct response to the previously identified gap in security measures, specifically addressing the need for rate limiting to protect against potential abuse. The implementation details, including the choice of rate limits and the use of `slowapi`, reflect a targeted approach to improving the system's resilience against brute-force attacks and other forms of abuse that could compromise user security and system integrity.\n\n-->\n<!-- end of auto-generated comment: short summary by coderabbit.ai --><!-- commit_ids_reviewed_start -->\n\n<!-- 32c06cb5bbdc003647756b59c6379d3c250cabc0 -->\n\n<!-- commit_ids_reviewed_end --><!-- tweet_start -->\n\nThank you for using CodeRabbit. We offer it for free to the OSS community and would appreciate your support in helping us grow. If you find it useful, would you consider giving us a shout-out on your favorite social media?\n\n<details>\n<summary>Share</summary>\n\n- [X](https://twitter.com/intent/tweet?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A&url=https%3A//coderabbit.ai)\n- [Mastodon](https://mastodon.social/share?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A%20https%3A%2F%2Fcoderabbit.ai)\n- [Reddit](https://www.reddit.com/submit?title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&text=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code.%20Check%20it%20out%3A%20https%3A//coderabbit.ai)\n- [LinkedIn](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcoderabbit.ai&mini=true&title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&summary=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code)\n\n</details>\n\n<!-- tweet_end --><!-- tips_start -->\n\n---\n\n<details>\n<summary>Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with CodeRabbit:\n\n- Review comments: Directly reply to a review comment made by CodeRabbit. Example:\n\t- `I pushed a fix in commit <commit_id>.`\n\t- `Generate unit-tests for this file.`\n\t- `Open a follow-up GitHub issue for this discussion.`\n- Files and specific lines of code (under the \"Files changed\" tab): Tag `@coderabbitai` in a new review comment at the desired location with your query. Examples:\n\t- `@coderabbitai generate unit tests for this file.`\n\t-\t`@coderabbitai modularize this function.`\n- PR comments: Tag `@coderabbitai` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n\t- `@coderabbitai generate interesting stats about this repository and render them as a table.`\n\t- `@coderabbitai show all the console.log statements in this repository.`\n\t- `@coderabbitai read src/utils.ts and generate unit tests.`\n\t- `@coderabbitai read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (invoked as PR comments)\n\n- `@coderabbitai pause` to pause the reviews on a PR.\n- `@coderabbitai resume` to resume the paused reviews.\n- `@coderabbitai review` to trigger a review. This is useful when automatic reviews are disabled for the repository.\n- `@coderabbitai resolve` resolve all the CodeRabbit review comments.\n- `@coderabbitai help` to get help.\n\n\nAdditionally, you can add `@coderabbitai ignore` anywhere in the PR description to prevent this PR from being reviewed.\n\n### CodeRabbit Configration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- The JSON schema for the configuration file is available [here](https://coderabbit.ai/integrations/coderabbit-overrides.v2.json).\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/coderabbit-overrides.v2.json`\n\n### CodeRabbit Discord Community\n\nJoin our [Discord Community](https://discord.com/invite/GsXnASn26c) to get help, request features, and share feedback.\n\n</details>\n\n<!-- tips_end -->",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-29T15:17:24Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2484#issuecomment-1971362152"
                    },
                    {
                        "body": "@coderabbitai review",
                        "user": "avishniakov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-29T15:21:28Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2484#issuecomment-1971370519"
                    },
                    {
                        "body": "Quickstart template updates in `examples/quickstart` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-29T15:24:28Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2484#issuecomment-1971376593"
                    },
                    {
                        "body": "NLP template updates in `examples/e2e_nlp` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-29T15:34:29Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2484#issuecomment-1971397311"
                    },
                    {
                        "body": "> I love how simple `slowapi` is. I don't recommend we use fastapi_limiter for this, it's overkill.\r\n> \r\n> I already closed the original vulnerability as informational on account of us not advertising the username/password authentication method as a full-fledged production-grade security scheme. If `slowapi` doesn't work out, we could also give up and not fix this at all.\r\n\r\ngood catch - forgot about redis",
                        "user": "AlexejPenner",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-01T10:23:09Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2484#issuecomment-1972921554"
                    },
                    {
                        "body": "E2E template updates in `examples/e2e` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-01T15:42:40Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2484#issuecomment-1973413129"
                    },
                    {
                        "body": "I just realized there's another reason why we need to be very very careful with this: rate-limiters rely on the ability to extract the *real* source IP address from an incoming request, but this can be difficult to achieve, especially with cloud or Kubernetes deployments, because a load balancer or proxy usually sits in front of the ZenML server and rewrites the source IP address.\r\n\r\nIf mis-configured, this can have disastrous consequences, because all requests are \"seen\" as coming from the same IP address. For example, someone trying to brute-force their way into the server can become a DoS attack, because everyone will be locked out of the server.\r\n\r\nMore info here:\r\n* https://stackoverflow.com/questions/60098005/fastapi-starlette-get-client-real-ip\r\n* https://www.uvicorn.org/settings/#http\r\n\r\nI think the safe thing to do is to have rate-limiting turned off by default and have proper documentation around how to properly configure it and the services around it to avoid problems.\r\n\r\nSee this PR for a bug related to the same problem: https://github.com/zenml-io/zenml/pull/2499",
                        "user": "stefannica",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-06T15:28:56Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2484#issuecomment-1981135392"
                    },
                    {
                        "body": "> I just realized there's another reason why we need to be very very careful with this: rate-limiters rely on the ability to extract the _real_ source IP address from an incoming request, but this can be difficult to achieve, especially with cloud or Kubernetes deployments, because a load balancer or proxy usually sits in front of the ZenML server and rewrites the source IP address.\r\n> \r\n> If mis-configured, this can have disastrous consequences, because all requests are \"seen\" as coming from the same IP address. For example, someone trying to brute-force their way into the server can become a DoS attack, because everyone will be locked out of the server.\r\n> \r\n> More info here:\r\n> \r\n> * https://stackoverflow.com/questions/60098005/fastapi-starlette-get-client-real-ip\r\n> * https://www.uvicorn.org/settings/#http\r\n> \r\n> I think the safe thing to do is to have rate-limiting turned off by default and have proper documentation around how to properly configure it and the services around it to avoid problems.\r\n> \r\n> See this PR for a bug related to the same problem: #2499\r\n\r\nYeah, this makes sense to me, but let's build on top of that:\r\nIf k8s or other infra is bombarding REST with incorrect credentials, why should it pass? Successful requests do not affect limits. This might be an issue indeed for users behind VPN, for instance (they all might land on the same IP).\r\n\r\nDue to all those complications, we can drop this feature completely for OSS. Based on my research - everything inside HTTP request can be spoofed, so we cannot rely really on any header or other info to make a weighted decision if this is the same requestor or not. I don't know what folks from CDN solution use to prevent DDoS and other things, but we are not CDN provider  ",
                        "user": "avishniakov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-07T10:59:10Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2484#issuecomment-1983264813"
                    },
                    {
                        "body": "> Yeah, this makes sense to me, but let's build on top of that: If k8s or other infra is bombarding REST with incorrect credentials, why should it pass? Successful requests do not affect limits. This might be an issue indeed for users behind VPN, for instance (they all might land on the same IP).\r\n> \r\n> Due to all those complications, we can drop this feature completely for OSS. Based on my research - everything inside HTTP request can be spoofed, so we cannot rely really on any header or other info to make a weighted decision if this is the same requestor or not. I don't know what folks from CDN solution use to prevent DDoS and other things, but we are not CDN provider \r\n\r\nThere's probably been a misunderstanding, it's not really k8s or other infra that's bombarding REST with incorrect credentials. This is what can happen if the ZenML server or the kubernetes cluster or load balancer, or proxy is incorrectly configured:\r\n* let's say you have 100 legit users regularly logging in\r\n* let's also say you have an attacker trying to brute-force his way into the server\r\n* when incorrectly configured, the server \"sees\" all requests coming from a single IP: the IP of the proxy or load-balancer\r\n* the \"bad\" requests will pile up until the limiter starts blocking traffic from that IP address, effectively stopping everyone from logging in, even the legit users\r\n\r\nWe should still offer the limiter as a feature, because it's a great thing to have for security, but have some way of configuring it and keeping it disabled by default. If the admins enable it, it's their responsibility to correctly configure the surrounding infrastructure (proxy/load-balancer/whatever).",
                        "user": "stefannica",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-07T11:17:29Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2484#issuecomment-1983294431"
                    },
                    {
                        "body": "@stefannica I added some docs describing how to configure it and cancel the current CI - the last one was all green. Please have a look.",
                        "user": "avishniakov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-11T08:30:42Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2484#issuecomment-1987866801"
                    },
                    {
                        "body": "Quickstart template updates in `examples/quickstart` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-11T16:11:04Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2484#issuecomment-1988814249"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/zenml-io/zenml/pulls/2484",
                    "merged_at": "2024-03-18T11:59:40Z"
                }
            },
            {
                "url": "https://github.com/zenml-io/zenml/pull/2483",
                "title": "Uniquely constrained users table",
                "labels": [
                    "bug",
                    "internal",
                    "security",
                    "run-slow-ci"
                ],
                "user": "avishniakov",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2483,
                "id": 2161404966,
                "state": "closed",
                "project_created_at": "2024-02-29T14:31:59Z",
                "closed_at": "2024-03-04T09:05:44Z",
                "body": "## Describe changes\r\nI fixed how we ensure that no duplicates are passed to the DB level for UserSchema.\r\n\r\n## Pre-requisites\r\nPlease ensure you have done the following:\r\n- [x] I have read the **CONTRIBUTING.md** document.\r\n- [x] If my change requires a change to docs, I have updated the documentation accordingly.\r\n- [x] I have added tests to cover my changes.\r\n- [x] I have based my new branch on `develop` and the open PR is targeting `develop`. If your branch wasn't based on develop read [Contribution guide on rebasing branch to develop](https://github.com/zenml-io/zenml/blob/main/CONTRIBUTING.md#-pull-requests-rebase-your-branch-on-develop).\r\n- [x] If my changes require changes to the dashboard, these changes are communicated/requested.\r\n\r\n## Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Other (add details above)\r\n\r\n\n\n<!-- This is an auto-generated comment: release notes by coderabbit.ai -->\n\n## Summary by CodeRabbit\n\n- **New Features**\n\t- Implemented a unique constraint for user names to ensure each user is distinct, enhancing data integrity.\n- **Refactor**\n\t- Improved transaction management with better exception handling for user creation and updates.\n\n<!-- end of auto-generated comment: release notes by coderabbit.ai -->",
                "comments": [
                    {
                        "body": "<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- This is an auto-generated comment: skip review by coderabbit.ai -->\n\n> [!IMPORTANT]\n> ## Auto Review Skipped\n> \n> Auto reviews are disabled on this repository.\n> \n> Please check the settings in the CodeRabbit UI or the `.coderabbit.yaml` file in this repository.\n> \n> To trigger a single review, invoke the `@coderabbitai review` command.\n> \n\n<!-- end of auto-generated comment: skip review by coderabbit.ai --><!-- walkthrough_start -->\n\n## Walkthrough\nThe update introduces a unique constraint to the `user` table, ensuring that each combination of user name and service account status is unique. It modifies the schema to include this constraint and enhances the transaction management in the SQL store. Exception handling is improved with specific attention to `IntegrityError`, streamlining the process of checking for existing entities before their creation.\n\n## Changes\n\n| File Path                         | Change Summary                                                           |\n|-----------------------------------|--------------------------------------------------------------------------|\n| `.../migrations/versions/72675226b2de_unique_users.py` | Adds a migration script for unique constraint on `user` table.          |\n| `.../zen_stores/schemas/user_schemas.py`               | Introduces `UniqueConstraint` in `UserSchema`.                           |\n| `.../zen_stores/sql_zen_store.py`                       | Enhances transaction management and exception handling for entity creation. |\n\n>   \n> To the database, we hop and bound,  \n> With unique users, no duplicates found.  \n> Try and catch, we gracefully manage,  \n> Ensuring integrity, with no damage.  \n> So here's to changes, both big and small,  \n> May our code run smoothly, bugs none at all.  \n> \n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: raw summary by coderabbit.ai -->\n<!--\n\n\nsrc/zenml/zen_stores/migrations/versions/72675226b2de_unique_users.py: This file introduces a migration script that adds a unique constraint to the \"user\" table on columns \"name\" and \"is_service_account.\"\n\n---\n\nsrc/zenml/zen_stores/schemas/user_schemas.py: Added a `UniqueConstraint` to the `UserSchema` table definition in `user_schemas.py`.\n\n---\n\nsrc/zenml/zen_stores/sql_zen_store.py: \n- The code now uses `try-except` blocks with `IntegrityError` handling for transaction management.\n- The logic for checking existing entities before creation has been updated to handle exceptions more effectively.\n\n-->\n<!-- end of auto-generated comment: raw summary by coderabbit.ai --><!-- This is an auto-generated comment: short summary by coderabbit.ai -->\n<!--\n\n\n### PR Objectives\n\nThe pull request (PR) number 2483, titled \"Uniquely constrained users table,\" aims to address an issue related to the duplication of user data in the database. The submitter has implemented a fix to ensure that the UserSchema does not allow duplicate entries at the database level, enhancing data integrity and consistency within the application's user management system.\n\nThe changes made in this PR involve the introduction of a unique constraint on the \"user\" table, specifically targeting the \"name\" and \"is_service_account\" columns to prevent the insertion of duplicate records. This modification is critical for maintaining a clean and reliable user database, especially in systems where the distinction between regular users and service accounts is vital.\n\nBefore submitting the PR, the author has adhered to several pre-requisites, including reading the contributing document, updating documentation if necessary, adding tests to cover the changes, basing their branch on `develop`, and communicating any dashboard-related changes. The types of changes introduced by this PR are categorized under \"Bug fix,\" indicating that the primary goal is to rectify an existing issue without introducing new features or breaking changes.\n\n### Comments Summary\n\nThe comment on the PR from `avishniakov` is a direct request for a review from `@coderabbitai`. This indicates that the PR is ready for evaluation and possibly requires expertise or insights from the mentioned reviewer. There are no additional comments providing further context or feedback on the PR, suggesting that the discussion is in its early stages or that the changes are straightforward enough not to warrant immediate concerns or questions from other contributors.\n\n### AI-Generated Summary of Generated Summaries\n\nThe PR introduces a set of changes aimed at enhancing the uniqueness constraints within the user management system of the application. Specifically, a migration script has been added to enforce a unique constraint on the \"name\" and \"is_service_account\" columns of the \"user\" table, ensuring that duplicate entries are prevented at the database level. This is further supported by modifications in the `UserSchema` within `user_schemas.py`, where a `UniqueConstraint` has been explicitly defined to uphold this requirement.\n\nAdditionally, the PR includes updates to the `sql_zen_store.py` file, where transaction management has been improved through the use of `try-except` blocks specifically designed to catch `IntegrityError`. This enhancement not only aids in handling exceptions more effectively but also updates the logic for checking existing entities before their creation, thereby reinforcing the overall integrity and reliability of the user data management process.\n\nIn summary, PR 2483 focuses on fixing an issue related to user data duplication by implementing unique constraints and improving exception handling mechanisms, thereby ensuring the integrity and uniqueness of user records in the database.\n\n-->\n<!-- end of auto-generated comment: short summary by coderabbit.ai --><!-- commit_ids_reviewed_start -->\n\n<!-- 135c2e05e7350f1b49ccddcf450e6533143900a7 -->\n\n<!-- commit_ids_reviewed_end --><!-- tweet_start -->\n\nThank you for using CodeRabbit. We offer it for free to the OSS community and would appreciate your support in helping us grow. If you find it useful, would you consider giving us a shout-out on your favorite social media?\n\n<details>\n<summary>Share</summary>\n\n- [X](https://twitter.com/intent/tweet?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A&url=https%3A//coderabbit.ai)\n- [Mastodon](https://mastodon.social/share?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A%20https%3A%2F%2Fcoderabbit.ai)\n- [Reddit](https://www.reddit.com/submit?title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&text=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code.%20Check%20it%20out%3A%20https%3A//coderabbit.ai)\n- [LinkedIn](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcoderabbit.ai&mini=true&title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&summary=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code)\n\n</details>\n\n<!-- tweet_end --><!-- tips_start -->\n\n---\n\n<details>\n<summary>Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with CodeRabbit:\n\n- Review comments: Directly reply to a review comment made by CodeRabbit. Example:\n\t- `I pushed a fix in commit <commit_id>.`\n\t- `Generate unit-tests for this file.`\n- Files and specific lines of code (under the \"Files changed\" tab): Tag `@coderabbitai` in a new review comment at the desired location with your query. Examples:\n\t- `@coderabbitai generate unit tests for this file.`\n\t-\t`@coderabbitai modularize this function.`\n- PR comments: Tag `@coderabbitai` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n\t- `@coderabbitai generate interesting stats about this repository from git and render them as a table.`\n\t- `@coderabbitai show all the console.log statements in this repository.`\n\t- `@coderabbitai read src/utils.ts and generate unit tests.`\n\t- `@coderabbitai read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (invoked as PR comments)\n\n- `@coderabbitai pause` to pause the reviews on a PR.\n- `@coderabbitai resume` to resume the paused reviews.\n- `@coderabbitai review` to trigger a review. This is useful when automatic reviews are disabled for the repository.\n- `@coderabbitai resolve` resolve all the CodeRabbit review comments.\n- `@coderabbitai help` to get help.\n\n\nAdditionally, you can add `@coderabbitai ignore` anywhere in the PR description to prevent this PR from being reviewed.\n\n### CodeRabbit Configration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- The JSON schema for the configuration file is available [here](https://coderabbit.ai/integrations/coderabbit-overrides.v2.json).\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/coderabbit-overrides.v2.json`\n\n### CodeRabbit Discord Community\n\nJoin our [Discord Community](https://discord.com/invite/GsXnASn26c) to get help, request features, and share feedback.\n\n</details>\n\n<!-- tips_end -->",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-29T14:32:06Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2483#issuecomment-1971271288"
                    },
                    {
                        "body": "@coderabbitai review",
                        "user": "avishniakov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-29T14:35:15Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2483#issuecomment-1971277466"
                    },
                    {
                        "body": "Quickstart template updates in `examples/quickstart` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-29T15:29:22Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2483#issuecomment-1971386763"
                    },
                    {
                        "body": "NLP template updates in `examples/e2e_nlp` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-29T15:39:53Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2483#issuecomment-1971407930"
                    },
                    {
                        "body": "Quickstart template updates in `examples/quickstart` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-01T07:23:11Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2483#issuecomment-1972655166"
                    },
                    {
                        "body": "NLP template updates in `examples/e2e_nlp` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-01T07:32:40Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2483#issuecomment-1972669241"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/zenml-io/zenml/pulls/2483",
                    "merged_at": "2024-03-04T09:05:44Z"
                }
            },
            {
                "url": "https://github.com/zenml-io/zenml/pull/2479",
                "title": "Race condition on creating new users allows duplicate usernames",
                "labels": [
                    "bug",
                    "internal",
                    "security",
                    "run-slow-ci"
                ],
                "user": "avishniakov",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2479,
                "id": 2160773280,
                "state": "closed",
                "project_created_at": "2024-02-29T09:13:57Z",
                "closed_at": "2024-02-29T12:04:58Z",
                "body": "## Describe changes\r\nI fixed the conditional check for new users/service account creation under heavy race conditions (e.g. 100 simultaneous request to create new user).\r\n\r\n## Pre-requisites\r\nPlease ensure you have done the following:\r\n- [x] I have read the **CONTRIBUTING.md** document.\r\n- [x] If my change requires a change to docs, I have updated the documentation accordingly.\r\n- [x] I have added tests to cover my changes.\r\n- [x] I have based my new branch on `develop` and the open PR is targeting `develop`. If your branch wasn't based on develop read [Contribution guide on rebasing branch to develop](https://github.com/zenml-io/zenml/blob/main/CONTRIBUTING.md#-pull-requests-rebase-your-branch-on-develop).\r\n- [x] If my changes require changes to the dashboard, these changes are communicated/requested.\r\n\r\n## Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Other (add details above)\r\n\r\n\n\n<!-- This is an auto-generated comment: release notes by coderabbit.ai -->\n\n## Summary by CodeRabbit\n\n- **Refactor**\n\t- Improved the handling and creation process of entities within the system to prevent duplication and enhance error management.\n- **Tests**\n\t- Added tests to ensure users and service accounts can be created in parallel without duplication, enhancing system reliability.\n\n<!-- end of auto-generated comment: release notes by coderabbit.ai -->",
                "comments": [
                    {
                        "body": "<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- This is an auto-generated comment: skip review by coderabbit.ai -->\n\n> [!IMPORTANT]\n> ## Auto Review Skipped\n> \n> Auto reviews are disabled on this repository.\n> \n> Please check the settings in the CodeRabbit UI or the `.coderabbit.yaml` file in this repository.\n> \n> To trigger a single review, invoke the `@coderabbitai review` command.\n> \n\n<!-- end of auto-generated comment: skip review by coderabbit.ai --><!-- walkthrough_start -->\n\n## Walkthrough\nThe recent updates focus on enhancing the reliability and concurrency of operations within a SQL-based storage system for ZenML, specifically targeting the creation of entities like users and service accounts. The changes ensure entities are uniquely created without duplication even when multiple requests are made in parallel, alongside improved error handling for entity existence.\n\n## Changes\n\n| File Path                                               | Change Summary                                                                 |\n|---------------------------------------------------------|---------------------------------------------------------------------------------|\n| `src/zenml/.../sql_zen_store.py`                        | Enhanced entity creation order, existence checks, and error handling.          |\n| `tests/integration/functional/zen_stores/.../test_zen_store.py` | Added tests for parallel user and service account creation without duplication.|\n\n>   \n> In the realm of code where the data flows,  \n> A rabbit hopped, fixing bugs in rows.  \n> No duplicates found, in parallel they thrive,  \n> Ensuring entities uniquely arrive.  \n> With each hop and leap, the code does improve,  \n> In the ZenML land, smooth and on the move.  \n> \n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: raw summary by coderabbit.ai -->\n<!--\n\n\nsrc/zenml/zen_stores/sql_zen_store.py: ## Short summary\n\nIn the `sql_zen_store.py` file, the changes involve reordering the creation of entities within a session, checking for existing entities before committing, adjusting error handling for entity existence.\n\n---\n\ntests/integration/functional/zen_stores/test_zen_store.py: ## Short summary\n\n- Added import for `threading`.\n- Added import for `UserFilter`.\n- Added a new test `test_creating_users_in_parallel_do_not_duplicate_fails` to test creating users in parallel without duplication.\n- Added a new test `test_creating_service_accounts_in_parallel_do_not_duplicate_fails` to test creating service accounts in parallel without duplication.\n\n-->\n<!-- end of auto-generated comment: raw summary by coderabbit.ai --><!-- This is an auto-generated comment: short summary by coderabbit.ai -->\n<!--\n\n\n### PR Objectives\n\nThe pull request (PR) #2479 addresses a critical issue related to the creation of new users and service accounts under heavy race conditions, such as when there are 100 simultaneous requests to create a new user. The submitter has identified and fixed a race condition that allowed for the creation of duplicate usernames, which is a significant bug fix enhancing the system's integrity and reliability.\n\nThe changes made include adjustments to the conditional checks during the user and service account creation process to prevent duplicates from occurring even under heavy load. This fix is crucial for maintaining the uniqueness of usernames across the system, which is fundamental for user identification and management.\n\nThe contributor has followed all the necessary pre-requisites for submitting the PR, including reading the contributing document, updating documentation if required, adding tests to cover the changes, basing the new branch on `develop`, and communicating any dashboard changes. The type of change is categorized under \"Bug fix,\" indicating that it resolves an issue without introducing new features or breaking existing functionality.\n\n### Comments Summary\n\nIn the comments section of the PR, there are two notable interactions:\n\n1. **GitGuardian Alert**: A comment from `avishniakov` highlights an alert from GitGuardian, which detected a hardcoded secret in the pull request. However, this was immediately addressed by the commenter as a false positive. This interaction is crucial as it concerns security and the integrity of the codebase, but since it's identified as a false positive, it doesn't impact the PR's review process directly.\n\n2. **Review Request**: `strickvl` has requested a review from `coderabbitai`. This indicates that the PR is ready for further examination and evaluation by peers or automated systems to ensure the changes meet the project's standards and effectively address the issue at hand.\n\n### AI-Generated Summary of Generated Summaries\n\nThe pull request introduces modifications primarily within the `sql_zen_store.py` file and the integration tests to address a race condition issue that allowed the creation of duplicate usernames during high concurrency scenarios. The core changes involve enhancing the logic for checking the existence of entities before committing their creation to the database and refining error handling related to entity existence checks. Specifically, the adjustments ensure that during the creation process of users and service accounts, the system now correctly identifies and prevents the creation of duplicates, thereby maintaining the uniqueness and integrity of usernames.\n\nAdditionally, the integration tests have been expanded to include new tests that simulate the parallel creation of users and service accounts, ensuring that the fixes are effective and that such race conditions are appropriately handled. These tests leverage threading to mimic concurrent requests, providing a robust validation for the changes made.\n\nIn summary, the PR effectively addresses a significant race condition issue by refining the entity creation process and enhancing the system's ability to handle high concurrency scenarios without compromising the uniqueness of usernames. The inclusion of targeted integration tests further ensures the reliability and effectiveness of these changes.\n\n-->\n<!-- end of auto-generated comment: short summary by coderabbit.ai --><!-- commit_ids_reviewed_start -->\n\n<!-- 618770b84cc75d2478070fc47a6a7da2848668ae -->\n\n<!-- commit_ids_reviewed_end --><!-- tweet_start -->\n\nThank you for using CodeRabbit. We offer it for free to the OSS community and would appreciate your support in helping us grow. If you find it useful, would you consider giving us a shout-out on your favorite social media?\n\n<details>\n<summary>Share</summary>\n\n- [X](https://twitter.com/intent/tweet?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A&url=https%3A//coderabbit.ai)\n- [Mastodon](https://mastodon.social/share?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A%20https%3A%2F%2Fcoderabbit.ai)\n- [Reddit](https://www.reddit.com/submit?title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&text=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code.%20Check%20it%20out%3A%20https%3A//coderabbit.ai)\n- [LinkedIn](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcoderabbit.ai&mini=true&title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&summary=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code)\n\n</details>\n\n<!-- tweet_end --><!-- tips_start -->\n\n---\n\n<details>\n<summary>Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with CodeRabbit:\n\n- Review comments: Directly reply to a review comment made by CodeRabbit. Example:\n\t- `I pushed a fix in commit <commit_id>.`\n\t- `Generate unit-tests for this file.`\n- Files and specific lines of code (under the \"Files changed\" tab): Tag `@coderabbitai` in a new review comment at the desired location with your query. Examples:\n\t- `@coderabbitai generate unit tests for this file.`\n\t-\t`@coderabbitai modularize this function.`\n- PR comments: Tag `@coderabbitai` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n\t- `@coderabbitai generate interesting stats about this repository from git and render them as a table.`\n\t- `@coderabbitai show all the console.log statements in this repository.`\n\t- `@coderabbitai read src/utils.ts and generate unit tests.`\n\t- `@coderabbitai read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (invoked as PR comments)\n\n- `@coderabbitai pause` to pause the reviews on a PR.\n- `@coderabbitai resume` to resume the paused reviews.\n- `@coderabbitai review` to trigger a review. This is useful when automatic reviews are disabled for the repository.\n- `@coderabbitai resolve` resolve all the CodeRabbit review comments.\n- `@coderabbitai help` to get help.\n\n\nAdditionally, you can add `@coderabbitai ignore` anywhere in the PR description to prevent this PR from being reviewed.\n\n### CodeRabbit Configration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- The JSON schema for the configuration file is available [here](https://coderabbit.ai/integrations/coderabbit-overrides.v2.json).\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/coderabbit-overrides.v2.json`\n\n### CodeRabbit Discord Community\n\nJoin our [Discord Community](https://discord.com/invite/GsXnASn26c) to get help, request features, and share feedback.\n\n</details>\n\n<!-- tips_end -->",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-29T09:14:02Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2479#issuecomment-1970716369"
                    },
                    {
                        "body": "####  GitGuardian has uncovered 2 secrets following the scan of your pull request.\n\nPlease consider investigating the findings and remediating the incidents. Failure to do so may lead to compromising the associated services or software components.\n\n<details>\n<summary> Detected hardcoded secrets in your pull request</summary>\n<br>\n\n| GitGuardian id | GitGuardian status | Secret                         | Commit           | Filename        |                      |\n| -------------- | ------------------ | ------------------------------ | ---------------- | --------------- | -------------------- |\n| [9700814](https://dashboard.gitguardian.com/incidents/9700814?occurrence=125675547) | Triggered | Generic Password | 8f50f478b5bacd74c88a6ae98723d2d4b6ddd0c4 | tests/integration/functional/zen_stores/test_zen_store.py | [View secret](https://github.com/zenml-io/zenml/commit/8f50f478b5bacd74c88a6ae98723d2d4b6ddd0c4#diff-bedf4b90bcbddd89de31e1e8af7a9e4166a99c046efd8a3dc5d66bff73753a1dR425) |\n| [9700814](https://dashboard.gitguardian.com/incidents/9700814?occurrence=125676867) | Triggered | Generic Password | dd303b90385dc805c5cdccf8974be19f8f82a951 | tests/integration/functional/zen_stores/test_zen_store.py | [View secret](https://github.com/zenml-io/zenml/commit/dd303b90385dc805c5cdccf8974be19f8f82a951#diff-bedf4b90bcbddd89de31e1e8af7a9e4166a99c046efd8a3dc5d66bff73753a1dL425) |\n\n\n\n</details>\n\n<details>\n<summary> Guidelines to remediate hardcoded secrets</summary>\n<br>\n\n1. Understand the implications of revoking this secret by investigating where it is used in your code.\n2. Replace and store your secrets safely. [Learn here](https://blog.gitguardian.com/secrets-api-management?utm_source=product&amp;utm_medium=GitHub_checks&amp;utm_campaign=check_run_comment) the best practices.\n3. Revoke and [rotate these secrets](https://docs.gitguardian.com/secrets-detection/secrets-detection-engine/detectors/generics/generic_password#revoke-the-secret?utm_source=product&amp;utm_medium=GitHub_checks&amp;utm_campaign=check_run_comment).\n4. If possible, [rewrite git history](https://blog.gitguardian.com/rewriting-git-history-cheatsheet?utm_source=product&amp;utm_medium=GitHub_checks&amp;utm_campaign=check_run_comment). Rewriting git history is not a trivial act. You might completely break other contributing developers' workflow and you risk accidentally deleting legitimate data.\n\nTo avoid such incidents in the future consider\n\n-   following these [best practices](https://blog.gitguardian.com/secrets-api-management/?utm_source=product&amp;utm_medium=GitHub_checks&amp;utm_campaign=check_run_comment) for managing and storing secrets including API keys and other credentials\n-   install [secret detection on pre-commit](https://docs.gitguardian.com/ggshield-docs/integrations/git-hooks/pre-commit?utm_source=product&amp;utm_medium=GitHub_checks&amp;utm_campaign=check_run_comment) to catch secret before it leaves your machine and ease remediation.\n\n\n</details>\n\n---\n\n<sup> [GitGuardian](https://dashboard.gitguardian.com/auth/login/?utm_medium=checkruns&amp;utm_source=github&amp;utm_campaign=cr1) detects secrets in your source code to help developers and security teams secure the modern development process. You are seeing this because you or someone else with access to this repository has authorized GitGuardian to scan your pull request.<br/><br/>Our GitHub checks need improvements? [Share your feedbacks](https://form.typeform.com/to/KmeAPTMk)!</sup>",
                        "user": "gitguardian[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-29T09:14:05Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2479#issuecomment-1970716439"
                    },
                    {
                        "body": "> ####  GitGuardian has uncovered 1 secret following the scan of your pull request.\r\n> Please consider investigating the findings and remediating the incidents. Failure to do so may lead to compromising the associated services or software components.\r\n> \r\n>  Detected hardcoded secret in your pull request\r\n>  Guidelines to remediate hardcoded secrets\r\n>  [GitGuardian](https://dashboard.gitguardian.com/auth/login/?utm_medium=checkruns&utm_source=github&utm_campaign=cr1) detects secrets in your source code to help developers and security teams secure the modern development process. You are seeing this because you or someone else with access to this repository has authorized GitGuardian to scan your pull request.Our GitHub checks need improvements? [Share your feedbacks](https://form.typeform.com/to/KmeAPTMk)!\r\n\r\nFalse positive",
                        "user": "avishniakov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-29T09:18:03Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2479#issuecomment-1970722825"
                    },
                    {
                        "body": "@coderabbitai review",
                        "user": "strickvl",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-29T09:41:50Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2479#issuecomment-1970761596"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/zenml-io/zenml/pulls/2479",
                    "merged_at": "2024-02-29T12:04:58Z"
                }
            },
            {
                "url": "https://github.com/zenml-io/zenml/pull/2437",
                "title": "Add vulnerability notice to README",
                "labels": [
                    "internal",
                    "security"
                ],
                "user": "strickvl",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2437,
                "id": 2129877372,
                "state": "closed",
                "project_created_at": "2024-02-12T10:53:48Z",
                "closed_at": "2024-02-13T13:32:45Z",
                "body": "## Describe changes\r\nI implemented/fixed _ to achieve _.\r\n\r\n## Pre-requisites\r\nPlease ensure you have done the following:\r\n- [ ] I have read the **CONTRIBUTING.md** document.\r\n- [ ] If my change requires a change to docs, I have updated the documentation accordingly.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] I have based my new branch on `develop` and the open PR is targeting `develop`. If your branch wasn't based on develop read [Contribution guide on rebasing branch to develop](https://github.com/zenml-io/zenml/blob/main/CONTRIBUTING.md#-pull-requests-rebase-your-branch-on-develop).\r\n- [ ] If my changes require changes to the dashboard, these changes are communicated/requested.\r\n\r\n## Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Other (add details above)\r\n\r\n",
                "comments": [
                    {
                        "body": "<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- This is an auto-generated comment: skip review by coderabbit.ai -->\n\n> [!IMPORTANT]\n> ## Auto Review Skipped\n> \n> Auto reviews are disabled on this repository.\n> \n> Please check the settings in the CodeRabbit UI or the `.coderabbit.yaml` file in this repository.\n> \n> To trigger a single review, invoke the `@coderabbitai review` command.\n> \n\n<!-- end of auto-generated comment: skip review by coderabbit.ai --><!-- tweet_start -->\n\nThank you for using CodeRabbit. We offer it for free to the OSS community and would appreciate your support in helping us grow. If you find it useful, would you consider giving us a shout-out on your favorite social media?\n\n<details>\n<summary>Share</summary>\n\n- [X](https://twitter.com/intent/tweet?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A&url=https%3A//coderabbit.ai)\n- [Mastodon](https://mastodon.social/share?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A%20https%3A%2F%2Fcoderabbit.ai)\n- [Reddit](https://www.reddit.com/submit?title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&text=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code.%20Check%20it%20out%3A%20https%3A//coderabbit.ai)\n- [LinkedIn](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcoderabbit.ai&mini=true&title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&summary=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code)\n\n</details>\n\n<!-- tweet_end --><!-- tips_start -->\n\n---\n\n<details>\n<summary>Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with CodeRabbit:\n\n- Review comments: Directly reply to a review comment made by CodeRabbit. Example:\n\t- `I pushed a fix in commit <commit_id>.`\n\t- `Generate unit-tests for this file.`\n- Files and specific lines of code (under the \"Files changed\" tab): Tag `@coderabbitai` in a new review comment at the desired location with your query. Examples:\n\t- `@coderabbitai generate unit tests for this file.`\n\t-\t`@coderabbitai modularize this function.`\n- PR comments: Tag `@coderabbitai` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n\t- `@coderabbitai generate interesting stats about this repository from git and render them as a table.`\n\t- `@coderabbitai show all the console.log statements in this repository.`\n\t- `@coderabbitai read src/utils.ts and generate unit tests.`\n\t- `@coderabbitai read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (invoked as PR comments)\n\n- `@coderabbitai pause` to pause the reviews on a PR.\n- `@coderabbitai resume` to resume the paused reviews.\n- `@coderabbitai review` to trigger a review. This is useful when automatic reviews are disabled for the repository.\n- `@coderabbitai resolve` resolve all the CodeRabbit review comments.\n- `@coderabbitai help` to get help.\n\n\nAdditionally, you can add `@coderabbitai ignore` anywhere in the PR description to prevent this PR from being reviewed.\n\n### CodeRabbit Configration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- The JSON schema for the configuration file is available [here](https://coderabbit.ai/integrations/coderabbit-overrides.v2.json).\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/coderabbit-overrides.v2.json`\n\n### CodeRabbit Discord Community\n\nJoin our [Discord Community](https://discord.com/invite/GsXnASn26c) to get help, request features, and share feedback.\n\n</details>\n\n<!-- tips_end -->",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-12T10:54:01Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2437#issuecomment-1938446756"
                    },
                    {
                        "body": "(approved orally by Hamza)",
                        "user": "strickvl",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-13T13:32:39Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2437#issuecomment-1941524333"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/zenml-io/zenml/pulls/2437",
                    "merged_at": "2024-02-13T13:32:45Z"
                }
            },
            {
                "url": "https://github.com/zenml-io/zenml/issues/1823",
                "title": "Add a security policy",
                "labels": [
                    "security"
                ],
                "user": "psmoros",
                "issue_author_association": "NONE",
                "number": 1823,
                "id": 1903654435,
                "state": "closed",
                "project_created_at": "2023-09-19T20:07:03Z",
                "closed_at": "2023-09-20T07:40:29Z",
                "body": "Hello \n\nI run a security community that finds and fixes vulnerabilities in OSS. A researcher (@andy53) has found a potential issue, which I would be eager to share with you.\n\nCould you add a `SECURITY.md` file with an e-mail address for me to send further details to? GitHub [recommends](https://docs.github.com/en/code-security/getting-started/adding-a-security-policy-to-your-repository) a security policy to ensure issues are responsibly disclosed, and it would help direct researchers in the future.\n\nLooking forward to hearing from you \n\n(cc @huntr-helper)",
                "comments": [
                    {
                        "body": "https://github.com/zenml-io/zenml/blob/main/CONTRIBUTING.md#-reporting-a-vulnerability explains our vulnerability reporting process and lists an email. Thanks for the pointer to the Github recommendation, too. We'll look into that.",
                        "user": "strickvl",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-20T07:27:29Z",
                        "url": "https://github.com/zenml-io/zenml/issues/1823#issuecomment-1727123871"
                    },
                    {
                        "body": "Closing this following the PR listed above. I trust @Andy53 will be in touch.",
                        "user": "strickvl",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-20T07:40:29Z",
                        "url": "https://github.com/zenml-io/zenml/issues/1823#issuecomment-1727143670"
                    }
                ],
                "pull_request": null
            }
        ],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 9,
        "num_security_issue_and_pull": 10,
        "security_issues_created_after_policy": [
            {
                "url": "https://github.com/zenml-io/zenml/pull/2587",
                "title": "Check old password during password change and add missing CLI commands",
                "labels": [
                    "bug",
                    "internal",
                    "security",
                    "run-slow-ci",
                    "P2"
                ],
                "user": "stefannica",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2587,
                "id": 2226139907,
                "state": "closed",
                "project_created_at": "2024-04-04T17:34:45Z",
                "closed_at": "2024-04-09T07:22:03Z",
                "body": "## Describe changes\r\nAs an extra security measure, this PR always requires that the current password value be supplied during a password change.\r\n\r\nAdditional related changes:\r\n* implement a separate `zenml user change-password` CLI command for changing the password for the current user\r\n* warn about passing passwords using command-line arguments in `zenml user change-password`, `zenml user create` and `zenml user update`\r\n* warn about using username/password to connect to a ZenML server and suggest using the web login flow or a service account API key instead\r\n* allow a user account to be activated and deactivated through `zenml user update`\r\n* implement the `zenml user deactivate` CLI command to be used to reset other user accounts through the CLI (by admins only).\r\n\r\n**IMPORTANT**: this change invalidates the current ZenML Dashboard password change support. A dashboard update is required to pass the current password to the call made to the API (handled with https://github.com/zenml-io/zenml-dashboard/pull/556)\r\n\r\n## Pre-requisites\r\nPlease ensure you have done the following:\r\n- [x] I have read the **CONTRIBUTING.md** document.\r\n- [ ] If my change requires a change to docs, I have updated the documentation accordingly.\r\n- [ ] I have added tests to cover my changes.\r\n- [x] I have based my new branch on `develop` and the open PR is targeting `develop`. If your branch wasn't based on develop read [Contribution guide on rebasing branch to develop](https://github.com/zenml-io/zenml/blob/main/CONTRIBUTING.md#-pull-requests-rebase-your-branch-on-develop).\r\n- [x] If my changes require changes to the dashboard, these changes are communicated/requested.\r\n\r\n## Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Other (add details above)\r\n\r\n",
                "comments": [
                    {
                        "body": "<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- This is an auto-generated comment: skip review by coderabbit.ai -->\n\n> [!IMPORTANT]\n> ## Auto Review Skipped\n> \n> Auto reviews are disabled on this repository.\n> \n> Please check the settings in the CodeRabbit UI or the `.coderabbit.yaml` file in this repository.\n> \n> To trigger a single review, invoke the `@coderabbitai review` command.\n> \n\n<!-- end of auto-generated comment: skip review by coderabbit.ai --><!-- tweet_start -->\n\nThank you for using CodeRabbit. We offer it for free to the OSS community and would appreciate your support in helping us grow. If you find it useful, would you consider giving us a shout-out on your favorite social media?\n\n<details>\n<summary>Share</summary>\n\n- [X](https://twitter.com/intent/tweet?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A&url=https%3A//coderabbit.ai)\n- [Mastodon](https://mastodon.social/share?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A%20https%3A%2F%2Fcoderabbit.ai)\n- [Reddit](https://www.reddit.com/submit?title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&text=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code.%20Check%20it%20out%3A%20https%3A//coderabbit.ai)\n- [LinkedIn](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcoderabbit.ai&mini=true&title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&summary=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code)\n\n</details>\n\n<!-- tweet_end --><!-- tips_start -->\n\n---\n\n<details>\n<summary>Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n- Review comments: Directly reply to a review comment made by CodeRabbit. Example:\n\t- `I pushed a fix in commit <commit_id>.`\n\t- `Generate unit testing code for this file.`\n\t- `Open a follow-up GitHub issue for this discussion.`\n- Files and specific lines of code (under the \"Files changed\" tab): Tag `@coderabbitai` in a new review comment at the desired location with your query. Examples:\n\t- `@coderabbitai generate unit testing code for this file.`\n\t-\t`@coderabbitai modularize this function.`\n- PR comments: Tag `@coderabbitai` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n\t- `@coderabbitai generate interesting stats about this repository and render them as a table.`\n\t- `@coderabbitai show all the console.log statements in this repository.`\n\t- `@coderabbitai read src/utils.ts and generate unit testing code.`\n\t- `@coderabbitai read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (invoked as PR comments)\n\n- `@coderabbitai pause` to pause the reviews on a PR.\n- `@coderabbitai resume` to resume the paused reviews.\n- `@coderabbitai review` to trigger a review. This is useful when automatic reviews are disabled for the repository.\n- `@coderabbitai resolve` resolve all the CodeRabbit review comments.\n- `@coderabbitai help` to get help.\n\n\nAdditionally, you can add `@coderabbitai ignore` anywhere in the PR description to prevent this PR from being reviewed.\n\n### CodeRabbit Configration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](https://discord.com/invite/GsXnASn26c) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-04T17:34:50Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2587#issuecomment-2037799998"
                    },
                    {
                        "body": "> Thanks, nice feature! Do we have dashboard changes ready? If not I would pause merging this, so it is not in the upcoming release, until Dashboard has this. @Cahllagerfeld\r\n\r\n@avishniakov yes, the dashboard changes have already been merged: https://github.com/zenml-io/zenml-dashboard/pull/556",
                        "user": "stefannica",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-08T13:07:51Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2587#issuecomment-2042715991"
                    },
                    {
                        "body": "E2E template updates in `examples/e2e` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-08T13:24:45Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2587#issuecomment-2042753537"
                    },
                    {
                        "body": "LLM Finetuning template updates in `examples/llm_finetuning` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-08T13:33:53Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2587#issuecomment-2042774453"
                    },
                    {
                        "body": "NLP template updates in `examples/e2e_nlp` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-08T13:41:37Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2587#issuecomment-2042794886"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/zenml-io/zenml/pulls/2587",
                    "merged_at": "2024-04-09T07:22:03Z"
                }
            },
            {
                "url": "https://github.com/zenml-io/zenml/pull/2583",
                "title": "Add security headers to the ZenML server",
                "labels": [
                    "security",
                    "run-slow-ci",
                    "P2"
                ],
                "user": "stefannica",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2583,
                "id": 2223918522,
                "state": "closed",
                "project_created_at": "2024-04-03T21:01:47Z",
                "closed_at": "2024-04-06T15:32:36Z",
                "body": "## Describe changes\r\nThere are a set of HTTP headers that can be added to all ZenML server responses for improved security. This PR adds them by using the middleware supplied with the [`secure`](https://secure.readthedocs.io/en/latest/index.html) Python library.\r\n\r\nFor comparison:\r\n* [headers scan for a server without headers](https://securityheaders.com/?q=https%3A%2F%2F1cf18d95-zenml.cloudinfra.zenml.io&followRedirects=on)\r\n* [headers scan for a server with headers](https://securityheaders.com/?q=https%3A%2F%2F9ba52960-zenml.staging.cloudinfra.zenml.io%2F&followRedirects=on)\r\n\r\nNOTE: the content-security-policy security headers are by default set to a \"non-safe\" value because the dashboard code requires special handling to allow its support. More details here: https://content-security-policy.com/examples/allow-inline-script/\r\n\r\n## Pre-requisites\r\nPlease ensure you have done the following:\r\n- [x] I have read the **CONTRIBUTING.md** document.\r\n- [x] If my change requires a change to docs, I have updated the documentation accordingly.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] I have based my new branch on `develop` and the open PR is targeting `develop`. If your branch wasn't based on develop read [Contribution guide on rebasing branch to develop](https://github.com/zenml-io/zenml/blob/main/CONTRIBUTING.md#-pull-requests-rebase-your-branch-on-develop).\r\n- [ ] If my changes require changes to the dashboard, these changes are communicated/requested.\r\n\r\n## Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Other (add details above)\r\n\r\n",
                "comments": [
                    {
                        "body": "<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- This is an auto-generated comment: skip review by coderabbit.ai -->\n\n> [!IMPORTANT]\n> ## Auto Review Skipped\n> \n> Auto reviews are disabled on this repository.\n> \n> Please check the settings in the CodeRabbit UI or the `.coderabbit.yaml` file in this repository.\n> \n> To trigger a single review, invoke the `@coderabbitai review` command.\n> \n\n<!-- end of auto-generated comment: skip review by coderabbit.ai --><!-- tweet_start -->\n\nThank you for using CodeRabbit. We offer it for free to the OSS community and would appreciate your support in helping us grow. If you find it useful, would you consider giving us a shout-out on your favorite social media?\n\n<details>\n<summary>Share</summary>\n\n- [X](https://twitter.com/intent/tweet?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A&url=https%3A//coderabbit.ai)\n- [Mastodon](https://mastodon.social/share?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A%20https%3A%2F%2Fcoderabbit.ai)\n- [Reddit](https://www.reddit.com/submit?title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&text=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code.%20Check%20it%20out%3A%20https%3A//coderabbit.ai)\n- [LinkedIn](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcoderabbit.ai&mini=true&title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&summary=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code)\n\n</details>\n\n<!-- tweet_end --><!-- tips_start -->\n\n---\n\n<details>\n<summary>Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n- Review comments: Directly reply to a review comment made by CodeRabbit. Example:\n\t- `I pushed a fix in commit <commit_id>.`\n\t- `Generate unit testing code for this file.`\n\t- `Open a follow-up GitHub issue for this discussion.`\n- Files and specific lines of code (under the \"Files changed\" tab): Tag `@coderabbitai` in a new review comment at the desired location with your query. Examples:\n\t- `@coderabbitai generate unit testing code for this file.`\n\t-\t`@coderabbitai modularize this function.`\n- PR comments: Tag `@coderabbitai` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n\t- `@coderabbitai generate interesting stats about this repository and render them as a table.`\n\t- `@coderabbitai show all the console.log statements in this repository.`\n\t- `@coderabbitai read src/utils.ts and generate unit testing code.`\n\t- `@coderabbitai read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (invoked as PR comments)\n\n- `@coderabbitai pause` to pause the reviews on a PR.\n- `@coderabbitai resume` to resume the paused reviews.\n- `@coderabbitai review` to trigger a review. This is useful when automatic reviews are disabled for the repository.\n- `@coderabbitai resolve` resolve all the CodeRabbit review comments.\n- `@coderabbitai help` to get help.\n\n\nAdditionally, you can add `@coderabbitai ignore` anywhere in the PR description to prevent this PR from being reviewed.\n\n### CodeRabbit Configration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/coderabbit-overrides.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](https://discord.com/invite/GsXnASn26c) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-03T21:01:51Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2583#issuecomment-2035584344"
                    },
                    {
                        "body": "<!-- overview-comment -->\n**New and removed dependencies detected.** Learn more about [Socket for GitHub ](https://socket.dev?utm_medium=gh)\n\n\n| Package | New capabilities | Transitives | Size | Publisher |\n|:--- |:--- |:--- |:--- |:--- |\n| [pypi/secure@0.3.0](https://socket.dev/pypi/package/secure/overview/0.3.0/py3-none-any-whl) | <a href=\"https://socket.dev?issue=usesEval\">eval</a>, <a href=\"https://socket.dev?issue=filesystemAccess\">filesystem</a>, <a href=\"https://socket.dev?issue=shellAccess\">shell</a> | <a href=\"https://socket.dev\">`0`</a> | 59.6 kB | <a href=\"https://socket.dev/pypi/user/cakinney\">cakinney</a> |\n\n\n[**View full report**](https://socket.dev/dashboard/org/gh/zenml-io/diff/3b9e57a6-aea9-4e5b-b87e-252c43505c22/88e56b20-255e-4855-93f9-293daeb05497)",
                        "user": "socket-security[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-04-03T21:02:34Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2583#issuecomment-2035585311"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/zenml-io/zenml/pulls/2583",
                    "merged_at": "2024-04-06T15:32:36Z"
                }
            },
            {
                "url": "https://github.com/zenml-io/zenml/pull/2494",
                "title": "Add admin users notion",
                "labels": [
                    "bug",
                    "internal",
                    "security",
                    "run-slow-ci",
                    "P1"
                ],
                "user": "avishniakov",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2494,
                "id": 2168644872,
                "state": "closed",
                "project_created_at": "2024-03-05T08:51:45Z",
                "closed_at": "2024-03-12T16:09:59Z",
                "body": "## Describe changes\r\nI implemented the `is_admin` flag for the user accounts and added protection to certain operations performed via the REST interface to ADMIN-allowed only.\r\n\r\n**Only admins can**: list all users, create users, get another user, update another user, deactivate another user, and delete a user.\r\n**All users can**: list self, get self, update self, and activate a user.\r\n\r\nThese checks are only performed if no RBAC is in place, so ZenML Cloud RBAC functionality is not affected.\r\n\r\n## Pre-requisites\r\nPlease ensure you have done the following:\r\n- [x] I have read the **CONTRIBUTING.md** document.\r\n- [x] If my change requires a change to docs, I have updated the documentation accordingly.\r\n- [x] I have added tests to cover my changes.\r\n- [x] I have based my new branch on `develop` and the open PR is targeting `develop`. If your branch wasn't based on develop read [Contribution guide on rebasing branch to develop](https://github.com/zenml-io/zenml/blob/main/CONTRIBUTING.md#-pull-requests-rebase-your-branch-on-develop).\r\n- [x] If my changes require changes to the dashboard, these changes are communicated/requested.\r\n\r\n## Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Other (add details above)\r\n\r\n\n\n<!-- This is an auto-generated comment: release notes by coderabbit.ai -->\n\n## Summary by CodeRabbit\n\n- **New Features**\n\t- Introduced admin user management, including the ability to create users with admin status and update user information with admin privileges.\n- **Documentation**\n\t- Updated the Quickstart guide with correct hyperlinks and improved the community links alignment.\n- **Bug Fixes**\n\t- Ensured that the default user is created with admin privileges and prevented removing admin status from the default user.\n- **Refactor**\n\t- Enhanced various user management functions to support new admin features and improved permission checks across the application.\n- **Tests**\n\t- Added comprehensive tests for new admin user management features, including scenarios for updating user information and admin status.\n\n<!-- end of auto-generated comment: release notes by coderabbit.ai -->",
                "comments": [
                    {
                        "body": "<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- This is an auto-generated comment: skip review by coderabbit.ai -->\n\n> [!IMPORTANT]\n> ## Auto Review Skipped\n> \n> Auto reviews are disabled on this repository.\n> \n> Please check the settings in the CodeRabbit UI or the `.coderabbit.yaml` file in this repository.\n> \n> To trigger a single review, invoke the `@coderabbitai review` command.\n> \n\n<!-- end of auto-generated comment: skip review by coderabbit.ai --><!-- walkthrough_start -->\n\n## Walkthrough\n\nThe recent updates focus on enhancing user management and role-based access control (RBAC) within the application. Key features include the introduction of an `is_admin` flag to distinguish between admin and regular users, updates to user creation and modification functions to handle admin status, and improvements in permission checks and error handling for user actions. These changes aim to provide more granular control over user roles and permissions, ensuring a more secure and customizable environment.\n\n## Changes\n\n| Files                                             | Change Summary                                                                                           |\n|---------------------------------------------------|----------------------------------------------------------------------------------------------------------|\n| `examples/quickstart/README.md`                   | Updated Google Colab badge URL and Slack community link.                                                |\n| `src/zenml/.../user_management.py`, `client.py`   | Added `is_admin` flag to user creation; updated user update functions with admin-related parameters.    |\n| `src/zenml/models/v2/.../service_account.py`, `user.py`, `external_user.py` | Added `is_admin` fields and updated inheritance structures.                                              |\n| `src/zenml/zen_server/...`                        | Enhanced user and admin permission checks, error handling, and RBAC settings in various server modules. |\n| `src/zenml/zen_stores/...`, `tests/...`           | Updated database schema for admin users, added `is_admin` in schemas, and integrated tests.             |\n\n## Poem\n\n> In the world of code, where changes are vast,  \n> A rabbit hopped in, making updates fast.  \n> With a flick of its ear, and a tap of its paw,  \n> Admins and users, it clearly saw.  \n>  \"Let's manage with care, and control with grace,  \n> Permissions and roles, in their right place.\"  \n> In a burrow so deep, with code so neat,  \n> The rabbit's work done, so clever and sweet.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: raw summary by coderabbit.ai -->\n<!--\n\n\nexamples/quickstart/README.md: ## Short summary\n\nThe diff in the `README.md` file updates a hyperlink in the Google Colab badge URL from `run.ipynb` to `quickstart.ipynb`, ensuring users are directed to the correct notebook. Additionally, it adjusts the Slack community link for better alignment.\n\n---\n\nsrc/zenml/cli/user_management.py: ## Short summary\n\n- Added an `is_admin` flag to the `create_user` function to specify if the user should be an admin.\n- Added options to update user information in the `update_user` function, including `updated_password`, `make_admin`, and `make_user`.\n\n---\n\nsrc/zenml/client.py: ## Short summary\n\n- Added a new parameter `is_admin` to the `create_user` function in `client.py`.\n- Added new parameters `updated_password` and `updated_is_admin` to the `update_user` function in `client.py.\n\n---\n\nsrc/zenml/models/v2/core/service_account.py: ## Short summary\n\nAdded the `is_admin` field with a default value of `False` in the `to_user_model` method of the `service_account.py` file.\n\n---\n\nsrc/zenml/models/v2/core/user.py: ## Short summary\n\nIn this change, the `UserRequest` class is refactored to inherit from `UserBase` and `BaseRequest`, introducing new fields like `is_admin` and modifying existing fields like `full_name` and `active`. The `UserUpdate` class now inherits from `UserBase` and `BaseZenModel`, with changes to fields like `name` and `is_admin`. Additionally, `UserResponseBody` gains a new field `is_admin`, and getter methods for `is_admin` and `email` are added.\n\n---\n\nsrc/zenml/models/v2/misc/external_user.py: ## Short summary\n\nAdded a new boolean field `is_admin` with a default value of `False` to the `ExternalUserModel` class.\n\n---\n\nsrc/zenml/zen_server/auth.py: ## Short summary\n\nIn the `authenticate_external_user` function in `auth.py`, the `is_admin` field is now being set based on the `external_user.is_admin` value.\n\n---\n\nsrc/zenml/zen_server/rbac/endpoint_utils.py: ## Short summary\n\nIn the `verify_permissions_and_create_entity` function within `endpoint_utils.py`, the `verify_permission` call has been reformatted to pass arguments on separate lines for `resource_type` and `action`.\n\n---\n\nsrc/zenml/zen_server/rbac/utils.py: ## Short Summary\n\nIn `utils.py`, the `batch_verify_permissions` function's signature was updated to include separate lines for each parameter, `resources` and `action`, instead of having them on a single line.\n\n---\n\nsrc/zenml/zen_server/routers/users_endpoints.py: ## Short summary\n\n- Added `verify_admin_status_if_no_rbac` function for permission checks.\n- Modified logic in `list_users` to handle RBAC settings.\n- Updated `create_user` to verify admin status for non-admin users.\n- Enhanced permission checks in `get_user` and `update_user`.\n- Improved error handling in `update_user` for admin status changes.\n- Enhanced `activate_user` to retain admin status during activation.\n- Added validation in `deactivate_user` to prevent self-deactivation.\n- Strengthened permission checks in `deactivate_user` and `delete_user`.\n- Updated `email_opt_in_response` for email opt-in handling.\n- Enhanced `update_myself` to retain user attributes during update.\n\n---\n\nsrc/zenml/zen_server/utils.py: ## Short summary\n\nIn `utils.py`, the `OAuthError` import is replaced with `IllegalOperationError` and `OAuthError`. Additionally, a new function `verify_admin_status_if_no_rbac` is added to validate admin status for sensitive requests when RBAC is disabled.\n\n---\n\nsrc/zenml/zen_stores/migrations/versions/1a9a9d2a836d_admin_users.py: This file introduces functionality to manage admin users in the database schema. It adds an \"is_admin\" column to the \"user\" table, setting all users as admin during migration for backward compatibility. Admin status can be adjusted by server admins post-upgrade.\n\n---\n\nsrc/zenml/zen_stores/schemas/user_schemas.py: ## Short summary\n\nIn the `UserSchema` class within `user_schemas.py`, a new field `is_admin` of type `bool` with a default value of `False` has been added. This field is now included in various methods like `from_user_request`, `from_service_account_request`, and `to_model`.\n\n---\n\nsrc/zenml/zen_stores/sql_zen_store.py: ## Short summary\n\nIn the `update_user` function of `sql_zen_store.py`, a check has been added to prevent removing admin status from the default user. Additionally, the default user is now created with admin privileges.\n\n---\n\ntests/integration/functional/zen_stores/test_zen_store.py: ## Short summary\n\n- Added `random` and `ascii_lowercase` imports.\n- Added `RestZenStore` import.\n- Added `TestAdminUser` class with various test methods for user management.\n- Updated user creation, listing, getting, updating, deactivating, and deleting logic.\n- Added tests for updating user information and admin status.\n- Added tests for self-update scenarios for admin and non-admin users.\n\n---\n\ntests/integration/functional/zen_stores/utils.py: ## Short summary\n\nIn the `utils.py` file, the `__init__` method of a class now accepts an additional parameter `is_admin`, which is set to `True` by default. The `UserRequest` object creation in the `__enter__` method now includes the `is_admin` attribute. The `create_model` attribute in `user_crud_test_config` now includes the `is_admin` parameter set to `True`.\n\n---\n\ntests/unit/conftest.py: ## Short summary\n\nIn the `tests/unit/conftest.py` file, a change was made to set the `is_admin` attribute to `True` for a user model instance, indicating an update to the user's admin status.\n\n---\n\ntests/unit/models/test_user_models.py: ## Short summary\n\nIn the `test_user_models.py` file, the changes involve modifying the instantiation of `UserRequest` instances by adding the `is_admin=False` parameter to the constructor calls in the test cases `test_user_request_model_fails_with_long_password` and `test_user_request_model_fails_with_long_activation_token`.\n\n-->\n<!-- end of auto-generated comment: raw summary by coderabbit.ai --><!-- This is an auto-generated comment: short summary by coderabbit.ai -->\n<!--\n\n\n### PR Objectives\n\nThe pull request (PR) titled \"Add admin users notion\" introduces the concept of administrative users within a system, enhancing security and user management capabilities. The main changes include the implementation of an `is_admin` flag for user accounts, which distinguishes between admin and non-admin users. This flag is crucial for controlling access to specific operations through the REST interface, ensuring that only admins can perform sensitive actions.\n\nAdmin users are granted exclusive permissions to list all users, create new users, access and modify other users' information, deactivate or delete user accounts. In contrast, regular users are limited to managing their own account details and activating a user account. These restrictions are designed to safeguard the system against unauthorized access and modifications, enhancing overall security.\n\nThe PR also specifies that these new access controls are implemented in a manner that does not interfere with existing Role-Based Access Control (RBAC) functionalities, particularly within the ZenML Cloud environment. This ensures that the new features can coexist with the current RBAC system without causing any disruptions or conflicts.\n\nTo support these changes, the PR includes updates to documentation, the addition of tests to cover the new functionalities, and modifications to various components of the system, including CLI commands, models, and server utilities. The contributor has followed the project's contribution guidelines, ensuring that the new branch is based on `develop` and that all pre-requisites for a successful PR have been met.\n\n### Comments Summary\n\nThe PR received feedback from a reviewer, avishniakov, who suggested improvements for the unit tests and conducted a thorough local test to assess the impact of the changes on the dashboard. The reviewer identified several areas for improvement, particularly regarding the creation and updating of user accounts through the Client/CLI and the dashboard. These include the inability to set or change a user's admin status upon account creation or update, and the need for the dashboard to reflect a user's admin status accurately.\n\nThe reviewer also highlighted a potential vulnerability where a non-admin user could elevate their status to admin during the first login process. This issue was addressed, and the backend points related to user activation and admin status were fixed. However, the dashboard-related enhancements were deferred to a separate task tracked in the project's issue tracking system.\n\nStefannica, the contributor, acknowledged the feedback and incorporated the suggested improvements into the PR. The changes were re-tested and confirmed to work as expected.\n\n### AI-Generated Summary of Generated Summaries\n\nThe PR introduces an `is_admin` flag to distinguish between admin and non-admin users, applying this distinction across various components of the system, including CLI commands, client functions, models, and server utilities. Admin users are granted exclusive permissions for sensitive operations, such as user management tasks, while regular users are limited to managing their own account details.\n\nSignificant changes include the addition of the `is_admin` flag to user creation and update functions, both in the CLI and the client layer, and the introduction of this flag in various user models. The server's authentication and permission verification mechanisms have been updated to accommodate the new admin concept, ensuring that only admins can perform certain actions unless RBAC settings override these restrictions.\n\nThe database schema has been updated to include an `is_admin` column for user management, and tests have been added to cover the new functionalities and ensure that admin and non-admin users are handled correctly. The PR also addresses a potential security vulnerability related to user activation and admin status elevation.\n\nDashboard-related enhancements, such as reflecting a user's admin status and modifying user creation and update functionalities to include admin status settings, have been identified but are to be addressed in a separate task.\n\n-->\n<!-- end of auto-generated comment: short summary by coderabbit.ai --><!-- commit_ids_reviewed_start -->\n\n<!-- 5c4545713838f0b28edfea7c9768339d2d899c2d -->\n\n<!-- commit_ids_reviewed_end --><!-- tweet_start -->\n\nThank you for using CodeRabbit. We offer it for free to the OSS community and would appreciate your support in helping us grow. If you find it useful, would you consider giving us a shout-out on your favorite social media?\n\n<details>\n<summary>Share</summary>\n\n- [X](https://twitter.com/intent/tweet?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A&url=https%3A//coderabbit.ai)\n- [Mastodon](https://mastodon.social/share?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A%20https%3A%2F%2Fcoderabbit.ai)\n- [Reddit](https://www.reddit.com/submit?title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&text=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code.%20Check%20it%20out%3A%20https%3A//coderabbit.ai)\n- [LinkedIn](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcoderabbit.ai&mini=true&title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&summary=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code)\n\n</details>\n\n<!-- tweet_end --><!-- tips_start -->\n\n---\n\n<details>\n<summary>Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with CodeRabbit:\n\n- Review comments: Directly reply to a review comment made by CodeRabbit. Example:\n\t- `I pushed a fix in commit <commit_id>.`\n\t- `Generate unit-tests for this file.`\n\t- `Open a follow-up GitHub issue for this discussion.`\n- Files and specific lines of code (under the \"Files changed\" tab): Tag `@coderabbitai` in a new review comment at the desired location with your query. Examples:\n\t- `@coderabbitai generate unit tests for this file.`\n\t-\t`@coderabbitai modularize this function.`\n- PR comments: Tag `@coderabbitai` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n\t- `@coderabbitai generate interesting stats about this repository and render them as a table.`\n\t- `@coderabbitai show all the console.log statements in this repository.`\n\t- `@coderabbitai read src/utils.ts and generate unit tests.`\n\t- `@coderabbitai read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (invoked as PR comments)\n\n- `@coderabbitai pause` to pause the reviews on a PR.\n- `@coderabbitai resume` to resume the paused reviews.\n- `@coderabbitai review` to trigger a review. This is useful when automatic reviews are disabled for the repository.\n- `@coderabbitai resolve` resolve all the CodeRabbit review comments.\n- `@coderabbitai help` to get help.\n\n\nAdditionally, you can add `@coderabbitai ignore` anywhere in the PR description to prevent this PR from being reviewed.\n\n### CodeRabbit Configration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- The JSON schema for the configuration file is available [here](https://coderabbit.ai/integrations/coderabbit-overrides.v2.json).\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/coderabbit-overrides.v2.json`\n\n### CodeRabbit Discord Community\n\nJoin our [Discord Community](https://discord.com/invite/GsXnASn26c) to get help, request features, and share feedback.\n\n</details>\n\n<!-- tips_end -->",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-05T08:51:52Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2494#issuecomment-1978245381"
                    },
                    {
                        "body": "> Left some improvement suggestions for the unit tests, otherwise looks good.\r\n\r\nThanks for the effort @stefannica ! I will use your suggestions.",
                        "user": "avishniakov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-06T13:57:56Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2494#issuecomment-1980934290"
                    },
                    {
                        "body": "> I gave this a thorough local test, because I wanted to see what impact this has on the dashboard and I found a few things that might need doing:\r\n> \r\n> Client/CLI (we should probably fix these in this PR):\r\n> \r\n> * when creating a new user account, there's no way to decide whether it's admin or not. They are non-admin by default.\r\n> * no way to make an account admin when updating a user\r\n> \r\n> Dashboard:\r\n> \r\n> * should mark users as admins/non-admins in the user list\r\n> * we should disable / remove the option of adding new users for a non-admin user account\r\n> * we should add the ability to decide if a user is admin or not during creation\r\n> \r\n> One new vulnerability that I'll check right away is that a non-admin user invited through an invitation token can elevate their status to admin during the first login.\r\n\r\nBackend points + take over during activation fixed.\r\n\r\nDashboard points shall fall into https://zenml.atlassian.net/browse/PRD-282 (team is aware)",
                        "user": "avishniakov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-07T16:28:22Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2494#issuecomment-1983929981"
                    },
                    {
                        "body": "> \r\n> Backend points + take over during activation fixed.\r\n> \r\n\r\nThank you, I re-tested it, works as expected.",
                        "user": "stefannica",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-07T17:39:44Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2494#issuecomment-1984092095"
                    },
                    {
                        "body": "Quickstart template updates in `examples/quickstart` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-11T16:11:16Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2494#issuecomment-1988814708"
                    },
                    {
                        "body": "Let's blow a bomb of CodeRabbit  \r\n\r\n@coderabbitai review",
                        "user": "avishniakov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-12T14:15:05Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2494#issuecomment-1991753343"
                    },
                    {
                        "body": "<!-- This is an auto-generated reply by CodeRabbit -->\n\n\n@avishniakov, I will review the changes in the PR. \n\n\n<details>\n<summary>Actions performed</summary>\n\nReview triggered.\n\n> Note: CodeRabbit is an incremental review system and does not re-review already reviewed commits. This command is applicable only when automatic reviews are paused.\n\n</details>",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-12T14:15:23Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2494#issuecomment-1991753974"
                    },
                    {
                        "body": "Ok, let's go!",
                        "user": "avishniakov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-12T16:09:52Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2494#issuecomment-1992025044"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/zenml-io/zenml/pulls/2494",
                    "merged_at": "2024-03-12T16:09:59Z"
                }
            },
            {
                "url": "https://github.com/zenml-io/zenml/pull/2491",
                "title": "Don't write the global config to file on server",
                "labels": [
                    "bug",
                    "internal",
                    "security",
                    "run-slow-ci"
                ],
                "user": "stefannica",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2491,
                "id": 2164081952,
                "state": "closed",
                "project_created_at": "2024-03-01T19:58:22Z",
                "closed_at": "2024-03-05T08:04:40Z",
                "body": "## Describe changes\r\nTo prevent accidentally leaking sensitive configuration information by exposing the global configuration file, the ZenML server doesn't dump any of its configuration to disk anymore.\r\n\r\n## Pre-requisites\r\nPlease ensure you have done the following:\r\n- [x] I have read the **CONTRIBUTING.md** document.\r\n- [ ] If my change requires a change to docs, I have updated the documentation accordingly.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] I have based my new branch on `develop` and the open PR is targeting `develop`. If your branch wasn't based on develop read [Contribution guide on rebasing branch to develop](https://github.com/zenml-io/zenml/blob/main/CONTRIBUTING.md#-pull-requests-rebase-your-branch-on-develop).\r\n- [ ] If my changes require changes to the dashboard, these changes are communicated/requested.\r\n\r\n## Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Other (add details above)\r\n\r\n",
                "comments": [
                    {
                        "body": "<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- This is an auto-generated comment: skip review by coderabbit.ai -->\n\n> [!IMPORTANT]\n> ## Auto Review Skipped\n> \n> Auto reviews are disabled on this repository.\n> \n> Please check the settings in the CodeRabbit UI or the `.coderabbit.yaml` file in this repository.\n> \n> To trigger a single review, invoke the `@coderabbitai review` command.\n> \n\n<!-- end of auto-generated comment: skip review by coderabbit.ai --><!-- tweet_start -->\n\nThank you for using CodeRabbit. We offer it for free to the OSS community and would appreciate your support in helping us grow. If you find it useful, would you consider giving us a shout-out on your favorite social media?\n\n<details>\n<summary>Share</summary>\n\n- [X](https://twitter.com/intent/tweet?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A&url=https%3A//coderabbit.ai)\n- [Mastodon](https://mastodon.social/share?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A%20https%3A%2F%2Fcoderabbit.ai)\n- [Reddit](https://www.reddit.com/submit?title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&text=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code.%20Check%20it%20out%3A%20https%3A//coderabbit.ai)\n- [LinkedIn](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcoderabbit.ai&mini=true&title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&summary=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code)\n\n</details>\n\n<!-- tweet_end --><!-- tips_start -->\n\n---\n\n<details>\n<summary>Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with CodeRabbit:\n\n- Review comments: Directly reply to a review comment made by CodeRabbit. Example:\n\t- `I pushed a fix in commit <commit_id>.`\n\t- `Generate unit-tests for this file.`\n- Files and specific lines of code (under the \"Files changed\" tab): Tag `@coderabbitai` in a new review comment at the desired location with your query. Examples:\n\t- `@coderabbitai generate unit tests for this file.`\n\t-\t`@coderabbitai modularize this function.`\n- PR comments: Tag `@coderabbitai` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n\t- `@coderabbitai generate interesting stats about this repository and render them as a table.`\n\t- `@coderabbitai show all the console.log statements in this repository.`\n\t- `@coderabbitai read src/utils.ts and generate unit tests.`\n\t- `@coderabbitai read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (invoked as PR comments)\n\n- `@coderabbitai pause` to pause the reviews on a PR.\n- `@coderabbitai resume` to resume the paused reviews.\n- `@coderabbitai review` to trigger a review. This is useful when automatic reviews are disabled for the repository.\n- `@coderabbitai resolve` resolve all the CodeRabbit review comments.\n- `@coderabbitai help` to get help.\n\n\nAdditionally, you can add `@coderabbitai ignore` anywhere in the PR description to prevent this PR from being reviewed.\n\n### CodeRabbit Configration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- The JSON schema for the configuration file is available [here](https://coderabbit.ai/integrations/coderabbit-overrides.v2.json).\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/coderabbit-overrides.v2.json`\n\n### CodeRabbit Discord Community\n\nJoin our [Discord Community](https://discord.com/invite/GsXnASn26c) to get help, request features, and share feedback.\n\n</details>\n\n<!-- tips_end -->",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-01T19:58:28Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2491#issuecomment-1973827539"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/zenml-io/zenml/pulls/2491",
                    "merged_at": "2024-03-05T08:04:40Z"
                }
            },
            {
                "url": "https://github.com/zenml-io/zenml/pull/2490",
                "title": "Improve Artifact Store isolation",
                "labels": [
                    "bug",
                    "internal",
                    "security",
                    "run-slow-ci"
                ],
                "user": "avishniakov",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2490,
                "id": 2163507127,
                "state": "closed",
                "project_created_at": "2024-03-01T14:15:25Z",
                "closed_at": "2024-03-05T08:02:33Z",
                "body": "## Describe changes\r\nI fixed some isolation issues while using Artifact Stores.\r\n\r\n- `_sanitize_paths` of `BaseArtifactStore` is extended to check that the requested path is not leaving Artifact Store bounds\r\n- various helper methods rerouted to use artifact store methods instead of direct file system\r\n- standard materializers rerouted to use artifact store methods instead of direct file system\r\n\r\nPotential breaking change:\r\n- If unsafe operations were used in user's code - it needs to be revisited to make sure that no objects are created/fetched outside of Artifact Store scopes. Example:\r\n    - Artifact Store is configured as `s3://some_bucket/some_sub_folder`\r\n    - Code is doing `artifact_store.open(\"s3://some_bucket/some_other_folder/dummy.txt\",\"w\")` -> this is not allowed any more\r\n    - Consider using `s3fs` or similar libraries if you need to execute such operations\r\n  \r\n## Pre-requisites\r\nPlease ensure you have done the following:\r\n- [x] I have read the **CONTRIBUTING.md** document.\r\n- [x] If my change requires a change to docs, I have updated the documentation accordingly.\r\n- [x] I have added tests to cover my changes.\r\n- [x] I have based my new branch on `develop` and the open PR is targeting `develop`. If your branch wasn't based on develop read [Contribution guide on rebasing branch to develop](https://github.com/zenml-io/zenml/blob/main/CONTRIBUTING.md#-pull-requests-rebase-your-branch-on-develop).\r\n- [x] If my changes require changes to the dashboard, these changes are communicated/requested.\r\n\r\n## Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Other (add details above)\r\n\r\n\r\n\r\n<!-- This is an auto-generated comment: release notes by coderabbit.ai -->\n## Summary by CodeRabbit\n\n\n## Summary by CodeRabbit\n\n- **New Features**\n\t- Enhanced security with input verification for artifact store operations.\n\t- Improved error handling by raising `IOError` for rejected artifact store requests.\n\n- **Refactor**\n\t- Implemented path verification for abstract method implementations in artifact store initialization.\n\n- **Tests**\n\t- Introduced integration tests to confine artifact store operations within specified bounds.\n\n<!-- end of auto-generated comment: release notes by coderabbit.ai -->",
                "comments": [
                    {
                        "body": "<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- This is an auto-generated comment: skip review by coderabbit.ai -->\n\n> [!IMPORTANT]\n> ## Auto Review Skipped\n> \n> Auto reviews are disabled on this repository.\n> \n> Please check the settings in the CodeRabbit UI or the `.coderabbit.yaml` file in this repository.\n> \n> To trigger a single review, invoke the `@coderabbitai review` command.\n> \n\n<!-- end of auto-generated comment: skip review by coderabbit.ai --><!-- walkthrough_start -->\n\n## Walkthrough\nThe recent updates to ZenML's artifact handling introduce enhanced input verification and path validation within artifact stores. These changes ensure that operations are securely contained within the bounds of the artifact stores, enhancing the robustness and security of data management. Additionally, a specific test suite has been added to validate these improvements, ensuring that artifact operations outside the designated bounds are correctly restricted.\n\n## Changes\n\n| File Path | Change Summary |\n|-----------|----------------|\n| `src/zenml/artifact_stores/base_artifact_store.py`<br>`src/zenml/artifacts/utils.py` | - Introduced input and path verification methods.<br>- Enhanced error handling for rejected requests in artifact store operations. |\n| `tests/integration/functional/artifacts/test_base_artifact_store.py` | - Added tests to verify artifact store boundary operations. |\n| `src/zenml/logging/step_logging.py`<br>`src/zenml/materializers/...materializer.py` | - Updated to use `Client` for artifact store operations instead of direct file I/O, improving integration and compatibility. |\n| `src/zenml/orchestrators/output_utils.py` | - Transitioned to using `Client` for artifact store operations, replacing direct `fileio` calls. |\n\n> <br>\n> In the realm of data, where artifacts dwell,<br>\n> A rabbit hopped, casting a secure spell.<br>\n> Paths verified, inputs checked with care,<br>\n> Ensuring that only safe travels are there.<br>\n> With every hop, a new test case born,<br>\n> Celebrating security from dusk till morn. \n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: raw summary by coderabbit.ai -->\n<!--\n\n\n```\nsrc/zenml/artifact_stores/base_artifact_store.py: ## Short summary\n\n- Added `inspect` and `Path` imports.\n- Modified `_sanitize_potential_path` to handle root path and path type.\n- Added `FileNotFoundError` raise condition.\n- Updated `_sanitize_paths` to handle fixed root path.\n- Added `decorator` function within `_sanitize_paths`.\n- Updated `inner_function` within `decorator` to handle root path and relevant arguments.\n- Added `ValueError` raise condition.\n- Updated `_register` method to use `inspect.getmembers` for method overloads.\n- Added `__init_subclass__` method to wrap abstract method implementations with path sanitizer.\n\n---\n\nsrc/zenml/artifacts/utils.py: ## Short summary\n\nIn `utils.py`, the `_load_file_from_artifact_store` function now raises `IOError` if the artifact store rejects the request.\n\n---\n\ntests/integration/functional/artifacts/test_base_artifact_store.py: This file introduces a test to ensure that operations outside the bounds of the artifact store are not accessible by it. It includes tests for creating, opening, and copying files both inside and outside the artifact store, verifying the expected behavior in each case.\n\n---\n\nsrc/zenml/logging/step_logging.py: ## Short summary\n\nThe functionality in `step_logging.py` has been updated to use `Client` for artifact store operations instead of `fileio`, affecting the preparation and saving of logs.\n\n---\n\nsrc/zenml/materializers/base_materializer.py: ## Short summary\n\nIn the `save_visualizations` method of the `BaseMaterializer` class, the code was updated to use `artifact_store` for file operations instead of `fileio`, enhancing integration with the active stack's artifact store.\n\n---\n\nsrc/zenml/materializers/built_in_materializer.py: ## Short summary\n\n- Added import statement for `Client` from `zenml.client`.\n- Replaced `fileio` references with `artifact_store` accessed through `Client().active_stack.artifact_store`.\n- Updated file operations to use `artifact_store` for reading, writing, existence checks, and directory operations.\n\n---\n\nsrc/zenml/materializers/cloudpickle_materializer.py: ## Short summary\n\nThe functionality of the `CloudpickleMaterializer` in `cloudpickle_materializer.py` has been updated to use the `Client` to access the active stack's artifact store for loading and saving data, replacing direct file I/O operations. This change ensures consistency and compatibility with the current Python environment.\n\n---\n\nsrc/zenml/materializers/numpy_materializer.py: ## Short summary\n\nThe functionality of the `numpy_materializer.py` module has been updated to use the `Client` class from `zenml.client` for artifact store operations instead of `fileio`. This change affects the loading and saving of numpy arrays and visualizations within the materializer.\n\n---\n\nsrc/zenml/materializers/pandas_materializer.py: ## Short summary\n\nThe functionality of the `PandasMaterializer` in the `zenml.materializers.pandas_materializer` module has been updated to use the `Client` to access the active stack's artifact store for loading and saving data. The changes involve replacing direct file I/O operations with interactions through the artifact store, enhancing flexibility and compatibility with different storage mechanisms.\n\n---\n\nsrc/zenml/materializers/service_materializer.py: ## Short summary\n\nThe `service_materializer.py` file in the `src/zenml/materializers` module has been updated to use the `Client` class from `zenml.client` for accessing the active stack's artifact store instead of directly using `fileio`. This change affects the `load` and `save` methods within the `ServiceMaterializer` class.\n\n---\n\nsrc/zenml/materializers/structured_string_materializer.py: ## Short summary\n\nThe functionality of the `structured_string_materializer.py` module has been updated to use the `Client` class from `zenml.client` for accessing the artifact store instead of directly using `fileio`. This change affects the `load` and `save` methods by utilizing the `artifact_store` attribute from the active stack's `Client` instance for file operations.\n\n---\n\nsrc/zenml/orchestrators/output_utils.py: ## Short summary\n\nIn `output_utils.py`, the functionality has been updated to use the `Client` class from `zenml.client` instead of `fileio` for handling artifact store operations. The changes involve replacing `fileio` with `artifact_store` methods for checking existence, creating directories, and removing directories related to artifact URIs.\n```\n\n-->\n<!-- end of auto-generated comment: raw summary by coderabbit.ai --><!-- This is an auto-generated comment: short summary by coderabbit.ai -->\n<!--\n\n\n### PR Objectives\n\nThe pull request titled \"[WIP] Improve Artifact Store isolation\" (PR #2490) aims to enhance the isolation mechanisms within the artifact store component of the ZenML framework. The contributor has implemented and/or fixed certain functionalities to achieve improved isolation. The changes include extending `_sanitize_paths` in `BaseArtifactStore` to enforce boundaries, rerouting helper methods to use artifact store methods, and updating standard materializers to interact with the artifact store directly. A potential breaking change is highlighted, requiring users to ensure operations stay within Artifact Store scopes to maintain security. The contributor has followed the contributing guidelines, including adding tests, updating documentation, and basing the branch on `develop`.\n\n### Comments Summary\n\nThe comments from `avishniakov` are direct requests for `@coderabbitai` to review the pull request, indicating a general review request without specific areas of concern mentioned.\n\n### AI-Generated Summary of Generated Summaries\n\nThe PR introduces key changes to enhance ZenML's artifact store isolation:\n\n1. **Base Artifact Store Enhancements:**\n   - Added imports for `inspect` and `Path`.\n   - Implemented `_verify` for input validation.\n   - Modified `__init_subclass__` for automatic path verification.\n   - Introduced `_inner_verify` for path validation within store bounds.\n\n2. **Artifact Utilities Update (`utils.py`):**\n   - Updated `_load_file_from_artifact_store` to raise `IOError` on rejection, improving error handling.\n\n3. **Integration Test Addition (`test_base_artifact_store.py`):**\n   - Added tests to ensure operations within artifact store bounds, covering file operations.\n\nThese changes collectively strengthen artifact store isolation by enforcing boundaries, enhancing error handling, and ensuring operations are confined within designated scopes.\n\n-->\n<!-- end of auto-generated comment: short summary by coderabbit.ai --><!-- commit_ids_reviewed_start -->\n\n<!-- b265c323bc8fab8cd82470795c5d7ca625f78c65 -->\n<!-- 18b1eb630f150bd7ba6439578f27e20da06b6d46 -->\n\n<!-- commit_ids_reviewed_end --><!-- tweet_start -->\n\nThank you for using CodeRabbit. We offer it for free to the OSS community and would appreciate your support in helping us grow. If you find it useful, would you consider giving us a shout-out on your favorite social media?\n\n<details>\n<summary>Share</summary>\n\n- [X](https://twitter.com/intent/tweet?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A&url=https%3A//coderabbit.ai)\n- [Mastodon](https://mastodon.social/share?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A%20https%3A%2F%2Fcoderabbit.ai)\n- [Reddit](https://www.reddit.com/submit?title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&text=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code.%20Check%20it%20out%3A%20https%3A//coderabbit.ai)\n- [LinkedIn](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcoderabbit.ai&mini=true&title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&summary=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code)\n\n</details>\n\n<!-- tweet_end --><!-- tips_start -->\n\n---\n\n<details>\n<summary>Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with CodeRabbit:\n\n- Review comments: Directly reply to a review comment made by CodeRabbit. Example:\n\t- `I pushed a fix in commit <commit_id>.`\n\t- `Generate unit-tests for this file.`\n- Files and specific lines of code (under the \"Files changed\" tab): Tag `@coderabbitai` in a new review comment at the desired location with your query. Examples:\n\t- `@coderabbitai generate unit tests for this file.`\n\t-\t`@coderabbitai modularize this function.`\n- PR comments: Tag `@coderabbitai` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n\t- `@coderabbitai generate interesting stats about this repository and render them as a table.`\n\t- `@coderabbitai show all the console.log statements in this repository.`\n\t- `@coderabbitai read src/utils.ts and generate unit tests.`\n\t- `@coderabbitai read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (invoked as PR comments)\n\n- `@coderabbitai pause` to pause the reviews on a PR.\n- `@coderabbitai resume` to resume the paused reviews.\n- `@coderabbitai review` to trigger a review. This is useful when automatic reviews are disabled for the repository.\n- `@coderabbitai resolve` resolve all the CodeRabbit review comments.\n- `@coderabbitai help` to get help.\n\n\nAdditionally, you can add `@coderabbitai ignore` anywhere in the PR description to prevent this PR from being reviewed.\n\n### CodeRabbit Configration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- The JSON schema for the configuration file is available [here](https://coderabbit.ai/integrations/coderabbit-overrides.v2.json).\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/coderabbit-overrides.v2.json`\n\n### CodeRabbit Discord Community\n\nJoin our [Discord Community](https://discord.com/invite/GsXnASn26c) to get help, request features, and share feedback.\n\n</details>\n\n<!-- tips_end -->",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-01T14:15:30Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2490#issuecomment-1973281965"
                    },
                    {
                        "body": "@coderabbitai review ",
                        "user": "avishniakov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-01T14:17:18Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2490#issuecomment-1973284908"
                    },
                    {
                        "body": "Quickstart template updates in `examples/quickstart` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-01T14:18:18Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2490#issuecomment-1973286505"
                    },
                    {
                        "body": "NLP template updates in `examples/e2e_nlp` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-01T14:28:35Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2490#issuecomment-1973301830"
                    },
                    {
                        "body": "E2E template updates in `examples/e2e` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-02T10:38:00Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2490#issuecomment-1974759630"
                    },
                    {
                        "body": "@coderabbitai review",
                        "user": "avishniakov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-04T07:59:59Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2490#issuecomment-1975934439"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/zenml-io/zenml/pulls/2490",
                    "merged_at": "2024-03-05T08:02:33Z"
                }
            },
            {
                "url": "https://github.com/zenml-io/zenml/pull/2484",
                "title": "Rate limiting for login API",
                "labels": [
                    "bug",
                    "internal",
                    "security",
                    "run-slow-ci",
                    "P2"
                ],
                "user": "avishniakov",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2484,
                "id": 2161501033,
                "state": "closed",
                "project_created_at": "2024-02-29T15:17:16Z",
                "closed_at": "2024-03-18T11:59:40Z",
                "body": "## Describe changes\r\nI fixed the missing rate limit for login API to prevent misuse and too frequent login attempts.\r\n\r\n## Pre-requisites\r\nPlease ensure you have done the following:\r\n- [x] I have read the **CONTRIBUTING.md** document.\r\n- [x] If my change requires a change to docs, I have updated the documentation accordingly.\r\n- [x] I have added tests to cover my changes.\r\n- [x] I have based my new branch on `develop` and the open PR is targeting `develop`. If your branch wasn't based on develop read [Contribution guide on rebasing branch to develop](https://github.com/zenml-io/zenml/blob/main/CONTRIBUTING.md#-pull-requests-rebase-your-branch-on-develop).\r\n- [x] If my changes require changes to the dashboard, these changes are communicated/requested.\r\n\r\n## Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Other (add details above)\r\n\r\n\n\n<!-- This is an auto-generated comment: release notes by coderabbit.ai -->\n\n## Summary by CodeRabbit\n\n- **New Features**\n\t- Introduced rate limiting on authentication requests to enhance security and manage traffic effectively. Users can now make up to 5 requests per minute and 1000 requests per day.\n\n<!-- end of auto-generated comment: release notes by coderabbit.ai -->",
                "comments": [
                    {
                        "body": "<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- This is an auto-generated comment: skip review by coderabbit.ai -->\n\n> [!IMPORTANT]\n> ## Auto Review Skipped\n> \n> Auto reviews are disabled on this repository.\n> \n> Please check the settings in the CodeRabbit UI or the `.coderabbit.yaml` file in this repository.\n> \n> To trigger a single review, invoke the `@coderabbitai review` command.\n> \n\n<!-- end of auto-generated comment: skip review by coderabbit.ai --><!-- walkthrough_start -->\n\n## Walkthrough\nThe recent update introduces `slowapi` as an optional dependency to enhance the server's resilience against abuse. Specifically, it applies rate limiting to authentication endpoints, ensuring they can only be accessed a certain number of times per minute or day. This measure helps protect the server from potential overload or attack by regulating access frequency.\n\n## Changes\n\n| File Path                        | Change Summary                                         |\n|----------------------------------|--------------------------------------------------------|\n| `pyproject.toml`                 | Added `slowapi` as an optional dependency (`>=0.1.9`). |\n| `.../zen_server/routers/auth_endpoints.py` | Imported `Limiter` and `get_remote_address` from `slowapi`; initialized `limiter` with `Limiter(key_func=get_remote_address)`; added rate limiting (`5/minute;1000/day`) to the `token` function. |\n\n>   \n> In the land of code and might,  \n> A new guard rises, shining bright.  \n> \"Slow and steady,\" it firmly said,  \n> Keeping the server safe, ahead.  \n> With every hop, it sets the pace,  \n> Ensuring all find their rightful place.  \n> \n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: raw summary by coderabbit.ai -->\n<!--\n\n\npyproject.toml: ## Short summary\n\nAdded `slowapi` as an optional dependency with version `>=0.1.9`.\n\nsrc/zenml/zen_server/routers/auth_endpoints.py: ## Short summary\n\nAdded import statements for `Limiter` and `get_remote_address`. Initialized `limiter` with `Limiter(key_func=get_remote_address)`. Decorated the `token` function with rate limiting using `@limiter.limit(\"5/minute;1000/day\")`.\n\n-->\n<!-- end of auto-generated comment: raw summary by coderabbit.ai --><!-- This is an auto-generated comment: short summary by coderabbit.ai -->\n<!--\n\n\n### PR Objectives\n\nThe pull request (PR) titled \"Rate limiting for login API\" (number 2484) introduces a crucial security enhancement to the login API by implementing rate limiting. This change aims to mitigate misuse and excessive login attempts, enhancing the overall security posture of the system. The contributor has completed several preparatory steps to ensure the quality and compatibility of this change, including reading the contributing guidelines, potentially updating documentation, basing their work on the `develop` branch, and communicating necessary changes to the dashboard if required. Although the PR does not include new tests to cover the changes, it marks a significant bug fix by adding rate limiting to an area previously lacking this safeguard. The changes are categorized under bug fixes, indicating an improvement to existing functionality without introducing new features or breaking changes.\n\n### Comments Summary\n\nThe comment from `avishniakov` directly requests a review from `@coderabbitai`. This indicates a need for evaluation and feedback on the implemented changes. There are no further comments providing additional context or raising specific concerns about the PR. Thus, the primary focus from the comments is on obtaining a thorough review of the modifications made to introduce rate limiting to the login API.\n\n### AI-generated Summary of Generated Summaries\n\nThe PR introduces rate limiting to the login API by incorporating `slowapi` as an optional dependency, specified to be version `>=0.1.9` in `pyproject.toml`. In `src/zenml/zen_server/routers/auth_endpoints.py`, the changes involve importing `Limiter` and `get_remote_address` to initialize a `limiter` instance with `Limiter(key_func=get_remote_address)`. The `token` function, responsible for handling login attempts, is now decorated with a rate limit of \"5/minute;1000/day\" to prevent misuse and excessive login attempts. This enhancement is a direct response to the previously identified gap in security measures, specifically addressing the need for rate limiting to protect against potential abuse. The implementation details, including the choice of rate limits and the use of `slowapi`, reflect a targeted approach to improving the system's resilience against brute-force attacks and other forms of abuse that could compromise user security and system integrity.\n\n-->\n<!-- end of auto-generated comment: short summary by coderabbit.ai --><!-- commit_ids_reviewed_start -->\n\n<!-- 32c06cb5bbdc003647756b59c6379d3c250cabc0 -->\n\n<!-- commit_ids_reviewed_end --><!-- tweet_start -->\n\nThank you for using CodeRabbit. We offer it for free to the OSS community and would appreciate your support in helping us grow. If you find it useful, would you consider giving us a shout-out on your favorite social media?\n\n<details>\n<summary>Share</summary>\n\n- [X](https://twitter.com/intent/tweet?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A&url=https%3A//coderabbit.ai)\n- [Mastodon](https://mastodon.social/share?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A%20https%3A%2F%2Fcoderabbit.ai)\n- [Reddit](https://www.reddit.com/submit?title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&text=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code.%20Check%20it%20out%3A%20https%3A//coderabbit.ai)\n- [LinkedIn](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcoderabbit.ai&mini=true&title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&summary=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code)\n\n</details>\n\n<!-- tweet_end --><!-- tips_start -->\n\n---\n\n<details>\n<summary>Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with CodeRabbit:\n\n- Review comments: Directly reply to a review comment made by CodeRabbit. Example:\n\t- `I pushed a fix in commit <commit_id>.`\n\t- `Generate unit-tests for this file.`\n\t- `Open a follow-up GitHub issue for this discussion.`\n- Files and specific lines of code (under the \"Files changed\" tab): Tag `@coderabbitai` in a new review comment at the desired location with your query. Examples:\n\t- `@coderabbitai generate unit tests for this file.`\n\t-\t`@coderabbitai modularize this function.`\n- PR comments: Tag `@coderabbitai` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n\t- `@coderabbitai generate interesting stats about this repository and render them as a table.`\n\t- `@coderabbitai show all the console.log statements in this repository.`\n\t- `@coderabbitai read src/utils.ts and generate unit tests.`\n\t- `@coderabbitai read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (invoked as PR comments)\n\n- `@coderabbitai pause` to pause the reviews on a PR.\n- `@coderabbitai resume` to resume the paused reviews.\n- `@coderabbitai review` to trigger a review. This is useful when automatic reviews are disabled for the repository.\n- `@coderabbitai resolve` resolve all the CodeRabbit review comments.\n- `@coderabbitai help` to get help.\n\n\nAdditionally, you can add `@coderabbitai ignore` anywhere in the PR description to prevent this PR from being reviewed.\n\n### CodeRabbit Configration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- The JSON schema for the configuration file is available [here](https://coderabbit.ai/integrations/coderabbit-overrides.v2.json).\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/coderabbit-overrides.v2.json`\n\n### CodeRabbit Discord Community\n\nJoin our [Discord Community](https://discord.com/invite/GsXnASn26c) to get help, request features, and share feedback.\n\n</details>\n\n<!-- tips_end -->",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-29T15:17:24Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2484#issuecomment-1971362152"
                    },
                    {
                        "body": "@coderabbitai review",
                        "user": "avishniakov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-29T15:21:28Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2484#issuecomment-1971370519"
                    },
                    {
                        "body": "Quickstart template updates in `examples/quickstart` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-29T15:24:28Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2484#issuecomment-1971376593"
                    },
                    {
                        "body": "NLP template updates in `examples/e2e_nlp` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-29T15:34:29Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2484#issuecomment-1971397311"
                    },
                    {
                        "body": "> I love how simple `slowapi` is. I don't recommend we use fastapi_limiter for this, it's overkill.\r\n> \r\n> I already closed the original vulnerability as informational on account of us not advertising the username/password authentication method as a full-fledged production-grade security scheme. If `slowapi` doesn't work out, we could also give up and not fix this at all.\r\n\r\ngood catch - forgot about redis",
                        "user": "AlexejPenner",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-01T10:23:09Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2484#issuecomment-1972921554"
                    },
                    {
                        "body": "E2E template updates in `examples/e2e` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-01T15:42:40Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2484#issuecomment-1973413129"
                    },
                    {
                        "body": "I just realized there's another reason why we need to be very very careful with this: rate-limiters rely on the ability to extract the *real* source IP address from an incoming request, but this can be difficult to achieve, especially with cloud or Kubernetes deployments, because a load balancer or proxy usually sits in front of the ZenML server and rewrites the source IP address.\r\n\r\nIf mis-configured, this can have disastrous consequences, because all requests are \"seen\" as coming from the same IP address. For example, someone trying to brute-force their way into the server can become a DoS attack, because everyone will be locked out of the server.\r\n\r\nMore info here:\r\n* https://stackoverflow.com/questions/60098005/fastapi-starlette-get-client-real-ip\r\n* https://www.uvicorn.org/settings/#http\r\n\r\nI think the safe thing to do is to have rate-limiting turned off by default and have proper documentation around how to properly configure it and the services around it to avoid problems.\r\n\r\nSee this PR for a bug related to the same problem: https://github.com/zenml-io/zenml/pull/2499",
                        "user": "stefannica",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-06T15:28:56Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2484#issuecomment-1981135392"
                    },
                    {
                        "body": "> I just realized there's another reason why we need to be very very careful with this: rate-limiters rely on the ability to extract the _real_ source IP address from an incoming request, but this can be difficult to achieve, especially with cloud or Kubernetes deployments, because a load balancer or proxy usually sits in front of the ZenML server and rewrites the source IP address.\r\n> \r\n> If mis-configured, this can have disastrous consequences, because all requests are \"seen\" as coming from the same IP address. For example, someone trying to brute-force their way into the server can become a DoS attack, because everyone will be locked out of the server.\r\n> \r\n> More info here:\r\n> \r\n> * https://stackoverflow.com/questions/60098005/fastapi-starlette-get-client-real-ip\r\n> * https://www.uvicorn.org/settings/#http\r\n> \r\n> I think the safe thing to do is to have rate-limiting turned off by default and have proper documentation around how to properly configure it and the services around it to avoid problems.\r\n> \r\n> See this PR for a bug related to the same problem: #2499\r\n\r\nYeah, this makes sense to me, but let's build on top of that:\r\nIf k8s or other infra is bombarding REST with incorrect credentials, why should it pass? Successful requests do not affect limits. This might be an issue indeed for users behind VPN, for instance (they all might land on the same IP).\r\n\r\nDue to all those complications, we can drop this feature completely for OSS. Based on my research - everything inside HTTP request can be spoofed, so we cannot rely really on any header or other info to make a weighted decision if this is the same requestor or not. I don't know what folks from CDN solution use to prevent DDoS and other things, but we are not CDN provider  ",
                        "user": "avishniakov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-07T10:59:10Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2484#issuecomment-1983264813"
                    },
                    {
                        "body": "> Yeah, this makes sense to me, but let's build on top of that: If k8s or other infra is bombarding REST with incorrect credentials, why should it pass? Successful requests do not affect limits. This might be an issue indeed for users behind VPN, for instance (they all might land on the same IP).\r\n> \r\n> Due to all those complications, we can drop this feature completely for OSS. Based on my research - everything inside HTTP request can be spoofed, so we cannot rely really on any header or other info to make a weighted decision if this is the same requestor or not. I don't know what folks from CDN solution use to prevent DDoS and other things, but we are not CDN provider \r\n\r\nThere's probably been a misunderstanding, it's not really k8s or other infra that's bombarding REST with incorrect credentials. This is what can happen if the ZenML server or the kubernetes cluster or load balancer, or proxy is incorrectly configured:\r\n* let's say you have 100 legit users regularly logging in\r\n* let's also say you have an attacker trying to brute-force his way into the server\r\n* when incorrectly configured, the server \"sees\" all requests coming from a single IP: the IP of the proxy or load-balancer\r\n* the \"bad\" requests will pile up until the limiter starts blocking traffic from that IP address, effectively stopping everyone from logging in, even the legit users\r\n\r\nWe should still offer the limiter as a feature, because it's a great thing to have for security, but have some way of configuring it and keeping it disabled by default. If the admins enable it, it's their responsibility to correctly configure the surrounding infrastructure (proxy/load-balancer/whatever).",
                        "user": "stefannica",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-07T11:17:29Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2484#issuecomment-1983294431"
                    },
                    {
                        "body": "@stefannica I added some docs describing how to configure it and cancel the current CI - the last one was all green. Please have a look.",
                        "user": "avishniakov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-11T08:30:42Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2484#issuecomment-1987866801"
                    },
                    {
                        "body": "Quickstart template updates in `examples/quickstart` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-11T16:11:04Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2484#issuecomment-1988814249"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/zenml-io/zenml/pulls/2484",
                    "merged_at": "2024-03-18T11:59:40Z"
                }
            },
            {
                "url": "https://github.com/zenml-io/zenml/pull/2483",
                "title": "Uniquely constrained users table",
                "labels": [
                    "bug",
                    "internal",
                    "security",
                    "run-slow-ci"
                ],
                "user": "avishniakov",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2483,
                "id": 2161404966,
                "state": "closed",
                "project_created_at": "2024-02-29T14:31:59Z",
                "closed_at": "2024-03-04T09:05:44Z",
                "body": "## Describe changes\r\nI fixed how we ensure that no duplicates are passed to the DB level for UserSchema.\r\n\r\n## Pre-requisites\r\nPlease ensure you have done the following:\r\n- [x] I have read the **CONTRIBUTING.md** document.\r\n- [x] If my change requires a change to docs, I have updated the documentation accordingly.\r\n- [x] I have added tests to cover my changes.\r\n- [x] I have based my new branch on `develop` and the open PR is targeting `develop`. If your branch wasn't based on develop read [Contribution guide on rebasing branch to develop](https://github.com/zenml-io/zenml/blob/main/CONTRIBUTING.md#-pull-requests-rebase-your-branch-on-develop).\r\n- [x] If my changes require changes to the dashboard, these changes are communicated/requested.\r\n\r\n## Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Other (add details above)\r\n\r\n\n\n<!-- This is an auto-generated comment: release notes by coderabbit.ai -->\n\n## Summary by CodeRabbit\n\n- **New Features**\n\t- Implemented a unique constraint for user names to ensure each user is distinct, enhancing data integrity.\n- **Refactor**\n\t- Improved transaction management with better exception handling for user creation and updates.\n\n<!-- end of auto-generated comment: release notes by coderabbit.ai -->",
                "comments": [
                    {
                        "body": "<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- This is an auto-generated comment: skip review by coderabbit.ai -->\n\n> [!IMPORTANT]\n> ## Auto Review Skipped\n> \n> Auto reviews are disabled on this repository.\n> \n> Please check the settings in the CodeRabbit UI or the `.coderabbit.yaml` file in this repository.\n> \n> To trigger a single review, invoke the `@coderabbitai review` command.\n> \n\n<!-- end of auto-generated comment: skip review by coderabbit.ai --><!-- walkthrough_start -->\n\n## Walkthrough\nThe update introduces a unique constraint to the `user` table, ensuring that each combination of user name and service account status is unique. It modifies the schema to include this constraint and enhances the transaction management in the SQL store. Exception handling is improved with specific attention to `IntegrityError`, streamlining the process of checking for existing entities before their creation.\n\n## Changes\n\n| File Path                         | Change Summary                                                           |\n|-----------------------------------|--------------------------------------------------------------------------|\n| `.../migrations/versions/72675226b2de_unique_users.py` | Adds a migration script for unique constraint on `user` table.          |\n| `.../zen_stores/schemas/user_schemas.py`               | Introduces `UniqueConstraint` in `UserSchema`.                           |\n| `.../zen_stores/sql_zen_store.py`                       | Enhances transaction management and exception handling for entity creation. |\n\n>   \n> To the database, we hop and bound,  \n> With unique users, no duplicates found.  \n> Try and catch, we gracefully manage,  \n> Ensuring integrity, with no damage.  \n> So here's to changes, both big and small,  \n> May our code run smoothly, bugs none at all.  \n> \n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: raw summary by coderabbit.ai -->\n<!--\n\n\nsrc/zenml/zen_stores/migrations/versions/72675226b2de_unique_users.py: This file introduces a migration script that adds a unique constraint to the \"user\" table on columns \"name\" and \"is_service_account.\"\n\n---\n\nsrc/zenml/zen_stores/schemas/user_schemas.py: Added a `UniqueConstraint` to the `UserSchema` table definition in `user_schemas.py`.\n\n---\n\nsrc/zenml/zen_stores/sql_zen_store.py: \n- The code now uses `try-except` blocks with `IntegrityError` handling for transaction management.\n- The logic for checking existing entities before creation has been updated to handle exceptions more effectively.\n\n-->\n<!-- end of auto-generated comment: raw summary by coderabbit.ai --><!-- This is an auto-generated comment: short summary by coderabbit.ai -->\n<!--\n\n\n### PR Objectives\n\nThe pull request (PR) number 2483, titled \"Uniquely constrained users table,\" aims to address an issue related to the duplication of user data in the database. The submitter has implemented a fix to ensure that the UserSchema does not allow duplicate entries at the database level, enhancing data integrity and consistency within the application's user management system.\n\nThe changes made in this PR involve the introduction of a unique constraint on the \"user\" table, specifically targeting the \"name\" and \"is_service_account\" columns to prevent the insertion of duplicate records. This modification is critical for maintaining a clean and reliable user database, especially in systems where the distinction between regular users and service accounts is vital.\n\nBefore submitting the PR, the author has adhered to several pre-requisites, including reading the contributing document, updating documentation if necessary, adding tests to cover the changes, basing their branch on `develop`, and communicating any dashboard-related changes. The types of changes introduced by this PR are categorized under \"Bug fix,\" indicating that the primary goal is to rectify an existing issue without introducing new features or breaking changes.\n\n### Comments Summary\n\nThe comment on the PR from `avishniakov` is a direct request for a review from `@coderabbitai`. This indicates that the PR is ready for evaluation and possibly requires expertise or insights from the mentioned reviewer. There are no additional comments providing further context or feedback on the PR, suggesting that the discussion is in its early stages or that the changes are straightforward enough not to warrant immediate concerns or questions from other contributors.\n\n### AI-Generated Summary of Generated Summaries\n\nThe PR introduces a set of changes aimed at enhancing the uniqueness constraints within the user management system of the application. Specifically, a migration script has been added to enforce a unique constraint on the \"name\" and \"is_service_account\" columns of the \"user\" table, ensuring that duplicate entries are prevented at the database level. This is further supported by modifications in the `UserSchema` within `user_schemas.py`, where a `UniqueConstraint` has been explicitly defined to uphold this requirement.\n\nAdditionally, the PR includes updates to the `sql_zen_store.py` file, where transaction management has been improved through the use of `try-except` blocks specifically designed to catch `IntegrityError`. This enhancement not only aids in handling exceptions more effectively but also updates the logic for checking existing entities before their creation, thereby reinforcing the overall integrity and reliability of the user data management process.\n\nIn summary, PR 2483 focuses on fixing an issue related to user data duplication by implementing unique constraints and improving exception handling mechanisms, thereby ensuring the integrity and uniqueness of user records in the database.\n\n-->\n<!-- end of auto-generated comment: short summary by coderabbit.ai --><!-- commit_ids_reviewed_start -->\n\n<!-- 135c2e05e7350f1b49ccddcf450e6533143900a7 -->\n\n<!-- commit_ids_reviewed_end --><!-- tweet_start -->\n\nThank you for using CodeRabbit. We offer it for free to the OSS community and would appreciate your support in helping us grow. If you find it useful, would you consider giving us a shout-out on your favorite social media?\n\n<details>\n<summary>Share</summary>\n\n- [X](https://twitter.com/intent/tweet?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A&url=https%3A//coderabbit.ai)\n- [Mastodon](https://mastodon.social/share?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A%20https%3A%2F%2Fcoderabbit.ai)\n- [Reddit](https://www.reddit.com/submit?title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&text=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code.%20Check%20it%20out%3A%20https%3A//coderabbit.ai)\n- [LinkedIn](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcoderabbit.ai&mini=true&title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&summary=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code)\n\n</details>\n\n<!-- tweet_end --><!-- tips_start -->\n\n---\n\n<details>\n<summary>Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with CodeRabbit:\n\n- Review comments: Directly reply to a review comment made by CodeRabbit. Example:\n\t- `I pushed a fix in commit <commit_id>.`\n\t- `Generate unit-tests for this file.`\n- Files and specific lines of code (under the \"Files changed\" tab): Tag `@coderabbitai` in a new review comment at the desired location with your query. Examples:\n\t- `@coderabbitai generate unit tests for this file.`\n\t-\t`@coderabbitai modularize this function.`\n- PR comments: Tag `@coderabbitai` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n\t- `@coderabbitai generate interesting stats about this repository from git and render them as a table.`\n\t- `@coderabbitai show all the console.log statements in this repository.`\n\t- `@coderabbitai read src/utils.ts and generate unit tests.`\n\t- `@coderabbitai read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (invoked as PR comments)\n\n- `@coderabbitai pause` to pause the reviews on a PR.\n- `@coderabbitai resume` to resume the paused reviews.\n- `@coderabbitai review` to trigger a review. This is useful when automatic reviews are disabled for the repository.\n- `@coderabbitai resolve` resolve all the CodeRabbit review comments.\n- `@coderabbitai help` to get help.\n\n\nAdditionally, you can add `@coderabbitai ignore` anywhere in the PR description to prevent this PR from being reviewed.\n\n### CodeRabbit Configration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- The JSON schema for the configuration file is available [here](https://coderabbit.ai/integrations/coderabbit-overrides.v2.json).\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/coderabbit-overrides.v2.json`\n\n### CodeRabbit Discord Community\n\nJoin our [Discord Community](https://discord.com/invite/GsXnASn26c) to get help, request features, and share feedback.\n\n</details>\n\n<!-- tips_end -->",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-29T14:32:06Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2483#issuecomment-1971271288"
                    },
                    {
                        "body": "@coderabbitai review",
                        "user": "avishniakov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-29T14:35:15Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2483#issuecomment-1971277466"
                    },
                    {
                        "body": "Quickstart template updates in `examples/quickstart` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-29T15:29:22Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2483#issuecomment-1971386763"
                    },
                    {
                        "body": "NLP template updates in `examples/e2e_nlp` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-29T15:39:53Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2483#issuecomment-1971407930"
                    },
                    {
                        "body": "Quickstart template updates in `examples/quickstart` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-01T07:23:11Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2483#issuecomment-1972655166"
                    },
                    {
                        "body": "NLP template updates in `examples/e2e_nlp` have been pushed.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-03-01T07:32:40Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2483#issuecomment-1972669241"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/zenml-io/zenml/pulls/2483",
                    "merged_at": "2024-03-04T09:05:44Z"
                }
            },
            {
                "url": "https://github.com/zenml-io/zenml/pull/2479",
                "title": "Race condition on creating new users allows duplicate usernames",
                "labels": [
                    "bug",
                    "internal",
                    "security",
                    "run-slow-ci"
                ],
                "user": "avishniakov",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2479,
                "id": 2160773280,
                "state": "closed",
                "project_created_at": "2024-02-29T09:13:57Z",
                "closed_at": "2024-02-29T12:04:58Z",
                "body": "## Describe changes\r\nI fixed the conditional check for new users/service account creation under heavy race conditions (e.g. 100 simultaneous request to create new user).\r\n\r\n## Pre-requisites\r\nPlease ensure you have done the following:\r\n- [x] I have read the **CONTRIBUTING.md** document.\r\n- [x] If my change requires a change to docs, I have updated the documentation accordingly.\r\n- [x] I have added tests to cover my changes.\r\n- [x] I have based my new branch on `develop` and the open PR is targeting `develop`. If your branch wasn't based on develop read [Contribution guide on rebasing branch to develop](https://github.com/zenml-io/zenml/blob/main/CONTRIBUTING.md#-pull-requests-rebase-your-branch-on-develop).\r\n- [x] If my changes require changes to the dashboard, these changes are communicated/requested.\r\n\r\n## Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Other (add details above)\r\n\r\n\n\n<!-- This is an auto-generated comment: release notes by coderabbit.ai -->\n\n## Summary by CodeRabbit\n\n- **Refactor**\n\t- Improved the handling and creation process of entities within the system to prevent duplication and enhance error management.\n- **Tests**\n\t- Added tests to ensure users and service accounts can be created in parallel without duplication, enhancing system reliability.\n\n<!-- end of auto-generated comment: release notes by coderabbit.ai -->",
                "comments": [
                    {
                        "body": "<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- This is an auto-generated comment: skip review by coderabbit.ai -->\n\n> [!IMPORTANT]\n> ## Auto Review Skipped\n> \n> Auto reviews are disabled on this repository.\n> \n> Please check the settings in the CodeRabbit UI or the `.coderabbit.yaml` file in this repository.\n> \n> To trigger a single review, invoke the `@coderabbitai review` command.\n> \n\n<!-- end of auto-generated comment: skip review by coderabbit.ai --><!-- walkthrough_start -->\n\n## Walkthrough\nThe recent updates focus on enhancing the reliability and concurrency of operations within a SQL-based storage system for ZenML, specifically targeting the creation of entities like users and service accounts. The changes ensure entities are uniquely created without duplication even when multiple requests are made in parallel, alongside improved error handling for entity existence.\n\n## Changes\n\n| File Path                                               | Change Summary                                                                 |\n|---------------------------------------------------------|---------------------------------------------------------------------------------|\n| `src/zenml/.../sql_zen_store.py`                        | Enhanced entity creation order, existence checks, and error handling.          |\n| `tests/integration/functional/zen_stores/.../test_zen_store.py` | Added tests for parallel user and service account creation without duplication.|\n\n>   \n> In the realm of code where the data flows,  \n> A rabbit hopped, fixing bugs in rows.  \n> No duplicates found, in parallel they thrive,  \n> Ensuring entities uniquely arrive.  \n> With each hop and leap, the code does improve,  \n> In the ZenML land, smooth and on the move.  \n> \n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: raw summary by coderabbit.ai -->\n<!--\n\n\nsrc/zenml/zen_stores/sql_zen_store.py: ## Short summary\n\nIn the `sql_zen_store.py` file, the changes involve reordering the creation of entities within a session, checking for existing entities before committing, adjusting error handling for entity existence.\n\n---\n\ntests/integration/functional/zen_stores/test_zen_store.py: ## Short summary\n\n- Added import for `threading`.\n- Added import for `UserFilter`.\n- Added a new test `test_creating_users_in_parallel_do_not_duplicate_fails` to test creating users in parallel without duplication.\n- Added a new test `test_creating_service_accounts_in_parallel_do_not_duplicate_fails` to test creating service accounts in parallel without duplication.\n\n-->\n<!-- end of auto-generated comment: raw summary by coderabbit.ai --><!-- This is an auto-generated comment: short summary by coderabbit.ai -->\n<!--\n\n\n### PR Objectives\n\nThe pull request (PR) #2479 addresses a critical issue related to the creation of new users and service accounts under heavy race conditions, such as when there are 100 simultaneous requests to create a new user. The submitter has identified and fixed a race condition that allowed for the creation of duplicate usernames, which is a significant bug fix enhancing the system's integrity and reliability.\n\nThe changes made include adjustments to the conditional checks during the user and service account creation process to prevent duplicates from occurring even under heavy load. This fix is crucial for maintaining the uniqueness of usernames across the system, which is fundamental for user identification and management.\n\nThe contributor has followed all the necessary pre-requisites for submitting the PR, including reading the contributing document, updating documentation if required, adding tests to cover the changes, basing the new branch on `develop`, and communicating any dashboard changes. The type of change is categorized under \"Bug fix,\" indicating that it resolves an issue without introducing new features or breaking existing functionality.\n\n### Comments Summary\n\nIn the comments section of the PR, there are two notable interactions:\n\n1. **GitGuardian Alert**: A comment from `avishniakov` highlights an alert from GitGuardian, which detected a hardcoded secret in the pull request. However, this was immediately addressed by the commenter as a false positive. This interaction is crucial as it concerns security and the integrity of the codebase, but since it's identified as a false positive, it doesn't impact the PR's review process directly.\n\n2. **Review Request**: `strickvl` has requested a review from `coderabbitai`. This indicates that the PR is ready for further examination and evaluation by peers or automated systems to ensure the changes meet the project's standards and effectively address the issue at hand.\n\n### AI-Generated Summary of Generated Summaries\n\nThe pull request introduces modifications primarily within the `sql_zen_store.py` file and the integration tests to address a race condition issue that allowed the creation of duplicate usernames during high concurrency scenarios. The core changes involve enhancing the logic for checking the existence of entities before committing their creation to the database and refining error handling related to entity existence checks. Specifically, the adjustments ensure that during the creation process of users and service accounts, the system now correctly identifies and prevents the creation of duplicates, thereby maintaining the uniqueness and integrity of usernames.\n\nAdditionally, the integration tests have been expanded to include new tests that simulate the parallel creation of users and service accounts, ensuring that the fixes are effective and that such race conditions are appropriately handled. These tests leverage threading to mimic concurrent requests, providing a robust validation for the changes made.\n\nIn summary, the PR effectively addresses a significant race condition issue by refining the entity creation process and enhancing the system's ability to handle high concurrency scenarios without compromising the uniqueness of usernames. The inclusion of targeted integration tests further ensures the reliability and effectiveness of these changes.\n\n-->\n<!-- end of auto-generated comment: short summary by coderabbit.ai --><!-- commit_ids_reviewed_start -->\n\n<!-- 618770b84cc75d2478070fc47a6a7da2848668ae -->\n\n<!-- commit_ids_reviewed_end --><!-- tweet_start -->\n\nThank you for using CodeRabbit. We offer it for free to the OSS community and would appreciate your support in helping us grow. If you find it useful, would you consider giving us a shout-out on your favorite social media?\n\n<details>\n<summary>Share</summary>\n\n- [X](https://twitter.com/intent/tweet?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A&url=https%3A//coderabbit.ai)\n- [Mastodon](https://mastodon.social/share?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A%20https%3A%2F%2Fcoderabbit.ai)\n- [Reddit](https://www.reddit.com/submit?title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&text=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code.%20Check%20it%20out%3A%20https%3A//coderabbit.ai)\n- [LinkedIn](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcoderabbit.ai&mini=true&title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&summary=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code)\n\n</details>\n\n<!-- tweet_end --><!-- tips_start -->\n\n---\n\n<details>\n<summary>Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with CodeRabbit:\n\n- Review comments: Directly reply to a review comment made by CodeRabbit. Example:\n\t- `I pushed a fix in commit <commit_id>.`\n\t- `Generate unit-tests for this file.`\n- Files and specific lines of code (under the \"Files changed\" tab): Tag `@coderabbitai` in a new review comment at the desired location with your query. Examples:\n\t- `@coderabbitai generate unit tests for this file.`\n\t-\t`@coderabbitai modularize this function.`\n- PR comments: Tag `@coderabbitai` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n\t- `@coderabbitai generate interesting stats about this repository from git and render them as a table.`\n\t- `@coderabbitai show all the console.log statements in this repository.`\n\t- `@coderabbitai read src/utils.ts and generate unit tests.`\n\t- `@coderabbitai read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (invoked as PR comments)\n\n- `@coderabbitai pause` to pause the reviews on a PR.\n- `@coderabbitai resume` to resume the paused reviews.\n- `@coderabbitai review` to trigger a review. This is useful when automatic reviews are disabled for the repository.\n- `@coderabbitai resolve` resolve all the CodeRabbit review comments.\n- `@coderabbitai help` to get help.\n\n\nAdditionally, you can add `@coderabbitai ignore` anywhere in the PR description to prevent this PR from being reviewed.\n\n### CodeRabbit Configration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- The JSON schema for the configuration file is available [here](https://coderabbit.ai/integrations/coderabbit-overrides.v2.json).\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/coderabbit-overrides.v2.json`\n\n### CodeRabbit Discord Community\n\nJoin our [Discord Community](https://discord.com/invite/GsXnASn26c) to get help, request features, and share feedback.\n\n</details>\n\n<!-- tips_end -->",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-29T09:14:02Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2479#issuecomment-1970716369"
                    },
                    {
                        "body": "####  GitGuardian has uncovered 2 secrets following the scan of your pull request.\n\nPlease consider investigating the findings and remediating the incidents. Failure to do so may lead to compromising the associated services or software components.\n\n<details>\n<summary> Detected hardcoded secrets in your pull request</summary>\n<br>\n\n| GitGuardian id | GitGuardian status | Secret                         | Commit           | Filename        |                      |\n| -------------- | ------------------ | ------------------------------ | ---------------- | --------------- | -------------------- |\n| [9700814](https://dashboard.gitguardian.com/incidents/9700814?occurrence=125675547) | Triggered | Generic Password | 8f50f478b5bacd74c88a6ae98723d2d4b6ddd0c4 | tests/integration/functional/zen_stores/test_zen_store.py | [View secret](https://github.com/zenml-io/zenml/commit/8f50f478b5bacd74c88a6ae98723d2d4b6ddd0c4#diff-bedf4b90bcbddd89de31e1e8af7a9e4166a99c046efd8a3dc5d66bff73753a1dR425) |\n| [9700814](https://dashboard.gitguardian.com/incidents/9700814?occurrence=125676867) | Triggered | Generic Password | dd303b90385dc805c5cdccf8974be19f8f82a951 | tests/integration/functional/zen_stores/test_zen_store.py | [View secret](https://github.com/zenml-io/zenml/commit/dd303b90385dc805c5cdccf8974be19f8f82a951#diff-bedf4b90bcbddd89de31e1e8af7a9e4166a99c046efd8a3dc5d66bff73753a1dL425) |\n\n\n\n</details>\n\n<details>\n<summary> Guidelines to remediate hardcoded secrets</summary>\n<br>\n\n1. Understand the implications of revoking this secret by investigating where it is used in your code.\n2. Replace and store your secrets safely. [Learn here](https://blog.gitguardian.com/secrets-api-management?utm_source=product&amp;utm_medium=GitHub_checks&amp;utm_campaign=check_run_comment) the best practices.\n3. Revoke and [rotate these secrets](https://docs.gitguardian.com/secrets-detection/secrets-detection-engine/detectors/generics/generic_password#revoke-the-secret?utm_source=product&amp;utm_medium=GitHub_checks&amp;utm_campaign=check_run_comment).\n4. If possible, [rewrite git history](https://blog.gitguardian.com/rewriting-git-history-cheatsheet?utm_source=product&amp;utm_medium=GitHub_checks&amp;utm_campaign=check_run_comment). Rewriting git history is not a trivial act. You might completely break other contributing developers' workflow and you risk accidentally deleting legitimate data.\n\nTo avoid such incidents in the future consider\n\n-   following these [best practices](https://blog.gitguardian.com/secrets-api-management/?utm_source=product&amp;utm_medium=GitHub_checks&amp;utm_campaign=check_run_comment) for managing and storing secrets including API keys and other credentials\n-   install [secret detection on pre-commit](https://docs.gitguardian.com/ggshield-docs/integrations/git-hooks/pre-commit?utm_source=product&amp;utm_medium=GitHub_checks&amp;utm_campaign=check_run_comment) to catch secret before it leaves your machine and ease remediation.\n\n\n</details>\n\n---\n\n<sup> [GitGuardian](https://dashboard.gitguardian.com/auth/login/?utm_medium=checkruns&amp;utm_source=github&amp;utm_campaign=cr1) detects secrets in your source code to help developers and security teams secure the modern development process. You are seeing this because you or someone else with access to this repository has authorized GitGuardian to scan your pull request.<br/><br/>Our GitHub checks need improvements? [Share your feedbacks](https://form.typeform.com/to/KmeAPTMk)!</sup>",
                        "user": "gitguardian[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-29T09:14:05Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2479#issuecomment-1970716439"
                    },
                    {
                        "body": "> ####  GitGuardian has uncovered 1 secret following the scan of your pull request.\r\n> Please consider investigating the findings and remediating the incidents. Failure to do so may lead to compromising the associated services or software components.\r\n> \r\n>  Detected hardcoded secret in your pull request\r\n>  Guidelines to remediate hardcoded secrets\r\n>  [GitGuardian](https://dashboard.gitguardian.com/auth/login/?utm_medium=checkruns&utm_source=github&utm_campaign=cr1) detects secrets in your source code to help developers and security teams secure the modern development process. You are seeing this because you or someone else with access to this repository has authorized GitGuardian to scan your pull request.Our GitHub checks need improvements? [Share your feedbacks](https://form.typeform.com/to/KmeAPTMk)!\r\n\r\nFalse positive",
                        "user": "avishniakov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-29T09:18:03Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2479#issuecomment-1970722825"
                    },
                    {
                        "body": "@coderabbitai review",
                        "user": "strickvl",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-29T09:41:50Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2479#issuecomment-1970761596"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/zenml-io/zenml/pulls/2479",
                    "merged_at": "2024-02-29T12:04:58Z"
                }
            },
            {
                "url": "https://github.com/zenml-io/zenml/pull/2437",
                "title": "Add vulnerability notice to README",
                "labels": [
                    "internal",
                    "security"
                ],
                "user": "strickvl",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2437,
                "id": 2129877372,
                "state": "closed",
                "project_created_at": "2024-02-12T10:53:48Z",
                "closed_at": "2024-02-13T13:32:45Z",
                "body": "## Describe changes\r\nI implemented/fixed _ to achieve _.\r\n\r\n## Pre-requisites\r\nPlease ensure you have done the following:\r\n- [ ] I have read the **CONTRIBUTING.md** document.\r\n- [ ] If my change requires a change to docs, I have updated the documentation accordingly.\r\n- [ ] I have added tests to cover my changes.\r\n- [ ] I have based my new branch on `develop` and the open PR is targeting `develop`. If your branch wasn't based on develop read [Contribution guide on rebasing branch to develop](https://github.com/zenml-io/zenml/blob/main/CONTRIBUTING.md#-pull-requests-rebase-your-branch-on-develop).\r\n- [ ] If my changes require changes to the dashboard, these changes are communicated/requested.\r\n\r\n## Types of changes\r\n<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\r\n- [ ] Other (add details above)\r\n\r\n",
                "comments": [
                    {
                        "body": "<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- This is an auto-generated comment: skip review by coderabbit.ai -->\n\n> [!IMPORTANT]\n> ## Auto Review Skipped\n> \n> Auto reviews are disabled on this repository.\n> \n> Please check the settings in the CodeRabbit UI or the `.coderabbit.yaml` file in this repository.\n> \n> To trigger a single review, invoke the `@coderabbitai review` command.\n> \n\n<!-- end of auto-generated comment: skip review by coderabbit.ai --><!-- tweet_start -->\n\nThank you for using CodeRabbit. We offer it for free to the OSS community and would appreciate your support in helping us grow. If you find it useful, would you consider giving us a shout-out on your favorite social media?\n\n<details>\n<summary>Share</summary>\n\n- [X](https://twitter.com/intent/tweet?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A&url=https%3A//coderabbit.ai)\n- [Mastodon](https://mastodon.social/share?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A%20https%3A%2F%2Fcoderabbit.ai)\n- [Reddit](https://www.reddit.com/submit?title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&text=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code.%20Check%20it%20out%3A%20https%3A//coderabbit.ai)\n- [LinkedIn](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcoderabbit.ai&mini=true&title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&summary=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code)\n\n</details>\n\n<!-- tweet_end --><!-- tips_start -->\n\n---\n\n<details>\n<summary>Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with CodeRabbit:\n\n- Review comments: Directly reply to a review comment made by CodeRabbit. Example:\n\t- `I pushed a fix in commit <commit_id>.`\n\t- `Generate unit-tests for this file.`\n- Files and specific lines of code (under the \"Files changed\" tab): Tag `@coderabbitai` in a new review comment at the desired location with your query. Examples:\n\t- `@coderabbitai generate unit tests for this file.`\n\t-\t`@coderabbitai modularize this function.`\n- PR comments: Tag `@coderabbitai` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n\t- `@coderabbitai generate interesting stats about this repository from git and render them as a table.`\n\t- `@coderabbitai show all the console.log statements in this repository.`\n\t- `@coderabbitai read src/utils.ts and generate unit tests.`\n\t- `@coderabbitai read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (invoked as PR comments)\n\n- `@coderabbitai pause` to pause the reviews on a PR.\n- `@coderabbitai resume` to resume the paused reviews.\n- `@coderabbitai review` to trigger a review. This is useful when automatic reviews are disabled for the repository.\n- `@coderabbitai resolve` resolve all the CodeRabbit review comments.\n- `@coderabbitai help` to get help.\n\n\nAdditionally, you can add `@coderabbitai ignore` anywhere in the PR description to prevent this PR from being reviewed.\n\n### CodeRabbit Configration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- The JSON schema for the configuration file is available [here](https://coderabbit.ai/integrations/coderabbit-overrides.v2.json).\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/coderabbit-overrides.v2.json`\n\n### CodeRabbit Discord Community\n\nJoin our [Discord Community](https://discord.com/invite/GsXnASn26c) to get help, request features, and share feedback.\n\n</details>\n\n<!-- tips_end -->",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-12T10:54:01Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2437#issuecomment-1938446756"
                    },
                    {
                        "body": "(approved orally by Hamza)",
                        "user": "strickvl",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-13T13:32:39Z",
                        "url": "https://github.com/zenml-io/zenml/pull/2437#issuecomment-1941524333"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/zenml-io/zenml/pulls/2437",
                    "merged_at": "2024-02-13T13:32:45Z"
                }
            }
        ],
        "SecurityPolicy_content_category": [
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 9,
        "has_generic_policy": true
    },
    {
        "project_name": "pyload/pyload",
        "project_url": "https://github.com/pyload/pyload",
        "SSF": {
            "date": "2024-10-29T20:04:25+07:00",
            "repo": {
                "name": "github.com/pyload/pyload",
                "commit": "1bbe45a2bda24231e43475dde239c649de4c5123"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.5,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'develop'",
                        "Info: 'allow deletion' disabled on branch 'stable'",
                        "Warn: 'force pushes' enabled on branch 'develop'",
                        "Info: 'force pushes' disabled on branch 'stable'",
                        "Warn: branch 'develop' does not require approvers",
                        "Warn: branch 'stable' does not require approvers",
                        "Warn: codeowners review is not required on branch 'develop'",
                        "Warn: codeowners review is not required on branch 'stable'",
                        "Info: status check found to merge onto on branch 'develop'",
                        "Warn: no status checks found to merge onto branch 'stable'"
                    ],
                    "score": 2,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no pull request found",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 0/30 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: pyload contributor org/company found, rossumai contributor org/company found, curious-today contributor org/company found, libratbag contributor org/company found, ParallelSSH contributor org/company found, paddlehq contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 6 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: PyUp: .pyup.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.md:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/build & deploy.yml:54"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build & deploy.yml:32: update your workflow using https://app.stepsecurity.io/secureworkflow/pyload/pyload/build & deploy.yml/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build & deploy.yml:35: update your workflow using https://app.stepsecurity.io/secureworkflow/pyload/pyload/build & deploy.yml/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build & deploy.yml:49: update your workflow using https://app.stepsecurity.io/secureworkflow/pyload/pyload/build & deploy.yml/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build & deploy.yml:70: update your workflow using https://app.stepsecurity.io/secureworkflow/pyload/pyload/build & deploy.yml/develop?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build & deploy.yml:76: update your workflow using https://app.stepsecurity.io/secureworkflow/pyload/pyload/build & deploy.yml/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint & test.yml:35: update your workflow using https://app.stepsecurity.io/secureworkflow/pyload/pyload/lint & test.yml/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint & test.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/pyload/pyload/lint & test.yml/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint & test.yml:49: update your workflow using https://app.stepsecurity.io/secureworkflow/pyload/pyload/lint & test.yml/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint & test.yml:88: update your workflow using https://app.stepsecurity.io/secureworkflow/pyload/pyload/lint & test.yml/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint & test.yml:95: update your workflow using https://app.stepsecurity.io/secureworkflow/pyload/pyload/lint & test.yml/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint & test.yml:107: update your workflow using https://app.stepsecurity.io/secureworkflow/pyload/pyload/lint & test.yml/develop?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/lock.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/pyload/pyload/lock.yml/develop?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/no-response.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/pyload/pyload/no-response.yml/develop?enable=pin",
                        "Warn: containerImage not pinned by hash: Dockerfile:29",
                        "Warn: containerImage not pinned by hash: Dockerfile:43",
                        "Warn: containerImage not pinned by hash: Dockerfile:59",
                        "Warn: containerImage not pinned by hash: Dockerfile:71",
                        "Warn: containerImage not pinned by hash: Dockerfile:81",
                        "Warn: containerImage not pinned by hash: Dockerfile.armhf:29",
                        "Warn: containerImage not pinned by hash: Dockerfile.armhf:42",
                        "Warn: containerImage not pinned by hash: Dockerfile.armhf:52",
                        "Warn: containerImage not pinned by hash: Dockerfile.armhf:64",
                        "Warn: containerImage not pinned by hash: Dockerfile.armhf:74",
                        "Warn: pipCommand not pinned by hash: Dockerfile:34-40",
                        "Warn: pipCommand not pinned by hash: Dockerfile:66-68",
                        "Warn: pipCommand not pinned by hash: Dockerfile:77-78",
                        "Warn: pipCommand not pinned by hash: Dockerfile.armhf:34-39",
                        "Warn: pipCommand not pinned by hash: Dockerfile.armhf:59-61",
                        "Warn: pipCommand not pinned by hash: Dockerfile.armhf:70-71",
                        "Warn: pipCommand not pinned by hash: .github/scripts/install_pycurl_win.sh:32",
                        "Warn: pipCommand not pinned by hash: .github/workflows/build & deploy.yml:41",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint & test.yml:58",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint & test.yml:116",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint & test.yml:117",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint & test.yml:117",
                        "Info:   0 out of  10 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   3 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of  10 containerImage dependencies pinned",
                        "Info:   0 out of  12 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: no pull requests merged into dev branch"
                    ],
                    "score": 0,
                    "reason": "no SAST tool detected",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact v0.4.20 not signed: https://api.github.com/repos/pyload/pyload/releases/23856648",
                        "Warn: release artifact v0.4.9 not signed: https://api.github.com/repos/pyload/pyload/releases/65198",
                        "Warn: release artifact v0.4.8 not signed: https://api.github.com/repos/pyload/pyload/releases/65895",
                        "Warn: release artifact v0.4.7 not signed: https://api.github.com/repos/pyload/pyload/releases/5102921",
                        "Warn: release artifact v0.4.6 not signed: https://api.github.com/repos/pyload/pyload/releases/5102924",
                        "Warn: release artifact v0.4.20 does not have provenance: https://api.github.com/repos/pyload/pyload/releases/23856648",
                        "Warn: release artifact v0.4.9 does not have provenance: https://api.github.com/repos/pyload/pyload/releases/65198",
                        "Warn: release artifact v0.4.8 does not have provenance: https://api.github.com/repos/pyload/pyload/releases/65895",
                        "Warn: release artifact v0.4.7 does not have provenance: https://api.github.com/repos/pyload/pyload/releases/5102921",
                        "Warn: release artifact v0.4.6 does not have provenance: https://api.github.com/repos/pyload/pyload/releases/5102924"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/build & deploy.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/lint & test.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/no-response.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/pyload/pyload/contents/SECURITY.md",
        "SecurityPolicy_content": "<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/pyload/pyload/main/media/logo.png\" alt=\"pyLoad\" height=\"100\" />\n</p>\n\n## Security Policy\n\n### Supported Versions\n\npyLoad Next releases will receive security vulnerabilities patches.\nOld versions of pyLoad, working on Python 2, will receive plugin updates only.\n\n### Reporting a Vulnerability\n\nPlease report any security vulnerabilities by sending an email to security@pyload.net.\n\nYou will receive a response from us within a short time.\nIf the issue is confirmed, we will release a patch as soon as possible depending on complexity.\n\n<br />\n\n---\n\n######  2008-2024 pyLoad team\n",
        "project_all_labels": [
            "account wanted",
            "API change",
            "bug",
            "checking",
            "documentation",
            "duplicate",
            "enhancement",
            "feature request",
            "feedback wanted",
            "help wanted",
            "invalid",
            "Linux",
            "MacOS",
            "outdated",
            "pinned",
            "plugin bug",
            "plugin enhancement",
            "plugin request",
            "pyLoad Next",
            "pyLoad Stable",
            "question",
            "Windows",
            "wontfix"
        ],
        "README_content": "<br />\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/pyload/pyload/main/media/banner.png\" alt=\"pyLoad\" height=\"110\" />\n</p>\n<h2 align=\"center\">The free and open-source Download Manager written in pure Python</h2>\n<h4 align=\"center\">\n  <img alt=\"status\" src=\"https://img.shields.io/pypi/status/pyload-ng?style=flat-square\">\n  <a href=\"https://github.com/pyload/pyload/actions\">\n    <img alt=\"build\" src=\"https://img.shields.io/github/actions/workflow/status/pyload/pyload/test.yml?event=push&style=flat-square\">\n  </a>\n  <a href=\"https://www.codacy.com/gh/pyload/pyload\">\n    <img alt=\"codacy\" src=\"https://img.shields.io/codacy/grade/1d047f77c0a6496eb708e1b3ca83006b?label=grade&style=flat-square\">\n  </a>\n  <img alt=\"python\" src=\"https://img.shields.io/pypi/pyversions/pyload-ng?style=flat-square\">\n  <a href=\"https://pypi.python.org/pypi/pyload-ng\">\n    <img alt=\"pypi\" src=\"https://img.shields.io/pypi/v/pyload-ng?style=flat-square\">\n  </a>\n  <a href=\"https://pyup.io/repos/github/pyload/pyload\">\n    <img alt=\"pyup\" src=\"https://pyup.io/repos/github/pyload/pyload/shield.svg\">\n  </a>\n</h4>\n\n<br />\n<br />\n\n## Choose your Version\n\n**The newest version of pyLoad** running on Python 3.6+ and PyPy (experimental) is developed in the [main branch on GitHub](https://github.com/pyload/pyload/tree/main) and published as [pyload-ng on PyPI](https://pypi.org/project/pyload-ng/).\n\n**The old version of pyLoad** working on Python 2 is still available in the [stable branch on GitHub](https://github.com/pyload/pyload/tree/stable), pre-built packages are available for download on the [releases page on GitHub](https://github.com/pyload/pyload/releases).\n\nThis README covers only the latest version of pyLoad.\n\n## Quick Start\n\nOpen a terminal window and install pyLoad typing:\n\n    pip install --pre pyload-ng[all]\n\nTo start pyLoad use the command:\n\n    pyload\n\nSee the [usage section](#usage) for information on all available options.\n\nIf you want to uninstall pyLoad:\n\n    pip uninstall pyload-ng\n\n## Usage\n\n    usage: pyload [-h] [-d] [-r] [--storagedir STORAGEDIR] [--userdir USERDIR]\n                  [--tempdir TEMPDIR] [--dry-run] [--daemon] [--version]\n\n    The free and open-source Download Manager written in pure Python\n\n    optional arguments:\n      -h, --help                    show this help message and exit\n      -d, --debug                   enable debug mode\n      -r, --reset                   reset default username/password\n      --storagedir STORAGEDIR       use this location to save downloads\n      --userdir USERDIR             use this location to store user data files\n      --tempdir TEMPDIR             use this location to store temporary files\n      --dry-run                     test start-up and exit\n      --daemon                      run as daemon\n      --version                     show program's version number and exit\n\nTo start pyLoad, type the command:\n\n    pyload\n\nThis will create the following directories (if they don't exist already):\n\n-   `~/Downloads/pyLoad`: where downloads will be saved.\n-   `~/.pyload`: where user data and configuration files are stored.\n-   `<TMPDIR>/pyLoad`: where temporary files are stored. `<TMPDIR>` is [platform-specific](https://docs.python.org/3/library/tempfile.html#tempfile.gettempdir).\n\n> **Note**:\n> On Windows, user data and configuration files are stored in the directory `~\\AppData\\Roaming\\pyLoad`.\n\n### Help\n\nTo show an overview of the available options, type:\n\n    pyload --help\n\n### Web Interface\n\nOpen your web browser and visit the url http://localhost:8000 to have access to\nthe pyLoad's web interface.\n\n-   Default username: `pyload`.\n-   Default password: `pyload`.\n\n**It's highly recommended to change the default access credentials on first start**.\n\n## Advanced Installation\n\n### Stable Release\n\nGet the latest stable release of pyLoad:\n\n    pip install pyload-ng\n\n> **Note**:\n> No stable release yet, pyLoad is now in pre-release phase.\n\n#### Available modules\n\n-   `pyload.core`: pyLoad's heart.\n-   `pyload.plugins`: the collection of officially supported plugins for pyLoad.\n-   `pyload.webui`: a web interface to interact with pyLoad.\n\n### Development Release\n\nYou can force the installation of the latest development release of pyLoad,\nappending the option `--pre` to the installation command:\n\n    pip install --pre pyload-ng\n\n**Do not use development releases in production**. Unexpected crashes may occur.\n\n### Extra Dependencies\n\nExtra dependencies are non-essential packages that enable additional features of pyLoad.\n\nTo install them you have to append a specific tag name to the installation command.\n\n#### Available tags\n\n-   `plugins`: includes packages used by several plugins.\n-   `build`: includes packages used to [build translations](#build-translations).\n-   `all`: includes both plugins and build packages.\n\nYou can use a tag in this way:\n\n    pip install pyload-ng[plugins]\n\nOr group more together:\n\n    pip install pyload-ng[plugins][build]\n\n### Build Translations\n\nUse the command `build_locale` to retrieve and build the latest locale files (translations):\n\n    python setup.py build_locale\n\nInvoke `build_locale` before building the package (eg. `bdist_wheel`).\n\n> **Note**:\n>\n> You don't need to build the translations if you installed pyLoad through `pip`, they're already included.\n\n## Report a Vulnerability\n\nPlease refer to [SECURITY](https://github.com/pyload/pyload/blob/main/SECURITY.md) to read our security policy.\n\n## Contribute to pyLoad\n\nPlease refer to [CONTRIBUTING](https://github.com/pyload/pyload/blob/main/CONTRIBUTING.md) to read our contribution guidelines.\n\n## Docker Images\n\n[![Docker build status](https://img.shields.io/docker/build/pyload/pyload?style=flat-square)](https://hub.docker.com/r/pyload/pyload)\n[![MicroBadger layers](https://img.shields.io/microbadger/layers/pyload/pyload?style=flat-square)](https://microbadger.com/images/pyload/pyload)\n[![MicroBadger size](https://img.shields.io/microbadger/image-size/pyload/pyload?style=flat-square)](https://microbadger.com/images/pyload/pyload)\n\n#### Available images\n\n-   `pyload/pyload:alpine`: docker image for amd64, arm and arm64v8.\n-   `pyload/pyload:ubuntu-arm32v7`: docker image for arm32v7.\n-   `pyload/pyload`: alias of `pyload/pyload:alpine`.\n\n### Create Container\n\n    docker create --name=pyload -v <USERDIR>:/config -v <STORAGEDIR>:/downloads --restart unless-stopped pyload/pyload\n\n> **Note**:\n>\n> Replace `<STORAGEDIR>` with the location on the host machine where you want that downloads will be saved.\n>\n> Replace `<USERDIR>` with where you want that user data files (configurations) are stored.\n\n### Start Container\n\n    docker start pyload\n\n### Stop Container\n\n    docker stop pyload\n\n### Show Logs\n\n    docker logs -f pyload\n\n### Docker Compose\n\nCompatible with `docker-compose` v2 schemas:\n\n    ---\n    version: '2'\n    services:\n      pyload:\n        image: pyload\n        build: <REPODIR>\n        container_name: pyload\n        environment:\n          - PUID=1000\n          - PGID=1000\n          - TZ=Europe/London\n        volumes:\n          - <USERDIR>:/config\n          - <STORAGEDIR>:/downloads\n        ports:\n          - 8000:8000 # Webinterface\n          - 9666:9666 # Click 'N' Load\n        restart: unless-stopped\n\n> **Note**:\n>\n> Replace `<REPODIR>` with the location on the host machine where you have checked out the pyload repository.\n>\n> Replace `<STORAGEDIR>` with the location on the host machine where you want that downloads will be saved.\n>\n> Replace `<USERDIR>` with where you want that user data files (configurations) are stored.\n\n## Troubleshooting\n\n### pip not found\n\nRetry replacing the command `pip` with `pip3`:\n\n    pip3 install pyload-ng\n\nIf fails again, you may not have the Python interpreter\nor the pip package manager installed on your system.\n\nTry reinstalling Python to fix this issue.\n\nVisit https://www.python.org/downloads\nto get the proper **Python 3** release for your system.\n\n### pyload-ng not found\n\nCheck the version of the Python interpreters installed on your system.\n\nTo show the version of your **default** Python interpreter, type the command:\n\n    python --version\n\nIf the version is too old, try to upgrage Python, then you can retry to install pyLoad.\n\nPython releases below version 3.6 are not supported!\n\n### Setuptools is too old\n\nTo upgrade the `setuptools` package, type the command:\n\n    pip install --upgrade setuptools\n\n### Permission denied\n\nUnder Unix-based systems, try to install pyLoad with root privileges.\n\nPrefix the installation/uninstallation command with `sudo`:\n\n    sudo pip install pyload-ng\n    sudo pip uninstall pyload-ng\n\nUnder Windows systems, open a _Command Prompt as administrator_ to install pyLoad\nwith root privileges.\n\nYou can also try to install the `pyload-ng` package **without** root privileges.\n\nAppend the option `--user` to the installation command:\n\n    pip install --user pyload-ng\n\n## Licensing\n\n[![license](https://img.shields.io/pypi/l/pyload-ng?style=flat-square)](https://github.com/pyload/pyload/blob/main/LICENSE.md)\n[![cla](https://cla-assistant.io/readme/badge/pyload/pyload)](https://cla-assistant.io/pyload/pyload)\n\n### Open Source License\n\nYou are allowed to use this software under the terms of the **GNU Affero\nGeneral Public License** as published by the Free Software Foundation;\neither **version 3** of the License, or (at your option) any later version.\n\nPlease refer to [LICENSE](https://github.com/pyload/pyload/blob/main/LICENSE.md) to read the project license.\n\n### Alternative License\n\nWith an explicit permission of the **pyLoad team** you may use or distribute\nthis software under a different license according to the agreement.\n\n### Contributor License Agreement\n\nPlease refer to [CLA](https://cla-assistant.io/pyload/pyload) for the full agreement conditions.\n\nThis is essentially what you will be agreeing to:\n\n-   You claim to have the right to make the contribution\n    (i.e. it's your own work).\n-   You grant the project a perpetual, non-exclusive license to use the\n    contribution.\n-   You grant the project rights to change the outbound license that we use to\n    distribute the code.\n-   You retain full ownership (copyright) of your submission and are free to do\n    with it as you please.\n\nContact us at licensing@pyload.net for any question about the pyLoad licensing policy.\n\n## Credits\n\nPlease refer to [AUTHORS](https://github.com/pyload/pyload/blob/main/AUTHORS.md) to know a bit more about the people behind pyLoad.\n\n<br />\n\n---\n\n######  2008-2024 pyLoad team\n",
        "num_commits": 7851,
        "project_age_days": 4279,
        "project_created_at": "2013-02-10",
        "latest_updated_at": "2024-10-27",
        "latest_pushed_at": "2024-10-26",
        "num_contributors": 162,
        "num_pull": 1253,
        "num_issues": 4451,
        "num_opening_issue": 211,
        "project_size(kB)": 49347,
        "num_stargazers": 3317,
        "num_watchers": 3317,
        "num_forks": 711,
        "num_subscribers": 130,
        "SecurityPolicy_created_at": "2021-09-21 23:03:08",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "bc7e50b3c900def9f5e867a12128b022d9691cd4",
                "url": "https://github.com/pyload/pyload/commit/bc7e50b3c900def9f5e867a12128b022d9691cd4",
                "date": "2024-01-14 20:18:57"
            },
            {
                "commit_id": "8b6aec3aa90f347066262f83f21e32f96ab81e8e",
                "url": "https://github.com/pyload/pyload/commit/8b6aec3aa90f347066262f83f21e32f96ab81e8e",
                "date": "2023-01-04 23:06:46"
            },
            {
                "commit_id": "982fb3b29e4fe255536d44874b4493e10ba01ce3",
                "url": "https://github.com/pyload/pyload/commit/982fb3b29e4fe255536d44874b4493e10ba01ce3",
                "date": "2022-01-04 00:06:08"
            },
            {
                "commit_id": "f59c884a785c63774192415d840924d03927df12",
                "url": "https://github.com/pyload/pyload/commit/f59c884a785c63774192415d840924d03927df12",
                "date": "2021-10-09 17:49:38"
            },
            {
                "commit_id": "fbd9d7d7cbc05a9efa8e6eb9eb0bf1dea10137ef",
                "url": "https://github.com/pyload/pyload/commit/fbd9d7d7cbc05a9efa8e6eb9eb0bf1dea10137ef",
                "date": "2021-09-21 23:03:08"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism",
            "Additional information"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "jamestheawesomedude/pypqc",
        "project_url": "https://github.com/jamestheawesomedude/pypqc",
        "SSF": {
            "date": "2024-10-29T20:49:59+07:00",
            "repo": {
                "name": "github.com/jamestheawesomedude/pypqc",
                "commit": "b9067fe29e816b7b9e2021dadb10180125b83d84"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 3.9,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'master'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no pull request found",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 0/30 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: PQClean contributor org/company found, one9.is/enough contributor org/company found, kemtls contributor org/company found, pqshield contributor org/company found, IACR contributor org/company found, university of waterloo contributor org/company found, quantum-safe migration center chelpis quantum tech contributor org/company found, mozilla contributor org/company found, open-quantum-safe contributor org/company found, rustpq contributor org/company found, post-quantum-cryptography contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 11 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: COPYING.rst:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "0 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 0",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python_build.yaml:10: update your workflow using https://app.stepsecurity.io/secureworkflow/James-E-A/pypqc/python_build.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python_build.yaml:11: update your workflow using https://app.stepsecurity.io/secureworkflow/James-E-A/pypqc/python_build.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python_build.yaml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/James-E-A/pypqc/python_build.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python_build.yaml:57: update your workflow using https://app.stepsecurity.io/secureworkflow/James-E-A/pypqc/python_build.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python_build.yaml:63: update your workflow using https://app.stepsecurity.io/secureworkflow/James-E-A/pypqc/python_build.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python_build.yaml:66: update your workflow using https://app.stepsecurity.io/secureworkflow/James-E-A/pypqc/python_build.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python_build.yaml:91: update your workflow using https://app.stepsecurity.io/secureworkflow/James-E-A/pypqc/python_build.yaml/master?enable=pin",
                        "Info:   0 out of   6 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: no pull requests merged into dev branch"
                    ],
                    "score": 0,
                    "reason": "no SAST tool detected",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/python_build.yaml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/jamestheawesomedude/pypqc/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\n* 0.7.X\n\n## Reporting a Vulnerability\n\n### Vulnerabilities in the implementations\n\nFirst, check to see if our upstream, PQClean, has issued any updates, and open a\nticket with them if necessary according to their policy:\nhttps://github.com/PQClean/PQClean/security/policy\n\nIf they claim no patch is available, you may have to escalate to the creators/implementors:\n\n* Classic McEliece: https://classic.mceliece.org/nist/mceliece-submission-20221023.pdf#:~:text=E%2Dmail%20address,%2Eyp%2Eto\n\n* Kyber: https://github.com/pq-crystals/kyber/issues?q=security\n\n* HQC: https://pqc-hqc.org/contact.html\n\n* SPHINCS+: https://github.com/sphincs/sphincsplus/issues?q=security\n\n* Dilithium: https://github.com/pq-crystals/dilithium/issues?q=security\n\n* Falcon: https://falcon-sign.info/falcon.pdf#:~:text=Zhang-,falcon,ens%2Efr\n\nIf upstream has already issued an update, but we have not included it,\nplease open a ticket on our issue tracker about that.\n\nIf you want this process to occur faster, contributions are currently being sought\nvia [ticket #19](https://github.com/JamesTheAwesomeDude/pypqc/issues/19) on our\nissue tracker.\n\n### Security flaws in the actual algorithms\n\nFirst, check to see if the flaw has already been publicly disclosed:\nhttps://csrc.nist.gov/Projects/post-quantum-cryptography/email-list\n\nIf the flaw has already been reported on, please proceed with the \"Vulnerabilities\nin the implementations\" process above.\n\nIf the flaw has **not** been reported on yet:\n\n- For algorithms which have **not** been standardized yet, please publish your\nfindings on that mailing list.\n\n- For algorithms which **have** been standardized already (see the NIST page on\n[Post-Quantum Cryptography Standardization](https://csrc.nist.gov/Projects/post-quantum-cryptography/Post-Quantum-Cryptography-Standardization)\nfor the current list), please contact the algorithm's creators/implementors directly\nas soon as possible.\n\n### Vulnerabilities in the bindings\n\nIf the vulnerability is *not* with the implementation, or with the actual algorithms,\nbut with our Python bindings, please open a ticket on our issue tracker about that.\n\n## Reporting a Supply-Chain Compromise\n\nIf you suspect some element of the supply chain has been compromised\n(e.g. pypqc has merged fake commits, or the PyPI project page has been\ncompromised, etc.), please e-mail james{{dot}}edington{{?}}uah.edu ASAP.\n",
        "project_all_labels": [
            "bug",
            "documentation",
            "duplicate",
            "enhancement",
            "good first issue",
            "help wanted",
            "invalid",
            "question",
            "wontfix"
        ],
        "README_content": "Usage\n=====\n\nSimply install from PyPI with ``pip install pypqc``, or see \"Development\" below\nif you want to tinker on the codebase!\n\nKEMs\n----\n\nMcEliece, Kyber, and HQC are currently provided, all with the same interface.::\n\n    # Available: hqc_128, hqc_192, hqc_256,\n    # kyber512, kyber768, kyber1024,\n    # mceliece348864, mceliece460896,\n    # mceliece6688128, mceliece6960119, mceliece8192128\n    from pqc.kem import mceliece6960119 as kemalg\n    \n    \n    # 1. Keypair generation\n    pk, sk = kemalg.keypair()\n    \n    \n    # 2. Key encapsulation\n    ss, kem_ct = kemalg.encap(pk)\n    \n    \n    # 3. Key de-encapsulation\n    ss_result = kemalg.decap(kem_ct, sk)\n    assert ss_result == ss\n\nCapabilities *not* included in PQClean, such as `McEliece signatures`_,\n`Hybrid Encryption`_ or `KEM-TRANS`_, and `message encapsulation`_, are\n*not* going to be implemented in this library. (Exception: `Plaintext\nConfirmation <https://www.github.com/thomwiggers/mceliece-clean/issues/3>`_\nis on the agenda for inclusion even if upstream ultimately decides to exclude\nit.)\n\nSignature Algorithms\n--------------------\n\nSPHINCS+, Dilithium, and Falcon are provided, all with the same interface.::\n\n    # Available: dilithium2, dilithium3, dilithium5,\n    # falcon_512, falcon_padded_512, falcon_1024, falcon_padded_1024,\n    # sphincs_sha2_128f_simple, sphincs_sha2_128s_simple,\n    # sphincs_shake_128f_simple, sphincs_shake_128s_simple,\n    # sphincs_sha2_192f_simple, sphincs_sha2_192s_simple,\n    # sphincs_shake_192f_simple, sphincs_shake_192s_simple,\n    # sphincs_sha2_256f_simple, sphincs_sha2_256s_simple,\n    # sphincs_shake_256f_simple, sphincs_shake_256s_simple\n    from pqc.sign import sphincs_shake_256s_simple as sigalg\n    \n    \n    # 1. Keypair generation\n    pk, sk = sigalg.keypair()\n    \n    \n    # 2. Signing\n    # (detached signature)\n    sig = sigalg.sign(MY_MESSAGE, sk)\n    \n    \n    # 3. Signature verification\n    # (Returns None on success; raises ValueError on failure.)\n    sigalg.verify(sig, MY_MESSAGE, pk)\n\nRegarding SPHINCS+: the Simple version is included; the Robust version is is not;\nSHA256 and SHAKE256 are included; Haraka is not. See https://github.com/PQClean/PQClean/discussions/548#discussioncomment-8565116\nfor more information.\n\nRegarding Falcon: the Compressed and Padded versions are included, and are able to\n``verify()`` each others' signatures. The CT version is not currently planned.\n\nDevelopment\n===========\n\nDependencies:\n-------------\n\n- Python 3 (tested mainly on CPython 3.9, 3.10, 3.11, and 3.12; and on PyPy\n  7.3.12)\n\n- cffi_\n\n  - Transitive non-PyPI build-time dependency: `Python Headers`_ (only Linux users\n    need to manually install these; they come OOtB on Windows. Not sure about Mac.)\n\n- setuptools_ (build-time dependency)\n\n- wheel_ (build-time dependency)\n\n- a C compiler (build-time dependency)\n\n  - If you're on Windows, https://visualstudio.microsoft.com/visual-cpp-build-tools/\n\n    - If setuptools is having trouble finding your compiler, make sure to\n      first enter the appropriate environment. (For AMD64, this will be\n      \"x64 Native Tools Command Prompt for VS 2022\"; for 32-bit x86, this\n      will be \"Developer Command Prompt for VS 2022\"; for other situations,\n      see `the documentation <https://learn.microsoft.com/en-us/cpp/build/building-on-the-command-line?view=msvc-170>`_.)\n\n  - If you're on Mac,\n    `reportedly Homebrew is a good choice <https://cffi.readthedocs.io/en/latest/installation.html#macos-x>`_.\n\n    - It looks like you will also need ``pkgconfig`` and ``libffi``, ideally\n      installed via Homebrew, to build this.\n\n  - If you're on Linux, install build-essential_ or `'Development Tools'`_ or\n    something like that.\n\n  - (I haven't tested it, but if you're allergic to installing things outside\n    the venv you might be able to use\n    `this C compiler <https://pypi.org/project/ziglang/>`_...)\n\nGetting started:\n----------------\n\n0. Maybe `use a venv <https://www.bitecode.dev/p/relieving-your-python-packaging-pain>`_\n   or whatever if you want to\n\n   - for Windows: ``py -m venv .venv & .venv\\Scripts\\activate.bat``\n\n   - for Linux and Mac: ``python3 -m venv .venv; . .venv/bin/activate``\n     (first `install it <https://packages.ubuntu.com/jammy/python/python3-venv>`_,\n     if needed)\n\n1. Run ``python -m pip install .``\n\n   - Alternatively: you may get cleaner building with ``python -m build .``\n     (only after ``python -m pip install build``)\n\n   - Editable / \"develop\" mode not supported currently (CFFI will have to\n     `support this <https://setuptools.pypa.io/en/latest/userguide/extension.html#setuptools.command.build.SubCommand.editable_mode>`_\n     before it's even on the table.)\n\n     - If you get error 1104 when trying to compile, make a folder ``C:\\temp``, then try ``set \"TMPDIR=C:\\temp\"`` and try again. (https://discuss.python.org/t/-/44077/5)\n\n2. Run ``python -m pqc.demo`` to test it. If it prints \"OK\" and exits, the\n   functions are almost certainly not broken. (Ideally, run this from a\n   DIFFERENT directory, such as your home folder, so you can be sure it's\n   being imported properly and not being masked by the local copy.)\n\n   - N.B. / FIXME: this function is currently NOT a full test suite;\n     it only does a single encap-decap cycle with\n     the default implementation of mceliece6960119.\n     It does NOT test any other version of McEliece,\n     or any signature algorithm.\n\n\n.. _cffi: https://cffi.readthedocs.io/en/release-1.16/\n.. _wheel: https://wheel.readthedocs.io/\n.. _setuptools: https://setuptools.pypa.io/en/stable/\n.. _`Python Headers`: https://packages.ubuntu.com/jammy/python3-dev\n.. _build-essential: https://packages.ubuntu.com/jammy/build-essential\n.. _`'Development Tools'`: https://git.rockylinux.org/rocky/comps/-/blob/e6c8f29a7686326a731ea72b6caa06dabc7801b5/comps-rocky-9-lh.xml#L2169\n\n.. _`McEliece Signatures`: https://inria.hal.science/inria-00072511\n.. _`Hybrid Encryption`: https://en.wikipedia.org/wiki/Hybrid_encryption\n.. _`KEM-TRANS`: https://www.ietf.org/staging/draft-prat-perret-lamps-cms-pq-kem-00.html\n.. _`message encapsulation`: https://en.wikipedia.org/wiki/Cryptographic_Message_Syntax\n",
        "num_commits": 1542,
        "project_age_days": 383,
        "project_created_at": "2023-10-12",
        "latest_updated_at": "2024-06-25",
        "latest_pushed_at": "2024-10-01",
        "num_contributors": 25,
        "num_pull": 2,
        "num_issues": 23,
        "num_opening_issue": 16,
        "project_size(kB)": 7644,
        "num_stargazers": 0,
        "num_watchers": 0,
        "num_forks": 1,
        "num_subscribers": 1,
        "SecurityPolicy_created_at": "2024-02-16 02:07:51",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "817dfa7fbaa7cc68965890a83e1a9becdc187647",
                "url": "https://github.com/James-E-A/pypqc/commit/817dfa7fbaa7cc68965890a83e1a9becdc187647",
                "date": "2024-02-28 20:28:15"
            },
            {
                "commit_id": "bc462668365a0d008d821955a28f61ec6d3ca13c",
                "url": "https://github.com/James-E-A/pypqc/commit/bc462668365a0d008d821955a28f61ec6d3ca13c",
                "date": "2024-02-16 02:10:44"
            },
            {
                "commit_id": "56ebb9041d463278274d6cd8a0688c2e891486fd",
                "url": "https://github.com/James-E-A/pypqc/commit/56ebb9041d463278274d6cd8a0688c2e891486fd",
                "date": "2024-02-16 02:09:18"
            },
            {
                "commit_id": "3b23af5cc6e9eca80798940675a5bcf79284ba9f",
                "url": "https://github.com/James-E-A/pypqc/commit/3b23af5cc6e9eca80798940675a5bcf79284ba9f",
                "date": "2024-02-16 02:07:51"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism",
            "Projects practice",
            "Reporting mechanism",
            "Reporting mechanism",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "vantage6/vantage6",
        "project_url": "https://github.com/vantage6/vantage6",
        "SSF": {
            "date": "2024-10-29T20:51:15+07:00",
            "repo": {
                "name": "github.com/vantage6/vantage6",
                "commit": "24a76a581354308f57b98dafc22c0a193d967151"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.6,
            "checks": [
                {
                    "details": [
                        "Warn: binary detected: docs/java/plantuml.jar:1"
                    ],
                    "score": 9,
                    "reason": "binaries present in source code",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: required approving review count is 1 on branch 'main'",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Info: status check found to merge onto on branch 'main'",
                        "Info: PRs are required in order to make changes on branch 'main'"
                    ],
                    "score": 8,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "13 out of 13 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 8,
                    "reason": "Found 11/13 approved changesets -- score normalized to 8",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: the netherlands escience center contributor org/company found, iknl @vantage6 contributor org/company found, iknl (netherlands comprehensive cancer organization) contributor org/company found, PDSW-ECI contributor org/company found, COSW-ECI contributor org/company found, MyDigiTwinNL contributor org/company found, IKNL contributor org/company found, netherlands escience center contributor org/company found, iknl contributor org/company found, NLeSC contributor org/company found, maastrichtu-biss and @maastrichtu-cds contributor org/company found, ARSW-ECI-archive contributor org/company found, ECI-Robotics contributor org/company found, vantage6 contributor org/company found, elastique contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 15 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: :0"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 8 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/release.yml:252"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/code-style.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/code-style.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/code-style.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/code-style.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:59: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:72: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:50: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:64: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:124: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release.yml:128: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:148: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release.yml:155: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release.yml:159: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:392: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:184: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release.yml:191: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release.yml:195: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:231: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release.yml:238: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release.yml:242: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:352: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:357: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/unit_tests.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/unit_tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/unit_tests.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/unit_tests.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/unit_tests.yml:42: update your workflow using https://app.stepsecurity.io/secureworkflow/vantage6/vantage6/unit_tests.yml/main?enable=pin",
                        "Warn: containerImage not pinned by hash: docker/algorithm-base.Dockerfile:1: pin your Docker image by updating python:3.10-slim-bullseye to python:3.10-slim-bullseye@sha256:2674abed3e7ffff21501d1a5ca773920c2ed6d2087a871fd07799ff029c909c2",
                        "Warn: containerImage not pinned by hash: docker/algorithm-ohdsi-base.Dockerfile:7",
                        "Warn: containerImage not pinned by hash: docker/algorithm-store.Dockerfile:9",
                        "Warn: containerImage not pinned by hash: docker/alpine.Dockerfile:2",
                        "Warn: containerImage not pinned by hash: docker/infrastructure-base.Dockerfile:1: pin your Docker image by updating python:3.10-slim-buster to python:3.10-slim-buster@sha256:37aa274c2d001f09b14828450d903c55f821c90f225fdfdd80c5180fcca77b3f",
                        "Warn: containerImage not pinned by hash: docker/node-and-server.Dockerfile:10",
                        "Warn: containerImage not pinned by hash: docker/squid.Dockerfile:1: pin your Docker image by updating debian:10 to debian:10@sha256:58ce6f1271ae1c8a2006ff7d3e54e9874d839f573d8009c20154ad0f2fb0a225",
                        "Warn: containerImage not pinned by hash: docker/ssh-tunnel.Dockerfile:1: pin your Docker image by updating debian:10 to debian:10@sha256:58ce6f1271ae1c8a2006ff7d3e54e9874d839f573d8009c20154ad0f2fb0a225",
                        "Warn: containerImage not pinned by hash: docker/ui.Dockerfile:3",
                        "Warn: containerImage not pinned by hash: docker/ui.Dockerfile:15: pin your Docker image by updating nginx:alpine to nginx:alpine@sha256:2140dad235c130ac861018a4e13a6bc8aea3a35f3a40e20c1b060d51a7efd250",
                        "Warn: containerImage not pinned by hash: docker/vpn-client.Dockerfile:2",
                        "Warn: containerImage not pinned by hash: docker/vpn-configurator.Dockerfile:1: pin your Docker image by updating ubuntu:22.04 to ubuntu:22.04@sha256:0e5e4a57c2499249aafc3b40fcd541e9a456aab7296681a3994d631587203f97",
                        "Warn: pipCommand not pinned by hash: docker/algorithm-base.Dockerfile:12",
                        "Warn: pipCommand not pinned by hash: docker/algorithm-base.Dockerfile:13",
                        "Warn: pipCommand not pinned by hash: docker/algorithm-base.Dockerfile:14",
                        "Warn: pipCommand not pinned by hash: docker/algorithm-ohdsi-base.Dockerfile:44",
                        "Warn: pipCommand not pinned by hash: docker/algorithm-ohdsi-base.Dockerfile:45",
                        "Warn: pipCommand not pinned by hash: docker/algorithm-ohdsi-base.Dockerfile:46",
                        "Warn: pipCommand not pinned by hash: docker/algorithm-ohdsi-base.Dockerfile:47",
                        "Warn: pipCommand not pinned by hash: docker/algorithm-ohdsi-base.Dockerfile:48",
                        "Warn: pipCommand not pinned by hash: docker/algorithm-ohdsi-base.Dockerfile:50",
                        "Warn: pipCommand not pinned by hash: docker/algorithm-store.Dockerfile:19",
                        "Warn: pipCommand not pinned by hash: docker/algorithm-store.Dockerfile:26",
                        "Warn: pipCommand not pinned by hash: docker/algorithm-store.Dockerfile:27",
                        "Warn: pipCommand not pinned by hash: docker/algorithm-store.Dockerfile:28",
                        "Warn: pipCommand not pinned by hash: docker/algorithm-store.Dockerfile:29",
                        "Warn: pipCommand not pinned by hash: docker/algorithm-store.Dockerfile:30",
                        "Warn: pipCommand not pinned by hash: docker/algorithm-store.Dockerfile:36-39",
                        "Warn: pipCommand not pinned by hash: docker/infrastructure-base.Dockerfile:15-16",
                        "Warn: pipCommand not pinned by hash: docker/node-and-server.Dockerfile:21",
                        "Warn: pipCommand not pinned by hash: docker/node-and-server.Dockerfile:26",
                        "Warn: pipCommand not pinned by hash: docker/node-and-server.Dockerfile:33-34",
                        "Warn: pipCommand not pinned by hash: docker/node-and-server.Dockerfile:37",
                        "Warn: pipCommand not pinned by hash: docker/node-and-server.Dockerfile:38",
                        "Warn: pipCommand not pinned by hash: docker/node-and-server.Dockerfile:39",
                        "Warn: pipCommand not pinned by hash: docker/node-and-server.Dockerfile:40",
                        "Warn: pipCommand not pinned by hash: docker/node-and-server.Dockerfile:41",
                        "Warn: pipCommand not pinned by hash: docker/node-and-server.Dockerfile:42",
                        "Warn: pipCommand not pinned by hash: docker/node-and-server.Dockerfile:43",
                        "Warn: pipCommand not pinned by hash: docker/node-and-server.Dockerfile:49-52",
                        "Warn: npmCommand not pinned by hash: docker/ui.Dockerfile:11",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release.yml:363",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release.yml:364",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release.yml:365",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release.yml:366",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release.yml:398",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release.yml:399",
                        "Warn: pipCommand not pinned by hash: .github/workflows/unit_tests.yml:25",
                        "Warn: pipCommand not pinned by hash: .github/workflows/unit_tests.yml:26",
                        "Warn: pipCommand not pinned by hash: .github/workflows/unit_tests.yml:29",
                        "Info:   0 out of  17 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of  10 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of  37 pipCommand dependencies pinned",
                        "Info:   0 out of   1 npmCommand dependencies pinned",
                        "Info:   0 out of  12 containerImage dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Warn: 6 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 7,
                    "reason": "SAST tool detected but not run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql-analysis.yml:28",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql-analysis.yml:29",
                        "Warn: no topLevel permission defined: .github/workflows/code-style.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/codeql-analysis.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/main.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/unit_tests.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-h4gh-qq45-vh27",
                        "Warn: Project is vulnerable to: GHSA-hxwh-jpp2-84pm / PYSEC-2024-71",
                        "Warn: Project is vulnerable to: GHSA-cx63-2mw6-8hw5",
                        "Warn: Project is vulnerable to: GHSA-f9vj-2wh5-fj8j",
                        "Warn: Project is vulnerable to: GHSA-q34m-jh98-gwm2",
                        "Warn: Project is vulnerable to: PYSEC-2023-117",
                        "Warn: Project is vulnerable to: GHSA-8hc4-vh64-cxmj",
                        "Warn: Project is vulnerable to: GHSA-qwcr-r2fm-qrc7",
                        "Warn: Project is vulnerable to: GHSA-pxg6-pf52-xh8x",
                        "Warn: Project is vulnerable to: GHSA-qw6h-vgh9-j6wx",
                        "Warn: Project is vulnerable to: GHSA-c7qv-q95q-8v27",
                        "Warn: Project is vulnerable to: GHSA-952p-6rrq-rcjv",
                        "Warn: Project is vulnerable to: GHSA-9wv6-86v2-598j",
                        "Warn: Project is vulnerable to: GHSA-gcx4-mw62-g8wm",
                        "Warn: Project is vulnerable to: GHSA-m6fv-jmcg-4jfg",
                        "Warn: Project is vulnerable to: GHSA-cm22-4g7w-348p",
                        "Warn: Project is vulnerable to: GHSA-4vvj-4cpr-p986 / GHSA-64vr-g452-qvp3",
                        "Warn: Project is vulnerable to: GHSA-9cwx-2883-4wfx"
                    ],
                    "score": 0,
                    "reason": "18 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/vantage6/vantage6/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\n| Version | Supported          |\n| ------- | ------------------ |\n| 4.x.x   | :white_check_mark: |\n| < 4.x.x | :x:                |\n\n## Reporting a Vulnerability\n\nPlease report (suspected) security vulnerabilities to vantage6@iknl.nl. You will receive a response from us within 72 hours.\nIf the issue is confirmed, we will release a patch as soon as possible. When the patched is released you will be informed.\n",
        "project_all_labels": [
            "bug",
            "change",
            "component:cli",
            "component:documentation",
            "component:store",
            "component:ui",
            "dependencies",
            "feature-request",
            "javascript",
            "New",
            "python",
            "status:new",
            "status:not-scheduled",
            "status:triage",
            "status:wontfix"
        ],
        "README_content": "<h1 align=\"center\">\n  <br>\n  <a href=\"https://vantage6.ai\"><img src=\"https://github.com/IKNL/guidelines/blob/master/resources/logos/vantage6.png?raw=true\" alt=\"vantage6\" width=\"350\"></a>\n</h1>\n\n<h3 align=center> A Privacy Enhancing Technology (PET) Operations platform</h3>\n<h3 align=\"center\">\n\n<!-- Badges go here-->\n\n[![Release](https://github.com/vantage6/vantage6/actions/workflows/release.yml/badge.svg)](https://github.com/vantage6/vantage6/actions/workflows/release.yml)\n[![PyPI vantage6](https://badge.fury.io/py/vantage6.svg)](https://badge.fury.io/py/vantage6)\n[![Unittests](https://github.com/vantage6/vantage6/actions/workflows/unit_tests.yml/badge.svg)](https://github.com/vantage6/vantage6/actions/workflows/unit_tests.yml)\n[![Coverage Status](https://coveralls.io/repos/github/vantage6/vantage6/badge.svg?branch=main)](https://coveralls.io/github/vantage6/vantage6?branch=main)\n[![Codacy Badge](https://app.codacy.com/project/badge/Grade/2e60ac3b3f284620805f7399cba317be)](https://app.codacy.com/gh/vantage6/vantage6/dashboard?utm_source=gh&utm_medium=referral&utm_content=&utm_campaign=Badge_grade)\n[![DOI](https://zenodo.org/badge/492818831.svg)](https://zenodo.org/badge/latestdoi/492818831)\n[![Discord](https://img.shields.io/discord/643526403207331841)](https://discord.gg/yAyFf6Y)\n[![Research software directory](https://img.shields.io/badge/rsd-vantage6-deepskyblue)](https://research-software-directory.org/software/vantage6)\n\n\n</h3>\n\n<p align=\"center\">\n  <a href=\"#books-quickstart\">Quickstart</a> \n  <a href=\"#project-structure\">Project structure</a> \n  <a href=\"#gift_heart-join-the-community\">Join the community</a> \n  <a href=\"#black_nib-references\">References</a>\n</p>\n\n---\n\nThis repository is contains all the **vantage6** infrastructure source code. The **vantage6** technology enables to manage and deploy privacy enhancing technologies like Federated Learning (FL) and Multi-Party Computation (MPC). Please visit our [website (vantage6.ai)](https://vantage6.ai) to learn more!\n\nYou can find more (user) documentation at [readthedocs (docs.vantage6.ai)](https://docs.vantage6.ai). If you have any questions, suggestions or just want to chat about federated learning: join our [Discord (https://discord.gg/yAyFf6Y)](https://discord.gg/yAyFf6Y) channel.\n\n## Infrastructure overview\n\n![Vantage6 architecture overview](docs/images/overview-infrastructure.png)\n\n_A High level overview of the vantage6 infrastructure. Vantage6 has both a\nclient-server and peer-to-peer architecture. The client is used by the researcher to\ncreate (PET) computation requests. It is also used to manage users, organizations and\ncollaborations. The server contains users, organizations, collaborations, tasks and\ntheir results. It provides a central access point for both the clients and nodes. The\nnodes have access to privacy sensitive data and handle computation requests retrieved\nfrom the server. Computation request are executed as separate containers on the node.\nThese containers are connected to containers at other nodes by a VPN network._\n\n## :books: Quickstart\n\n### Requirements\n\nThe **vantage6** infrastructure is delivered in Docker images. To run these images, you\nneed to have [Docker](https://docs.docker.com/get-docker/) installed. To install the\nlatest version of the vantage6 CLI, you need to have\n[Python](https://www.python.org/downloads/), we recommend using an environment manager\nlike [mini-conda](https://docs.conda.io/en/latest/miniconda.html).\n\nInstall the latest version of the vantage6 CLI by using:\n\n```bash\npip install vantage6\n```\n\nThis install the `v6` commands, which allows you to manage your nodes and servers. To view all available options, run:\n\n```bash\nv6 --help\n```\n\nFor example you can create a local test setup by using:\n\n```bash\nv6 dev create-demo-network\n```\n\nThis creates a local network with a server and two nodes. You can start the network by running:\n\n```bash\nv6 dev start-demo-network\n```\n\nThis will start the server and nodes in the background. You can view the logs by running:\n\n```bash\n# View node logs\nv6 node attach\n\n# View server logs\nv6 server attach\n```\n\nFrom here you can use the [vantage6-client](https://pypi.org/project/vantage6-client)\nto interact with the server. The demo network has a pre-configured organization with\nthe following credentials:\n\n- Username: `dev_admin`\n- Password: `password`\n\nFor example, you can create a new organization by running:\n\n```python\nfrom vantage6.client import Client\n\nclient = Client('http://127.0.0.1', 7601, '/api', log_level='debug')\nclient.authenticate('dev_admin', 'password')\nclient.setup_encryption(None)\n\nclient.organization.create(\n    name='My organization',\n    address1='My address',\n    address2='My address',\n    zipcode='1234AB',\n    country='The Netherlands',\n    domain='my-organization.com'\n)\n```\n\nYou can find more (user) documentation at\n[readthedocs (docs.vantage6.ai)](https://docs.vantage6.ai)\n\n## Project structure\n\n### PYPI packages\n\nThis repository is home to 6 PyPi packages:\n\n- [vantage6](https://pypi.org/project/vantage6) -> _CLI for managing node and server instances_\n- [vantage6-client](https://pypi.org/project/vantage6-client) -> _Python client for interacting with the vantage6-server_\n- [vantage6-algorithm-tools](https://pypi.org/project/vantage6-algorithm-tools) -> _Python tools to facilitate algorithm development_\n- [vantage6-node](https://pypi.org/project/vantage6-node) -> _Node application package_\n- [vantage6-server](https://pypi.org/project/vantage6-server) -> _Server application package_\n- [vantage6-algorithm-store](https://pypi.org/project/vantage6-algorithm-store) -> _Algorithm store application package_\n- [vantage6-common](https://pypi.org/project/vantage6-common) -> _Package with common vantage6 functions_\n- [vantage6-backend-common](https://pypi.org/project/vantage6-backend-common) -> _Package with functions common to central server and algorithm store_\n\n**Note that when using vantage6 you do not install the _server_ and _node_ packages. These are delivered to you in Docker images.**\n\nThis repository also hosts the code for the vantage6 user interface (UI). The UI\nis an Angular web application that can be used to interact with the vantage6 server\neasily.\n\n### Docker images\n\nThe vantage6 infrastructure is delivered in Docker images. All Docker images are stored\nin our private [Harbor](https://goharbor.io/) registry. The most important images are:\n\n- `harbor2.vantage6.ai/infrastructure/node:VERSION` -> _Node application Docker image_\n- `harbor2.vantage6.ai/infrastructure/server:VERSION` -> _Server application Docker image_\n- `harbor2.vantage6.ai/infrastructure/ui:VERSION` -> _User interface Docker image_\n- `harbor2.vantage6.ai/infrastructure/algorithm-store:VERSION` -> _Algorithm store Docker image_\n\nwith `VERSION` being the full semantic version of the vantage6 infrastructure, e.g.\n`4.0.0` or `4.1.0rc0`.\n\nSeveral other images are used to support the infrastructure:\n\n- `harbor2.vantage6.ai/infrastructure/infrastructure-base:VERSION` -> _Base image for the infrastructure_\n- `harbor2.vantage6.ai/infrastructure/squid:VERSION` -> _Squid proxy image used for the whitelisting service_\n- `harbor2.vantage6.ai/infrastructure/alpine` -> _Alpine image used for vpn traffic forwarding_\n- `harbor2.vantage6.ai/infrastructure/vpn-client` -> _VPN image used to connect to the VPN_\n- `harbor2.vantage6.ai/infrastructure/vpn-configurator` -> _VPN image used for initialization_\n- `harbor2.vantage6.ai/infrastructure/ssh-tunnel` -> _SSH tunnel image used for connecting algorithms to external services_\n\nAnd finally there are some images released for algorithm development:\n\n- `harbor2.vantage6.ai/infrastructure/algorithm-base:MAJOR.MINOR` -> _Base image for algorithm development_\n- `harbor2.vantage6.ai/infrastructure/algorithm-ohdsi-base:MAJOR.MINOR` -> _Extended algorithm base image for OHDSI algorithm development_\n\n## :gift_heart: Join the community!\n\nWe hope to continue developing, improving, and supporting **vantage6** with the help of\nthe federated learning community. If you are interested in contributing, first of all,\nthank you! Second, please take a look at our\n[contributing guidelines](https://docs.vantage6.ai/en/main/devops/contribute.html)\n\n<a href=\"https://github.com/vantage6/vantage6/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=vantage6/vantage6\" />\n</a>\n\n## :black_nib: References\n\nIf you are using **vantage6**, please cite this repository as well as the accompanying papers as follows:\n\n> - F. Martin, M. Sieswerda, H. Alradhi, et al. vantage6. Available at https://doi.org/10.5281/zenodo.7221216. Accessed on MONTH, 20XX.\n> - A. Moncada-Torres, F. Martin, M. Sieswerda, J. van Soest, G. Gelijnse. VANTAGE6: an open source priVAcy preserviNg federaTed leArninG infrastructurE for Secure Insight eXchange. AMIA Annual Symposium Proceedings, 2020, p. 870-877. [[BibTeX](https://arturomoncadatorres.com/bibtex/moncada-torres2020vantage6.txt), [PDF](https://vantage6.ai/vantage6/)]\n> - D. Smits\\*, B. van Beusekom\\*, F. Martin, L. Veen, G. Geleijnse, A. Moncada-Torres, An Improved Infrastructure for Privacy-Preserving Analysis of Patient Data, Proceedings of the International Conference of Informatics, Management, and Technology in Healthcare (ICIMTH), vol. 25, 2022, p. 144-147. [[BibTeX](https://arturomoncadatorres.com/bibtex/smits2022improved.txt), [PDF](https://ebooks.iospress.nl/volumearticle/60190)]\n\n---\n\n<p align=\"center\">\n  <a href=\"https://vantage6.ai\">vantage6.ai</a> \n  <a href=\"https://discord.gg/yAyFf6Y\">Discord</a> \n  <a href=\"https://vantage6.discourse.group/\">Discourse</a> \n  <a href=\"https://docs.vantage6.ai\">User documentation</a> \n</p>\n",
        "num_commits": 7077,
        "project_age_days": 897,
        "project_created_at": "2022-05-16",
        "latest_updated_at": "2024-10-01",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 18,
        "num_pull": 816,
        "num_issues": 1549,
        "num_opening_issue": 254,
        "project_size(kB)": 44316,
        "num_stargazers": 29,
        "num_watchers": 29,
        "num_forks": 11,
        "num_subscribers": 4,
        "SecurityPolicy_created_at": "2022-09-20 07:20:31",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "a66617aeb62dfc7c84b85c46c8f80267c3d489b1",
                "url": "https://github.com/vantage6/vantage6/commit/a66617aeb62dfc7c84b85c46c8f80267c3d489b1",
                "date": "2024-03-14 14:46:39"
            },
            {
                "commit_id": "dcffb145844360b07c54032a43c5c073426e8cd2",
                "url": "https://github.com/vantage6/vantage6/commit/dcffb145844360b07c54032a43c5c073426e8cd2",
                "date": "2023-09-11 15:30:13"
            },
            {
                "commit_id": "ab75ee5597eb7a1d2e256cbf4305924228909f48",
                "url": "https://github.com/vantage6/vantage6/commit/ab75ee5597eb7a1d2e256cbf4305924228909f48",
                "date": "2022-09-20 07:20:31"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "apache/arrow",
        "project_url": "https://github.com/apache/arrow",
        "SSF": {
            "date": "2024-10-29T21:47:59+07:00",
            "repo": {
                "name": "github.com/apache/arrow",
                "commit": "6c95dfa2771ad3462c3a4e7a9e74ab4409a79c92"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.6,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: branch 'main' does not require approvers",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Warn: no status checks found to merge onto branch 'main'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 out of 30 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 8,
                    "reason": "Found 19/23 approved changesets -- score normalized to 8",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: posit-pbc contributor org/company found, tomahawk-player contributor org/company found, lancedb contributor org/company found, arm contributor org/company found, openmensa contributor org/company found, PyCampES contributor org/company found, nteract contributor org/company found, apache contributor org/company found, daskos contributor org/company found, scikit-learn contributor org/company found, Toblerity contributor org/company found, nskicpp contributor org/company found, python-spain contributor org/company found, cmu apple contributor org/company found, groonga contributor org/company found, ruby-gnome contributor org/company found, ibis-project contributor org/company found, python contributor org/company found, conda-incubator contributor org/company found, frictionlessdata contributor org/company found, nroonga contributor org/company found, Quantco contributor org/company found, CornellCSWiki contributor org/company found, vega contributor org/company found, cmudig contributor org/company found, clear-code contributor org/company found, ruby contributor org/company found, conda-forge contributor org/company found, scientific-python contributor org/company found, CSE512-15S contributor org/company found, publicos-pt contributor org/company found, Optable contributor org/company found, ranguba contributor org/company found, datapad contributor org/company found, hubot-archive contributor org/company found, geopandas contributor org/company found, python-madrid contributor org/company found, substrait-io contributor org/company found, stadtlandcode contributor org/company found, cse512-19s contributor org/company found, rabbit-shocker contributor org/company found, logaling contributor org/company found, RubyData contributor org/company found, numpy contributor org/company found, uwdata contributor org/company found, crosstype contributor org/company found, tagshot contributor org/company found, anyscale contributor org/company found, taiyaki contributor org/company found, milter-manager contributor org/company found, test-unit contributor org/company found, datafusion-contrib contributor org/company found, pydata contributor org/company found, RoaringBitmap contributor org/company found, spacegraphcats contributor org/company found, MakingDataVisual contributor org/company found, hiki contributor org/company found, uim contributor org/company found, dask contributor org/company found, python-sprints contributor org/company found, data-apis contributor org/company found, Telefonica contributor org/company found, pgroonga contributor org/company found, llvm contributor org/company found, python-compilers-workshop contributor org/company found, CSE512-14W contributor org/company found, rr contributor org/company found, sympy contributor org/company found, EuroPython contributor org/company found, apple contributor org/company found, uwdb contributor org/company found, rurema contributor org/company found, oss-gate contributor org/company found, quantco contributor org/company found, mroonga contributor org/company found, pygeos contributor org/company found, OpenSourceCornell contributor org/company found, munin data aps contributor org/company found, tidyverse contributor org/company found, jupyterlab contributor org/company found, voltrondata contributor org/company found, rhoket-scientists contributor org/company found, activeldap contributor org/company found, rake-compiler contributor org/company found, statsmodels contributor org/company found, cloudpipe contributor org/company found, CodeforKarlsruhe contributor org/company found, data-engineering-collective contributor org/company found, duckdb-wasm-examples contributor org/company found, voltron data contributor org/company found, rcairo contributor org/company found, ruby-gettext contributor org/company found, regro contributor org/company found, shapely contributor org/company found, react-monaco-editor contributor org/company found, red-data-tools contributor org/company found, pandas-dev contributor org/company found, HaDiNet contributor org/company found, paris-saclay-cds contributor org/company found, uwescience contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 100 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Info: OSSFuzz integration found",
                        "Info: CppLibFuzzer integration found: cpp/src/arrow/ipc/file_fuzz.cc:21",
                        "Info: CppLibFuzzer integration found: cpp/src/arrow/ipc/stream_fuzz.cc:21",
                        "Info: CppLibFuzzer integration found: cpp/src/arrow/ipc/tensor_stream_fuzz.cc:21",
                        "Info: CppLibFuzzer integration found: cpp/src/parquet/arrow/fuzz.cc:21",
                        "Info: CppLibFuzzer integration found: cpp/src/arrow/ipc/file_fuzz.cc:21",
                        "Info: CppLibFuzzer integration found: cpp/src/arrow/ipc/stream_fuzz.cc:21",
                        "Info: CppLibFuzzer integration found: cpp/src/arrow/ipc/tensor_stream_fuzz.cc:21",
                        "Info: CppLibFuzzer integration found: cpp/src/parquet/arrow/fuzz.cc:21"
                    ],
                    "score": 10,
                    "reason": "project is fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.txt:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE.txt:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 20 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/cpp.yml:121"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Info: Possibly incomplete results: error parsing shell code: \"if <cond>\" must be followed by \"then\": ci/docker/python-wheel-windows-test-vs2019.dockerfile:52-56",
                        "Info: Possibly incomplete results: error parsing shell code: \"if <cond>\" must be followed by \"then\": ci/docker/python-wheel-windows-vs2019.dockerfile:82-86",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/archery.yml:61: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/archery.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/archery.yml:68: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/archery.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cpp.yml:192: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/cpp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cpp.yml:248: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/cpp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cpp.yml:260: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/cpp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cpp.yml:275: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/cpp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cpp.yml:346: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/cpp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cpp.yml:367: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/cpp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cpp.yml:445: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/cpp.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/cpp.yml:449: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/cpp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cpp.yml:457: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/cpp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cpp.yml:479: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/cpp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/csharp.yml:57: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/csharp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/csharp.yml:65: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/csharp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/csharp.yml:89: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/csharp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/csharp.yml:93: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/csharp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/csharp.yml:116: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/csharp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/csharp.yml:124: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/csharp.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/dev.yml:61: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/dev.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/dev.yml:116: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/dev.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/java.yml:155: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/java.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/java.yml:160: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/java.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/java.yml:124: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/java.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/java.yml:129: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/java.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/js.yml:99: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/js.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/js.yml:103: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/js.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/js.yml:109: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/js.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/js.yml:130: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/js.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/js.yml:134: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/js.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/js.yml:140: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/js.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/matlab.yml:70: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/matlab.yml:76: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/matlab.yml:89: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/matlab.yml:101: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/matlab.yml:118: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/matlab.yml:124: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/matlab.yml:137: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/matlab.yml:149: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/matlab.yml:159: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/matlab.yml:163: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/matlab.yml:180: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/matlab.yml:196: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/matlab.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python.yml:181: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/python.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python.yml:186: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/python.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python.yml:208: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/python.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/r.yml:98: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/r.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/r.yml:103: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/r.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/r.yml:109: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/r.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/r.yml:269: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/r.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/r.yml:278: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/r.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/r.yml:285: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/r.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/r.yml:325: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/r.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/r.yml:340: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/r.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/r.yml:350: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/r.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/r.yml:354: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/r.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release_candidate.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/release_candidate.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ruby.yml:151: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/ruby.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ruby.yml:176: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/ruby.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ruby.yml:247: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/ruby.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ruby.yml:252: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/ruby.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ruby.yml:259: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/ruby.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ruby.yml:283: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/ruby.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ruby.yml:367: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/ruby.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ruby.yml:392: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/arrow/ruby.yml/main?enable=pin",
                        "Warn: containerImage not pinned by hash: ci/docker/almalinux-8-verify-rc.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/alpine-linux-3.16-cpp.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/centos-7-cpp.dockerfile:18: pin your Docker image by updating centos:centos7 to centos:centos7@sha256:be65f488b7764ad3638f236b7b515b3678369a5124c47b8d32916d6487418ea4",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-cpp.dockerfile:20",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-integration.dockerfile:20",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-python-cpython-debug.dockerfile:21",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-python-cython2.dockerfile:21",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-python-dask.dockerfile:21",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-python-emscripten.dockerfile:21",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-python-hdfs.dockerfile:21",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-python-jpype.dockerfile:21",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-python-pandas.dockerfile:21",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-python-spark.dockerfile:21",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-python-substrait.dockerfile:22",
                        "Warn: containerImage not pinned by hash: ci/docker/conda-python.dockerfile:20",
                        "Warn: containerImage not pinned by hash: ci/docker/conda.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/debian-12-cpp.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/debian-12-js.dockerfile:20",
                        "Warn: containerImage not pinned by hash: ci/docker/fedora-39-cpp.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/java-jni-manylinux-201x.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/linux-apt-c-glib.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/linux-apt-docs.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/linux-apt-lint.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/linux-apt-lint.dockerfile:20",
                        "Warn: containerImage not pinned by hash: ci/docker/linux-apt-python-3.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/linux-apt-python-313-freethreading.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/linux-apt-r.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/linux-apt-ruby.dockerfile:20",
                        "Warn: containerImage not pinned by hash: ci/docker/linux-dnf-python-3.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/linux-r.dockerfile:22",
                        "Warn: containerImage not pinned by hash: ci/docker/python-free-threaded-wheel-manylinux-test-imports.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/python-free-threaded-wheel-manylinux-test-unittests.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/python-sdist.dockerfile:18: pin your Docker image by updating amd64/ubuntu:20.04 to amd64/ubuntu:20.04@sha256:10ce2724e9d27deaba0e1a8a6061e77955ca6385d6abb9fdec90d6094844cc52",
                        "Warn: containerImage not pinned by hash: ci/docker/python-wheel-manylinux-test.dockerfile:20",
                        "Warn: containerImage not pinned by hash: ci/docker/python-wheel-manylinux.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/python-wheel-windows-test-vs2019.dockerfile:23: pin your Docker image by updating abrarov/msvc-2019:2.11.0 to abrarov/msvc-2019:2.11.0@sha256:164aabdb3f9dbef34bf558703de6b8936aa84e66553778192334cb3b8ba40a6e",
                        "Warn: containerImage not pinned by hash: ci/docker/python-wheel-windows-vs2019.dockerfile:23: pin your Docker image by updating abrarov/msvc-2019:2.11.0 to abrarov/msvc-2019:2.11.0@sha256:164aabdb3f9dbef34bf558703de6b8936aa84e66553778192334cb3b8ba40a6e",
                        "Warn: containerImage not pinned by hash: ci/docker/ubuntu-20.04-cpp-minimal.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/ubuntu-20.04-cpp.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/ubuntu-20.04-verify-rc.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/ubuntu-22.04-cpp-minimal.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/ubuntu-22.04-cpp.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/ubuntu-22.04-csharp.dockerfile:21",
                        "Warn: containerImage not pinned by hash: ci/docker/ubuntu-22.04-verify-rc.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/ubuntu-24.04-cpp-minimal.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/ubuntu-24.04-cpp.dockerfile:19",
                        "Warn: containerImage not pinned by hash: ci/docker/ubuntu-swift.dockerfile:18: pin your Docker image by updating swift:5.9.0 to swift:5.9.0@sha256:a13d1eff9d1639c967c2c1f28740328f57cde4caaf979d07e86811cbaefdd84d",
                        "Warn: containerImage not pinned by hash: cpp/examples/minimal_build/minimal.dockerfile:18: pin your Docker image by updating ubuntu:focal to ubuntu:focal@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b",
                        "Warn: containerImage not pinned by hash: cpp/examples/minimal_build/system_dependency.dockerfile:18: pin your Docker image by updating ubuntu:focal to ubuntu:focal@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b",
                        "Warn: containerImage not pinned by hash: cpp/examples/tutorial_examples/tutorial.dockerfile:18: pin your Docker image by updating ubuntu:focal to ubuntu:focal@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b",
                        "Warn: containerImage not pinned by hash: dev/release/binary/Dockerfile:18: pin your Docker image by updating debian:bookworm to debian:bookworm@sha256:e11072c1614c08bf88b543fcfe09d75a0426d90896408e926454e88078274fcb",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow-apt-source/apt/debian-bookworm/Dockerfile:18: pin your Docker image by updating debian:bookworm to debian:bookworm@sha256:e11072c1614c08bf88b543fcfe09d75a0426d90896408e926454e88078274fcb",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow-apt-source/apt/debian-trixie/Dockerfile:18: pin your Docker image by updating debian:trixie to debian:trixie@sha256:4bf4a3ee5cd9a4a6bc048af9bf7c0666f761e391e7ebb158b3da554ffe75994e",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow-apt-source/apt/ubuntu-focal/Dockerfile:18: pin your Docker image by updating ubuntu:focal to ubuntu:focal@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow-apt-source/apt/ubuntu-jammy/Dockerfile:18: pin your Docker image by updating ubuntu:jammy to ubuntu:jammy@sha256:0e5e4a57c2499249aafc3b40fcd541e9a456aab7296681a3994d631587203f97",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow-apt-source/apt/ubuntu-noble/Dockerfile:18: pin your Docker image by updating ubuntu:noble to ubuntu:noble@sha256:99c35190e22d294cdace2783ac55effc69d32896daaa265f0bbedbcde4fbe3e5",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow-release/yum/almalinux-8/Dockerfile:18: pin your Docker image by updating almalinux:8 to almalinux:8@sha256:d7dbaf57916185b2be09e1eaa1156b543f3937164ffa08d7fdc020a0a3800a5a",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow-release/yum/almalinux-9/Dockerfile:18: pin your Docker image by updating almalinux:9 to almalinux:9@sha256:1c718a4cd7bab3bdb069ddbbd1eb593a390e6932d51d0048a2f6556303bafba7",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow-release/yum/amazon-linux-2023/Dockerfile:18: pin your Docker image by updating amazonlinux:2023 to amazonlinux:2023@sha256:5bf4cf420ef7e50835911993c6a2ddb0e8f5101c0ef89ca20e9d02a03c8c3a8c",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow-release/yum/centos-7/Dockerfile:18: pin your Docker image by updating centos:7 to centos:7@sha256:be65f488b7764ad3638f236b7b515b3678369a5124c47b8d32916d6487418ea4",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow-release/yum/centos-8-stream/Dockerfile:18: pin your Docker image by updating quay.io/centos/centos:stream8 to quay.io/centos/centos:stream8@sha256:20da069d4f8126c4517ee563e6e723d4cbe79ff62f6c4597f753478af91a09a3",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow-release/yum/centos-9-stream/Dockerfile:18: pin your Docker image by updating quay.io/centos/centos:stream9 to quay.io/centos/centos:stream9@sha256:e5fdd83894773a25f22fbdf0b5253c63677d0cbaf8d3a8366b165a3ef5902964",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow/apt/debian-bookworm/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow/apt/debian-trixie/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow/apt/ubuntu-focal/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow/apt/ubuntu-jammy/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow/apt/ubuntu-noble/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow/yum/almalinux-8/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow/yum/almalinux-9/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow/yum/amazon-linux-2023/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow/yum/centos-7/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow/yum/centos-8-stream/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: dev/tasks/linux-packages/apache-arrow/yum/centos-9-stream/Dockerfile:19",
                        "Warn: containerImage not pinned by hash: python/examples/minimal_build/Dockerfile.fedora:18: pin your Docker image by updating fedora:39 to fedora:39@sha256:f23412a1ad7c430fc5ed9c029b15715aed3d50e6322902a066869310cddaf915",
                        "Warn: containerImage not pinned by hash: python/examples/minimal_build/Dockerfile.ubuntu:18: pin your Docker image by updating ubuntu:jammy to ubuntu:jammy@sha256:0e5e4a57c2499249aafc3b40fcd541e9a456aab7296681a3994d631587203f97",
                        "Warn: downloadThenRun not pinned by hash: ci/docker/conda-integration.dockerfile:47-50",
                        "Warn: downloadThenRun not pinned by hash: ci/docker/conda-integration.dockerfile:73",
                        "Warn: pipCommand not pinned by hash: ci/docker/conda-python-emscripten.dockerfile:35-36",
                        "Warn: pipCommand not pinned by hash: ci/docker/conda-python-emscripten.dockerfile:35-36",
                        "Warn: npmCommand not pinned by hash: ci/docker/linux-apt-docs.dockerfile:27-81",
                        "Warn: pipCommand not pinned by hash: ci/docker/linux-apt-docs.dockerfile:114-117",
                        "Warn: pipCommand not pinned by hash: ci/docker/linux-apt-python-3.dockerfile:27-32",
                        "Warn: pipCommand not pinned by hash: ci/docker/linux-apt-python-3.dockerfile:27-32",
                        "Warn: pipCommand not pinned by hash: ci/docker/linux-apt-r.dockerfile:91-94",
                        "Warn: pipCommand not pinned by hash: ci/docker/linux-apt-r.dockerfile:91-94",
                        "Warn: pipCommand not pinned by hash: ci/docker/linux-dnf-python-3.dockerfile:29",
                        "Warn: pipCommand not pinned by hash: ci/docker/linux-dnf-python-3.dockerfile:35-37",
                        "Warn: pipCommand not pinned by hash: ci/docker/python-free-threaded-wheel-manylinux-test-unittests.dockerfile:45-49",
                        "Warn: pipCommand not pinned by hash: ci/docker/python-free-threaded-wheel-manylinux-test-unittests.dockerfile:50",
                        "Warn: pipCommand not pinned by hash: ci/docker/python-free-threaded-wheel-manylinux-test-unittests.dockerfile:51",
                        "Warn: pipCommand not pinned by hash: ci/docker/python-sdist.dockerfile:34",
                        "Warn: pipCommand not pinned by hash: ci/docker/python-wheel-manylinux-test.dockerfile:25",
                        "Warn: pipCommand not pinned by hash: ci/docker/python-wheel-manylinux.dockerfile:118-120",
                        "Warn: pipCommand not pinned by hash: ci/docker/python-wheel-manylinux.dockerfile:123",
                        "Warn: chocoCommand not pinned by hash: ci/docker/python-wheel-windows-test-vs2019.dockerfile:44",
                        "Warn: chocoCommand not pinned by hash: ci/docker/python-wheel-windows-test-vs2019.dockerfile:60-61",
                        "Warn: chocoCommand not pinned by hash: ci/docker/python-wheel-windows-test-vs2019.dockerfile:60-61",
                        "Warn: chocoCommand not pinned by hash: ci/docker/python-wheel-windows-vs2019.dockerfile:27-28",
                        "Warn: chocoCommand not pinned by hash: ci/docker/python-wheel-windows-vs2019.dockerfile:27-28",
                        "Warn: chocoCommand not pinned by hash: ci/docker/python-wheel-windows-vs2019.dockerfile:88",
                        "Warn: pipCommand not pinned by hash: ci/docker/python-wheel-windows-vs2019.dockerfile:89",
                        "Warn: pipCommand not pinned by hash: ci/docker/python-wheel-windows-vs2019.dockerfile:92",
                        "Warn: pipCommand not pinned by hash: dev/tasks/linux-packages/apache-arrow/apt/ubuntu-focal/Dockerfile:30-81",
                        "Warn: pipCommand not pinned by hash: python/examples/minimal_build/Dockerfile.fedora:33",
                        "Warn: pipCommand not pinned by hash: python/examples/minimal_build/Dockerfile.ubuntu:39",
                        "Warn: npmCommand not pinned by hash: ci/scripts/install_azurite.sh:37",
                        "Warn: chocoCommand not pinned by hash: ci/scripts/install_azurite.sh:41",
                        "Warn: npmCommand not pinned by hash: ci/scripts/install_azurite.sh:42",
                        "Warn: npmCommand not pinned by hash: ci/scripts/install_azurite.sh:45",
                        "Warn: downloadThenRun not pinned by hash: ci/scripts/install_conda.sh:38",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_dask.sh:30",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_dask.sh:31",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_dask.sh:33",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_dask.sh:35",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_dask.sh:40",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_numba.sh:34",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_numba.sh:36",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_numba.sh:38",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_numpy.sh:30",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_numpy.sh:32",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_pandas.sh:31",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_pandas.sh:33",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_pandas.sh:35",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_pandas.sh:39",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_pandas.sh:41",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_pandas.sh:43",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_pandas.sh:45",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_substrait_consumer.sh:29",
                        "Warn: pipCommand not pinned by hash: ci/scripts/install_substrait_consumer.sh:32",
                        "Warn: pipCommand not pinned by hash: ci/scripts/integration_arrow.sh:38",
                        "Warn: pipCommand not pinned by hash: ci/scripts/integration_arrow.sh:44",
                        "Warn: pipCommand not pinned by hash: ci/scripts/integration_arrow.sh:47",
                        "Warn: pipCommand not pinned by hash: ci/scripts/integration_skyhook.sh:126",
                        "Warn: pipCommand not pinned by hash: ci/scripts/python_benchmark.sh:26",
                        "Warn: pipCommand not pinned by hash: ci/scripts/python_wheel_macos_build.sh:55",
                        "Warn: pipCommand not pinned by hash: ci/scripts/python_wheel_macos_build.sh:58",
                        "Warn: pipCommand not pinned by hash: ci/scripts/python_wheel_macos_build.sh:60",
                        "Warn: pipCommand not pinned by hash: ci/scripts/python_wheel_macos_build.sh:64",
                        "Warn: pipCommand not pinned by hash: ci/scripts/python_wheel_unix_test.sh:62",
                        "Warn: pipCommand not pinned by hash: ci/scripts/python_wheel_unix_test.sh:98",
                        "Warn: pipCommand not pinned by hash: dev/conbench_envs/hooks.sh:42",
                        "Warn: pipCommand not pinned by hash: dev/conbench_envs/hooks.sh:78",
                        "Warn: npmCommand not pinned by hash: dev/release/setup-rhel-rebuilds.sh:54",
                        "Warn: downloadThenRun not pinned by hash: dev/release/verify-release-candidate.sh:319",
                        "Warn: pipCommand not pinned by hash: dev/release/verify-release-candidate.sh:517",
                        "Warn: pipCommand not pinned by hash: dev/release/verify-release-candidate.sh:526",
                        "Warn: pipCommand not pinned by hash: dev/release/verify-release-candidate.sh:726",
                        "Warn: pipCommand not pinned by hash: dev/release/verify-release-candidate.sh:757",
                        "Warn: npmCommand not pinned by hash: dev/release/verify-release-candidate.sh:871",
                        "Warn: pipCommand not pinned by hash: dev/release/verify-release-candidate.sh:894",
                        "Warn: pipCommand not pinned by hash: dev/release/verify-release-candidate.sh:895",
                        "Warn: pipCommand not pinned by hash: dev/release/verify-release-candidate.sh:1063",
                        "Warn: pipCommand not pinned by hash: dev/release/verify-release-candidate.sh:1104",
                        "Warn: downloadThenRun not pinned by hash: python/examples/minimal_build/build_conda.sh:39",
                        "Warn: pipCommand not pinned by hash: python/examples/minimal_build/build_conda.sh:101",
                        "Warn: pipCommand not pinned by hash: python/examples/minimal_build/build_venv.sh:37",
                        "Warn: pipCommand not pinned by hash: python/examples/minimal_build/build_venv.sh:38",
                        "Warn: pipCommand not pinned by hash: python/examples/minimal_build/build_venv.sh:73",
                        "Warn: pipCommand not pinned by hash: python/examples/minimal_build/build_venv.sh:77",
                        "Warn: pipCommand not pinned by hash: .github/workflows/archery.yml:73",
                        "Warn: pipCommand not pinned by hash: .github/workflows/archery.yml:75",
                        "Warn: pipCommand not pinned by hash: .github/workflows/archery.yml:76",
                        "Warn: pipCommand not pinned by hash: .github/workflows/comment_bot.yml:49",
                        "Warn: pipCommand not pinned by hash: .github/workflows/comment_bot.yml:105",
                        "Warn: pipCommand not pinned by hash: .github/workflows/comment_bot.yml:106",
                        "Warn: pipCommand not pinned by hash: .github/workflows/cpp.yml:161",
                        "Warn: pipCommand not pinned by hash: .github/workflows/cpp.yml:164",
                        "Warn: pipCommand not pinned by hash: .github/workflows/dev.yml:127",
                        "Warn: pipCommand not pinned by hash: .github/workflows/dev.yml:58",
                        "Warn: pipCommand not pinned by hash: .github/workflows/dev.yml:70",
                        "Warn: pipCommand not pinned by hash: .github/workflows/docs.yml:60",
                        "Warn: pipCommand not pinned by hash: .github/workflows/docs_light.yml:67",
                        "Warn: pipCommand not pinned by hash: .github/workflows/integration.yml:109",
                        "Warn: pipCommand not pinned by hash: .github/workflows/java.yml:91",
                        "Warn: pipCommand not pinned by hash: .github/workflows/java_jni.yml:127",
                        "Warn: pipCommand not pinned by hash: .github/workflows/java_jni.yml:85",
                        "Warn: pipCommand not pinned by hash: .github/workflows/java_nightly.yml:68",
                        "Warn: pipCommand not pinned by hash: .github/workflows/js.yml:69",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pr_bot.yml:90",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python.yml:193",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python.yml:216",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python.yml:122",
                        "Warn: pipCommand not pinned by hash: .github/workflows/r.yml:222",
                        "Warn: pipCommand not pinned by hash: .github/workflows/r.yml:163",
                        "Warn: pipCommand not pinned by hash: .github/workflows/r_nightly.yml:70",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ruby.yml:98",
                        "Warn: pipCommand not pinned by hash: .github/workflows/swift.yml:72",
                        "Info:  72 out of 121 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   5 out of  20 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of  94 pipCommand dependencies pinned",
                        "Info:   0 out of   6 npmCommand dependencies pinned",
                        "Info:   0 out of   7 chocoCommand dependencies pinned",
                        "Info:   1 out of   1 goCommand dependencies pinned",
                        "Info:   0 out of  75 containerImage dependencies pinned",
                        "Info:   0 out of   5 downloadThenRun dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/apache/.github/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/apache/.github/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/apache/.github/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/apache/.github/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Info: signed release artifact: matlab-arrow-18.0.0.mltbx.asc: https://api.github.com/repos/apache/arrow/releases/assets/202288752",
                        "Info: signed release artifact: matlab-arrow-18.0.0.mltbx.asc: https://api.github.com/repos/apache/arrow/releases/assets/199677095",
                        "Info: signed release artifact: matlab-arrow-17.0.0.mltbx.asc: https://api.github.com/repos/apache/arrow/releases/assets/179848419",
                        "Info: signed release artifact: matlab-arrow-17.0.0.mltbx.asc: https://api.github.com/repos/apache/arrow/releases/assets/179062050",
                        "Warn: release artifact apache-arrow-17.0.0-rc1 not signed: https://api.github.com/repos/apache/arrow/releases/164639050",
                        "Warn: release artifact apache-arrow-18.0.0 does not have provenance: https://api.github.com/repos/apache/arrow/releases/182193262",
                        "Warn: release artifact apache-arrow-18.0.0-rc0 does not have provenance: https://api.github.com/repos/apache/arrow/releases/180184541",
                        "Warn: release artifact apache-arrow-17.0.0 does not have provenance: https://api.github.com/repos/apache/arrow/releases/165584429",
                        "Warn: release artifact apache-arrow-17.0.0-rc2 does not have provenance: https://api.github.com/repos/apache/arrow/releases/164955245",
                        "Warn: release artifact apache-arrow-17.0.0-rc1 does not have provenance: https://api.github.com/repos/apache/arrow/releases/164639050"
                    ],
                    "score": 6,
                    "reason": "4 out of the last 5 releases have a total of 4 signed artifacts.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/archery.yml:50",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/comment_bot.yml:28",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/cpp.yml:64",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/csharp.yml:42",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/dev.yml:35",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/dev_pr.yml:37",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/docs.yml:24",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/docs_light.yml:34",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/integration.yml:60",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/issue_bot.yml:26",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/java.yml:52",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/java_jni.yml:52",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/java_nightly.yml:35",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/js.yml:46",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/matlab.yml:44",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/pr_bot.yml:31",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/pr_review_trigger.yml:22",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/python.yml:48",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/r.yml:58",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/r_nightly.yml:40",
                        "Warn: topLevel 'contents' permission set to 'write': .github/workflows/release.yml:28",
                        "Warn: topLevel 'contents' permission set to 'write': .github/workflows/release_candidate.yml:28",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/ruby.yml:60",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/swift.yml:48",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: CVE-2021-46141",
                        "Warn: Project is vulnerable to: CVE-2021-46142",
                        "Warn: Project is vulnerable to: CVE-2024-34402",
                        "Warn: Project is vulnerable to: CVE-2024-34403",
                        "Warn: Project is vulnerable to: GHSA-grv7-fg5c-xmjg",
                        "Warn: Project is vulnerable to: GHSA-952p-6rrq-rcjv",
                        "Warn: Project is vulnerable to: GHSA-7fh5-64p2-3v2j",
                        "Warn: Project is vulnerable to: GHSA-4vvj-4cpr-p986"
                    ],
                    "score": 2,
                    "reason": "8 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/apache/.github/contents/.github/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\nThis is a project of the [Apache Software Foundation](https://apache.org) and follows the ASF [vulnerability handling process](https://apache.org/security/#vulnerability-handling).\n\n## Reporting a Vulnerability\n\nTo report a new vulnerability you have discovered please follow the [ASF vulnerability reporting process](https://apache.org/security/#reporting-a-vulnerability).\n",
        "project_all_labels": [
            ".NET",
            "awaiting change review",
            "awaiting changes",
            "awaiting committer review",
            "awaiting merge",
            "awaiting review",
            "backport-candidate",
            "Breaking Change",
            "Component: Archery",
            "Component: Benchmarking",
            "Component: C",
            "Component: C#",
            "Component: C++",
            "Component: C++ - Gandiva",
            "Component: C++ - Plasma",
            "Component: Continuous Integration",
            "Component: Developer Tools",
            "Component: Documentation",
            "Component: FlightRPC",
            "Component: Format",
            "Component: GLib",
            "Component: Go",
            "Component: GPU",
            "Component: Integration",
            "Component: Java",
            "Component: JavaScript",
            "Component: Julia",
            "Component: MATLAB",
            "Component: Other",
            "Component: Packaging",
            "Component: Parquet",
            "Component: Python",
            "Component: R",
            "Component: Release",
            "Component: Ruby",
            "Component: Rust",
            "Component: Rust - Ballista",
            "Component: Rust - DataFusion",
            "Component: Swift",
            "Component: Website",
            "Component: Wiki",
            "Critical Fix",
            "dependencies",
            "github_actions",
            "go",
            "good-first-issue",
            "good-second-issue",
            "hacktoberfest-accepted",
            "installation",
            "java",
            "javascript",
            "needs-rebase",
            "Priority: Blocker",
            "Priority: Critical",
            "Priority: Major",
            "Priority: Medium",
            "Priority: Minor",
            "Priority: Trivial",
            "ready-for-review",
            "Type: bug",
            "Type: enhancement",
            "Type: task",
            "Type: test",
            "Type: usage",
            "WIP"
        ],
        "README_content": "<!---\n  Licensed to the Apache Software Foundation (ASF) under one\n  or more contributor license agreements.  See the NOTICE file\n  distributed with this work for additional information\n  regarding copyright ownership.  The ASF licenses this file\n  to you under the Apache License, Version 2.0 (the\n  \"License\"); you may not use this file except in compliance\n  with the License.  You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing,\n  software distributed under the License is distributed on an\n  \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n  KIND, either express or implied.  See the License for the\n  specific language governing permissions and limitations\n  under the License.\n-->\n\n# Apache Arrow\n\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/arrow.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:arrow)\n[![License](http://img.shields.io/:license-Apache%202-blue.svg)](https://github.com/apache/arrow/blob/main/LICENSE.txt)\n[![Twitter Follow](https://img.shields.io/twitter/follow/apachearrow.svg?style=social&label=Follow)](https://twitter.com/apachearrow)\n\n## Powering In-Memory Analytics\n\nApache Arrow is a universal columnar format and multi-language toolbox for fast\ndata interchange and in-memory analytics. It contains a set of technologies that\nenable data systems to efficiently store, process, and move data.\n\nMajor components of the project include:\n\n - [The Arrow Columnar In-Memory Format](https://arrow.apache.org/docs/dev/format/Columnar.html):\n   a standard and efficient in-memory representation of various datatypes, plain or nested\n - [The Arrow IPC Format](https://arrow.apache.org/docs/dev/format/Columnar.html#serialization-and-interprocess-communication-ipc):\n   an efficient serialization of the Arrow format and associated metadata,\n   for communication between processes and heterogeneous environments\n - [The Arrow Flight RPC protocol](https://github.com/apache/arrow/tree/main/format/Flight.proto):\n   based on the Arrow IPC format, a building block for remote services exchanging\n   Arrow data with application-defined semantics (for example a storage server or a database)\n - [C++ libraries](https://github.com/apache/arrow/tree/main/cpp)\n - [C bindings using GLib](https://github.com/apache/arrow/tree/main/c_glib)\n - [C# .NET libraries](https://github.com/apache/arrow/tree/main/csharp)\n - [Gandiva](https://github.com/apache/arrow/tree/main/cpp/src/gandiva):\n   an [LLVM](https://llvm.org)-based Arrow expression compiler, part of the C++ codebase\n - [Go libraries](https://github.com/apache/arrow-go)\n - [Java libraries](https://github.com/apache/arrow/tree/main/java)\n - [JavaScript libraries](https://github.com/apache/arrow/tree/main/js)\n - [Python libraries](https://github.com/apache/arrow/tree/main/python)\n - [R libraries](https://github.com/apache/arrow/tree/main/r)\n - [Ruby libraries](https://github.com/apache/arrow/tree/main/ruby)\n - [Rust libraries](https://github.com/apache/arrow-rs)\n\nArrow is an [Apache Software Foundation](https://www.apache.org) project. Learn more at\n[arrow.apache.org](https://arrow.apache.org).\n\n## What's in the Arrow libraries?\n\nThe reference Arrow libraries contain many distinct software components:\n\n- Columnar vector and table-like containers (similar to data frames) supporting\n  flat or nested types\n- Fast, language agnostic metadata messaging layer (using Google's Flatbuffers\n  library)\n- Reference-counted off-heap buffer memory management, for zero-copy memory\n  sharing and handling memory-mapped files\n- IO interfaces to local and remote filesystems\n- Self-describing binary wire formats (streaming and batch/file-like) for\n  remote procedure calls (RPC) and interprocess communication (IPC)\n- Integration tests for verifying binary compatibility between the\n  implementations (e.g. sending data from Java to C++)\n- Conversions to and from other in-memory data structures\n- Readers and writers for various widely-used file formats (such as Parquet, CSV)\n\n## Implementation status\n\nThe official Arrow libraries in this repository are in different stages of\nimplementing the Arrow format and related features.  See our current\n[feature matrix](https://arrow.apache.org/docs/dev/status.html)\non git main.\n\n## How to Contribute\n\nPlease read our latest [project contribution guide][5].\n\n## Getting involved\n\nEven if you do not plan to contribute to Apache Arrow itself or Arrow\nintegrations in other projects, we'd be happy to have you involved:\n\n- Join the mailing list: send an email to\n  [dev-subscribe@arrow.apache.org][1]. Share your ideas and use cases for the\n  project.\n- Follow our activity on [GitHub issues][3]\n- [Learn the format][2]\n- Contribute code to one of the reference implementations\n\n[1]: mailto:dev-subscribe@arrow.apache.org\n[2]: https://github.com/apache/arrow/tree/main/format\n[3]: https://github.com/apache/arrow/issues\n[4]: https://github.com/apache/arrow\n[5]: https://arrow.apache.org/docs/dev/developers/index.html\n",
        "num_commits": 16828,
        "project_age_days": 3177,
        "project_created_at": "2016-02-17",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-30",
        "num_contributors": 369,
        "num_pull": 18757,
        "num_issues": 44507,
        "num_opening_issue": 4799,
        "project_size(kB)": 201183,
        "num_stargazers": 14495,
        "num_watchers": 14495,
        "num_forks": 3525,
        "num_subscribers": 351,
        "SecurityPolicy_created_at": "2021-07-19 11:31:44",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "c5e16821126392a9613ee5def9d1cce56a1f64bf",
                "url": "https://github.com/apache/.github/commit/c5e16821126392a9613ee5def9d1cce56a1f64bf",
                "date": "2021-07-19 11:31:44"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "9001/copyparty",
        "project_url": "https://github.com/9001/copyparty",
        "SSF": {
            "date": "2024-10-29T21:55:00+07:00",
            "repo": {
                "name": "github.com/9001/copyparty",
                "commit": "efd8a32ed6618ae89c0827133e3982b383abf8bc"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 3.8,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'hovudstraum'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no pull request found",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 0/30 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: vg-mjg contributor org/company found, "
                    ],
                    "score": 3,
                    "reason": "project has 1 contributing companies or organizations -- score normalized to 3",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no workflows found",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 20 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Info: Possibly incomplete results: error parsing shell code: statements must be separated by &, ; or a newline: docs/music-analysis.sh:0",
                        "Info: Possibly incomplete results: error parsing shell code: a command can only contain words and redirects; encountered (: docs/notes.sh:0",
                        "Info: Possibly incomplete results: error parsing shell code: a command can only contain words and redirects; encountered (: docs/tcp-debug.sh:0",
                        "Warn: containerImage not pinned by hash: scripts/deps-docker/Dockerfile:1: pin your Docker image by updating alpine:3.18 to alpine:3.18@sha256:3ddf7bf1d408188f9849efbf4f902720ae08f5131bb39013518b918aa056d0de",
                        "Warn: containerImage not pinned by hash: scripts/docker/Dockerfile.ac:1: pin your Docker image by updating alpine:latest to alpine:latest@sha256:beefdbd8a1da6d2915566fde36db9db0b524eb737fc57cd1367effd16dc0d06d",
                        "Warn: containerImage not pinned by hash: scripts/docker/Dockerfile.dj:1: pin your Docker image by updating alpine:latest to alpine:latest@sha256:beefdbd8a1da6d2915566fde36db9db0b524eb737fc57cd1367effd16dc0d06d",
                        "Warn: containerImage not pinned by hash: scripts/docker/Dockerfile.djd:1: pin your Docker image by updating debian:12-slim to debian:12-slim@sha256:36e591f228bb9b99348f584e83f16e012c33ba5cad44ef5981a1d7c0a93eca22",
                        "Warn: containerImage not pinned by hash: scripts/docker/Dockerfile.djf:1: pin your Docker image by updating fedora:39 to fedora:39@sha256:f23412a1ad7c430fc5ed9c029b15715aed3d50e6322902a066869310cddaf915",
                        "Warn: containerImage not pinned by hash: scripts/docker/Dockerfile.djff:1: pin your Docker image by updating fedora:38 to fedora:38@sha256:b9ff6f23cceb5bde20bb1f79b492b98d71ef7a7ae518ca1b15b26661a11e6a94",
                        "Warn: containerImage not pinned by hash: scripts/docker/Dockerfile.dju:1: pin your Docker image by updating ubuntu:23.04 to ubuntu:23.04@sha256:5a828e28de105c3d7821c4442f0f5d1c52dc16acf4999d5f31a3bc0f03f06edd",
                        "Warn: containerImage not pinned by hash: scripts/docker/Dockerfile.im:1: pin your Docker image by updating alpine:latest to alpine:latest@sha256:beefdbd8a1da6d2915566fde36db9db0b524eb737fc57cd1367effd16dc0d06d",
                        "Warn: containerImage not pinned by hash: scripts/docker/Dockerfile.iv:1: pin your Docker image by updating alpine:latest to alpine:latest@sha256:beefdbd8a1da6d2915566fde36db9db0b524eb737fc57cd1367effd16dc0d06d",
                        "Warn: containerImage not pinned by hash: scripts/docker/Dockerfile.min:1: pin your Docker image by updating alpine:latest to alpine:latest@sha256:beefdbd8a1da6d2915566fde36db9db0b524eb737fc57cd1367effd16dc0d06d",
                        "Warn: containerImage not pinned by hash: scripts/docker/Dockerfile.min.pip:1: pin your Docker image by updating alpine:latest to alpine:latest@sha256:beefdbd8a1da6d2915566fde36db9db0b524eb737fc57cd1367effd16dc0d06d",
                        "Warn: npmCommand not pinned by hash: scripts/deps-docker/Dockerfile:25-62",
                        "Warn: npmCommand not pinned by hash: scripts/deps-docker/Dockerfile:25-62",
                        "Warn: npmCommand not pinned by hash: scripts/deps-docker/Dockerfile:25-62",
                        "Warn: npmCommand not pinned by hash: scripts/deps-docker/Dockerfile:25-62",
                        "Warn: npmCommand not pinned by hash: scripts/deps-docker/Dockerfile:25-62",
                        "Warn: npmCommand not pinned by hash: scripts/deps-docker/Dockerfile:25-62",
                        "Warn: pipCommand not pinned by hash: scripts/deps-docker/Dockerfile:71-81",
                        "Warn: npmCommand not pinned by hash: scripts/deps-docker/Dockerfile:120-127",
                        "Warn: pipCommand not pinned by hash: scripts/docker/Dockerfile.dj:13-30",
                        "Warn: pipCommand not pinned by hash: scripts/docker/Dockerfile.djd:17-59",
                        "Warn: pipCommand not pinned by hash: scripts/docker/Dockerfile.djf:14-54",
                        "Warn: pipCommand not pinned by hash: scripts/docker/Dockerfile.djff:14-51",
                        "Warn: pipCommand not pinned by hash: scripts/docker/Dockerfile.dju:27-56",
                        "Warn: pipCommand not pinned by hash: scripts/docker/Dockerfile.iv:10-20",
                        "Warn: pipCommand not pinned by hash: scripts/docker/Dockerfile.min.pip:11-18",
                        "Warn: pipCommand not pinned by hash: scripts/copyparty-android.sh:44",
                        "Warn: pipCommand not pinned by hash: scripts/make-pypi-release.sh:95",
                        "Info:   0 out of  11 containerImage dependencies pinned",
                        "Info:   0 out of   7 npmCommand dependencies pinned",
                        "Info:   0 out of  10 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: no pull requests merged into dev branch"
                    ],
                    "score": 0,
                    "reason": "no SAST tool detected",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact v1.15.10 not signed: https://api.github.com/repos/9001/copyparty/releases/182117284",
                        "Warn: release artifact v1.15.9 not signed: https://api.github.com/repos/9001/copyparty/releases/180772941",
                        "Warn: release artifact v1.15.8 not signed: https://api.github.com/repos/9001/copyparty/releases/180333405",
                        "Warn: release artifact v1.15.7 not signed: https://api.github.com/repos/9001/copyparty/releases/179709070",
                        "Warn: release artifact v1.15.6 not signed: https://api.github.com/repos/9001/copyparty/releases/179612533",
                        "Warn: release artifact v1.15.10 does not have provenance: https://api.github.com/repos/9001/copyparty/releases/182117284",
                        "Warn: release artifact v1.15.9 does not have provenance: https://api.github.com/repos/9001/copyparty/releases/180772941",
                        "Warn: release artifact v1.15.8 does not have provenance: https://api.github.com/repos/9001/copyparty/releases/180333405",
                        "Warn: release artifact v1.15.7 does not have provenance: https://api.github.com/repos/9001/copyparty/releases/179709070",
                        "Warn: release artifact v1.15.6 does not have provenance: https://api.github.com/repos/9001/copyparty/releases/179612533"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "No tokens found",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/9001/copyparty/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\nif you hit something extra juicy pls let me know on either of the following\n* email -- `copyparty@ocv.ze` except `ze` should be `me`\n* [mastodon dm](https://layer8.space/@tripflag) -- `@tripflag@layer8.space`\n* [github private vulnerability report](https://github.com/9001/copyparty/security/advisories/new), wow that form is complicated\n* [twitter dm](https://twitter.com/tripflag) (if im somehow not banned yet)\n\nno bug bounties sorry! all i can offer is greetz in the release notes\n",
        "project_all_labels": [
            "bug",
            "duplicate",
            "enhancement",
            "good first issue",
            "help wanted",
            "invalid",
            "need info",
            "question",
            "wontfix"
        ],
        "README_content": "<img src=\"https://github.com/9001/copyparty/raw/hovudstraum/docs/logo.svg\" width=\"250\" align=\"right\"/>\n\n###  copyparty\n\nturn almost any device into a file server with resumable uploads/downloads using [*any*](#browser-support) web browser\n\n* server only needs Python (2 or 3), all dependencies optional\n*  protocols: [http](#the-browser) // [webdav](#webdav-server) // [ftp](#ftp-server) // [tftp](#tftp-server) // [smb/cifs](#smb-server)\n*  [android app](#android-app) // [iPhone shortcuts](#ios-shortcuts)\n\n **[Get started](#quickstart)!** or visit the **[read-only demo server](https://a.ocv.me/pub/demo/)**  running from a basement in finland\n\n **screenshots:** [browser](#the-browser) // [upload](#uploading) // [unpost](#unpost) // [thumbnails](#thumbnails) // [search](#searching) // [fsearch](#file-search) // [zip-DL](#zip-downloads) // [md-viewer](#markdown-viewer)\n\n **videos:** [upload](https://a.ocv.me/pub/demo/pics-vids/up2k.webm) // [cli-upload](https://a.ocv.me/pub/demo/pics-vids/u2cli.webm) // [race-the-beam](https://a.ocv.me/pub/g/nerd-stuff/cpp/2024-0418-race-the-beam.webm)\n\n\n## readme toc\n\n* top\n    * [quickstart](#quickstart) - just run **[copyparty-sfx.py](https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py)** -- that's it! \n        * [at home](#at-home) - make it accessible over the internet\n        * [on servers](#on-servers) - you may also want these, especially on servers\n    * [features](#features) - also see [comparison to similar software](./docs/versus.md)\n    * [testimonials](#testimonials) - small collection of user feedback\n* [motivations](#motivations) - project goals / philosophy\n    * [notes](#notes) - general notes\n* [bugs](#bugs) - roughly sorted by chance of encounter\n    * [not my bugs](#not-my-bugs) - same order here too\n* [breaking changes](#breaking-changes) - upgrade notes\n* [FAQ](#FAQ) - \"frequently\" asked questions\n* [accounts and volumes](#accounts-and-volumes) - per-folder, per-user permissions\n    * [shadowing](#shadowing) - hiding specific subfolders\n    * [dotfiles](#dotfiles) - unix-style hidden files/folders\n* [the browser](#the-browser) - accessing a copyparty server using a web-browser\n    * [tabs](#tabs) - the main tabs in the ui\n    * [hotkeys](#hotkeys) - the browser has the following hotkeys\n    * [navpane](#navpane) - switching between breadcrumbs or navpane\n    * [thumbnails](#thumbnails) - press `g` or `` to toggle grid-view instead of the file listing\n    * [zip downloads](#zip-downloads) - download folders (or file selections) as `zip` or `tar` files\n    * [uploading](#uploading) - drag files/folders into the web-browser to upload\n        * [file-search](#file-search) - dropping files into the browser also lets you see if they exist on the server\n        * [unpost](#unpost) - undo/delete accidental uploads\n        * [self-destruct](#self-destruct) - uploads can be given a lifetime\n        * [race the beam](#race-the-beam) - download files while they're still uploading ([demo video](http://a.ocv.me/pub/g/nerd-stuff/cpp/2024-0418-race-the-beam.webm))\n        * [incoming files](#incoming-files) - the control-panel shows the ETA for all incoming files\n    * [file manager](#file-manager) - cut/paste, rename, and delete files/folders (if you have permission)\n    * [shares](#shares) - share a file or folder by creating a temporary link\n    * [batch rename](#batch-rename) - select some files and press `F2` to bring up the rename UI\n    * [rss feeds](#rss-feeds) - monitor a folder with your RSS reader\n    * [media player](#media-player) - plays almost every audio format there is\n        * [audio equalizer](#audio-equalizer) - and [dynamic range compressor](https://en.wikipedia.org/wiki/Dynamic_range_compression)\n        * [fix unreliable playback on android](#fix-unreliable-playback-on-android) - due to phone / app settings\n    * [markdown viewer](#markdown-viewer) - and there are *two* editors\n        * [markdown vars](#markdown-vars) - dynamic docs with serverside variable expansion\n    * [other tricks](#other-tricks)\n    * [searching](#searching) - search by size, date, path/name, mp3-tags, ...\n* [server config](#server-config) - using arguments or config files, or a mix of both\n    * [zeroconf](#zeroconf) - announce enabled services on the LAN ([pic](https://user-images.githubusercontent.com/241032/215344737-0eae8d98-9496-4256-9aa8-cd2f6971810d.png))\n        * [mdns](#mdns) - LAN domain-name and feature announcer\n        * [ssdp](#ssdp) - windows-explorer announcer\n    * [qr-code](#qr-code) - print a qr-code [(screenshot)](https://user-images.githubusercontent.com/241032/194728533-6f00849b-c6ac-43c6-9359-83e454d11e00.png) for quick access\n    * [ftp server](#ftp-server) - an FTP server can be started using `--ftp 3921`\n    * [webdav server](#webdav-server) - with read-write support\n        * [connecting to webdav from windows](#connecting-to-webdav-from-windows) - using the GUI\n    * [tftp server](#tftp-server) - a TFTP server (read/write) can be started using `--tftp 3969`\n    * [smb server](#smb-server) - unsafe, slow, not recommended for wan\n    * [browser ux](#browser-ux) - tweaking the ui\n    * [opengraph](#opengraph) - discord and social-media embeds\n    * [file deduplication](#file-deduplication) - enable symlink-based upload deduplication\n    * [file indexing](#file-indexing) - enable music search, upload-undo, and better dedup\n        * [exclude-patterns](#exclude-patterns) - to save some time\n        * [filesystem guards](#filesystem-guards) - avoid traversing into other filesystems\n        * [periodic rescan](#periodic-rescan) - filesystem monitoring\n    * [upload rules](#upload-rules) - set upload rules using volflags\n    * [compress uploads](#compress-uploads) - files can be autocompressed on upload\n    * [other flags](#other-flags)\n    * [database location](#database-location) - in-volume (`.hist/up2k.db`, default) or somewhere else\n    * [metadata from audio files](#metadata-from-audio-files) - set `-e2t` to index tags on upload\n    * [file parser plugins](#file-parser-plugins) - provide custom parsers to index additional tags\n    * [event hooks](#event-hooks) - trigger a program on uploads, renames etc ([examples](./bin/hooks/))\n        * [upload events](#upload-events) - the older, more powerful approach ([examples](./bin/mtag/))\n    * [handlers](#handlers) - redefine behavior with plugins ([examples](./bin/handlers/))\n    * [ip auth](#ip-auth) - autologin based on IP range (CIDR)\n    * [identity providers](#identity-providers) - replace copyparty passwords with oauth and such\n    * [user-changeable passwords](#user-changeable-passwords) - if permitted, users can change their own passwords\n    * [using the cloud as storage](#using-the-cloud-as-storage) - connecting to an aws s3 bucket and similar\n    * [hiding from google](#hiding-from-google) - tell search engines you don't wanna be indexed\n    * [themes](#themes)\n    * [complete examples](#complete-examples)\n    * [listen on port 80 and 443](#listen-on-port-80-and-443) - become a *real* webserver\n    * [reverse-proxy](#reverse-proxy) - running copyparty next to other websites\n        * [real-ip](#real-ip) - teaching copyparty how to see client IPs\n    * [prometheus](#prometheus) - metrics/stats can be enabled\n    * [other extremely specific features](#other-extremely-specific-features) - you'll never find a use for these\n        * [custom mimetypes](#custom-mimetypes) - change the association of a file extension\n        * [feature chickenbits](#feature-chickenbits) - buggy feature? rip it out\n* [packages](#packages) - the party might be closer than you think\n    * [arch package](#arch-package) - now [available on aur](https://aur.archlinux.org/packages/copyparty) maintained by [@icxes](https://github.com/icxes)\n    * [fedora package](#fedora-package) - does not exist yet\n    * [nix package](#nix-package) - `nix profile install github:9001/copyparty`\n    * [nixos module](#nixos-module)\n* [browser support](#browser-support) - TLDR: yes\n* [client examples](#client-examples) - interact with copyparty using non-browser clients\n    * [folder sync](#folder-sync) - sync folders to/from copyparty\n    * [mount as drive](#mount-as-drive) - a remote copyparty server as a local filesystem\n* [android app](#android-app) - upload to copyparty with one tap\n* [iOS shortcuts](#iOS-shortcuts) - there is no iPhone app, but\n* [performance](#performance) - defaults are usually fine - expect `8 GiB/s` download, `1 GiB/s` upload\n    * [client-side](#client-side) - when uploading files\n* [security](#security) - there is a [discord server](https://discord.gg/25J8CdTT6G)\n    * [gotchas](#gotchas) - behavior that might be unexpected\n    * [cors](#cors) - cross-site request config\n    * [filekeys](#filekeys) - prevent filename bruteforcing\n        * [dirkeys](#dirkeys) - share specific folders in a volume\n    * [password hashing](#password-hashing) - you can hash passwords\n    * [https](#https) - both HTTP and HTTPS are accepted\n* [recovering from crashes](#recovering-from-crashes)\n    * [client crashes](#client-crashes)\n        * [firefox wsod](#firefox-wsod) - firefox 87 can crash during uploads\n* [HTTP API](#HTTP-API) - see [devnotes](./docs/devnotes.md#http-api)\n* [dependencies](#dependencies) - mandatory deps\n    * [optional dependencies](#optional-dependencies) - install these to enable bonus features\n        * [dependency chickenbits](#dependency-chickenbits) - prevent loading an optional dependency\n    * [optional gpl stuff](#optional-gpl-stuff)\n* [sfx](#sfx) - the self-contained \"binary\" (recommended!)\n    * [copyparty.exe](#copypartyexe) - download [copyparty.exe](https://github.com/9001/copyparty/releases/latest/download/copyparty.exe) (win8+) or [copyparty32.exe](https://github.com/9001/copyparty/releases/latest/download/copyparty32.exe) (win7+)\n    * [zipapp](#zipapp) - another emergency alternative, [copyparty.pyz](https://github.com/9001/copyparty/releases/latest/download/copyparty.pyz)\n* [install on android](#install-on-android)\n* [reporting bugs](#reporting-bugs) - ideas for context to include, and where to submit them\n* [devnotes](#devnotes) - for build instructions etc, see [./docs/devnotes.md](./docs/devnotes.md)\n\n\n## quickstart\n\njust run **[copyparty-sfx.py](https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py)** -- that's it! \n\n* or install through [pypi](https://pypi.org/project/copyparty/): `python3 -m pip install --user -U copyparty`\n* or if you cannot install python, you can use [copyparty.exe](#copypartyexe) instead\n* or install [on arch](#arch-package)  [on NixOS](#nixos-module)  [through nix](#nix-package)\n* or if you are on android, [install copyparty in termux](#install-on-android)\n* or if your computer is messed up and nothing else works, [try the pyz](#zipapp)\n* or if you prefer to [use docker](./scripts/docker/)  you can do that too\n  * docker has all deps built-in, so skip this step:\n\nenable thumbnails (images/audio/video), media indexing, and audio transcoding by installing some recommended deps:\n\n* **Alpine:** `apk add py3-pillow ffmpeg`\n* **Debian:** `apt install --no-install-recommends python3-pil ffmpeg`\n* **Fedora:** rpmfusion + `dnf install python3-pillow ffmpeg --allowerasing`\n* **FreeBSD:** `pkg install py39-sqlite3 py39-pillow ffmpeg`\n* **MacOS:** `port install py-Pillow ffmpeg`\n* **MacOS** (alternative): `brew install pillow ffmpeg`\n* **Windows:** `python -m pip install --user -U Pillow`\n  * install python and ffmpeg manually; do not use `winget` or `Microsoft Store` (it breaks $PATH)\n  * copyparty.exe comes with `Pillow` and only needs `ffmpeg`\n* see [optional dependencies](#optional-dependencies) to enable even more features\n\nrunning copyparty without arguments (for example doubleclicking it on Windows) will give everyone read/write access to the current folder; you may want [accounts and volumes](#accounts-and-volumes)\n\nor see [some usage examples](#complete-examples) for inspiration, or the [complete windows example](./docs/examples/windows.md)\n\nsome recommended options:\n* `-e2dsa` enables general [file indexing](#file-indexing)\n* `-e2ts` enables audio metadata indexing (needs either FFprobe or Mutagen)\n* `-v /mnt/music:/music:r:rw,foo -a foo:bar` shares `/mnt/music` as `/music`, `r`eadable by anyone, and read-write for user `foo`, password `bar`\n  * replace `:r:rw,foo` with `:r,foo` to only make the folder readable by `foo` and nobody else\n  * see [accounts and volumes](#accounts-and-volumes) (or `--help-accounts`) for the syntax and other permissions\n\n\n### at home\n\nmake it accessible over the internet  by starting a [cloudflare quicktunnel](https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/do-more-with-tunnels/trycloudflare/) like so:\n\nfirst download [cloudflared](https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/downloads/) and then start the tunnel with `cloudflared tunnel --url http://127.0.0.1:3923`\n\nas the tunnel starts, it will show a URL which you can share to let anyone browse your stash or upload files to you\n\nsince people will be connecting through cloudflare, run copyparty with `--xff-hdr cf-connecting-ip` to detect client IPs correctly\n\n\n### on servers\n\nyou may also want these, especially on servers:\n\n* [contrib/systemd/copyparty.service](contrib/systemd/copyparty.service) to run copyparty as a systemd service (see guide inside)\n* [contrib/systemd/prisonparty.service](contrib/systemd/prisonparty.service) to run it in a chroot (for extra security)\n* [contrib/openrc/copyparty](contrib/openrc/copyparty) to run copyparty on Alpine / Gentoo\n* [contrib/rc/copyparty](contrib/rc/copyparty) to run copyparty on FreeBSD\n* [nixos module](#nixos-module) to run copyparty on NixOS hosts\n* [contrib/nginx/copyparty.conf](contrib/nginx/copyparty.conf) to [reverse-proxy](#reverse-proxy) behind nginx (for better https)\n\nand remember to open the ports you want; here's a complete example including every feature copyparty has to offer:\n```\nfirewall-cmd --permanent --add-port={80,443,3921,3923,3945,3990}/tcp  # --zone=libvirt\nfirewall-cmd --permanent --add-port=12000-12099/tcp  # --zone=libvirt\nfirewall-cmd --permanent --add-port={69,1900,3969,5353}/udp  # --zone=libvirt\nfirewall-cmd --reload\n```\n(69:tftp, 1900:ssdp, 3921:ftp, 3923:http/https, 3945:smb, 3969:tftp, 3990:ftps, 5353:mdns, 12000:passive-ftp)\n\n\n## features\n\nalso see [comparison to similar software](./docs/versus.md)\n\n* backend stuff\n  *  IPv6 + unix-sockets\n  *  [multiprocessing](#performance) (actual multithreading)\n  *  volumes (mountpoints)\n  *  [accounts](#accounts-and-volumes)\n  *  [ftp server](#ftp-server)\n  *  [tftp server](#tftp-server)\n  *  [webdav server](#webdav-server)\n  *  [smb/cifs server](#smb-server)\n  *  [qr-code](#qr-code) for quick access\n  *  [upnp / zeroconf / mdns / ssdp](#zeroconf)\n  *  [event hooks](#event-hooks) / script runner\n  *  [reverse-proxy support](https://github.com/9001/copyparty#reverse-proxy)\n* upload\n  *  basic: plain multipart, ie6 support\n  *  [up2k](#uploading): js, resumable, multithreaded\n    * **no filesize limit!** even on Cloudflare\n  *  stash: simple PUT filedropper\n  *  filename randomizer\n  *  write-only folders\n  *  [unpost](#unpost): undo/delete accidental uploads\n  *  [self-destruct](#self-destruct) (specified server-side or client-side)\n  *  [race the beam](#race-the-beam) (almost like peer-to-peer)\n  *  symlink/discard duplicates (content-matching)\n* download\n  *  single files in browser\n  *  [folders as zip / tar files](#zip-downloads)\n  *  [FUSE client](https://github.com/9001/copyparty/tree/hovudstraum/bin#partyfusepy) (read-only)\n* browser\n  *  [navpane](#navpane) (directory tree sidebar)\n  *  file manager (cut/paste, delete, [batch-rename](#batch-rename))\n  *  audio player (with [OS media controls](https://user-images.githubusercontent.com/241032/215347492-b4250797-6c90-4e09-9a4c-721edf2fb15c.png) and opus/mp3 transcoding)\n    *  play video files as audio (converted on server)\n  *  image gallery with webm player\n  *  textfile browser with syntax hilighting\n  *  [thumbnails](#thumbnails)\n    *  ...of images using Pillow, pyvips, or FFmpeg\n    *  ...of videos using FFmpeg\n    *  ...of audio (spectrograms) using FFmpeg\n    *  cache eviction (max-age; maybe max-size eventually)\n  *  multilingual UI (english, norwegian, chinese, [add your own](./docs/rice/#translations)))\n  *  SPA (browse while uploading)\n* server indexing\n  *  [locate files by contents](#file-search)\n  *  search by name/path/date/size\n  *  [search by ID3-tags etc.](#searching)\n* client support\n  *  [folder sync](#folder-sync)\n  *  [curl-friendly](https://user-images.githubusercontent.com/241032/215322619-ea5fd606-3654-40ad-94ee-2bc058647bb2.png)\n  *  [opengraph](#opengraph) (discord embeds)\n* markdown\n  *  [viewer](#markdown-viewer)\n  *  editor (sure why not)\n  *  [variables](#markdown-vars)\n\nPS: something missing? post any crazy ideas you've got as a [feature request](https://github.com/9001/copyparty/issues/new?assignees=9001&labels=enhancement&template=feature_request.md) or [discussion](https://github.com/9001/copyparty/discussions/new?category=ideas) \n\n\n## testimonials\n\nsmall collection of user feedback\n\n`good enough`, `surprisingly correct`, `certified good software`, `just works`, `why`, `wow this is better than nextcloud`\n\n\n# motivations\n\nproject goals / philosophy\n\n* inverse linux philosophy -- do all the things, and do an *okay* job\n  * quick drop-in service to get a lot of features in a pinch\n  * some of [the alternatives](./docs/versus.md) might be a better fit for you\n* run anywhere, support everything\n  * as many web-browsers and python versions as possible\n    * every browser should at least be able to browse, download, upload files\n    * be a good emergency solution for transferring stuff between ancient boxes\n  * minimal dependencies\n    * but optional dependencies adding bonus-features are ok\n    * everything being plaintext makes it possible to proofread for malicious code\n  * no preparations / setup necessary, just run the sfx (which is also plaintext)\n* adaptable, malleable, hackable\n  * no build steps; modify the js/python without needing node.js or anything like that\n\n\n## notes\n\ngeneral notes:\n* paper-printing is affected by dark/light-mode! use lightmode for color, darkmode for grayscale\n  * because no browsers currently implement the media-query to do this properly orz\n\nbrowser-specific:\n* iPhone/iPad: use Firefox to download files\n* Android-Chrome: increase \"parallel uploads\" for higher speed (android bug)\n* Android-Firefox: takes a while to select files (their fix for )\n* Desktop-Firefox: ~~may use gigabytes of RAM if your files are massive~~ *seems to be OK now*\n* Desktop-Firefox: [may stop you from unplugging USB flashdrives](https://bugzilla.mozilla.org/show_bug.cgi?id=1792598) until you visit `about:memory` and click `Minimize memory usage`\n\nserver-os-specific:\n* RHEL8 / Rocky8: you can run copyparty using `/usr/libexec/platform-python`\n\nserver notes:\n* pypy is supported but regular cpython is faster if you enable the database\n\n\n# bugs\n\nroughly sorted by chance of encounter\n\n* general:\n  * `--th-ff-jpg` may fix video thumbnails on some FFmpeg versions (macos, some linux)\n  * `--th-ff-swr` may fix audio thumbnails on some FFmpeg versions\n  * if the `up2k.db` (filesystem index) is on a samba-share or network disk, you'll get unpredictable behavior if the share is disconnected for a bit\n    * use `--hist` or the `hist` volflag (`-v [...]:c,hist=/tmp/foo`) to place the db on a local disk instead\n  * all volumes must exist / be available on startup; up2k (mtp especially) gets funky otherwise\n  * probably more, pls let me know\n\n* python 3.4 and older (including 2.7):\n  * many rare and exciting edge-cases because [python didn't handle EINTR yet](https://peps.python.org/pep-0475/)\n    * downloads from copyparty may suddenly fail, but uploads *should* be fine\n\n* python 2.7 on Windows:\n  * cannot index non-ascii filenames with `-e2d`\n  * cannot handle filenames with mojibake\n\nif you have a new exciting bug to share, see [reporting bugs](#reporting-bugs)\n\n\n## not my bugs\n\nsame order here too\n\n* [Chrome issue 1317069](https://bugs.chromium.org/p/chromium/issues/detail?id=1317069) -- if you try to upload a folder which contains symlinks by dragging it into the browser, the symlinked files will not get uploaded\n\n* [Chrome issue 1352210](https://bugs.chromium.org/p/chromium/issues/detail?id=1352210) -- plaintext http may be faster at filehashing than https (but also extremely CPU-intensive)\n\n* [Firefox issue 1790500](https://bugzilla.mozilla.org/show_bug.cgi?id=1790500) -- entire browser can crash after uploading ~4000 small files\n\n* Android: music playback randomly stops due to [battery usage settings](#fix-unreliable-playback-on-android)\n\n* iPhones: the volume control doesn't work because [apple doesn't want it to](https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/Using_HTML5_Audio_Video/Device-SpecificConsiderations/Device-SpecificConsiderations.html#//apple_ref/doc/uid/TP40009523-CH5-SW11)\n  * `AudioContext` will probably never be a viable workaround as apple introduces new issues faster than they fix current ones\n\n* iPhones: the preload feature (in the media-player-options tab) can cause a tiny audio glitch 20sec before the end of each song, but disabling it may cause worse iOS bugs to appear instead\n  * just a hunch, but disabling preloading may cause playback to stop entirely, or possibly mess with bluetooth speakers\n  * tried to add a tooltip regarding this but looks like apple broke my tooltips\n\n* Windows: folders cannot be accessed if the name ends with `.`\n  * python or windows bug\n\n* Windows: msys2-python 3.8.6 occasionally throws `RuntimeError: release unlocked lock` when leaving a scoped mutex in up2k\n  * this is an msys2 bug, the regular windows edition of python is fine\n\n* VirtualBox: sqlite throws `Disk I/O Error` when running in a VM and the up2k database is in a vboxsf\n  * use `--hist` or the `hist` volflag (`-v [...]:c,hist=/tmp/foo`) to place the db inside the vm instead\n  * also happens on mergerfs, so put the db elsewhere\n\n* Ubuntu: dragging files from certain folders into firefox or chrome is impossible\n  * due to snap security policies -- see `snap connections firefox` for the allowlist, `removable-media` permits all of `/mnt` and `/media` apparently\n\n\n# breaking changes\n\nupgrade notes\n\n* `1.9.16` (2023-11-04):\n  * `--stats`/prometheus: `cpp_bans` renamed to `cpp_active_bans`, and that + `cpp_uptime` are gauges\n* `1.6.0` (2023-01-29):\n  * http-api: delete/move is now `POST` instead of `GET`\n  * everything other than `GET` and `HEAD` must pass [cors validation](#cors)\n* `1.5.0` (2022-12-03): [new chunksize formula](https://github.com/9001/copyparty/commit/54e1c8d261df) for files larger than 128 GiB\n  * **users:** upgrade to the latest [cli uploader](https://github.com/9001/copyparty/blob/hovudstraum/bin/u2c.py) if you use that\n  * **devs:** update third-party up2k clients (if those even exist)\n\n\n# FAQ\n\n\"frequently\" asked questions\n\n* is it possible to block read-access to folders unless you know the exact URL for a particular file inside?\n  * yes, using the [`g` permission](#accounts-and-volumes), see the examples there\n  * you can also do this with linux filesystem permissions; `chmod 111 music` will make it possible to access files and folders inside the `music` folder but not list the immediate contents -- also works with other software, not just copyparty\n\n* can I link someone to a password-protected volume/file by including the password in the URL?\n  * yes, by adding `?pw=hunter2` to the end; replace `?` with `&` if there are parameters in the URL already, meaning it contains a `?` near the end\n\n* how do I stop `.hist` folders from appearing everywhere on my HDD?\n  * by default, a `.hist` folder is created inside each volume for the filesystem index, thumbnails, audio transcodes, and markdown document history. Use the `--hist` global-option or the `hist` volflag to move it somewhere else; see [database location](#database-location)\n\n* can I make copyparty download a file to my server if I give it a URL?\n  * yes, using [hooks](https://github.com/9001/copyparty/blob/hovudstraum/bin/hooks/wget.py)\n\n* firefox refuses to connect over https, saying \"Secure Connection Failed\" or \"SEC_ERROR_BAD_SIGNATURE\", but the usual button to \"Accept the Risk and Continue\" is not shown\n  * firefox has corrupted its certstore; fix this by exiting firefox, then find and delete the file named `cert9.db` somewhere in your firefox profile folder\n\n* the server keeps saying `thank you for playing` when I try to access the website\n  * you've gotten banned for malicious traffic! if this happens by mistake, and you're running a reverse-proxy and/or something like cloudflare, see [real-ip](#real-ip) on how to fix this\n\n* copyparty seems to think I am using http, even though the URL is https\n  * your reverse-proxy is not sending the `X-Forwarded-Proto: https` header; this could be because your reverse-proxy itself is confused. Ensure that none of the intermediates (such as cloudflare) are terminating https before the traffic hits your entrypoint\n\n* i want to learn python and/or programming and am considering looking at the copyparty source code in that occasion\n  * ```bash\n     _|  _      __   _  _|_\n    (_| (_)     | | (_)  |_\n    ```\n\n\n# accounts and volumes\n\nper-folder, per-user permissions  - if your setup is getting complex, consider making a [config file](./docs/example.conf) instead of using arguments\n* much easier to manage, and you can modify the config at runtime with `systemctl reload copyparty` or more conveniently using the `[reload cfg]` button in the control-panel (if the user has `a`/admin in any volume)\n  * changes to the `[global]` config section requires a restart to take effect\n\na quick summary can be seen using `--help-accounts`\n\nconfiguring accounts/volumes with arguments:\n* `-a usr:pwd` adds account `usr` with password `pwd`\n* `-v .::r` adds current-folder `.` as the webroot, `r`eadable by anyone\n  * the syntax is `-v src:dst:perm:perm:...` so local-path, url-path, and one or more permissions to set\n  * granting the same permissions to multiple accounts:  \n    `-v .::r,usr1,usr2:rw,usr3,usr4` = usr1/2 read-only, 3/4 read-write\n\npermissions:\n* `r` (read): browse folder contents, download files, download as zip/tar, see filekeys/dirkeys\n* `w` (write): upload files, move files *into* this folder\n* `m` (move): move files/folders *from* this folder\n* `d` (delete): delete files/folders\n* `.` (dots): user can ask to show dotfiles in directory listings\n* `g` (get): only download files, cannot see folder contents or zip/tar\n* `G` (upget): same as `g` except uploaders get to see their own [filekeys](#filekeys) (see `fk` in examples below)\n* `h` (html): same as `g` except folders return their index.html, and filekeys are not necessary for index.html\n* `a` (admin): can see upload time, uploader IPs, config-reload\n* `A` (\"all\"): same as `rwmda.` (read/write/move/delete/admin/dotfiles)\n\nexamples:\n* add accounts named u1, u2, u3 with passwords p1, p2, p3: `-a u1:p1 -a u2:p2 -a u3:p3`\n* make folder `/srv` the root of the filesystem, read-only by anyone: `-v /srv::r`\n* make folder `/mnt/music` available at `/music`, read-only for u1 and u2, read-write for u3: `-v /mnt/music:music:r,u1,u2:rw,u3`\n  * unauthorized users accessing the webroot can see that the `music` folder exists, but cannot open it\n* make folder `/mnt/incoming` available at `/inc`, write-only for u1, read-move for u2: `-v /mnt/incoming:inc:w,u1:rm,u2`\n  * unauthorized users accessing the webroot can see that the `inc` folder exists, but cannot open it\n  * `u1` can open the `inc` folder, but cannot see the contents, only upload new files to it\n  * `u2` can browse it and move files *from* `/inc` into any folder where `u2` has write-access\n* make folder `/mnt/ss` available at `/i`, read-write for u1, get-only for everyone else, and enable filekeys: `-v /mnt/ss:i:rw,u1:g:c,fk=4`\n  * `c,fk=4` sets the `fk` ([filekey](#filekeys)) volflag to 4, meaning each file gets a 4-character accesskey\n  * `u1` can upload files, browse the folder, and see the generated filekeys\n  * other users cannot browse the folder, but can access the files if they have the full file URL with the filekey\n  * replacing the `g` permission with `wg` would let anonymous users upload files, but not see the required filekey to access it\n  * replacing the `g` permission with `wG` would let anonymous users upload files, receiving a working direct link in return\n\nanyone trying to bruteforce a password gets banned according to `--ban-pw`; default is 24h ban for 9 failed attempts in 1 hour\n\n\n## shadowing\n\nhiding specific subfolders  by mounting another volume on top of them\n\nfor example `-v /mnt::r -v /var/empty:web/certs:r` mounts the server folder `/mnt` as the webroot, but another volume is mounted at `/web/certs` -- so visitors can only see the contents of `/mnt` and `/mnt/web` (at URLs `/` and `/web`), but not `/mnt/web/certs` because URL `/web/certs` is mapped to `/var/empty`\n\n\n## dotfiles\n\nunix-style hidden files/folders  by starting the name with a dot\n\nanyone can access these if they know the name, but they normally don't appear in directory listings\n\na client can request to see dotfiles in directory listings if global option `-ed` is specified, or the volume has volflag `dots`, or the user has permission `.`\n\ndotfiles do not appear in search results unless one of the above is true, **and** the global option / volflag `dotsrch` is set\n\n\n# the browser\n\naccessing a copyparty server using a web-browser\n\n![copyparty-browser-fs8](https://user-images.githubusercontent.com/241032/192042695-522b3ec7-6845-494a-abdb-d1c0d0e23801.png)\n\n\n## tabs\n\nthe main tabs in the ui\n* `[]` [search](#searching) by size, date, path/name, mp3-tags ...\n* `[]` [unpost](#unpost): undo/delete accidental uploads\n* `[]` and `[]` are the [uploaders](#uploading)\n* `[]` mkdir: create directories\n* `[]` new-md: create a new markdown document\n* `[]` send-msg: either to server-log or into textfiles if `--urlform save`\n* `[]` audio-player config options\n* `[]` general client config options\n\n\n## hotkeys\n\nthe browser has the following hotkeys  (always qwerty)\n* `?` show hotkeys help\n* `B` toggle breadcrumbs / [navpane](#navpane)\n* `I/K` prev/next folder\n* `M` parent folder (or unexpand current)\n* `V` toggle folders / textfiles in the navpane\n* `G` toggle list / [grid view](#thumbnails) -- same as `` bottom-right\n* `T` toggle thumbnails / icons\n* `ESC` close various things\n* `ctrl-K` delete selected files/folders\n* `ctrl-X` cut selected files/folders\n* `ctrl-V` paste\n* `Y` download selected files\n* `F2` [rename](#batch-rename) selected file/folder\n* when a file/folder is selected (in not-grid-view):\n  * `Up/Down` move cursor\n  * shift+`Up/Down` select and move cursor\n  * ctrl+`Up/Down` move cursor and scroll viewport\n  * `Space` toggle file selection\n  * `Ctrl-A` toggle select all\n* when a textfile is open:\n  * `I/K` prev/next textfile\n  * `S` toggle selection of open file\n  * `M` close textfile\n* when playing audio:\n  * `J/L` prev/next song\n  * `U/O` skip 10sec back/forward\n  * `0..9` jump to 0%..90%\n  * `P` play/pause (also starts playing the folder)\n  * `Y` download file\n* when viewing images / playing videos:\n  * `J/L, Left/Right` prev/next file\n  * `Home/End` first/last file\n  * `F` toggle fullscreen\n  * `S` toggle selection\n  * `R` rotate clockwise (shift=ccw)\n  * `Y` download file\n  * `Esc` close viewer\n  * videos:\n    * `U/O` skip 10sec back/forward\n    * `0..9` jump to 0%..90%\n    * `P/K/Space` play/pause\n    * `M` mute\n    * `C` continue playing next video\n    * `V` loop entire file\n    * `[` loop range (start)\n    * `]` loop range (end)\n* when the navpane is open:\n  * `A/D` adjust tree width\n* in the [grid view](#thumbnails):\n  * `S` toggle multiselect\n  * shift+`A/D` zoom\n* in the markdown editor:\n  * `^s` save\n  * `^h` header\n  * `^k` autoformat table\n  * `^u` jump to next unicode character\n  * `^e` toggle editor / preview\n  * `^up, ^down` jump paragraphs\n\n\n## navpane\n\nswitching between breadcrumbs or navpane\n\nclick the `` or pressing the `B` hotkey to toggle between breadcrumbs path (default), or a navpane (tree-browser sidebar thing)\n\n* `[+]` and `[-]` (or hotkeys `A`/`D`) adjust the size\n* `[]` jumps to the currently open folder\n* `[]` toggles between showing folders and textfiles\n* `[]` shows the name of all parent folders in a docked panel\n* `[a]` toggles automatic widening as you go deeper\n* `[]` toggles wordwrap\n* `[]` show full name on hover (if wordwrap is off)\n\n\n## thumbnails\n\npress `g` or `` to toggle grid-view instead of the file listing  and `t` toggles icons / thumbnails\n* can be made default globally with `--grid` or per-volume with volflag `grid`\n\n![copyparty-thumbs-fs8](https://user-images.githubusercontent.com/241032/129636211-abd20fa2-a953-4366-9423-1c88ebb96ba9.png)\n\nit does static images with Pillow / pyvips / FFmpeg, and uses FFmpeg for video files, so you may want to `--no-thumb` or maybe just `--no-vthumb` depending on how dangerous your users are\n* pyvips is 3x faster than Pillow, Pillow is 3x faster than FFmpeg\n* disable thumbnails for specific volumes with volflag `dthumb` for all, or `dvthumb` / `dathumb` / `dithumb` for video/audio/images only\n\naudio files are converted into spectrograms using FFmpeg unless you `--no-athumb` (and some FFmpeg builds may need `--th-ff-swr`)\n\nimages with the following names (see `--th-covers`) become the thumbnail of the folder they're in: `folder.png`, `folder.jpg`, `cover.png`, `cover.jpg`\n* the order is significant, so if both `cover.png` and `folder.jpg` exist in a folder, it will pick the first matching `--th-covers` entry (`folder.jpg`)\n* and, if you enable [file indexing](#file-indexing), it will also try those names as dotfiles (`.folder.jpg` and so), and then fallback on the first picture in the folder (if it has any pictures at all)\n\nenabling `multiselect` lets you click files to select them, and then shift-click another file for range-select\n* `multiselect` is mostly intended for phones/tablets, but the `sel` option in the `[] settings` tab is better suited for desktop use, allowing selection by CTRL-clicking and range-selection with SHIFT-click, all without affecting regular clicking\n  * the `sel` option can be made default globally with `--gsel` or per-volume with volflag `gsel`\n\n\n## zip downloads\n\ndownload folders (or file selections) as `zip` or `tar` files\n\nselect which type of archive you want in the `[] config` tab:\n\n| name | url-suffix | description |\n|--|--|--|\n| `tar` | `?tar` | plain gnutar, works great with `curl \\| tar -xv` |\n| `pax` | `?tar=pax` | pax-format tar, futureproof, not as fast |\n| `tgz` | `?tar=gz` | gzip compressed gnu-tar (slow), for `curl \\| tar -xvz` |\n| `txz` | `?tar=xz` | gnu-tar with xz / lzma compression (v.slow) |\n| `zip` | `?zip=utf8` | works everywhere, glitchy filenames on win7 and older |\n| `zip_dos` | `?zip` | traditional cp437 (no unicode) to fix glitchy filenames |\n| `zip_crc` | `?zip=crc` | cp437 with crc32 computed early for truly ancient software |\n\n* gzip default level is `3` (0=fast, 9=best), change with `?tar=gz:9`\n* xz default level is `1` (0=fast, 9=best), change with `?tar=xz:9`\n* bz2 default level is `2` (1=fast, 9=best), change with `?tar=bz2:9`\n* hidden files ([dotfiles](#dotfiles)) are excluded unless account is allowed to list them\n  * `up2k.db` and `dir.txt` is always excluded\n* bsdtar supports streaming unzipping: `curl foo?zip=utf8 | bsdtar -xv`\n  * good, because copyparty's zip is faster than tar on small files\n* `zip_crc` will take longer to download since the server has to read each file twice\n  * this is only to support MS-DOS PKZIP v2.04g (october 1993) and older\n    * how are you accessing copyparty actually\n\nyou can also zip a selection of files or folders by clicking them in the browser, that brings up a selection editor and zip button in the bottom right\n\n![copyparty-zipsel-fs8](https://user-images.githubusercontent.com/241032/129635374-e5136e01-470a-49b1-a762-848e8a4c9cdc.png)\n\ncool trick: download a folder by appending url-params `?tar&opus` or `?tar&mp3` to transcode all audio files (except aac|m4a|mp3|ogg|opus|wma) to opus/mp3 before they're added to the archive\n* super useful if you're 5 minutes away from takeoff and realize you don't have any music on your phone but your server only has flac files and downloading those will burn through all your data + there wouldn't be enough time anyways\n* and url-params `&j` / `&w` produce jpeg/webm thumbnails/spectrograms instead of the original audio/video/images (`&p` for audio waveforms)\n  * can also be used to pregenerate thumbnails; combine with `--th-maxage=9999999` or `--th-clean=0`\n\n\n## uploading\n\ndrag files/folders into the web-browser to upload\n\ndragdrop is the recommended way, but you may also:\n\n* select some files (not folders) in your file explorer and press CTRL-V inside the browser window\n* use the [command-line uploader](https://github.com/9001/copyparty/tree/hovudstraum/bin#u2cpy)\n* upload using [curl or sharex](#client-examples)\n\nwhen uploading files through dragdrop or CTRL-V, this initiates an upload using `up2k`; there are two browser-based uploaders available:\n* `[] bup`, the basic uploader, supports almost every browser since netscape 4.0\n* `[] up2k`, the good / fancy one\n\nNB: you can undo/delete your own uploads with `[]` [unpost](#unpost) (and this is also where you abort unfinished uploads, but you have to refresh the page first)\n\nup2k has several advantages:\n* you can drop folders into the browser (files are added recursively)\n* files are processed in chunks, and each chunk is checksummed\n  * uploads autoresume if they are interrupted by network issues\n  * uploads resume if you reboot your browser or pc, just upload the same files again\n  * server detects any corruption; the client reuploads affected chunks\n  * the client doesn't upload anything that already exists on the server\n  * no filesize limit, even when a proxy limits the request size (for example Cloudflare)\n* much higher speeds than ftp/scp/tarpipe on some internet connections (mainly american ones) thanks to parallel connections\n* the last-modified timestamp of the file is preserved\n\n> it is perfectly safe to restart / upgrade copyparty while someone is uploading to it!  \n> all known up2k clients will resume just fine \n\nsee [up2k](./docs/devnotes.md#up2k) for details on how it works, or watch a [demo video](https://a.ocv.me/pub/demo/pics-vids/#gf-0f6f5c0d)\n\n![copyparty-upload-fs8](https://user-images.githubusercontent.com/241032/129635371-48fc54ca-fa91-48e3-9b1d-ba413e4b68cb.png)\n\n**protip:** you can avoid scaring away users with [contrib/plugins/minimal-up2k.js](contrib/plugins/minimal-up2k.js) which makes it look [much simpler](https://user-images.githubusercontent.com/241032/118311195-dd6ca380-b4ef-11eb-86f3-75a3ff2e1332.png)\n\n**protip:** if you enable `favicon` in the `[] settings` tab (by typing something into the textbox), the icon in the browser tab will indicate upload progress -- also, the `[]` and/or `[]` switches enable visible and/or audible notifications on upload completion\n\nthe up2k UI is the epitome of polished intuitive experiences:\n* \"parallel uploads\" specifies how many chunks to upload at the same time\n* `[]` analysis of other files should continue while one is uploading\n* `[]` shows a simpler UI for faster uploads from slow devices\n* `[]` generate random filenames during upload\n* `[]` preserve last-modified timestamps; server times will match yours\n* `[]` switch between upload and [file-search](#file-search) mode\n  * ignore `[]` if you add files by dragging them into the browser\n\nand then theres the tabs below it,\n* `[ok]` is the files which completed successfully\n* `[ng]` is the ones that failed / got rejected (already exists, ...)\n* `[done]` shows a combined list of `[ok]` and `[ng]`, chronological order\n* `[busy]` files which are currently hashing, pending-upload, or uploading\n  * plus up to 3 entries each from `[done]` and `[que]` for context\n* `[que]` is all the files that are still queued\n\nnote that since up2k has to read each file twice, `[] bup` can *theoretically* be up to 2x faster in some extreme cases (files bigger than your ram, combined with an internet connection faster than the read-speed of your HDD, or if you're uploading from a cuo2duo)\n\nif you are resuming a massive upload and want to skip hashing the files which already finished, you can enable `turbo` in the `[] config` tab, but please read the tooltip on that button\n\nif the server is behind a proxy which imposes a request-size limit, you can configure up2k to sneak below the limit with server-option `--u2sz` (the default is 96 MiB to support Cloudflare)\n\n\n### file-search\n\ndropping files into the browser also lets you see if they exist on the server\n\n![copyparty-fsearch-fs8](https://user-images.githubusercontent.com/241032/129635361-c79286f0-b8f1-440e-aaf4-6e929428fac9.png)\n\nwhen you drag/drop files into the browser, you will see two dropzones: `Upload` and `Search`\n\n> on a phone? toggle the `[]` switch green before tapping the big yellow Search button to select your files\n\nthe files will be hashed on the client-side, and each hash is sent to the server, which checks if that file exists somewhere\n\nfiles go into `[ok]` if they exist (and you get a link to where it is), otherwise they land in `[ng]`\n* the main reason filesearch is combined with the uploader is cause the code was too spaghetti to separate it out somewhere else, this is no longer the case but now i've warmed up to the idea too much\n\n\n### unpost\n\nundo/delete accidental uploads\n\n![copyparty-unpost-fs8](https://user-images.githubusercontent.com/241032/129635368-3afa6634-c20f-418c-90dc-ec411f3b3897.png)\n\nyou can unpost even if you don't have regular move/delete access, however only for files uploaded within the past `--unpost` seconds (default 12 hours) and the server must be running with `-e2d`\n\n\n### self-destruct\n\nuploads can be given a lifetime,  after which they expire / self-destruct\n\nthe feature must be enabled per-volume with the `lifetime` [upload rule](#upload-rules) which sets the upper limit for how long a file gets to stay on the server\n\nclients can specify a shorter expiration time using the [up2k ui](#uploading) -- the relevant options become visible upon navigating into a folder with `lifetimes` enabled -- or by using the `life` [upload modifier](./docs/devnotes.md#write)\n\nspecifying a custom expiration time client-side will affect the timespan in which unposts are permitted, so keep an eye on the estimates in the up2k ui\n\n\n### race the beam\n\ndownload files while they're still uploading ([demo video](http://a.ocv.me/pub/g/nerd-stuff/cpp/2024-0418-race-the-beam.webm))  -- it's almost like peer-to-peer\n\nrequires the file to be uploaded using up2k (which is the default drag-and-drop uploader), alternatively the command-line program\n\n\n### incoming files\n\nthe control-panel shows the ETA for all incoming files  , but only for files being uploaded into volumes where you have read-access\n\n![copyparty-cpanel-upload-eta-or8](https://github.com/user-attachments/assets/fd275ffa-698c-4fca-a307-4d2181269a6a)\n\n\n## file manager\n\ncut/paste, rename, and delete files/folders (if you have permission)\n\nfile selection: click somewhere on the line (not the link itself), then:\n* `space` to toggle\n* `up/down` to move\n* `shift-up/down` to move-and-select\n* `ctrl-shift-up/down` to also scroll\n* shift-click another line for range-select\n\n* cut: select some files and `ctrl-x`\n* paste: `ctrl-v` in another folder\n* rename: `F2`\n\nyou can move files across browser tabs (cut in one tab, paste in another)\n\n\n## shares\n\nshare a file or folder by creating a temporary link\n\nwhen enabled in the server settings (`--shr`), click the bottom-right `share` button to share the folder you're currently in, or alternatively:\n* select a folder first to share that folder instead\n* select one or more files to share only those files\n\nthis feature was made with [identity providers](#identity-providers) in mind -- configure your reverseproxy to skip the IdP's access-control for a given URL prefix and use that to safely share specific files/folders sans the usual auth checks\n\nwhen creating a share, the creator can choose any of the following options:\n\n* password-protection\n* expire after a certain time; `0` or blank means infinite\n* allow visitors to upload (if the user who creates the share has write-access)\n\nsemi-intentional limitations:\n\n* cleanup of expired shares only works when global option `e2d` is set, and/or at least one volume on the server has volflag `e2d`\n* only folders from the same volume are shared; if you are sharing a folder which contains other volumes, then the contents of those volumes will not be available\n* related to [IdP volumes being forgotten on shutdown](https://github.com/9001/copyparty/blob/hovudstraum/docs/idp.md#idp-volumes-are-forgotten-on-shutdown), any shares pointing into a user's IdP volume will be unavailable until that user makes their first request after a restart\n* no option to \"delete after first access\" because tricky\n  * when linking something to discord (for example) it'll get accessed by their scraper and that would count as a hit\n  * browsers wouldn't be able to resume a broken download unless the requester's IP gets allowlisted for X minutes (ref. tricky)\n\nspecify `--shr /foobar` to enable this feature; a toplevel virtual folder named `foobar` is then created, and that's where all the shares will be served from\n\n* you can name it whatever, `foobar` is just an example\n* if you're using config files, put `shr: /foobar` inside the `[global]` section instead\n\nusers can delete their own shares in the controlpanel, and a list of privileged users (`--shr-adm`) are allowed to see and/or delet any share on the server\n\nafter a share has expired, it remains visible in the controlpanel for `--shr-rt` minutes (default is 1 day), and the owner can revive it by extending the expiration time there\n\n**security note:** using this feature does not mean that you can skip the [accounts and volumes](#accounts-and-volumes) section -- you still need to restrict access to volumes that you do not intend to share with unauthenticated users! it is not sufficient to use rules in the reverseproxy to restrict access to just the `/share` folder.\n\n\n## batch rename\n\nselect some files and press `F2` to bring up the rename UI\n\n![batch-rename-fs8](https://user-images.githubusercontent.com/241032/128434204-eb136680-3c07-4ec7-92e0-ae86af20c241.png)\n\nquick explanation of the buttons,  \n* `[ apply rename]` confirms and begins renaming\n* `[ cancel]` aborts and closes the rename window\n* `[ reset]` reverts any filename changes back to the original name\n* `[decode]` does a URL-decode on the filename, fixing stuff like `&amp;` and `%20`\n* `[advanced]` toggles advanced mode\n\nadvanced mode: rename files based on rules to decide the new names, based on the original name (regex), or based on the tags collected from the file (artist/title/...), or a mix of both\n\nin advanced mode,  \n* `[case]` toggles case-sensitive regex\n* `regex` is the regex pattern to apply to the original filename; any files which don't match will be skipped\n* `format` is the new filename, taking values from regex capturing groups and/or from file tags\n  * very loosely based on foobar2000 syntax\n* `presets` lets you save rename rules for later\n\navailable functions:\n* `$lpad(text, length, pad_char)`\n* `$rpad(text, length, pad_char)`\n\nso,\n\nsay you have a file named [`meganeko - Eclipse - 07 Sirius A.mp3`](https://www.youtube.com/watch?v=-dtb0vDPruI) (absolutely fantastic album btw) and the tags are: `Album:Eclipse`, `Artist:meganeko`, `Title:Sirius A`, `tn:7`\n\nyou could use just regex to rename it:\n* `regex` = `(.*) - (.*) - ([0-9]{2}) (.*)`\n* `format` = `(3). (1) - (4)`\n* `output` = `07. meganeko - Sirius A.mp3`\n\nor you could use just tags:\n* `format` = `$lpad((tn),2,0). (artist) - (title).(ext)`\n* `output` = `7. meganeko - Sirius A.mp3`\n\nor a mix of both:\n* `regex` = ` - ([0-9]{2}) `\n* `format` = `(1). (artist) - (title).(ext)`\n* `output` = `07. meganeko - Sirius A.mp3`\n\nthe metadata keys you can use in the format field are the ones in the file-browser table header (whatever is collected with `-mte` and `-mtp`)\n\n\n## rss feeds\n\nmonitor a folder with your RSS reader  , optionally recursive\n\nmust be enabled per-volume with volflag `rss` or globally with `--rss`\n\nthe feed includes itunes metadata for use with podcast readers such as [AntennaPod](https://antennapod.org/)\n\na feed example: https://cd.ocv.me/a/d2/d22/?rss&fext=mp3\n\nurl parameters:\n\n* `pw=hunter2` for password auth\n* `recursive` to also include subfolders\n* `title=foo` changes the feed title (default: folder name)\n* `fext=mp3,opus` only include mp3 and opus files (default: all)\n* `nf=30` only show the first 30 results (default: 250)\n* `sort=m` sort by mtime (file last-modified), newest first (default)\n  * `u` = upload-time; NOTE: non-uploaded files have upload-time `0`\n  * `n` = filename\n  * `a` = filesize\n  * uppercase = reverse-sort; `M` = oldest file first\n\n\n## media player\n\nplays almost every audio format there is  (if the server has FFmpeg installed for on-demand transcoding)\n\nthe following audio formats are usually always playable, even without FFmpeg: `aac|flac|m4a|mp3|ogg|opus|wav`\n\nsome hilights:\n* OS integration; control playback from your phone's lockscreen ([windows](https://user-images.githubusercontent.com/241032/233213022-298a98ba-721a-4cf1-a3d4-f62634bc53d5.png) // [iOS](https://user-images.githubusercontent.com/241032/142711926-0700be6c-3e31-47b3-9928-53722221f722.png) // [android](https://user-images.githubusercontent.com/241032/233212311-a7368590-08c7-4f9f-a1af-48ccf3f36fad.png))\n* shows the audio waveform in the seekbar\n* not perfectly gapless but can get really close (see settings + eq below); good enough to enjoy gapless albums as intended\n* videos can be played as audio, without wasting bandwidth on the video\n\nclick the `play` link next to an audio file, or copy the link target to [share it](https://a.ocv.me/pub/demo/music/Ubiktune%20-%20SOUNDSHOCK%202%20-%20FM%20FUNK%20TERRROR!!/#af-1fbfba61&t=18) (optionally with a timestamp to start playing from, like that example does)\n\nopen the `[]` media-player-settings tab to configure it,\n* \"switches\":\n  * `[]` shuffles the files inside each folder\n  * `[preload]` starts loading the next track when it's about to end, reduces the silence between songs\n  * `[full]` does a full preload by downloading the entire next file; good for unreliable connections, bad for slow connections\n  * `[~s]` toggles the seekbar waveform display\n  * `[/np]` enables buttons to copy the now-playing info as an irc message\n  * `[os-ctl]` makes it possible to control audio playback from the lockscreen of your device (enables [mediasession](https://developer.mozilla.org/en-US/docs/Web/API/MediaSession))\n  * `[seek]` allows seeking with lockscreen controls (buggy on some devices)\n  * `[art]` shows album art on the lockscreen\n  * `[]` keeps the playing song scrolled into view (good when using the player as a taskbar dock)\n  * `[]` shrinks the playback controls\n* \"buttons\":\n  * `[uncache]` may fix songs that won't play correctly due to bad files in browser cache\n* \"at end of folder\":\n  * `[loop]` keeps looping the folder\n  * `[next]` plays into the next folder\n* \"transcode\":\n  * `[flac]` converts `flac` and `wav` files into opus (if supported by browser) or mp3\n  * `[aac]` converts `aac` and `m4a` files into opus (if supported by browser) or mp3\n  * `[oth]` converts all other known formats into opus (if supported by browser) or mp3\n    * `aac|ac3|aif|aiff|alac|alaw|amr|ape|au|dfpwm|dts|flac|gsm|it|m4a|mo3|mod|mp2|mp3|mpc|mptm|mt2|mulaw|ogg|okt|opus|ra|s3m|tak|tta|ulaw|wav|wma|wv|xm|xpk`\n* \"tint\" reduces the contrast of the playback bar\n\n\n### audio equalizer\n\nand [dynamic range compressor](https://en.wikipedia.org/wiki/Dynamic_range_compression)\n\ncan also boost the volume in general, or increase/decrease stereo width (like [crossfeed](https://www.foobar2000.org/components/view/foo_dsp_meiercf) just worse)\n\nhas the convenient side-effect of reducing the pause between songs, so gapless albums play better with the eq enabled (just make it flat)\n\nnot available on iPhones / iPads because AudioContext currently breaks background audio playback on iOS (15.7.8)\n\n\n### fix unreliable playback on android\n\ndue to phone / app settings,  android phones may randomly stop playing music when the power saver kicks in, especially at the end of an album -- you can fix it by [disabling power saving](https://user-images.githubusercontent.com/241032/235262123-c328cca9-3930-4948-bd18-3949b9fd3fcf.png) in the [app settings](https://user-images.githubusercontent.com/241032/235262121-2ffc51ae-7821-4310-a322-c3b7a507890c.png) of the browser you use for music streaming (preferably a dedicated one)\n\n\n## markdown viewer\n\nand there are *two* editors\n\n![copyparty-md-read-fs8](https://user-images.githubusercontent.com/241032/115978057-66419080-a57d-11eb-8539-d2be843991aa.png)\n\nthere is a built-in extension for inline clickable thumbnails;\n* enable it by adding `<!-- th -->` somewhere in the doc\n* add thumbnails with `!th[l](your.jpg)` where `l` means left-align (`r` = right-align)\n* a single line with `---` clears the float / inlining\n* in the case of README.md being displayed below a file listing, thumbnails will open in the gallery viewer\n\nother notes,\n* the document preview has a max-width which is the same as an A4 paper when printed\n\n\n### markdown vars\n\ndynamic docs with serverside variable expansion  to replace stuff like `{{self.ip}}` with the client's IP, or `{{srv.htime}}` with the current time on the server\n\nsee [./srv/expand/](./srv/expand/) for usage and examples\n\n\n## other tricks\n\n* you can link a particular timestamp in an audio file by adding it to the URL, such as `&20` / `&20s` / `&1m20` / `&t=1:20` after the `.../#af-c8960dab`\n\n* enabling the audio equalizer can help make gapless albums fully gapless in some browsers (chrome), so consider leaving it on with all the values at zero\n\n* get a plaintext file listing by adding `?ls=t` to a URL, or a compact colored one with `?ls=v` (for unix terminals)\n\n* if you are using media hotkeys to switch songs and are getting tired of seeing the OSD popup which Windows doesn't let you disable, consider [./contrib/media-osd-bgone.ps1](contrib/#media-osd-bgoneps1)\n\n* click the bottom-left `` to open a javascript prompt for debugging\n\n* files named `.prologue.html` / `.epilogue.html` will be rendered before/after directory listings unless `--no-logues`\n\n* files named `descript.ion` / `DESCRIPT.ION` are parsed and displayed in the file listing, or as the epilogue if nonstandard\n\n* files named `README.md` / `readme.md` will be rendered after directory listings unless `--no-readme` (but `.epilogue.html` takes precedence)\n\n  * and `PREADME.md` / `preadme.md` is shown above directory listings unless `--no-readme` or `.prologue.html`\n\n* `README.md` and `*logue.html` can contain placeholder values which are replaced server-side before embedding into directory listings; see `--help-exp`\n\n\n## searching\n\nsearch by size, date, path/name, mp3-tags, ...\n\n![copyparty-search-fs8](https://user-images.githubusercontent.com/241032/129635365-c0ff2a9f-0ee5-4fc3-8bb6-006033cf67b8.png)\n\nwhen started with `-e2dsa` copyparty will scan/index all your files. This avoids duplicates on upload, and also makes the volumes searchable through the web-ui:\n* make search queries by `size`/`date`/`directory-path`/`filename`, or...\n* drag/drop a local file to see if the same contents exist somewhere on the server, see [file-search](#file-search)\n\npath/name queries are space-separated, AND'ed together, and words are negated with a `-` prefix, so for example:\n* path: `shibayan -bossa` finds all files where one of the folders contain `shibayan` but filters out any results where `bossa` exists somewhere in the path\n* name: `demetori styx` gives you [good stuff](https://www.youtube.com/watch?v=zGh0g14ZJ8I&list=PL3A147BD151EE5218&index=9)\n\nthe `raw` field allows for more complex stuff such as `( tags like *nhato* or tags like *taishi* ) and ( not tags like *nhato* or not tags like *taishi* )` which finds all songs by either nhato or taishi, excluding collabs (terrible example, why would you do that)\n\nfor the above example to work, add the commandline argument `-e2ts` to also scan/index tags from music files, which brings us over to:\n\n\n# server config\n\nusing arguments or config files, or a mix of both:\n* config files (`-c some.conf`) can set additional commandline arguments; see [./docs/example.conf](docs/example.conf) and [./docs/example2.conf](docs/example2.conf)\n* `kill -s USR1` (same as `systemctl reload copyparty`) to reload accounts and volumes from config files without restarting\n  * or click the `[reload cfg]` button in the control-panel if the user has `a`/admin in any volume\n  * changes to the `[global]` config section requires a restart to take effect\n\n**NB:** as humongous as this readme is, there is also a lot of undocumented features. Run copyparty with `--help` to see all available global options; all of those can be used in the `[global]` section of config files, and everything listed in `--help-flags` can be used in volumes as volflags.\n* if running in docker/podman, try this: `docker run --rm -it copyparty/ac --help`\n* or see this (probably outdated): https://ocv.me/copyparty/helptext.html\n* or if you prefer plaintext, https://ocv.me/copyparty/helptext.txt\n\n\n## zeroconf\n\nannounce enabled services on the LAN ([pic](https://user-images.githubusercontent.com/241032/215344737-0eae8d98-9496-4256-9aa8-cd2f6971810d.png))  -- `-z` enables both [mdns](#mdns) and [ssdp](#ssdp)\n\n* `--z-on` / `--z-off`' limits the feature to certain networks\n\n\n### mdns\n\nLAN domain-name and feature announcer\n\nuses [multicast dns](https://en.wikipedia.org/wiki/Multicast_DNS) to give copyparty a domain which any machine on the LAN can use to access it\n\nall enabled services ([webdav](#webdav-server), [ftp](#ftp-server), [smb](#smb-server)) will appear in mDNS-aware file managers (KDE, gnome, macOS, ...)\n\nthe domain will be `partybox.local` if the machine's hostname is `partybox` unless `--name` specifies something else\n\nand the web-UI will be available at http://partybox.local:3923/\n\n* if you want to get rid of the `:3923` so you can use http://partybox.local/ instead then see [listen on port 80 and 443](#listen-on-port-80-and-443)\n\n\n### ssdp\n\nwindows-explorer announcer\n\nuses [ssdp](https://en.wikipedia.org/wiki/Simple_Service_Discovery_Protocol) to make copyparty appear in the windows file explorer on all machines on the LAN\n\ndoubleclicking the icon opens the \"connect\" page which explains how to mount copyparty as a local filesystem\n\nif copyparty does not appear in windows explorer, use `--zsv` to see why:\n\n* maybe the discovery multicast was sent from an IP which does not intersect with the server subnets\n\n\n## qr-code\n\nprint a qr-code [(screenshot)](https://user-images.githubusercontent.com/241032/194728533-6f00849b-c6ac-43c6-9359-83e454d11e00.png) for quick access,  great between phones on android hotspots which keep changing the subnet\n\n* `--qr` enables it\n* `--qrs` does https instead of http\n* `--qrl lootbox/?pw=hunter2` appends to the url, linking to the `lootbox` folder with password `hunter2`\n* `--qrz 1` forces 1x zoom instead of autoscaling to fit the terminal size\n  * 1x may render incorrectly on some terminals/fonts, but 2x should always work\n\nit uses the server hostname if [mdns](#mdns) is enabled, otherwise it'll use your external ip (default route) unless `--qri` specifies a specific ip-prefix or domain\n\n\n## ftp server\n\nan FTP server can be started using `--ftp 3921`,  and/or `--ftps` for explicit TLS (ftpes)\n\n* based on [pyftpdlib](https://github.com/giampaolo/pyftpdlib)\n* needs a dedicated port (cannot share with the HTTP/HTTPS API)\n* uploads are not resumable -- delete and restart if necessary\n* runs in active mode by default, you probably want `--ftp-pr 12000-13000`\n  * if you enable both `ftp` and `ftps`, the port-range will be divided in half\n  * some older software (filezilla on debian-stable) cannot passive-mode with TLS\n* login with any username + your password, or put your password in the username field\n\nsome recommended FTP / FTPS clients; `wark` = example password:\n* https://winscp.net/eng/download.php\n* https://filezilla-project.org/ struggles a bit with ftps in active-mode, but is fine otherwise\n* https://rclone.org/ does FTPS with `tls=false explicit_tls=true`\n* `lftp -u k,wark -p 3921 127.0.0.1 -e ls`\n* `lftp -u k,wark -p 3990 127.0.0.1 -e 'set ssl:verify-certificate no; ls'`\n\n\n## webdav server\n\nwith read-write support,  supports winXP and later, macos, nautilus/gvfs  ... a great way to [access copyparty straight from the file explorer in your OS](#mount-as-drive)\n\nclick the [connect](http://127.0.0.1:3923/?hc) button in the control-panel to see connection instructions for windows, linux, macos\n\ngeneral usage:\n* login with any username + your password, or put your password in the username field (password field can be empty/whatever)\n\non macos, connect from finder:\n* [Go] -> [Connect to Server...] -> http://192.168.123.1:3923/\n\nin order to grant full write-access to webdav clients, the volflag `daw` must be set and the account must also have delete-access (otherwise the client won't be allowed to replace the contents of existing files, which is how webdav works)\n\n\n### connecting to webdav from windows\n\nusing the GUI  (winXP or later):\n* rightclick [my computer] -> [map network drive] -> Folder: `http://192.168.123.1:3923/`\n  * on winXP only, click the `Sign up for online storage` hyperlink instead and put the URL there\n  * providing your password as the username is recommended; the password field can be anything or empty\n\nknown client bugs:\n* win7+ doesn't actually send the password to the server when reauthenticating after a reboot unless you first try to login with an incorrect password and then switch to the correct password\n  * or just type your password into the username field instead to get around it entirely\n* connecting to a folder which allows anonymous read will make writing impossible, as windows has decided it doesn't need to login\n  * workaround: connect twice; first to a folder which requires auth, then to the folder you actually want, and leave both of those mounted\n* win7+ may open a new tcp connection for every file and sometimes forgets to close them, eventually needing a reboot\n  * maybe NIC-related (??), happens with win10-ltsc on e1000e but not virtio\n* windows cannot access folders which contain filenames with invalid unicode or forbidden characters (`<>:\"/\\|?*`), or names ending with `.`\n* winxp cannot show unicode characters outside of *some range*\n  * latin-1 is fine, hiragana is not (not even as shift-jis on japanese xp)\n\n\n## tftp server\n\na TFTP server (read/write) can be started using `--tftp 3969`  (you probably want [ftp](#ftp-server) instead unless you are *actually* communicating with hardware from the 90s (in which case we should definitely hang some time))\n\n> that makes this the first RTX DECT Base that has been updated using copyparty \n\n* based on [partftpy](https://github.com/9001/partftpy)\n* no accounts; read from world-readable folders, write to world-writable, overwrite in world-deletable\n* needs a dedicated port (cannot share with the HTTP/HTTPS API)\n  * run as root (or see below) to use the spec-recommended port `69` (nice)\n* can reply from a predefined portrange (good for firewalls)\n* only supports the binary/octet/image transfer mode (no netascii)\n* [RFC 7440](https://datatracker.ietf.org/doc/html/rfc7440) is **not** supported, so will be extremely slow over WAN\n  * assuming default blksize (512), expect 1100 KiB/s over 100BASE-T, 400-500 KiB/s over wifi, 200 on bad wifi\n\nmost clients expect to find TFTP on port 69, but on linux and macos you need to be root to listen on that. Alternatively, listen on 3969 and use NAT on the server to forward 69 to that port;\n* on linux: `iptables -t nat -A PREROUTING -i eth0 -p udp --dport 69 -j REDIRECT --to-port 3969`\n\nsome recommended TFTP clients:\n* curl (cross-platform, read/write)\n  * get: `curl --tftp-blksize 1428 tftp://127.0.0.1:3969/firmware.bin`\n  * put: `curl --tftp-blksize 1428 -T firmware.bin tftp://127.0.0.1:3969/`\n* windows: `tftp.exe` (you probably already have it)\n  * `tftp -i 127.0.0.1 put firmware.bin`\n* linux: `tftp-hpa`, `atftp`\n  * `atftp --option \"blksize 1428\" 127.0.0.1 3969 -p -l firmware.bin -r firmware.bin`\n  * `tftp -v -m binary 127.0.0.1 3969 -c put firmware.bin`\n\n\n## smb server\n\nunsafe, slow, not recommended for wan,  enable with `--smb` for read-only or `--smbw` for read-write\n\nclick the [connect](http://127.0.0.1:3923/?hc) button in the control-panel to see connection instructions for windows, linux, macos\n\ndependencies: `python3 -m pip install --user -U impacket==0.11.0`\n* newer versions of impacket will hopefully work just fine but there is monkeypatching so maybe not\n\nsome **BIG WARNINGS** specific to SMB/CIFS, in decreasing importance:\n* not entirely confident that read-only is read-only\n* the smb backend is not fully integrated with vfs, meaning there could be security issues (path traversal). Please use `--smb-port` (see below) and [prisonparty](./bin/prisonparty.sh)\n  * account passwords work per-volume as expected, and so does account permissions (read/write/move/delete), but `--smbw` must be given to allow write-access from smb\n  * [shadowing](#shadowing) probably works as expected but no guarantees\n\nand some minor issues,\n* clients only see the first ~400 files in big folders;\n  * this was originally due to [impacket#1433](https://github.com/SecureAuthCorp/impacket/issues/1433) which was fixed in impacket-0.12, so you can disable the workaround with `--smb-nwa-1` but then you get unacceptably poor performance instead\n* hot-reload of server config (`/?reload=cfg`) does not include the `[global]` section (commandline args)\n* listens on the first IPv4 `-i` interface only (default = :: = 0.0.0.0 = all)\n* login doesn't work on winxp, but anonymous access is ok -- remove all accounts from copyparty config for that to work\n  * win10 onwards does not allow connecting anonymously / without accounts\n* python3 only\n* slow (the builtin webdav support in windows is 5x faster, and rclone-webdav is 30x faster)\n\nknown client bugs:\n* on win7 only, `--smb1` is much faster than smb2 (default) because it keeps rescanning folders on smb2\n  * however smb1 is buggy and is not enabled by default on win10 onwards\n* windows cannot access folders which contain filenames with invalid unicode or forbidden characters (`<>:\"/\\|?*`), or names ending with `.`\n\nthe smb protocol listens on TCP port 445, which is a privileged port on linux and macos, which would require running copyparty as root. However, this can be avoided by listening on another port using `--smb-port 3945` and then using NAT on the server to forward the traffic from 445 to there;\n* on linux: `iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 445 -j REDIRECT --to-port 3945`\n\nauthenticate with one of the following:\n* username `$username`, password `$password`\n* username `$password`, password `k`\n\n\n## browser ux\n\ntweaking the ui\n\n* set default sort order globally with `--sort` or per-volume with the `sort` volflag; specify one or more comma-separated columns to sort by, and prefix the column name with `-` for reverse sort\n  * the column names you can use are visible as tooltips when hovering over the column headers in the directory listing, for example `href ext sz ts tags/.up_at tags/Circle tags/.tn tags/Artist tags/Title`\n  * to sort in music order (album, track, artist, title) with filename as fallback, you could `--sort tags/Circle,tags/.tn,tags/Artist,tags/Title,href`\n  * to sort by upload date, first enable showing the upload date in the listing with `-e2d -mte +.up_at` and then `--sort tags/.up_at`\n\nsee [./docs/rice](./docs/rice) for more, including how to add stuff (css/`<meta>`/...) to the html `<head>` tag, or to add your own translation\n\n\n## opengraph\n\ndiscord and social-media embeds\n\ncan be enabled globally with `--og` or per-volume with volflag `og`\n\nnote that this disables hotlinking because the opengraph spec demands it; to sneak past this intentional limitation, you can enable opengraph selectively by user-agent, for example `--og-ua '(Discord|Twitter|Slack)bot'` (or volflag `og_ua`)\n\nyou can also hotlink files regardless by appending `?raw` to the url\n\nif you want to entirely replace the copyparty response with your own jinja2 template, give the template filepath to `--og-tpl` or volflag `og_tpl` (all members of `HttpCli` are available through the `this` object)\n\n\n## file deduplication\n\nenable symlink-based upload deduplication  globally with `--dedup` or per-volume with volflag `dedup`\n\nby default, when someone tries to upload a file that already exists on the server, the upload will be politely declined, and the server will copy the existing file over to where the upload would have gone\n\nif you enable deduplication with `--dedup` then it'll create a symlink instead of a full copy, thus reducing disk space usage\n\n* on the contrary, if your server is hooked up to s3-glacier or similar storage where reading is expensive, and you cannot use `--safe-dedup=1` because you have other software tampering with your files, so you want to entirely disable detection of duplicate data instead, then you can specify `--no-clone` globally or `noclone` as a volflag\n\n**warning:** when enabling dedup, you should also:\n* enable indexing with `-e2dsa` or volflag `e2dsa` (see [file indexing](#file-indexing) section below); strongly recommended\n* ...and/or `--hardlink-only` to use hardlink-based deduplication instead of symlinks; see explanation below\n\nit will not be safe to rename/delete files if you only enable dedup and none of the above; if you enable indexing then it is not *necessary* to also do hardlinks (but you may still want to)\n\nby default, deduplication is done based on symlinks (symbolic links); these are tiny files which are pointers to the nearest full copy of the file\n\nyou can choose to use hardlinks instead of softlinks, globally with `--hardlink-only` or volflag `hardlinkonly`;\n\nadvantages of using hardlinks:\n* hardlinks are more compatible with other software; they behave entirely like regular files\n* you can safely move and rename files using other file managers\n  * symlinks need to be managed by copyparty to ensure the destinations remain correct\n\nadvantages of using symlinks (default):\n* each symlink can have its own last-modified timestamp, but a single timestamp is shared by all hardlinks\n* symlinks make it more obvious to other software that the file is not a regular file, so this can be less dangerous\n  * hardlinks look like regular files, so other software may assume they are safe to edit without affecting the other copies\n\n**warning:** if you edit the contents of a deduplicated file, then you will also edit all other copies of that file! This is especially surprising with hardlinks, because they look like regular files, but that same file exists in multiple locations\n\nglobal-option `--xlink` / volflag `xlink` additionally enables deduplication across volumes, but this is probably buggy and not recommended\n\n\n\n## file indexing\n\nenable music search, upload-undo, and better dedup\n\nfile indexing relies on two database tables, the up2k filetree (`-e2d`) and the metadata tags (`-e2t`), stored in `.hist/up2k.db`. Configuration can be done through arguments, volflags, or a mix of both.\n\nthrough arguments:\n* `-e2d` enables file indexing on upload\n* `-e2ds` also scans writable folders for new files on startup\n* `-e2dsa` also scans all mounted volumes (including readonly ones)\n* `-e2t` enables metadata indexing on upload\n* `-e2ts` also scans for tags in all files that don't have tags yet\n* `-e2tsr` also deletes all existing tags, doing a full reindex\n* `-e2v` verifies file integrity at startup, comparing hashes from the db\n* `-e2vu` patches the database with the new hashes from the filesystem\n* `-e2vp` panics and kills copyparty instead\n\nthe same arguments can be set as volflags, in addition to `d2d`, `d2ds`, `d2t`, `d2ts`, `d2v` for disabling:\n* `-v ~/music::r:c,e2ds,e2tsr` does a full reindex of everything on startup\n* `-v ~/music::r:c,d2d` disables **all** indexing, even if any `-e2*` are on\n* `-v ~/music::r:c,d2t` disables all `-e2t*` (tags), does not affect `-e2d*`\n* `-v ~/music::r:c,d2ds` disables on-boot scans; only index new uploads\n* `-v ~/music::r:c,d2ts` same except only affecting tags\n\nnote:\n* upload-times can be displayed in the file listing by enabling the `.up_at` metadata key, either globally with `-e2d -mte +.up_at` or per-volume with volflags `e2d,mte=+.up_at` (will have a ~17% performance impact on directory listings)\n* `e2tsr` is probably always overkill, since `e2ds`/`e2dsa` would pick up any file modifications and `e2ts` would then reindex those, unless there is a new copyparty version with new parsers and the release note says otherwise\n* the rescan button in the admin panel has no effect unless the volume has `-e2ds` or higher\n\n### exclude-patterns\n\nto save some time,  you can provide a regex pattern for filepaths to only index by filename/path/size/last-modified (and not the hash of the file contents) by setting `--no-hash \\.iso$` or the volflag `:c,nohash=\\.iso$`, this has the following consequences:\n* initial indexing is way faster, especially when the volume is on a network disk\n* makes it impossible to [file-search](#file-search)\n* if someone uploads the same file contents, the upload will not be detected as a dupe, so it will not get symlinked or rejected\n\nsimilarly, you can fully ignore files/folders using `--no-idx [...]` and `:c,noidx=\\.iso$`\n\n* when running on macos, all the usual apple metadata files are excluded by default\n\nif you set `--no-hash [...]` globally, you can enable hashing for specific volumes using flag `:c,nohash=`\n\n### filesystem guards\n\navoid traversing into other filesystems  using `--xdev` / volflag `:c,xdev`, skipping any symlinks or bind-mounts to another HDD for example\n\nand/or you can `--xvol` / `:c,xvol` to ignore all symlinks leaving the volume's top directory, but still allow bind-mounts pointing elsewhere\n\n* symlinks are permitted with `xvol` if they point into another volume where the user has the same level of access\n\nthese options will reduce performance; unlikely worst-case estimates are 14% reduction for directory listings, 35% for download-as-tar\n\nas of copyparty v1.7.0 these options also prevent file access at runtime -- in previous versions it was just hints for the indexer\n\n### periodic rescan\n\nfilesystem monitoring;  if copyparty is not the only software doing stuff on your filesystem, you may want to enable periodic rescans to keep the index up to date\n\nargument `--re-maxage 60` will rescan all volumes every 60 sec, same as volflag `:c,scan=60` to specify it per-volume\n\nuploads are disabled while a rescan is happening, so rescans will be delayed by `--db-act` (default 10 sec) when there is write-activity going on (uploads, renames, ...)\n\n\n## upload rules\n\nset upload rules using volflags,  some examples:\n\n* `:c,sz=1k-3m` sets allowed filesize between 1 KiB and 3 MiB inclusive (suffixes: `b`, `k`, `m`, `g`)\n* `:c,df=4g` block uploads if there would be less than 4 GiB free disk space afterwards\n* `:c,vmaxb=1g` block uploads if total volume size would exceed 1 GiB afterwards\n* `:c,vmaxn=4k` block uploads if volume would contain more than 4096 files afterwards\n* `:c,nosub` disallow uploading into subdirectories; goes well with `rotn` and `rotf`:\n* `:c,rotn=1000,2` moves uploads into subfolders, up to 1000 files in each folder before making a new one, two levels deep (must be at least 1)\n* `:c,rotf=%Y/%m/%d/%H` enforces files to be uploaded into a structure of subfolders according to that date format\n  * if someone uploads to `/foo/bar` the path would be rewritten to `/foo/bar/2021/08/06/23` for example\n  * but the actual value is not verified, just the structure, so the uploader can choose any values which conform to the format string\n    * just to avoid additional complexity in up2k which is enough of a mess already\n* `:c,lifetime=300` delete uploaded files when they become 5 minutes old\n\nyou can also set transaction limits which apply per-IP and per-volume, but these assume `-j 1` (default) otherwise the limits will be off, for example `-j 4` would allow anywhere between 1x and 4x the limits you set depending on which processing node the client gets routed to\n\n* `:c,maxn=250,3600` allows 250 files over 1 hour from each IP (tracked per-volume)\n* `:c,maxb=1g,300` allows 1 GiB total over 5 minutes from each IP (tracked per-volume)\n\nnotes:\n* `vmaxb` and `vmaxn` requires either the `e2ds` volflag or `-e2dsa` global-option\n\n\n## compress uploads\n\nfiles can be autocompressed on upload,  either on user-request (if config allows) or forced by server-config\n\n* volflag `gz` allows gz compression\n* volflag `xz` allows lzma compression\n* volflag `pk` **forces** compression on all files\n* url parameter `pk` requests compression with server-default algorithm\n* url parameter `gz` or `xz` requests compression with a specific algorithm\n* url parameter `xz` requests xz compression\n\nthings to note,\n* the `gz` and `xz` arguments take a single optional argument, the compression level (range 0 to 9)\n* the `pk` volflag takes the optional argument `ALGORITHM,LEVEL` which will then be forced for all uploads, for example `gz,9` or `xz,0`\n* default compression is gzip level 9\n* all upload methods except up2k are supported\n* the files will be indexed after compression, so dupe-detection and file-search will not work as expected\n\nsome examples,\n* `-v inc:inc:w:c,pk=xz,0`  \n  folder named inc, shared at inc, write-only for everyone, forces xz compression at level 0\n* `-v inc:inc:w:c,pk`  \n  same write-only inc, but forces gz compression (default) instead of xz\n* `-v inc:inc:w:c,gz`  \n  allows (but does not force) gz compression if client uploads to `/inc?pk` or `/inc?gz` or `/inc?gz=4`\n\n\n## other flags\n\n* `:c,magic` enables filetype detection for nameless uploads, same as `--magic`\n  * needs https://pypi.org/project/python-magic/ `python3 -m pip install --user -U python-magic`\n  * on windows grab this instead `python3 -m pip install --user -U python-magic-bin`\n\n\n## database location\n\nin-volume (`.hist/up2k.db`, default) or somewhere else\n\ncopyparty creates a subfolder named `.hist` inside each volume where it stores the database, thumbnails, and some other stuff\n\nthis can instead be kept in a single place using the `--hist` argument, or the `hist=` volflag, or a mix of both:\n* `--hist ~/.cache/copyparty -v ~/music::r:c,hist=-` sets `~/.cache/copyparty` as the default place to put volume info, but `~/music` gets the regular `.hist` subfolder (`-` restores default behavior)\n\nnote:\n* markdown edits are always stored in a local `.hist` subdirectory\n* on windows the volflag path is cyglike, so `/c/temp` means `C:\\temp` but use regular paths for `--hist`\n  * you can use cygpaths for volumes too, `-v C:\\Users::r` and `-v /c/users::r` both work\n\n\n## metadata from audio files\n\nset `-e2t` to index tags on upload\n\n`-mte` decides which tags to index and display in the browser (and also the display order), this can be changed per-volume:\n* `-v ~/music::r:c,mte=title,artist` indexes and displays *title* followed by *artist*\n\nif you add/remove a tag from `mte` you will need to run with `-e2tsr` once to rebuild the database, otherwise only new files will be affected\n\nbut instead of using `-mte`, `-mth` is a better way to hide tags in the browser: these tags will not be displayed by default, but they still get indexed and become searchable, and users can choose to unhide them in the `[] config` pane\n\n`-mtm` can be used to add or redefine a metadata mapping, say you have media files with `foo` and `bar` tags and you want them to display as `qux` in the browser (preferring `foo` if both are present), then do `-mtm qux=foo,bar` and now you can `-mte artist,title,qux`\n\ntags that start with a `.` such as `.bpm` and `.dur`(ation) indicate numeric value\n\nsee the beautiful mess of a dictionary in [mtag.py](https://github.com/9001/copyparty/blob/hovudstraum/copyparty/mtag.py) for the default mappings (should cover mp3,opus,flac,m4a,wav,aif,)\n\n`--no-mutagen` disables Mutagen and uses FFprobe instead, which...\n* is about 20x slower than Mutagen\n* catches a few tags that Mutagen doesn't\n  * melodic key, video resolution, framerate, pixfmt\n* avoids pulling any GPL code into copyparty\n* more importantly runs FFprobe on incoming files which is bad if your FFmpeg has a cve\n\n`--mtag-to` sets the tag-scan timeout; very high default (60 sec) to cater for zfs and other randomly-freezing filesystems. Lower values like 10 are usually safe, allowing for faster processing of tricky files\n\n\n## file parser plugins\n\nprovide custom parsers to index additional tags,  also see [./bin/mtag/README.md](./bin/mtag/README.md)\n\ncopyparty can invoke external programs to collect additional metadata for files using `mtp` (either as argument or volflag), there is a default timeout of 60sec, and only files which contain audio get analyzed by default (see ay/an/ad below)\n\n* `-mtp .bpm=~/bin/audio-bpm.py` will execute `~/bin/audio-bpm.py` with the audio file as argument 1 to provide the `.bpm` tag, if that does not exist in the audio metadata\n* `-mtp key=f,t5,~/bin/audio-key.py` uses `~/bin/audio-key.py` to get the `key` tag, replacing any existing metadata tag (`f,`), aborting if it takes longer than 5sec (`t5,`)\n* `-v ~/music::r:c,mtp=.bpm=~/bin/audio-bpm.py:c,mtp=key=f,t5,~/bin/audio-key.py` both as a per-volume config wow this is getting ugly\n\n*but wait, there's more!* `-mtp` can be used for non-audio files as well using the `a` flag: `ay` only do audio files (default), `an` only do non-audio files, or `ad` do all files (d as in dontcare)\n\n* \"audio file\" also means videos btw, as long as there is an audio stream\n* `-mtp ext=an,~/bin/file-ext.py` runs `~/bin/file-ext.py` to get the `ext` tag only if file is not audio (`an`)\n* `-mtp arch,built,ver,orig=an,eexe,edll,~/bin/exe.py` runs `~/bin/exe.py` to get properties about windows-binaries only if file is not audio (`an`) and file extension is exe or dll\n* if you want to daisychain parsers, use the `p` flag to set processing order\n  * `-mtp foo=p1,~/a.py` runs before `-mtp foo=p2,~/b.py` and will forward all the tags detected so far as json to the stdin of b.py\n* option `c0` disables capturing of stdout/stderr, so copyparty will not receive any tags from the process at all -- instead the invoked program is free to print whatever to the console, just using copyparty as a launcher\n  * `c1` captures stdout only, `c2` only stderr, and `c3` (default) captures both\n* you can control how the parser is killed if it times out with option `kt` killing the entire process tree (default), `km` just the main process, or `kn` let it continue running until copyparty is terminated\n\nif something doesn't work, try `--mtag-v` for verbose error messages\n\n\n## event hooks\n\ntrigger a program on uploads, renames etc ([examples](./bin/hooks/))\n\nyou can set hooks before and/or after an event happens, and currently you can hook uploads, moves/renames, and deletes\n\nthere's a bunch of flags and stuff, see `--help-hooks`\n\nif you want to write your own hooks, see [devnotes](./docs/devnotes.md#event-hooks)\n\n\n### upload events\n\nthe older, more powerful approach ([examples](./bin/mtag/)):\n\n```\n-v /mnt/inc:inc:w:c,mte=+x1:c,mtp=x1=ad,kn,/usr/bin/notify-send\n```\n\nso filesystem location `/mnt/inc` shared at `/inc`, write-only for everyone, appending `x1` to the list of tags to index (`mte`), and using `/usr/bin/notify-send` to \"provide\" tag `x1` for any filetype (`ad`) with kill-on-timeout disabled (`kn`)\n\nthat'll run the command `notify-send` with the path to the uploaded file as the first and only argument (so on linux it'll show a notification on-screen)\n\nnote that this is way more complicated than the new [event hooks](#event-hooks) but this approach has the following advantages:\n* non-blocking and multithreaded; doesn't hold other uploads back\n* you get access to tags from FFmpeg and other mtp parsers\n* only trigger on new unique files, not dupes\n\nnote that it will occupy the parsing threads, so fork anything expensive (or set `kn` to have copyparty fork it for you) -- otoh if you want to intentionally queue/singlethread you can combine it with `--mtag-mt 1`\n\n\n## handlers\n\nredefine behavior with plugins ([examples](./bin/handlers/))\n\nreplace 404 and 403 errors with something completely different (that's it for now)\n\n\n## ip auth\n\nautologin based on IP range (CIDR)  , using the global-option `--ipu`\n\nfor example, if everyone with an IP that starts with `192.168.123` should automatically log in as the user `spartacus`, then you can either specify `--ipu=192.168.123.0/24=spartacus` as a commandline option, or put this in a config file:\n\n```yaml\n[global]\n  ipu: 192.168.123.0/24=spartacus\n```\n\nrepeat the option to map additional subnets\n\n**be careful with this one!** if you have a reverseproxy, then you definitely want to make sure you have [real-ip](#real-ip) configured correctly, and it's probably a good idea to nullmap the reverseproxy's IP just in case; so if your reverseproxy is sending requests from `172.24.27.9` then that would be `--ipu=172.24.27.9/32=`\n\n\n## identity providers\n\nreplace copyparty passwords with oauth and such\n\nyou can disable the built-in password-based login system, and instead replace it with a separate piece of software (an identity provider) which will then handle authenticating / authorizing of users; this makes it possible to login with passkeys / fido2 / webauthn / yubikey / ldap / active directory / oauth / many other single-sign-on contraptions\n\na popular choice is [Authelia](https://www.authelia.com/) (config-file based), another one is [authentik](https://goauthentik.io/) (GUI-based, more complex)\n\nthere is a [docker-compose example](./docs/examples/docker/idp-authelia-traefik) which is hopefully a good starting point (alternatively see [./docs/idp.md](./docs/idp.md) if you're the DIY type)\n\na more complete example of the copyparty configuration options [look like this](./docs/examples/docker/idp/copyparty.conf)\n\nbut if you just want to let users change their own passwords, then you probably want [user-changeable passwords](#user-changeable-passwords) instead\n\n\n## user-changeable passwords\n\nif permitted, users can change their own passwords  in the control-panel\n\n* not compatible with [identity providers](#identity-providers)\n\n* must be enabled with `--chpw` because account-sharing is a popular usecase\n\n  * if you want to enable the feature but deny password-changing for a specific list of accounts, you can do that with `--chpw-no name1,name2,name3,...`\n\n* to perform a password reset, edit the server config and give the user another password there, then do a [config reload](#server-config) or server restart\n\n* the custom passwords are kept in a textfile at filesystem-path `--chpw-db`, by default `chpw.json` in the copyparty config folder\n\n  * if you run multiple copyparty instances with different users you *almost definitely* want to specify separate DBs for each instance\n\n  * if [password hashing](#password-hashing) is enabled, the passwords in the db are also hashed\n\n    * ...which means that all user-defined passwords will be forgotten if you change password-hashing settings\n\n\n## using the cloud as storage\n\nconnecting to an aws s3 bucket and similar\n\nthere is no built-in support for this, but you can use FUSE-software such as [rclone](https://rclone.org/) / [geesefs](https://github.com/yandex-cloud/geesefs) / [JuiceFS](https://juicefs.com/en/) to first mount your cloud storage as a local disk, and then let copyparty use (a folder in) that disk as a volume\n\nyou may experience poor upload performance this way, but that can sometimes be fixed by specifying the volflag `sparse` to force the use of sparse files; this has improved the upload speeds from `1.5 MiB/s` to over `80 MiB/s` in one case, but note that you are also more likely to discover funny bugs in your FUSE software this way, so buckle up\n\nsomeone has also tested geesefs in combination with [gocryptfs](https://nuetzlich.net/gocryptfs/) with surprisingly good results, getting 60 MiB/s upload speeds on a gbit line, but JuiceFS won with 80 MiB/s using its built-in encryption\n\nyou may improve performance by specifying larger values for `--iobuf` / `--s-rd-sz` / `--s-wr-sz`\n\n\n## hiding from google\n\ntell search engines you don't wanna be indexed,  either using the good old [robots.txt](https://www.robotstxt.org/robotstxt.html) or through copyparty settings:\n\n* `--no-robots` adds HTTP (`X-Robots-Tag`) and HTML (`<meta>`) headers with `noindex, nofollow` globally\n* volflag `[...]:c,norobots` does the same thing for that single volume\n* volflag `[...]:c,robots` ALLOWS search-engine crawling for that volume, even if `--no-robots` is set globally\n\nalso, `--force-js` disables the plain HTML folder listing, making things harder to parse for search engines\n\n\n## themes\n\nyou can change the default theme with `--theme 2`, and add your own themes by modifying `browser.css` or providing your own css to `--css-browser`, then telling copyparty they exist by increasing `--themes`\n\n<table><tr><td width=\"33%\" align=\"center\"><a href=\"https://user-images.githubusercontent.com/241032/165864907-17e2ac7d-319d-4f25-8718-2f376f614b51.png\"><img src=\"https://user-images.githubusercontent.com/241032/165867551-fceb35dd-38f0-42bb-bef3-25ba651ca69b.png\"></a>\n0. classic dark</td><td width=\"33%\" align=\"center\"><a href=\"https://user-images.githubusercontent.com/241032/168644399-68938de5-da9b-445f-8d92-b51c74b5f345.png\"><img src=\"https://user-images.githubusercontent.com/241032/168644404-8e1a2fdc-6e59-4c41-905e-ba5399ed686f.png\"></a>\n2. flat pm-monokai</td><td width=\"33%\" align=\"center\"><a href=\"https://user-images.githubusercontent.com/241032/165864901-db13a429-a5da-496d-8bc6-ce838547f69d.png\"><img src=\"https://user-images.githubusercontent.com/241032/165867560-aa834aef-58dc-4abe-baef-7e562b647945.png\"></a>\n4. vice</td></tr><tr><td align=\"center\"><a href=\"https://user-images.githubusercontent.com/241032/165864905-692682eb-6fb4-4d40-b6fe-27d2c7d3e2a7.png\"><img src=\"https://user-images.githubusercontent.com/241032/165867555-080b73b6-6d85-41bb-a7c6-ad277c608365.png\"></a>\n1. classic light</td><td align=\"center\"><a href=\"https://user-images.githubusercontent.com/241032/168645276-fb02fd19-190a-407a-b8d3-d58fee277e02.png\"><img src=\"https://user-images.githubusercontent.com/241032/168645280-f0662b3c-9764-4875-a2e2-d91cc8199b23.png\"></a>\n3. flat light\n</td><td align=\"center\"><a href=\"https://user-images.githubusercontent.com/241032/165864898-10ce7052-a117-4fcf-845b-b56c91687908.png\"><img src=\"https://user-images.githubusercontent.com/241032/165867562-f3003d45-dd2a-4564-8aae-fed44c1ae064.png\"></a>\n5. <a href=\"https://blog.codinghorror.com/a-tribute-to-the-windows-31-hot-dog-stand-color-scheme/\">hotdog stand</a></td></tr></table>\n\nthe classname of the HTML tag is set according to the selected theme, which is used to set colors as css variables ++\n\n* each theme *generally* has a dark theme (even numbers) and a light theme (odd numbers), showing in pairs\n* the first theme (theme 0 and 1) is `html.a`, second theme (2 and 3) is `html.b`\n* if a light theme is selected, `html.y` is set, otherwise `html.z` is\n* so if the dark edition of the 2nd theme is selected, you use any of `html.b`, `html.z`, `html.bz` to specify rules\n\nsee the top of [./copyparty/web/browser.css](./copyparty/web/browser.css) where the color variables are set, and there's layout-specific stuff near the bottom\n\nif you want to change the fonts, see [./docs/rice/](./docs/rice/)\n\n\n## complete examples\n\n* see [running on windows](./docs/examples/windows.md) for a fancy windows setup\n\n  * or use any of the examples below, just replace `python copyparty-sfx.py` with `copyparty.exe` if you're using the exe edition\n\n* allow anyone to download or upload files into the current folder:  \n  `python copyparty-sfx.py`\n\n  * enable searching and music indexing with `-e2dsa -e2ts`\n\n  * start an FTP server on port 3921 with `--ftp 3921`\n\n  * announce it on your LAN with `-z` so it appears in windows/Linux file managers\n\n* anyone can upload, but nobody can see any files (even the uploader):  \n  `python copyparty-sfx.py -e2dsa -v .::w`\n\n  * block uploads if there's less than 4 GiB free disk space with `--df 4`\n\n  * show a popup on new uploads with `--xau bin/hooks/notify.py`\n\n* anyone can upload, and receive \"secret\" links for each upload they do:  \n  `python copyparty-sfx.py -e2dsa -v .::wG:c,fk=8`\n\n* anyone can browse (`r`), only `kevin` (password `okgo`) can upload/move/delete (`A`) files:  \n  `python copyparty-sfx.py -e2dsa -a kevin:okgo -v .::r:A,kevin`\n\n* read-only music server:  \n  `python copyparty-sfx.py -v /mnt/nas/music:/music:r -e2dsa -e2ts --no-robots --force-js --theme 2`\n  \n  * ...with bpm and key scanning  \n    `-mtp .bpm=f,audio-bpm.py -mtp key=f,audio-key.py`\n  \n  * ...with a read-write folder for `kevin` whose password is `okgo`  \n    `-a kevin:okgo -v /mnt/nas/inc:/inc:rw,kevin`\n  \n  * ...with logging to disk  \n    `-lo log/cpp-%Y-%m%d-%H%M%S.txt.xz`\n\n\n## listen on port 80 and 443\n\nbecome a *real* webserver  which people can access by just going to your IP or domain without specifying a port\n\n**if you're on windows,** then you just need to add the commandline argument `-p 80,443` and you're done! nice\n\n**if you're on macos,** sorry, I don't know\n\n**if you're on Linux,** you have the following 4 options:\n\n* **option 1:** set up a [reverse-proxy](#reverse-proxy) -- this one makes a lot of sense if you're running on a proper headless server, because that way you get real HTTPS too\n\n* **option 2:** NAT to port 3923 -- this is cumbersome since you'll need to do it every time you reboot, and the exact command may depend on your linux distribution:\n  ```bash\n  iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 3923\n  iptables -t nat -A PREROUTING -p tcp --dport 443 -j REDIRECT --to-port 3923\n  ```\n\n* **option 3:** disable the [security policy](https://www.w3.org/Daemon/User/Installation/PrivilegedPorts.html) which prevents the use of 80 and 443; this is *probably* fine:\n  ```\n  setcap CAP_NET_BIND_SERVICE=+eip $(realpath $(which python))\n  python copyparty-sfx.py -p 80,443\n  ```\n\n* **option 4:** run copyparty as root (please don't)\n\n\n## reverse-proxy\n\nrunning copyparty next to other websites  hosted on an existing webserver such as nginx, caddy, or apache\n\nyou can either:\n* give copyparty its own domain or subdomain (recommended)\n* or do location-based proxying, using `--rp-loc=/stuff` to tell copyparty where it is mounted -- has a slight performance cost and higher chance of bugs\n  * if copyparty says `incorrect --rp-loc or webserver config; expected vpath starting with [...]` it's likely because the webserver is stripping away the proxy location from the request URLs -- see the `ProxyPass` in the apache example below\n\nwhen running behind a reverse-proxy (this includes services like cloudflare), it is important to configure real-ip correctly, as many features rely on knowing the client's IP. Look out for red and yellow log messages which explain how to do this. But basically, set `--xff-hdr` to the name of the http header to read the IP from (usually `x-forwarded-for`, but cloudflare uses `cf-connecting-ip`), and then `--xff-src` to the IP of the reverse-proxy so copyparty will trust the xff-hdr. Note that `--rp-loc` in particular will not work at all unless you do this\n\nsome reverse proxies (such as [Caddy](https://caddyserver.com/)) can automatically obtain a valid https/tls certificate for you, and some support HTTP/2 and QUIC which *could* be a nice speed boost, depending on a lot of factors\n* **warning:** nginx-QUIC (HTTP/3) is still experimental and can make uploads much slower, so HTTP/1.1 is recommended for now\n* depending on server/client, HTTP/1.1 can also be 5x faster than HTTP/2\n\nfor improved security (and a 10% performance boost) consider listening on a unix-socket with `-i unix:770:www:/tmp/party.sock` (permission `770` means only members of group `www` can access it)\n\nexample webserver configs:\n\n* [nginx config](contrib/nginx/copyparty.conf) -- entire domain/subdomain\n* [apache2 config](contrib/apache/copyparty.conf) -- location-based\n\n\n### real-ip\n\nteaching copyparty how to see client IPs  when running behind a reverse-proxy, or a WAF, or another protection service such as cloudflare\n\nif you (and maybe everybody else) keep getting a message that says `thank you for playing`, then you've gotten banned for malicious traffic. This ban applies to the IP address that copyparty *thinks* identifies the shady client -- so, depending on your setup, you might have to tell copyparty where to find the correct IP\n\nfor most common setups, there should be a helpful message in the server-log explaining what to do, but see [docs/xff.md](docs/xff.md) if you want to learn more, including a quick hack to **just make it work** (which is **not** recommended, but hey...)\n\n\n## prometheus\n\nmetrics/stats can be enabled  at URL `/.cpr/metrics` for grafana / prometheus / etc (openmetrics 1.0.0)\n\nmust be enabled with `--stats` since it reduces startup time a tiny bit, and you probably want `-e2dsa` too\n\nthe endpoint is only accessible by `admin` accounts, meaning the `a` in `rwmda` in the following example commandline: `python3 -m copyparty -a ed:wark -v /mnt/nas::rwmda,ed --stats -e2dsa`\n\nfollow a guide for setting up `node_exporter` except have it read from copyparty instead; example `/etc/prometheus/prometheus.yml` below\n\n```yaml\nscrape_configs:\n  - job_name: copyparty\n    metrics_path: /.cpr/metrics\n    basic_auth:\n      password: wark\n    static_configs:\n      - targets: ['192.168.123.1:3923']\n```\n\ncurrently the following metrics are available,\n* `cpp_uptime_seconds` time since last copyparty restart\n* `cpp_boot_unixtime_seconds` same but as an absolute timestamp\n* `cpp_http_conns` number of open http(s) connections\n* `cpp_http_reqs` number of http(s) requests handled\n* `cpp_sus_reqs` number of 403/422/malicious requests\n* `cpp_active_bans` number of currently banned IPs\n* `cpp_total_bans` number of IPs banned since last restart\n\nthese are available unless `--nos-vst` is specified:\n* `cpp_db_idle_seconds` time since last database activity (upload/rename/delete)\n* `cpp_db_act_seconds` same but as an absolute timestamp\n* `cpp_idle_vols` number of volumes which are idle / ready\n* `cpp_busy_vols` number of volumes which are busy / indexing\n* `cpp_offline_vols` number of volumes which are offline / unavailable\n* `cpp_hashing_files` number of files queued for hashing / indexing\n* `cpp_tagq_files` number of files queued for metadata scanning\n* `cpp_mtpq_files` number of files queued for plugin-based analysis\n\nand these are available per-volume only:\n* `cpp_disk_size_bytes` total HDD size\n* `cpp_disk_free_bytes` free HDD space\n\nand these are per-volume and `total`:\n* `cpp_vol_bytes` size of all files in volume\n* `cpp_vol_files` number of files\n* `cpp_dupe_bytes` disk space presumably saved by deduplication\n* `cpp_dupe_files` number of dupe files\n* `cpp_unf_bytes` currently unfinished / incoming uploads\n\nsome of the metrics have additional requirements to function correctly,\n* `cpp_vol_*` requires either the `e2ds` volflag or `-e2dsa` global-option\n\nthe following options are available to disable some of the metrics:\n* `--nos-hdd` disables `cpp_disk_*` which can prevent spinning up HDDs\n* `--nos-vol` disables `cpp_vol_*` which reduces server startup time\n* `--nos-vst` disables volume state, reducing the worst-case prometheus query time by 0.5 sec\n* `--nos-dup` disables `cpp_dupe_*` which reduces the server load caused by prometheus queries\n* `--nos-unf` disables `cpp_unf_*` for no particular purpose\n\nnote: the following metrics are counted incorrectly if multiprocessing is enabled with `-j`: `cpp_http_conns`, `cpp_http_reqs`, `cpp_sus_reqs`, `cpp_active_bans`, `cpp_total_bans`\n\n\n## other extremely specific features\n\nyou'll never find a use for these:\n\n\n### custom mimetypes\n\nchange the association of a file extension\n\nusing commandline args, you can do something like `--mime gif=image/jif` and `--mime ts=text/x.typescript` (can be specified multiple times)\n\nin a config-file, this is the same as:\n\n```yaml\n[global]\n  mime: gif=image/jif\n  mime: ts=text/x.typescript\n```\n\nrun copyparty with `--mimes` to list all the default mappings\n\n\n### feature chickenbits\n\nbuggy feature? rip it out  by setting any of the following environment variables to disable its associated bell or whistle,\n\n| env-var              | what it does |\n| -------------------- | ------------ |\n| `PRTY_NO_IFADDR`     | disable ip/nic discovery by poking into your OS with ctypes |\n| `PRTY_NO_IPV6`       | disable some ipv6 support (should not be necessary since windows 2000) |\n| `PRTY_NO_LZMA`       | disable streaming xz compression of incoming uploads |\n| `PRTY_NO_MP`         | disable all use of the python `multiprocessing` module (actual multithreading, cpu-count for parsers/thumbnailers) |\n| `PRTY_NO_SQLITE`     | disable all database-related functionality (file indexing, metadata indexing, most file deduplication logic) |\n| `PRTY_NO_TLS`        | disable native HTTPS support; if you still want to accept HTTPS connections then TLS must now be terminated by a reverse-proxy |\n| `PRTY_NO_TPOKE`      | disable systemd-tmpfilesd avoider |\n\nexample: `PRTY_NO_IFADDR=1 python3 copyparty-sfx.py`\n\n\n# packages\n\nthe party might be closer than you think\n\nif your distro/OS is not mentioned below, there might be some hints in the [on servers](#on-servers) section\n\n\n## arch package\n\nnow [available on aur](https://aur.archlinux.org/packages/copyparty) maintained by [@icxes](https://github.com/icxes)\n\nit comes with a [systemd service](./contrib/package/arch/copyparty.service) and expects to find one or more [config files](./docs/example.conf) in `/etc/copyparty.d/`\n\n\n## fedora package\n\ndoes not exist yet;  using the [copr-pypi](https://copr.fedorainfracloud.org/coprs/g/copr/PyPI/) builds is **NOT recommended** because updates can be delayed by [several months](https://github.com/fedora-copr/copr/issues/3056)\n\n\n## nix package\n\n`nix profile install github:9001/copyparty`\n\nrequires a [flake-enabled](https://nixos.wiki/wiki/Flakes) installation of nix\n\nsome recommended dependencies are enabled by default; [override the package](https://github.com/9001/copyparty/blob/hovudstraum/contrib/package/nix/copyparty/default.nix#L3-L22) if you want to add/remove some features/deps\n\n`ffmpeg-full` was chosen over `ffmpeg-headless` mainly because we need `withWebp` (and `withOpenmpt` is also nice) and being able to use a cached build felt more important than optimizing for size at the time -- PRs welcome if you disagree \n\n\n## nixos module\n\nfor this setup, you will need a [flake-enabled](https://nixos.wiki/wiki/Flakes) installation of NixOS.\n\n```nix\n{\n  # add copyparty flake to your inputs\n  inputs.copyparty.url = \"github:9001/copyparty\";\n\n  # ensure that copyparty is an allowed argument to the outputs function\n  outputs = { self, nixpkgs, copyparty }: {\n    nixosConfigurations.yourHostName = nixpkgs.lib.nixosSystem {\n      modules = [\n        # load the copyparty NixOS module\n        copyparty.nixosModules.default\n        ({ pkgs, ... }: {\n          # add the copyparty overlay to expose the package to the module\n          nixpkgs.overlays = [ copyparty.overlays.default ];\n          # (optional) install the package globally\n          environment.systemPackages = [ pkgs.copyparty ];\n          # configure the copyparty module\n          services.copyparty.enable = true;\n        })\n      ];\n    };\n  };\n}\n```\n\ncopyparty on NixOS is configured via `services.copyparty` options, for example:\n```nix\nservices.copyparty = {\n  enable = true;\n  # directly maps to values in the [global] section of the copyparty config.\n  # see `copyparty --help` for available options\n  settings = {\n    i = \"0.0.0.0\";\n    # use lists to set multiple values\n    p = [ 3210 3211 ];\n    # use booleans to set binary flags\n    no-reload = true;\n    # using 'false' will do nothing and omit the value when generating a config\n    ignored-flag = false;\n  };\n\n  # create users\n  accounts = {\n    # specify the account name as the key\n    ed = {\n      # provide the path to a file containing the password, keeping it out of /nix/store\n      # must be readable by the copyparty service user\n      passwordFile = \"/run/keys/copyparty/ed_password\";\n    };\n    # or do both in one go\n    k.passwordFile = \"/run/keys/copyparty/k_password\";\n  };\n\n  # create a volume\n  volumes = {\n    # create a volume at \"/\" (the webroot), which will\n    \"/\" = {\n      # share the contents of \"/srv/copyparty\"\n      path = \"/srv/copyparty\";\n      # see `copyparty --help-accounts` for available options\n      access = {\n        # everyone gets read-access, but\n        r = \"*\";\n        # users \"ed\" and \"k\" get read-write\n        rw = [ \"ed\" \"k\" ];\n      };\n      # see `copyparty --help-flags` for available options\n      flags = {\n        # \"fk\" enables filekeys (necessary for upget permission) (4 chars long)\n        fk = 4;\n        # scan for new files every 60sec\n        scan = 60;\n        # volflag \"e2d\" enables the uploads database\n        e2d = true;\n        # \"d2t\" disables multimedia parsers (in case the uploads are malicious)\n        d2t = true;\n        # skips hashing file contents if path matches *.iso\n        nohash = \"\\.iso$\";\n      };\n    };\n  };\n  # you may increase the open file limit for the process\n  openFilesLimit = 8192;\n};\n```\n\nthe passwordFile at /run/keys/copyparty/ could for example be generated by [agenix](https://github.com/ryantm/agenix), or you could just dump it in the nix store instead if that's acceptable\n\n\n# browser support\n\nTLDR: yes\n\n![copyparty-ie4-fs8](https://user-images.githubusercontent.com/241032/118192791-fb31fe00-b446-11eb-9647-898ea8efc1f7.png)\n\n`ie` = internet-explorer, `ff` = firefox, `c` = chrome, `iOS` = iPhone/iPad, `Andr` = Android\n\n| feature         | ie6 | ie9  | ie10 | ie11 | ff 52 | c 49 | iOS | Andr |\n| --------------- | --- | ---- | ---- | ---- | ----- | ---- | --- | ---- |\n| browse files    | yep | yep  | yep  | yep  |  yep  | yep  | yep | yep  |\n| thumbnail view  |  -  | yep  | yep  | yep  |  yep  | yep  | yep | yep  |\n| basic uploader  | yep | yep  | yep  | yep  |  yep  | yep  | yep | yep  |\n| up2k            |  -  |  -   | `*1` | `*1` |  yep  | yep  | yep | yep  |\n| make directory  | yep | yep  | yep  | yep  |  yep  | yep  | yep | yep  |\n| send message    | yep | yep  | yep  | yep  |  yep  | yep  | yep | yep  |\n| set sort order  |  -  | yep  | yep  | yep  |  yep  | yep  | yep | yep  |\n| zip selection   |  -  | yep  | yep  | yep  |  yep  | yep  | yep | yep  |\n| file rename     |  -  | yep  | yep  | yep  |  yep  | yep  | yep | yep  |\n| file cut/paste  |  -  | yep  | yep  | yep  |  yep  | yep  | yep | yep  |\n| navpane         |  -  | yep  | yep  | yep  |  yep  | yep  | yep | yep  |\n| image viewer    |  -  | yep  | yep  | yep  |  yep  | yep  | yep | yep  |\n| video player    |  -  | yep  | yep  | yep  |  yep  | yep  | yep | yep  |\n| markdown editor |  -  |  -   | `*2` | `*2` |  yep  | yep  | yep | yep  |\n| markdown viewer |  -  | `*2` | `*2` | `*2` |  yep  | yep  | yep | yep  |\n| play mp3/m4a    |  -  | yep  | yep  | yep  |  yep  | yep  | yep | yep  |\n| play ogg/opus   |  -  |  -   |  -   |  -   |  yep  | yep  | `*3` | yep |\n| **= feature =** | ie6 | ie9  | ie10 | ie11 | ff 52 | c 49 | iOS | Andr |\n\n* internet explorer 6 through 8 behave the same\n* firefox 52 and chrome 49 are the final winxp versions\n* `*1` yes, but extremely slow (ie10: `1 MiB/s`, ie11: `270 KiB/s`)\n* `*2` only able to do plaintext documents (no markdown rendering)\n* `*3` iOS 11 and newer, opus only, and requires FFmpeg on the server\n\nquick summary of more eccentric web-browsers trying to view a directory index:\n\n| browser | will it blend |\n| ------- | ------------- |\n| **links** (2.21/macports) | can browse, login, upload/mkdir/msg |\n| **lynx** (2.8.9/macports) | can browse, login, upload/mkdir/msg |\n| **w3m** (0.5.3/macports)  | can browse, login, upload at 100kB/s, mkdir/msg |\n| **netsurf** (3.10/arch)   | is basically ie6 with much better css (javascript has almost no effect) | \n| **opera** (11.60/winxp)   | OK: thumbnails, image-viewer, zip-selection, rename/cut/paste. NG: up2k, navpane, markdown, audio |\n| **ie4** and **netscape** 4.0  | can browse, upload with `?b=u`, auth with `&pw=wark` |\n| **ncsa mosaic** 2.7       | does not get a pass, [pic1](https://user-images.githubusercontent.com/241032/174189227-ae816026-cf6f-4be5-a26e-1b3b072c1b2f.png) - [pic2](https://user-images.githubusercontent.com/241032/174189225-5651c059-5152-46e9-ac26-7e98e497901b.png) |\n| **SerenityOS** (7e98457)  | hits a page fault, works with `?b=u`, file upload not-impl |\n| **nintendo 3ds**          | can browse, upload, view thumbnails (thx bnjmn) |\n\n<p align=\"center\"><img src=\"https://github.com/user-attachments/assets/88deab3d-6cad-4017-8841-2f041472b853\" /></p>\n\n\n# client examples\n\ninteract with copyparty using non-browser clients\n\n* javascript: dump some state into a file (two separate examples)\n  * `await fetch('//127.0.0.1:3923/', {method:\"PUT\", body: JSON.stringify(foo)});`\n  * `var xhr = new XMLHttpRequest(); xhr.open('POST', '//127.0.0.1:3923/msgs?raw'); xhr.send('foo');`\n\n* curl/wget: upload some files (post=file, chunk=stdin)\n  * `post(){ curl -F f=@\"$1\" http://127.0.0.1:3923/?pw=wark;}`  \n    `post movie.mkv`  (gives HTML in return)\n  * `post(){ curl -F f=@\"$1\" 'http://127.0.0.1:3923/?want=url&pw=wark';}`  \n    `post movie.mkv`  (gives hotlink in return)\n  * `post(){ curl -H pw:wark -H rand:8 -T \"$1\" http://127.0.0.1:3923/;}`  \n    `post movie.mkv`  (randomized filename)\n  * `post(){ wget --header='pw: wark' --post-file=\"$1\" -O- http://127.0.0.1:3923/?raw;}`  \n    `post movie.mkv`\n  * `chunk(){ curl -H pw:wark -T- http://127.0.0.1:3923/;}`  \n    `chunk <movie.mkv`\n\n* bash: when curl and wget is not available or too boring\n  * `(printf 'PUT /junk?pw=wark HTTP/1.1\\r\\n\\r\\n'; cat movie.mkv) | nc 127.0.0.1 3923`\n  * `(printf 'PUT / HTTP/1.1\\r\\n\\r\\n'; cat movie.mkv) >/dev/tcp/127.0.0.1/3923`\n\n* python: [u2c.py](https://github.com/9001/copyparty/blob/hovudstraum/bin/u2c.py) is a command-line up2k client [(webm)](https://ocv.me/stuff/u2cli.webm)\n  * file uploads, file-search, [folder sync](#folder-sync), autoresume of aborted/broken uploads\n  * can be downloaded from copyparty: controlpanel -> connect -> [u2c.py](http://127.0.0.1:3923/.cpr/a/u2c.py)\n  * see [./bin/README.md#u2cpy](bin/README.md#u2cpy)\n\n* FUSE: mount a copyparty server as a local filesystem\n  * cross-platform python client available in [./bin/](bin/)\n  * able to mount nginx and iis directory listings too, not just copyparty\n  * can be downloaded from copyparty: controlpanel -> connect -> [partyfuse.py](http://127.0.0.1:3923/.cpr/a/partyfuse.py)\n  * [rclone](https://rclone.org/) as client can give ~5x performance, see [./docs/rclone.md](docs/rclone.md)\n\n* sharex (screenshot utility): see [./contrib/sharex.sxcu](contrib/#sharexsxcu)\n  * and for screenshots on linux, see [./contrib/flameshot.sh](./contrib/flameshot.sh)\n\n* contextlet (web browser integration); see [contrib contextlet](contrib/#send-to-cppcontextletjson)\n\n* [igloo irc](https://iglooirc.com/): Method: `post` Host: `https://you.com/up/?want=url&pw=hunter2` Multipart: `yes` File parameter: `f`\n\ncopyparty returns a truncated sha512sum of your PUT/POST as base64; you can generate the same checksum locally to verify uploads:\n\n    b512(){ printf \"$((sha512sum||shasum -a512)|sed -E 's/ .*//;s/(..)/\\\\x\\1/g')\"|base64|tr '+/' '-_'|head -c44;}\n    b512 <movie.mkv\n\nyou can provide passwords using header `PW: hunter2`, cookie `cppwd=hunter2`, url-param `?pw=hunter2`, or with basic-authentication (either as the username or password)\n\nNOTE: curl will not send the original filename if you use `-T` combined with url-params! Also, make sure to always leave a trailing slash in URLs unless you want to override the filename\n\n\n## folder sync\n\nsync folders to/from copyparty\n\nthe commandline uploader [u2c.py](https://github.com/9001/copyparty/tree/hovudstraum/bin#u2cpy) with `--dr` is the best way to sync a folder to copyparty; verifies checksums and does files in parallel, and deletes unexpected files on the server after upload has finished which makes file-renames really cheap (it'll rename serverside and skip uploading)\n\nalternatively there is [rclone](./docs/rclone.md) which allows for bidirectional sync and is *way* more flexible (stream files straight from sftp/s3/gcs to copyparty, ...), although there is no integrity check and it won't work with files over 100 MiB if copyparty is behind cloudflare\n\n* starting from rclone v1.63, rclone is faster than u2c.py on low-latency connections\n\n\n## mount as drive\n\na remote copyparty server as a local filesystem;  go to the control-panel and click `connect` to see a list of commands to do that\n\nalternatively, some alternatives roughly sorted by speed (unreproducible benchmark), best first:\n\n* [rclone-webdav](./docs/rclone.md) (25s), read/WRITE (rclone v1.63 or later)\n* [rclone-http](./docs/rclone.md) (26s), read-only\n* [partyfuse.py](./bin/#partyfusepy) (26s), read-only\n* [rclone-ftp](./docs/rclone.md) (47s), read/WRITE\n* davfs2 (103s), read/WRITE\n* [win10-webdav](#webdav-server) (138s), read/WRITE\n* [win10-smb2](#smb-server) (387s), read/WRITE\n\nmost clients will fail to mount the root of a copyparty server unless there is a root volume (so you get the admin-panel instead of a browser when accessing it) -- in that case, mount a specific volume instead\n\nif you have volumes that are accessible without a password, then some webdav clients (such as davfs2) require the global-option `--dav-auth` to access any password-protected areas\n\n\n# android app\n\nupload to copyparty with one tap\n\n<a href=\"https://f-droid.org/packages/me.ocv.partyup/\"><img src=\"https://ocv.me/fdroid.png\" alt=\"Get it on F-Droid\" height=\"50\" /> '' <img src=\"https://img.shields.io/f-droid/v/me.ocv.partyup.svg\" alt=\"f-droid version info\" /></a> '' <a href=\"https://github.com/9001/party-up\"><img src=\"https://img.shields.io/github/release/9001/party-up.svg?logo=github\" alt=\"github version info\" /></a>\n\nthe app is **NOT** the full copyparty server! just a basic upload client, nothing fancy yet\n\nif you want to run the copyparty server on your android device, see [install on android](#install-on-android)\n\n\n# iOS shortcuts\n\nthere is no iPhone app, but  the following shortcuts are almost as good:\n\n* [upload to copyparty](https://www.icloud.com/shortcuts/41e98dd985cb4d3bb433222bc1e9e770) ([offline](https://github.com/9001/copyparty/raw/hovudstraum/contrib/ios/upload-to-copyparty.shortcut)) ([png](https://user-images.githubusercontent.com/241032/226118053-78623554-b0ed-482e-98e4-6d57ada58ea4.png)) based on the [original](https://www.icloud.com/shortcuts/ab415d5b4de3467b9ce6f151b439a5d7) by [Daedren](https://github.com/Daedren) (thx!)\n  * can strip exif, upload files, pics, vids, links, clipboard\n  * can download links and rehost the target file on copyparty (see first comment inside the shortcut)\n  * pics become lowres if you share from gallery to shortcut, so better to launch the shortcut and pick stuff from there\n\n\n# performance\n\ndefaults are usually fine - expect `8 GiB/s` download, `1 GiB/s` upload\n\nbelow are some tweaks roughly ordered by usefulness:\n\n* disabling HTTP/2 and HTTP/3 can make uploads 5x faster, depending on server/client software\n* `-q` disables logging and can help a bunch, even when combined with `-lo` to redirect logs to file\n* `--hist` pointing to a fast location (ssd) will make directory listings and searches faster when `-e2d` or `-e2t` is set\n  * and also makes thumbnails load faster, regardless of e2d/e2t\n* `--dedup` enables deduplication and thus avoids writing to the HDD if someone uploads a dupe\n* `--safe-dedup 1` makes deduplication much faster during upload by skipping verification of file contents; safe if there is no other software editing/moving the files in the volumes\n* `--no-dirsz` shows the size of folder inodes instead of the total size of the contents, giving about 30% faster folder listings\n* `--no-hash .` when indexing a network-disk if you don't care about the actual filehashes and only want the names/tags searchable\n* if your volumes are on a network-disk such as NFS / SMB / s3, specifying larger values for `--iobuf` and/or `--s-rd-sz` and/or `--s-wr-sz` may help; try setting all of them to `524288` or `1048576` or `4194304`\n* `--no-htp --hash-mt=0 --mtag-mt=1 --th-mt=1` minimizes the number of threads; can help in some eccentric environments (like the vscode debugger)\n* `-j0` enables multiprocessing (actual multithreading), can reduce latency to `20+80/numCores` percent and generally improve performance in cpu-intensive workloads, for example:\n  * lots of connections (many users or heavy clients)\n  * simultaneous downloads and uploads saturating a 20gbps connection\n  * if `-e2d` is enabled, `-j2` gives 4x performance for directory listings; `-j4` gives 16x\n  \n  ...however it also increases the server/filesystem/HDD load during uploads, and adds an overhead to internal communication, so it is usually a better idea to don't\n* using [pypy](https://www.pypy.org/) instead of [cpython](https://www.python.org/) *can* be 70% faster for some workloads, but slower for many others\n  * and pypy can sometimes crash on startup with `-j0` (TODO make issue)\n\n\n## client-side\n\nwhen uploading files,\n\n* chrome is recommended (unfortunately), at least compared to firefox:\n  * up to 90% faster when hashing, especially on SSDs\n  * up to 40% faster when uploading over extremely fast internets\n  * but [u2c.py](https://github.com/9001/copyparty/blob/hovudstraum/bin/u2c.py) can be 40% faster than chrome again\n\n* if you're cpu-bottlenecked, or the browser is maxing a cpu core:\n  * up to 30% faster uploads if you hide the upload status list by switching away from the `[]` up2k ui-tab (or closing it)\n    * optionally you can switch to the lightweight potato ui by clicking the `[]`\n    * switching to another browser-tab also works, the favicon will update every 10 seconds in that case\n  * unlikely to be a problem, but can happen when uploading many small files, or your internet is too fast, or PC too slow\n\n\n# security\n\nthere is a [discord server](https://discord.gg/25J8CdTT6G)  with an `@everyone` for all important updates (at the lack of better ideas)\n\nsome notes on hardening\n\n* set `--rproxy 0` if your copyparty is directly facing the internet (not through a reverse-proxy)\n  * cors doesn't work right otherwise\n* if you allow anonymous uploads or otherwise don't trust the contents of a volume, you can prevent XSS with volflag `nohtml`\n  * this returns html documents as plaintext, and also disables markdown rendering\n* when running behind a reverse-proxy, listen on a unix-socket for tighter access control (and more performance); see [reverse-proxy](#reverse-proxy) or `--help-bind`\n\nsafety profiles:\n\n* option `-s` is a shortcut to set the following options:\n  * `--no-thumb` disables thumbnails and audio transcoding to stop copyparty from running `FFmpeg`/`Pillow`/`VIPS` on uploaded files, which is a [good idea](https://www.cvedetails.com/vulnerability-list.php?vendor_id=3611) if anonymous upload is enabled\n  * `--no-mtag-ff` uses `mutagen` to grab music tags instead of `FFmpeg`, which is safer and faster but less accurate\n  * `--dotpart` hides uploads from directory listings while they're still incoming\n  * `--no-robots` and `--force-js` makes life harder for crawlers, see [hiding from google](#hiding-from-google)\n\n* option `-ss` is a shortcut for the above plus:\n  * `--unpost 0`, `--no-del`, `--no-mv` disables all move/delete support\n  * `--hardlink` creates hardlinks instead of symlinks when deduplicating uploads, which is less maintenance\n    * however note if you edit one file it will also affect the other copies\n  * `--vague-403` returns a \"404 not found\" instead of \"401 unauthorized\" which is a common enterprise meme\n  * `-nih` removes the server hostname from directory listings\n\n* option `-sss` is a shortcut for the above plus:\n  * `--no-dav` disables webdav support\n  * `--no-logues` and `--no-readme` disables support for readme's and prologues / epilogues in directory listings, which otherwise lets people upload arbitrary (but sandboxed) `<script>` tags\n  * `-lo cpp-%Y-%m%d-%H%M%S.txt.xz` enables logging to disk\n  * `-ls **,*,ln,p,r` does a scan on startup for any dangerous symlinks\n\nother misc notes:\n\n* you can disable directory listings by giving permission `g` instead of `r`, only accepting direct URLs to files\n  * you may want [filekeys](#filekeys) to prevent filename bruteforcing\n  * permission `h` instead of `r` makes copyparty behave like a traditional webserver with directory listing/index disabled, returning index.html instead\n    * compatibility with filekeys: index.html itself can be retrieved without the correct filekey, but all other files are protected\n\n\n## gotchas\n\nbehavior that might be unexpected\n\n* users without read-access to a folder can still see the `.prologue.html` / `.epilogue.html` / `PREADME.md` / `README.md` contents, for the purpose of showing a description on how to use the uploader for example\n* users can submit `<script>`s which autorun (in a sandbox) for other visitors in a few ways;\n  * uploading a `README.md` -- avoid with `--no-readme`\n  * renaming `some.html` to `.epilogue.html` -- avoid with either `--no-logues` or `--no-dot-ren`\n  * the directory-listing embed is sandboxed (so any malicious scripts can't do any damage) but the markdown editor is not 100% safe, see below\n* markdown documents can contain html and `<script>`s; attempts are made to prevent scripts from executing (unless `-emp` is specified) but this is not 100% bulletproof, so setting the `nohtml` volflag is still the safest choice\n  * or eliminate the problem entirely by only giving write-access to trustworthy people :^)\n\n\n## cors\n\ncross-site request config\n\nby default, except for `GET` and `HEAD` operations, all requests must either:\n* not contain an `Origin` header at all\n* or have an `Origin` matching the server domain\n* or the header `PW` with your password as value\n\ncors can be configured with `--acao` and `--acam`, or the protections entirely disabled with `--allow-csrf`\n\n\n## filekeys\n\nprevent filename bruteforcing\n\nvolflag `fk` generates filekeys (per-file accesskeys) for all files; users which have full read-access (permission `r`) will then see URLs with the correct filekey `?k=...` appended to the end, and `g` users must provide that URL including the correct key to avoid a 404\n\nby default, filekeys are generated based on salt (`--fk-salt`) + filesystem-path + file-size + inode (if not windows); add volflag `fka` to generate slightly weaker filekeys which will not be invalidated if the file is edited (only salt + path)\n\npermissions `wG` (write + upget) lets users upload files and receive their own filekeys, still without being able to see other uploads\n\n### dirkeys\n\nshare specific folders in a volume  without giving away full read-access to the rest -- the visitor only needs the `g` (get) permission to view the link\n\nvolflag `dk` generates dirkeys (per-directory accesskeys) for all folders, granting read-access to that folder; by default only that folder itself, no subfolders\n\nvolflag `dky` disables the actual key-check, meaning anyone can see the contents of a folder where they have `g` access, but not its subdirectories\n\n* `dk` + `dky` gives the same behavior as if all users with `g` access have full read-access, but subfolders are hidden files (as if their names start with a dot), so `dky` is an alternative to renaming all the folders for that purpose, maybe just for some users\n\nvolflag `dks` lets people enter subfolders as well, and also enables download-as-zip/tar\n\nif you enable dirkeys, it is probably a good idea to enable filekeys too, otherwise it will be impossible to hotlink files from a folder which was accessed using a dirkey\n\ndirkeys are generated based on another salt (`--dk-salt`) + filesystem-path and have a few limitations:\n* the key does not change if the contents of the folder is modified\n  * if you need a new dirkey, either change the salt or rename the folder\n* linking to a textfile (so it opens in the textfile viewer) is not possible if recipient doesn't have read-access\n\n\n## password hashing\n\nyou can hash passwords  before putting them into config files / providing them as arguments; see `--help-pwhash` for all the details\n\n`--ah-alg argon2` enables it, and if you have any plaintext passwords then it'll print the hashed versions on startup so you can replace them\n\noptionally also specify `--ah-cli` to enter an interactive mode where it will hash passwords without ever writing the plaintext ones to disk\n\nthe default configs take about 0.4 sec and 256 MiB RAM to process a new password on a decent laptop\n\n\n## https\n\nboth HTTP and HTTPS are accepted  by default, but letting a [reverse proxy](#reverse-proxy) handle the https/tls/ssl would be better (probably more secure by default)\n\ncopyparty doesn't speak HTTP/2 or QUIC, so using a reverse proxy would solve that as well -- but note that HTTP/1 is usually faster than both HTTP/2 and HTTP/3\n\nif [cfssl](https://github.com/cloudflare/cfssl/releases/latest) is installed, copyparty will automatically create a CA and server-cert on startup\n* the certs are written to `--crt-dir` for distribution, see `--help` for the other `--crt` options\n* this will be a self-signed certificate so you must install your `ca.pem` into all your browsers/devices\n* if you want to avoid the hassle of distributing certs manually, please consider using a reverse proxy\n\n\n# recovering from crashes\n\n## client crashes\n\n### firefox wsod\n\nfirefox 87 can crash during uploads  -- the entire browser goes, including all other browser tabs, everything turns white\n\nhowever you can hit `F12` in the up2k tab and use the devtools to see how far you got in the uploads:\n\n* get a complete list of all uploads, organized by status (ok / no-good / busy / queued):  \n  `var tabs = { ok:[], ng:[], bz:[], q:[] }; for (var a of up2k.ui.tab) tabs[a.in].push(a); tabs`\n\n* list of filenames which failed:  \n  `var ng = []; for (var a of up2k.ui.tab) if (a.in != 'ok') ng.push(a.hn.split('<a href=\\\"').slice(-1)[0].split('\\\">')[0]); ng`\n\n* send the list of filenames to copyparty for safekeeping:  \n  `await fetch('/inc', {method:'PUT', body:JSON.stringify(ng,null,1)})`\n\n\n# HTTP API\n\nsee [devnotes](./docs/devnotes.md#http-api)\n\n\n# dependencies\n\nmandatory deps:\n* `jinja2` (is built into the SFX)\n\n\n## optional dependencies\n\ninstall these to enable bonus features\n\nenable hashed passwords in config: `argon2-cffi`\n\nenable ftp-server:\n* for just plaintext FTP, `pyftpdlib` (is built into the SFX)\n* with TLS encryption, `pyftpdlib pyopenssl`\n\nenable music tags:\n* either `mutagen` (fast, pure-python, skips a few tags, makes copyparty GPL? idk)\n* or `ffprobe` (20x slower, more accurate, possibly dangerous depending on your distro and users)\n\nenable [thumbnails](#thumbnails) of...\n* **images:** `Pillow` and/or `pyvips` and/or `ffmpeg` (requires py2.7 or py3.5+)\n* **videos/audio:** `ffmpeg` and `ffprobe` somewhere in `$PATH`\n* **HEIF pictures:** `pyvips` or `ffmpeg` or `pyheif-pillow-opener` (requires Linux or a C compiler)\n* **AVIF pictures:** `pyvips` or `ffmpeg` or `pillow-avif-plugin`\n* **JPEG XL pictures:** `pyvips` or `ffmpeg`\n\nenable [smb](#smb-server) support (**not** recommended):\n* `impacket==0.12.0`\n\n`pyvips` gives higher quality thumbnails than `Pillow` and is 320% faster, using 270% more ram: `sudo apt install libvips42 && python3 -m pip install --user -U pyvips`\n\n\n### dependency chickenbits\n\nprevent loading an optional dependency  , for example if:\n\n* you have an incompatible version installed and it causes problems\n* you just don't want copyparty to use it, maybe to save ram\n\nset any of the following environment variables to disable its associated optional feature,\n\n| env-var              | what it does |\n| -------------------- | ------------ |\n| `PRTY_NO_ARGON2`     | disable argon2-cffi password hashing |\n| `PRTY_NO_CFSSL`      | never attempt to generate self-signed certificates using [cfssl](https://github.com/cloudflare/cfssl) |\n| `PRTY_NO_FFMPEG`     | **audio transcoding** goes byebye, **thumbnailing** must be handled by Pillow/libvips |\n| `PRTY_NO_FFPROBE`    | **audio transcoding** goes byebye, **thumbnailing** must be handled by Pillow/libvips, **metadata-scanning** must be handled by mutagen |\n| `PRTY_NO_MUTAGEN`    | do not use [mutagen](https://pypi.org/project/mutagen/) for reading metadata from media files; will fallback to ffprobe |\n| `PRTY_NO_PIL`        | disable all [Pillow](https://pypi.org/project/pillow/)-based thumbnail support; will fallback to libvips or ffmpeg |\n| `PRTY_NO_PILF`       | disable Pillow `ImageFont` text rendering, used for folder thumbnails |\n| `PRTY_NO_PIL_AVIF`   | disable 3rd-party Pillow plugin for [AVIF support](https://pypi.org/project/pillow-avif-plugin/) |\n| `PRTY_NO_PIL_HEIF`   | disable 3rd-party Pillow plugin for [HEIF support](https://pypi.org/project/pyheif-pillow-opener/) |\n| `PRTY_NO_PIL_WEBP`   | disable use of native webp support in Pillow |\n| `PRTY_NO_PSUTIL`     | do not use [psutil](https://pypi.org/project/psutil/) for reaping stuck hooks and plugins on Windows |\n| `PRTY_NO_VIPS`       | disable all [libvips](https://pypi.org/project/pyvips/)-based thumbnail support; will fallback to Pillow or ffmpeg |\n\nexample: `PRTY_NO_PIL=1 python3 copyparty-sfx.py`\n\n* `PRTY_NO_PIL` saves ram\n* `PRTY_NO_VIPS` saves ram and startup time\n* python2.7 on windows: `PRTY_NO_FFMPEG` + `PRTY_NO_FFPROBE` saves startup time\n\n\n## optional gpl stuff\n\nsome bundled tools have copyleft dependencies, see [./bin/#mtag](bin/#mtag)\n\nthese are standalone programs and will never be imported / evaluated by copyparty, and must be enabled through `-mtp` configs\n\n\n# sfx\n\nthe self-contained \"binary\" (recommended!)  [copyparty-sfx.py](https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py) will unpack itself and run copyparty, assuming you have python installed of course\n\nyou can reduce the sfx size by repacking it; see [./docs/devnotes.md#sfx-repack](./docs/devnotes.md#sfx-repack)\n\n\n## copyparty.exe\n\ndownload [copyparty.exe](https://github.com/9001/copyparty/releases/latest/download/copyparty.exe) (win8+) or [copyparty32.exe](https://github.com/9001/copyparty/releases/latest/download/copyparty32.exe) (win7+)\n\n![copyparty-exe-fs8](https://user-images.githubusercontent.com/241032/221445946-1e328e56-8c5b-44a9-8b9f-dee84d942535.png)\n\ncan be convenient on machines where installing python is problematic, however is **not recommended** -- if possible, please use **[copyparty-sfx.py](https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py)** instead\n\n* [copyparty.exe](https://github.com/9001/copyparty/releases/latest/download/copyparty.exe) runs on win8 or newer, was compiled on win10, does thumbnails + media tags, and is *currently* safe to use, but any future python/expat/pillow CVEs can only be remedied by downloading a newer version of the exe\n\n  * on win8 it needs [vc redist 2015](https://www.microsoft.com/en-us/download/details.aspx?id=48145), on win10 it just works\n  * some antivirus may freak out (false-positive), possibly [Avast, AVG, and McAfee](https://www.virustotal.com/gui/file/52391a1e9842cf70ad243ef83844d46d29c0044d101ee0138fcdd3c8de2237d6/detection)\n\n* dangerous: [copyparty32.exe](https://github.com/9001/copyparty/releases/latest/download/copyparty32.exe) is compatible with [windows7](https://user-images.githubusercontent.com/241032/221445944-ae85d1f4-d351-4837-b130-82cab57d6cca.png), which means it uses an ancient copy of python (3.7.9) which cannot be upgraded and should never be exposed to the internet (LAN is fine)\n\n* dangerous and deprecated: [copyparty-winpe64.exe](https://github.com/9001/copyparty/releases/download/v1.8.7/copyparty-winpe64.exe) lets you [run copyparty in WinPE](https://user-images.githubusercontent.com/241032/205454984-e6b550df-3c49-486d-9267-1614078dd0dd.png) and is otherwise completely useless\n\nmeanwhile [copyparty-sfx.py](https://github.com/9001/copyparty/releases/latest/download/copyparty-sfx.py) instead relies on your system python which gives better performance and will stay safe as long as you keep your python install up-to-date\n\nthen again, if you are already into downloading shady binaries from the internet, you may also want my [minimal builds](./scripts/pyinstaller#ffmpeg) of [ffmpeg](https://ocv.me/stuff/bin/ffmpeg.exe) and [ffprobe](https://ocv.me/stuff/bin/ffprobe.exe) which enables copyparty to extract multimedia-info, do audio-transcoding, and thumbnails/spectrograms/waveforms, however it's much better to instead grab a [recent official build](https://www.gyan.dev/ffmpeg/builds/ffmpeg-git-full.7z) every once ina while if you can afford the size\n\n\n## zipapp\n\nanother emergency alternative, [copyparty.pyz](https://github.com/9001/copyparty/releases/latest/download/copyparty.pyz)  has less features, is slow, requires python 3.7 or newer, worse compression, and more importantly is unable to benefit from more recent versions of jinja2 and such (which makes it less secure)... lots of drawbacks with this one really -- but it does not unpack any temporary files to disk, so it *may* just work if the regular sfx fails to start because the computer is messed up in certain funky ways, so it's worth a shot if all else fails\n\nrun it by doubleclicking it, or try typing `python copyparty.pyz` in your terminal/console/commandline/telex if that fails\n\nit is a python [zipapp](https://docs.python.org/3/library/zipapp.html) meaning it doesn't have to unpack its own python code anywhere to run, so if the filesystem is busted it has a better chance of getting somewhere\n* but note that it currently still needs to extract the web-resources somewhere (they'll land in the default TEMP-folder of your OS)\n\n\n# install on android\n\ninstall [Termux](https://termux.com/) + its companion app `Termux:API` (see [ocv.me/termux](https://ocv.me/termux/)) and then copy-paste this into Termux (long-tap) all at once:\n```sh\nyes | pkg upgrade && termux-setup-storage && yes | pkg install python termux-api && python -m ensurepip && python -m pip install --user -U copyparty && { grep -qE 'PATH=.*\\.local/bin' ~/.bashrc 2>/dev/null || { echo 'PATH=\"$HOME/.local/bin:$PATH\"' >> ~/.bashrc && . ~/.bashrc; }; }\necho $?\n```\n\nafter the initial setup, you can launch copyparty at any time by running `copyparty` anywhere in Termux -- and if you run it with `--qr` you'll get a [neat qr-code](#qr-code) pointing to your external ip\n\nif you want thumbnails (photos+videos) and you're okay with spending another 132 MiB of storage, `pkg install ffmpeg && python3 -m pip install --user -U pillow`\n\n* or if you want to use `vips` for photo-thumbs instead, `pkg install libvips && python -m pip install --user -U wheel && python -m pip install --user -U pyvips && (cd /data/data/com.termux/files/usr/lib/; ln -s libgobject-2.0.so{,.0}; ln -s libvips.so{,.42})`\n\n\n# reporting bugs\n\nideas for context to include, and where to submit them\n\nplease get in touch using any of the following URLs:\n* https://github.com/9001/copyparty/ **(primary)**\n* https://gitlab.com/9001/copyparty/ *(mirror)*\n* https://codeberg.org/9001/copyparty *(mirror)*\n\nin general, commandline arguments (and config file if any)\n\nif something broke during an upload (replacing FILENAME with a part of the filename that broke):\n```\njournalctl -aS '48 hour ago' -u copyparty | grep -C10 FILENAME | tee bug.log\n```\n\nif there's a wall of base64 in the log (thread stacks) then please include that, especially if you run into something freezing up or getting stuck, for example `OperationalError('database is locked')` -- alternatively you can visit `/?stack` to see the stacks live, so http://127.0.0.1:3923/?stack for example\n\n\n# devnotes\n\nfor build instructions etc, see [./docs/devnotes.md](./docs/devnotes.md)\n\nsee [./docs/TODO.md](./docs/TODO.md) for planned features / fixes / changes\n\n",
        "num_commits": 3321,
        "project_age_days": 1983,
        "project_created_at": "2019-05-26",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-28",
        "num_contributors": 10,
        "num_pull": 17,
        "num_issues": 109,
        "num_opening_issue": 8,
        "project_size(kB)": 8200,
        "num_stargazers": 811,
        "num_watchers": 811,
        "num_forks": 47,
        "num_subscribers": 8,
        "SecurityPolicy_created_at": "2022-12-19 21:18:27",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "8491a40a04598bdc5d4b1e69aeb4166bf1476a2e",
                "url": "https://github.com/9001/copyparty/commit/8491a40a04598bdc5d4b1e69aeb4166bf1476a2e",
                "date": "2022-12-19 21:18:27"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email_advisory_external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "indico/indico",
        "project_url": "https://github.com/indico/indico",
        "SSF": {
            "date": "2024-10-29T22:10:41+07:00",
            "repo": {
                "name": "github.com/indico/indico",
                "commit": "ba4f9be8f5506e5e997f95e5f8ad35af141956fc"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.9,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Warn: 'force pushes' enabled on branch 'master'",
                        "Warn: branch 'master' does not require approvers",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Info: status check found to merge onto on branch 'master'"
                    ],
                    "score": 1,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "21 out of 21 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 5,
                    "reason": "Found 14/28 approved changesets -- score normalized to 5",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: cern / @indico contributor org/company found, unconventionaldotdev contributor org/company found, python contributor org/company found, inveniosoftware contributor org/company found, eForceDriverless contributor org/company found, unog contributor org/company found, genericwebsite contributor org/company found, padelpro contributor org/company found, bonfirelink contributor org/company found, cernopendata contributor org/company found, mlz tu mnchen contributor org/company found, HumanCellAtlas contributor org/company found, CERN contributor org/company found, indico contributor org/company found, muses-fm contributor org/company found, embl-ebi contributor org/company found, GameSurge contributor org/company found, reanahub contributor org/company found, dc-js contributor org/company found, indico at cern contributor org/company found, swisscom contributor org/company found, mlz-ictrl contributor org/company found, identifiers-org contributor org/company found, devius llp contributor org/company found, genericsa contributor org/company found, ikigau contributor org/company found, pallets contributor org/company found, pivotal contributor org/company found, Am-I-Going-On-Holiday contributor org/company found, cern contributor org/company found, python-babel contributor org/company found, advaya-life contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 32 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 20 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/pypi.yml:78"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/build.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/build.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/build.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:55: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/build.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:68: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/build.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:71: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:89: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:101: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:104: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:109: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:117: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/ci.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yml:206: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:243: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:246: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:251: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:259: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:302: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:305: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:310: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:318: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:61: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:64: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/labeler.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/labeler.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi.yml:89: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/pypi.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pypi.yml:92: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/pypi.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pypi.yml:97: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi.yml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi.yml:35: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi.yml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pypi.yml:65: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/translations.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/translations.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/translations.yml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/translations.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/translations.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/translations.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/translations.yml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/indico/indico/translations.yml/master?enable=pin",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/build.yml:51",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/ci.yml:55",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/ci.yml:115",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/ci.yml:257",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/ci.yml:316",
                        "Warn: pipCommand not pinned by hash: .github/workflows/codeql-analysis.yml:45",
                        "Warn: pipCommand not pinned by hash: .github/workflows/codeql-analysis.yml:46",
                        "Warn: pipCommand not pinned by hash: .github/workflows/codeql-analysis.yml:47",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pypi.yml:30",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pypi.yml:41",
                        "Warn: pipCommand not pinned by hash: .github/workflows/translations.yml:34",
                        "Warn: pipCommand not pinned by hash: .github/workflows/translations.yml:35",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/translations.yml:40",
                        "Info:   0 out of  40 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   3 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   6 downloadThenRun dependencies pinned",
                        "Info:   4 out of   4 npmCommand dependencies pinned",
                        "Info:   0 out of   7 pipCommand dependencies pinned"
                    ],
                    "score": 1,
                    "reason": "dependency not pinned by hash detected -- score normalized to 1",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: all commits (21) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact v3.3.4 not signed: https://api.github.com/repos/indico/indico/releases/173441816",
                        "Warn: release artifact v3.3.3 not signed: https://api.github.com/repos/indico/indico/releases/162408257",
                        "Warn: release artifact v3.3.2 not signed: https://api.github.com/repos/indico/indico/releases/151882377",
                        "Warn: release artifact v3.3.1 not signed: https://api.github.com/repos/indico/indico/releases/149212960",
                        "Warn: release artifact v3.3 not signed: https://api.github.com/repos/indico/indico/releases/149099907",
                        "Warn: release artifact v3.3.4 does not have provenance: https://api.github.com/repos/indico/indico/releases/173441816",
                        "Warn: release artifact v3.3.3 does not have provenance: https://api.github.com/repos/indico/indico/releases/162408257",
                        "Warn: release artifact v3.3.2 does not have provenance: https://api.github.com/repos/indico/indico/releases/151882377",
                        "Warn: release artifact v3.3.1 does not have provenance: https://api.github.com/repos/indico/indico/releases/149212960",
                        "Warn: release artifact v3.3 does not have provenance: https://api.github.com/repos/indico/indico/releases/149099907"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql-analysis.yml:20",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql-analysis.yml:21",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/labeler.yml:9",
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/pypi.yml:86",
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/pypi.yml:63",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/translations.yml:16",
                        "Warn: no topLevel permission defined: .github/workflows/build.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/ci.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/codeql-analysis.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/labeler.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/pypi.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/translations.yml:1"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-36jr-mh4h-2g58",
                        "Warn: Project is vulnerable to: GHSA-9gj3-hwp5-pmwc",
                        "Warn: Project is vulnerable to: GHSA-gpqq-952q-5327",
                        "Warn: Project is vulnerable to: GHSA-j7qv-pgf6-hvh4",
                        "Warn: Project is vulnerable to: GHSA-h6gj-6jjq-h8g9",
                        "Warn: Project is vulnerable to: GHSA-952p-6rrq-rcjv",
                        "Warn: Project is vulnerable to: GHSA-5359-pvf2-pw78",
                        "Warn: Project is vulnerable to: GHSA-g92j-qhmh-64v2"
                    ],
                    "score": 2,
                    "reason": "8 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/indico/indico/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nIndico uses the second part of the version number for major feature releases, ie.\n3.1, 3.2, ...\n\n**Bugfixes are generally only released for the latest major version (e.g. 3.1.1 to\nfix bugs discovered in 3.1).**\n\n**For security releases we usually follow the same schema.** In exceptional cases\nwhere the previous version (e.g. 3.0) is still somewhat recent and thus widely\nused AND no suitable workarounds exist, we may also create a patch release for\nthat version.\n\n## Reporting a Vulnerability\n\nPlease report it privately using GitHub's [\"Report a Vulnerability\"][gh-vuln] option.\nIn case you do not have a GitHub account, you can also email indico-team@cern.ch.\n\n\n[gh-vuln]: https://github.com/indico/indico/security/advisories/new\n",
        "project_all_labels": [
            "a11y",
            "alembic",
            "bug",
            "build-wheel",
            "dependencies",
            "duplicate",
            "enhancement",
            "github_actions",
            "Hacktoberfest",
            "hacktoberfest-accepted",
            "help wanted",
            "infoneeded",
            "invalid",
            "jacow",
            "javascript",
            "needs-fix",
            "new-timetable",
            "norepro",
            "p-blocker",
            "p-critical",
            "p-desirable",
            "p-essential",
            "p-medium",
            "p-minor",
            "prj-global",
            "python",
            "trivial",
            "usability",
            "wontfix"
        ],
        "README_content": "# Indico ![CI Status](https://github.com/indico/indico/workflows/CI/badge.svg) [![License](https://img.shields.io/github/license/indico/indico.svg)](https://github.com/indico/indico/blob/master/LICENSE) [![Available on PyPI](https://img.shields.io/pypi/v/indico.svg)](https://pypi.python.org/pypi/indico/) [![Made at CERN!](https://img.shields.io/badge/CERN-Open%20Source-%232980b9.svg)](https://home.cern)\n\n<img src=\"https://github.com/indico/indico/raw/master/indico/web/static/images/logo_indico.png\"\n     align=\"right\"\n     width=\"300\"\n     style=\"width: 300px; float: right; margin-right: 50px;\">\n\n**Indico** is:\n *  a general-purpose **event management** tool;\n *  fully **web-based**;\n *  **feature-rich** but also **extensible** through the use of [plugins](https://docs.getindico.io/en/stable/plugins/);\n *  **Open-Source** Software under the MIT License;\n * <img src=\"https://raw.githubusercontent.com/indico/assets/master/cern_badge.png\" width=\"20\"> **made at CERN**, [the place where the web was born](https://home.cern/science/computing/birth-web)!\n\n![A sneak peek of Indico](https://raw.githubusercontent.com/indico/indico/master/sneakpeek.gif)\n\n## What does it do?\nIndico's **main features** are:\n * a powerful and flexible **hierarchical content management** system for events;\n * a full-blown **conference organization workflow** with:\n   -  **Call for Abstracts** and **abstract reviewing** modules;\n   -  flexible **registration form** creation and configuration;\n   -  integration with existing **payment systems**;\n   -  a **paper reviewing** workflow;\n   -  a **drag and drop timetable management interface**;\n   -  a simple **badge editor** with the possibility to print badges and tickets for participants;\n * tools for **meeting management** and archival of presentation materials;\n * a powerful **room booking** interface;\n * integration with existing **video conferencing solutions**;\n\nA more detailed list [can be found here](https://getindico.io/features/). There is also a [video](https://www.youtube.com/watch?v=yo8rgg9dOcc)!\n\n## I just want to try it out!\n\nWe've got a [Sandbox](https://sandbox.getindico.io)!\n\n## Browser support\n\nThese are the minimum versions of major browsers currently supported by Indico. We try to target all modern browsers as\nmuch as possible, but only issues detected on those will be considered at critical level.\n\n<!-- BROWSERS - this is all machine-generated! Don't change it. -->\n| <img src=\"https://raw.githubusercontent.com/alrra/browser-logos/master/src/firefox/firefox_48x48.png\" alt=\"Firefox\" width=\"24px\" height=\"24px\" /><br>Firefox | <img src=\"https://raw.githubusercontent.com/alrra/browser-logos/master/src/chrome/chrome_48x48.png\" alt=\"Chrome\" width=\"24px\" height=\"24px\" /><br>Chrome | <img src=\"https://raw.githubusercontent.com/alrra/browser-logos/master/src/safari/safari_48x48.png\" alt=\"Safari\" width=\"24px\" height=\"24px\" /><br>Safari | <img src=\"https://raw.githubusercontent.com/alrra/browser-logos/master/src/edge/edge_48x48.png\" alt=\"Edge\" width=\"24px\" height=\"24px\" /><br>Edge |\n|:---------:|:---------:|:---------:|:---------:|\n| 127+ | 125+ | 17.4+ | 125+ |\n\nHowever, if you have an issue with a browser [on this list](https://browserl.ist/?q=and_chr%20126%2C%20and_ff%20127%2C%20chrome%20126%2C%20chrome%20125%2C%20chrome%20124%2C%20chrome%20123%2C%20chrome%20109%2C%20edge%20126%2C%20edge%20125%2C%20edge%20124%2C%20edge%20123%2C%20firefox%20128%2C%20firefox%20127%2C%20firefox%20126%2C%20firefox%20125%2C%20firefox%20115%2C%20ios_saf%2017.4%2C%20ios_saf%2016.6-16.7%2C%20safari%2017.5%2C%20safari%2017.4%2C%20safari%2017.3%2C%20safari%2017.2%2C%20samsung%2025), please feel free to open a bug report.\n<!-- ENDBROWSERS -->\n\n## Getting Indico\n\nInformation on how to get the latest release can be found [at the project's web site](https://getindico.io/getting-started/).\nThere are installation guides for different systems available in [the project's documentation](https://docs.getindico.io/en/stable/installation/).\n\n## Contributing\n\nIndico is the result of the collective work of more than 100 different developers, translators and usability\nspecialists of many nationalities. You can be the next one - read our\n[Contribution Guide](https://github.com/indico/indico/blob/master/CONTRIBUTING.md) if you'd like to help out.\n\n**You don't need to know how to write code in order to help!**\n\n## Roadmap\n\nThe full roadmap is [available on the project site](https://getindico.io/roadmap/).\n\n## Community\n\nThe main meeting points for the community are:\n * the [Project Forum](https://talk.getindico.io);\n * the Chat Room\n([#indico on Libera.Chat](https://web.libera.chat/gamja/?channels=#indico) or on [Matrix](https://app.element.io/#/room/#indico:matrix.org)).\n\nWe follow [CERN's Values](https://hr.web.cern.ch/cerns-values) and the principles established by\n[CERN's Code of Conduct](https://hr.web.cern.ch/codeofconduct).\n\n## History\n\nThis software project was initially funded by the European Union's FP5 programme, in what was called the [**In**tegrated **Di**gital **Co**nferencing Project](https://cordis.europa.eu/project/rcn/61849/factsheet/en), or just **InDiCo**. CERN was responsible for the development of the \"Make-a-Confererence\" workpackage (inspired by an already existing system called **CDS Agenda**, also developed at the Organization) which would then become what we nowadays know as **Indico**.\n\nWe have since stopped using the ~~*InDiCo*~~ acronym, as it no longer reflects accurately the nature of the project. The word *Indico* now has no particular meaning other than the product's name.\n\n\n---\n\n\n|||\n|-|-|\n|<a href=\"https://home.cern\"><img src=\"https://raw.githubusercontent.com/indico/assets/master/cern_badge.png\" width=\"64\"></a>|Made at [CERN](https://home.cern)<br>[Take part!](https://careers.cern/)|\n|||\n\n> ### Note\n>\n> *In applying the MIT license, CERN does not waive the privileges and immunities\n> granted to it by virtue of its status as an Intergovernmental Organization\n> or submit itself to any jurisdiction.*\n",
        "num_commits": 25267,
        "project_age_days": 4843,
        "project_created_at": "2011-07-27",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 101,
        "num_pull": 2973,
        "num_issues": 6569,
        "num_opening_issue": 778,
        "project_size(kB)": 258587,
        "num_stargazers": 1771,
        "num_watchers": 1771,
        "num_forks": 428,
        "num_subscribers": 62,
        "SecurityPolicy_created_at": "2021-04-09 14:22:47",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "c68ed525e6d5368e4d22d3c176c30bd716b51d58",
                "url": "https://github.com/indico/indico/commit/c68ed525e6d5368e4d22d3c176c30bd716b51d58",
                "date": "2024-06-17 14:52:11"
            },
            {
                "commit_id": "21cc18e7922b7bd95b984b294988bfee49e588aa",
                "url": "https://github.com/indico/indico/commit/21cc18e7922b7bd95b984b294988bfee49e588aa",
                "date": "2023-11-23 20:24:36"
            },
            {
                "commit_id": "b9e3462770579cea8604c84c64faab2bfe30f2b8",
                "url": "https://github.com/indico/indico/commit/b9e3462770579cea8604c84c64faab2bfe30f2b8",
                "date": "2022-04-20 17:08:47"
            },
            {
                "commit_id": "cf034e215c6a94bd9a52e5d39ada391a8f178849",
                "url": "https://github.com/indico/indico/commit/cf034e215c6a94bd9a52e5d39ada391a8f178849",
                "date": "2021-04-09 14:22:47"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email_advisory",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "allegroai/clearml",
        "project_url": "https://github.com/allegroai/clearml",
        "SSF": {
            "date": "2024-10-29T20:59:54+07:00",
            "repo": {
                "name": "github.com/allegroai/clearml",
                "commit": "05e4e2eb4a8e3846cf75f8824df3de1a87d0c160"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.4,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'release/v1.10.4'",
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: branch 'master' does not require approvers",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Warn: no status checks found to merge onto branch 'master'"
                    ],
                    "score": 1,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "0 out of 5 merged PRs checked by a CI test -- score normalized to 0",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 1,
                    "reason": "Found 5/30 approved changesets -- score normalized to 1",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: allegroai contributor org/company found, clearml contributor org/company found, magpie-linux contributor org/company found, hivegpt contributor org/company found, allegro.ai contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 5 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: :0"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 15 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:42: update your workflow using https://app.stepsecurity.io/secureworkflow/allegroai/clearml/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/allegroai/clearml/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:57: update your workflow using https://app.stepsecurity.io/secureworkflow/allegroai/clearml/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:71: update your workflow using https://app.stepsecurity.io/secureworkflow/allegroai/clearml/codeql-analysis.yml/master?enable=pin",
                        "Info:   0 out of   4 GitHub-owned GitHubAction dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Warn: 0 commits out of 5 are checked with a SAST tool"
                    ],
                    "score": 7,
                    "reason": "SAST tool detected but not run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Warn: One or no descriptive hints of disclosure, vulnerability, and/or timelines in security policy",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 9,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact v1.16.5 not signed: https://api.github.com/repos/allegroai/clearml/releases/172435480",
                        "Warn: release artifact v1.16.4 not signed: https://api.github.com/repos/allegroai/clearml/releases/172182699",
                        "Warn: release artifact v1.16.3 not signed: https://api.github.com/repos/allegroai/clearml/releases/168898056",
                        "Warn: release artifact v1.16.2 not signed: https://api.github.com/repos/allegroai/clearml/releases/161087016",
                        "Warn: release artifact v1.16.1 not signed: https://api.github.com/repos/allegroai/clearml/releases/156330464",
                        "Warn: release artifact v1.16.5 does not have provenance: https://api.github.com/repos/allegroai/clearml/releases/172435480",
                        "Warn: release artifact v1.16.4 does not have provenance: https://api.github.com/repos/allegroai/clearml/releases/172182699",
                        "Warn: release artifact v1.16.3 does not have provenance: https://api.github.com/repos/allegroai/clearml/releases/168898056",
                        "Warn: release artifact v1.16.2 does not have provenance: https://api.github.com/repos/allegroai/clearml/releases/161087016",
                        "Warn: release artifact v1.16.1 does not have provenance: https://api.github.com/repos/allegroai/clearml/releases/156330464"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql-analysis.yml:28",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql-analysis.yml:29",
                        "Warn: no topLevel permission defined: .github/workflows/codeql-analysis.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 9,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-47fc-vmwq-366v / PYSEC-2022-43015",
                        "Warn: Project is vulnerable to: GHSA-5pcm-hx3q-hm94",
                        "Warn: Project is vulnerable to: GHSA-pg7h-5qx3-wjr3",
                        "Warn: Project is vulnerable to: GHSA-6p56-wp2h-9hxr",
                        "Warn: Project is vulnerable to: GHSA-fpfv-jqm9-f5jm",
                        "Warn: Project is vulnerable to: GHSA-x4wf-678h-2pmq",
                        "Warn: Project is vulnerable to: GHSA-8gq9-2x98-w8hf",
                        "Warn: Project is vulnerable to: GHSA-6hrg-qmvc-2xh8 / PYSEC-2022-288",
                        "Warn: Project is vulnerable to: GHSA-23hm-7w47-xw72",
                        "Warn: Project is vulnerable to: GHSA-2475-53vw-vp25",
                        "Warn: Project is vulnerable to: GHSA-247x-2f9f-5wp7",
                        "Warn: Project is vulnerable to: GHSA-24x4-6qmh-88qg",
                        "Warn: Project is vulnerable to: GHSA-24x6-8c7m-hv3f / PYSEC-2021-227",
                        "Warn: Project is vulnerable to: GHSA-26j7-6w8w-7922 / PYSEC-2021-223",
                        "Warn: Project is vulnerable to: GHSA-278g-rq84-9hmg",
                        "Warn: Project is vulnerable to: GHSA-27j5-4p9v-pp67",
                        "Warn: Project is vulnerable to: GHSA-27qf-jwm8-g7f3",
                        "Warn: Project is vulnerable to: GHSA-27rc-728f-x5w2",
                        "Warn: Project is vulnerable to: GHSA-2cpx-427x-q2c6 / PYSEC-2021-160",
                        "Warn: Project is vulnerable to: GHSA-2gfx-95x2-5v3x / PYSEC-2021-173",
                        "Warn: Project is vulnerable to: GHSA-2p25-55c9-h58q / PYSEC-2021-391",
                        "Warn: Project is vulnerable to: GHSA-2p9q-h29j-3f5v",
                        "Warn: Project is vulnerable to: GHSA-2r2f-g8mw-9gvr",
                        "Warn: Project is vulnerable to: GHSA-2r8p-fg3c-wcj4",
                        "Warn: Project is vulnerable to: GHSA-2vv3-56qg-g2cf",
                        "Warn: Project is vulnerable to: GHSA-2wmv-37vq-52g5",
                        "Warn: Project is vulnerable to: GHSA-2xgj-xhgf-ggjv / PYSEC-2021-249",
                        "Warn: Project is vulnerable to: GHSA-34f9-hjfq-rr8j",
                        "Warn: Project is vulnerable to: GHSA-368v-7v32-52fx",
                        "Warn: Project is vulnerable to: GHSA-36vm-xw34-x4pj / PYSEC-2021-199",
                        "Warn: Project is vulnerable to: GHSA-374m-jm66-3vj8 / PYSEC-2021-418",
                        "Warn: Project is vulnerable to: GHSA-37jf-mjv6-xfqw",
                        "Warn: Project is vulnerable to: GHSA-393f-2jr3-cp69 / PYSEC-2021-170",
                        "Warn: Project is vulnerable to: GHSA-397c-5g2j-qxpv",
                        "Warn: Project is vulnerable to: GHSA-3ff2-r28g-w7h9 / PYSEC-2021-408",
                        "Warn: Project is vulnerable to: GHSA-3h8m-483j-7xxm / PYSEC-2021-206",
                        "Warn: Project is vulnerable to: GHSA-3hxh-8cp2-g4hg",
                        "Warn: Project is vulnerable to: GHSA-3mw4-6rj6-74g5",
                        "Warn: Project is vulnerable to: GHSA-3qgw-p4fm-x7gf / PYSEC-2021-231",
                        "Warn: Project is vulnerable to: GHSA-3qxp-qjq7-w4hf / PYSEC-2021-168",
                        "Warn: Project is vulnerable to: GHSA-3rcw-9p9x-582v / PYSEC-2021-420",
                        "Warn: Project is vulnerable to: GHSA-3w67-q784-6w7c / PYSEC-2021-226",
                        "Warn: Project is vulnerable to: GHSA-428x-9xc2-m8mj",
                        "Warn: Project is vulnerable to: GHSA-43jf-985q-588j",
                        "Warn: Project is vulnerable to: GHSA-43q8-3fv7-pr5x",
                        "Warn: Project is vulnerable to: GHSA-44qp-9wwf-734r",
                        "Warn: Project is vulnerable to: GHSA-452g-f7fp-9jf7 / PYSEC-2021-150",
                        "Warn: Project is vulnerable to: GHSA-49rq-hwc3-x77w",
                        "Warn: Project is vulnerable to: GHSA-49rx-x2rw-pc6f / PYSEC-2021-398",
                        "Warn: Project is vulnerable to: GHSA-4c4g-crqm-xrxw",
                        "Warn: Project is vulnerable to: GHSA-4f99-p9c2-3j8x / PYSEC-2021-411",
                        "Warn: Project is vulnerable to: GHSA-4fg4-p75j-w5xj / PYSEC-2021-184",
                        "Warn: Project is vulnerable to: GHSA-4g9f-63rx-5cw4 / PYSEC-2020-113",
                        "Warn: Project is vulnerable to: GHSA-4hrh-9vmp-2jgg / PYSEC-2021-179",
                        "Warn: Project is vulnerable to: GHSA-4hvf-hxvg-f67v",
                        "Warn: Project is vulnerable to: GHSA-4hvv-7x94-7vq8 / PYSEC-2021-253",
                        "Warn: Project is vulnerable to: GHSA-4j82-5ccr-4r8v",
                        "Warn: Project is vulnerable to: GHSA-4p4p-www8-8fv9 / PYSEC-2021-205",
                        "Warn: Project is vulnerable to: GHSA-4pc4-m9mj-v2r9",
                        "Warn: Project is vulnerable to: GHSA-4v5p-v5h9-6xjx",
                        "Warn: Project is vulnerable to: GHSA-4vf2-4xcg-65cx / PYSEC-2021-163",
                        "Warn: Project is vulnerable to: GHSA-4vrf-ff7v-hpgr / PYSEC-2021-233",
                        "Warn: Project is vulnerable to: GHSA-4w68-4x85-mjj9",
                        "Warn: Project is vulnerable to: GHSA-4xfp-4pfp-89wg",
                        "Warn: Project is vulnerable to: GHSA-545v-42p7-98fq / PYSEC-2021-207",
                        "Warn: Project is vulnerable to: GHSA-54ch-gjq5-4976",
                        "Warn: Project is vulnerable to: GHSA-54pp-c6pp-7fpx",
                        "Warn: Project is vulnerable to: GHSA-558h-mq8x-7q9g",
                        "Warn: Project is vulnerable to: GHSA-57wx-m983-2f88 / PYSEC-2021-400",
                        "Warn: Project is vulnerable to: GHSA-5889-7v45-q28m",
                        "Warn: Project is vulnerable to: GHSA-59q2-x2qc-4c97 / PYSEC-2021-196",
                        "Warn: Project is vulnerable to: GHSA-5crj-c72x-m7gq / PYSEC-2021-409",
                        "Warn: Project is vulnerable to: GHSA-5f2r-qp73-37mr",
                        "Warn: Project is vulnerable to: GHSA-5gqf-456p-4836 / PYSEC-2021-209",
                        "Warn: Project is vulnerable to: GHSA-5hj3-vjjf-f5m7",
                        "Warn: Project is vulnerable to: GHSA-5hx2-qx8j-qjqm / PYSEC-2021-392",
                        "Warn: Project is vulnerable to: GHSA-5qw5-89mw-wcg2",
                        "Warn: Project is vulnerable to: GHSA-5v77-j66x-4c4g",
                        "Warn: Project is vulnerable to: GHSA-5w96-866f-6rm8",
                        "Warn: Project is vulnerable to: GHSA-5wpj-c6f7-24x8",
                        "Warn: Project is vulnerable to: GHSA-5xwc-mrhx-5g3m",
                        "Warn: Project is vulnerable to: GHSA-627q-g293-49q7",
                        "Warn: Project is vulnerable to: GHSA-62gx-355r-9fhg / PYSEC-2021-155",
                        "Warn: Project is vulnerable to: GHSA-63xm-rx5p-xvqr / PYSEC-2020-118",
                        "Warn: Project is vulnerable to: GHSA-6445-fm66-fvq2",
                        "Warn: Project is vulnerable to: GHSA-647v-r7qq-24fh",
                        "Warn: Project is vulnerable to: GHSA-64jg-wjww-7c5w",
                        "Warn: Project is vulnerable to: GHSA-66vq-54fq-6jvv",
                        "Warn: Project is vulnerable to: GHSA-67pf-62xr-q35m",
                        "Warn: Project is vulnerable to: GHSA-689c-r7h2-fv9v",
                        "Warn: Project is vulnerable to: GHSA-68v3-g9cm-rmm6",
                        "Warn: Project is vulnerable to: GHSA-6f84-42vf-ppwp / PYSEC-2021-165",
                        "Warn: Project is vulnerable to: GHSA-6f89-8j54-29xf / PYSEC-2021-215",
                        "Warn: Project is vulnerable to: GHSA-6gmv-pjp9-p8w8",
                        "Warn: Project is vulnerable to: GHSA-6gv8-p3vj-pxvr",
                        "Warn: Project is vulnerable to: GHSA-6hg6-5c2q-7rcr",
                        "Warn: Project is vulnerable to: GHSA-6hpv-v2rx-c5g6 / PYSEC-2021-401",
                        "Warn: Project is vulnerable to: GHSA-6j9c-grc6-5m6g / PYSEC-2021-171",
                        "Warn: Project is vulnerable to: GHSA-6p5r-g9mq-ggh2",
                        "Warn: Project is vulnerable to: GHSA-6qgm-fv6v-rfpv / PYSEC-2021-212",
                        "Warn: Project is vulnerable to: GHSA-6wfh-89q8-44jq",
                        "Warn: Project is vulnerable to: GHSA-6x99-gv2v-q76v",
                        "Warn: Project is vulnerable to: GHSA-75c9-jrh4-79mc",
                        "Warn: Project is vulnerable to: GHSA-75f6-78jr-4656 / PYSEC-2021-201",
                        "Warn: Project is vulnerable to: GHSA-762h-vpvw-3rcx",
                        "Warn: Project is vulnerable to: GHSA-772j-h9xw-ffp5 / PYSEC-2021-156",
                        "Warn: Project is vulnerable to: GHSA-772p-x54p-hjrv / PYSEC-2021-154",
                        "Warn: Project is vulnerable to: GHSA-77gp-3h4r-6428",
                        "Warn: Project is vulnerable to: GHSA-786j-5qwq-r36x / PYSEC-2021-397",
                        "Warn: Project is vulnerable to: GHSA-79fv-9865-4qcv / PYSEC-2021-216",
                        "Warn: Project is vulnerable to: GHSA-79h2-q768-fpxr",
                        "Warn: Project is vulnerable to: GHSA-7cqx-92hp-x6wh / PYSEC-2021-213",
                        "Warn: Project is vulnerable to: GHSA-7fvx-3jfc-2cpc",
                        "Warn: Project is vulnerable to: GHSA-7ghq-fvr3-pj2x",
                        "Warn: Project is vulnerable to: GHSA-7j3m-8g3c-9qqq",
                        "Warn: Project is vulnerable to: GHSA-7jvm-xxmr-v5cw",
                        "Warn: Project is vulnerable to: GHSA-7pxj-m4jf-r6h2 / PYSEC-2021-396",
                        "Warn: Project is vulnerable to: GHSA-7r94-xv9v-63jw / PYSEC-2021-417",
                        "Warn: Project is vulnerable to: GHSA-7v94-64hj-m82h / PYSEC-2021-399",
                        "Warn: Project is vulnerable to: GHSA-7x4v-9gxg-9hwj",
                        "Warn: Project is vulnerable to: GHSA-7xwj-5r4v-429p",
                        "Warn: Project is vulnerable to: GHSA-828c-5j5q-vrjq",
                        "Warn: Project is vulnerable to: GHSA-828x-qc2p-wprq / PYSEC-2021-211",
                        "Warn: Project is vulnerable to: GHSA-844w-j86r-4x2j / PYSEC-2019-209",
                        "Warn: Project is vulnerable to: GHSA-84jm-4cf3-9jfm",
                        "Warn: Project is vulnerable to: GHSA-84mw-34w6-2q43 / PYSEC-2021-153",
                        "Warn: Project is vulnerable to: GHSA-87v6-crgm-2gfj",
                        "Warn: Project is vulnerable to: GHSA-8c89-2vwr-chcq / PYSEC-2021-174",
                        "Warn: Project is vulnerable to: GHSA-8cxv-76p7-jxwr",
                        "Warn: Project is vulnerable to: GHSA-8fvv-46hw-vpg3",
                        "Warn: Project is vulnerable to: GHSA-8gv3-57p6-g35r / PYSEC-2021-197",
                        "Warn: Project is vulnerable to: GHSA-8jj7-5vxc-pg2q",
                        "Warn: Project is vulnerable to: GHSA-8pmx-p244-g88h / PYSEC-2021-251",
                        "Warn: Project is vulnerable to: GHSA-8r7c-3cm2-3h8f",
                        "Warn: Project is vulnerable to: GHSA-8rcj-c8pj-v3m3",
                        "Warn: Project is vulnerable to: GHSA-8rm6-75mf-7r7r / PYSEC-2021-241",
                        "Warn: Project is vulnerable to: GHSA-8w5g-3wcv-9g2j",
                        "Warn: Project is vulnerable to: GHSA-8wwm-6264-x792",
                        "Warn: Project is vulnerable to: GHSA-93vr-9q9m-pj8p",
                        "Warn: Project is vulnerable to: GHSA-94mm-g2mv-8p7r",
                        "Warn: Project is vulnerable to: GHSA-95xm-g58g-3p88",
                        "Warn: Project is vulnerable to: GHSA-9697-98pf-4rw7",
                        "Warn: Project is vulnerable to: GHSA-977j-xj7q-2jr9 / PYSEC-2020-258",
                        "Warn: Project is vulnerable to: GHSA-97p7-w86h-vcf9",
                        "Warn: Project is vulnerable to: GHSA-97wf-p777-86jq / PYSEC-2021-236",
                        "Warn: Project is vulnerable to: GHSA-98j8-c9q4-r38g",
                        "Warn: Project is vulnerable to: GHSA-98p5-x8x4-c9m5",
                        "Warn: Project is vulnerable to: GHSA-9942-r22v-78cp",
                        "Warn: Project is vulnerable to: GHSA-9c78-vcq7-7vxq",
                        "Warn: Project is vulnerable to: GHSA-9c84-4hx6-xmm4 / PYSEC-2021-238",
                        "Warn: Project is vulnerable to: GHSA-9c8h-2mv3-49ww",
                        "Warn: Project is vulnerable to: GHSA-9c8h-vvrj-w2p8",
                        "Warn: Project is vulnerable to: GHSA-9cr2-8pwr-fhfq",
                        "Warn: Project is vulnerable to: GHSA-9crf-c6qr-r273 / PYSEC-2021-410",
                        "Warn: Project is vulnerable to: GHSA-9fpg-838v-wpv7",
                        "Warn: Project is vulnerable to: GHSA-9gwq-6cwj-47h3",
                        "Warn: Project is vulnerable to: GHSA-9j4v-pp28-mxv7",
                        "Warn: Project is vulnerable to: GHSA-9mqp-7v2h-2382 / PYSEC-2020-117",
                        "Warn: Project is vulnerable to: GHSA-9p77-mmrw-69c7",
                        "Warn: Project is vulnerable to: GHSA-9px9-73fg-3fqp",
                        "Warn: Project is vulnerable to: GHSA-9v8w-xmr4-wgxp",
                        "Warn: Project is vulnerable to: GHSA-9vpm-rcf4-9wqw / PYSEC-2021-210",
                        "Warn: Project is vulnerable to: GHSA-9vqj-64pv-w55c",
                        "Warn: Project is vulnerable to: GHSA-9w2p-5mgw-p94c",
                        "Warn: Project is vulnerable to: GHSA-9xh4-23q4-v6wr / PYSEC-2021-220",
                        "Warn: Project is vulnerable to: GHSA-c45w-2wxr-pp53 / PYSEC-2021-219",
                        "Warn: Project is vulnerable to: GHSA-c545-c4f9-rf6v",
                        "Warn: Project is vulnerable to: GHSA-c582-c96p-r5cq",
                        "Warn: Project is vulnerable to: GHSA-c5x2-p679-95wc",
                        "Warn: Project is vulnerable to: GHSA-c6fh-56w7-fvjw",
                        "Warn: Project is vulnerable to: GHSA-c94w-c95p-phf8",
                        "Warn: Project is vulnerable to: GHSA-c968-pq7h-7fxv / PYSEC-2021-159",
                        "Warn: Project is vulnerable to: GHSA-c9f3-9wfr-wgh7 / PYSEC-2020-140",
                        "Warn: Project is vulnerable to: GHSA-c9qf-r67m-p7cg",
                        "Warn: Project is vulnerable to: GHSA-cfpj-3q4c-jhvr",
                        "Warn: Project is vulnerable to: GHSA-cfx7-2xpc-8w4h / PYSEC-2021-230",
                        "Warn: Project is vulnerable to: GHSA-cg88-rpvp-cjv5",
                        "Warn: Project is vulnerable to: GHSA-cgfm-62j4-v4rf",
                        "Warn: Project is vulnerable to: GHSA-ch4f-829c-v5pw",
                        "Warn: Project is vulnerable to: GHSA-cjc7-49v2-jp64 / PYSEC-2021-246",
                        "Warn: Project is vulnerable to: GHSA-cm5x-837x-jf3c",
                        "Warn: Project is vulnerable to: GHSA-cmgw-8vpc-rc59",
                        "Warn: Project is vulnerable to: GHSA-cpf4-wx82-gxp6 / PYSEC-2021-414",
                        "Warn: Project is vulnerable to: GHSA-cq76-mxrc-vchh / PYSEC-2021-842",
                        "Warn: Project is vulnerable to: GHSA-cqv6-3phm-hcwx / PYSEC-2021-413",
                        "Warn: Project is vulnerable to: GHSA-cqvq-fvhr-v6hc",
                        "Warn: Project is vulnerable to: GHSA-crch-j389-5f84 / PYSEC-2021-240",
                        "Warn: Project is vulnerable to: GHSA-cv2p-32v3-vhwq",
                        "Warn: Project is vulnerable to: GHSA-cvpc-8phh-8f45 / PYSEC-2020-134",
                        "Warn: Project is vulnerable to: GHSA-cwpm-f78v-7m5c",
                        "Warn: Project is vulnerable to: GHSA-cwv3-863g-39vx / PYSEC-2021-228",
                        "Warn: Project is vulnerable to: GHSA-f2vv-v9cg-qhh7",
                        "Warn: Project is vulnerable to: GHSA-f2w8-jw48-fr7j",
                        "Warn: Project is vulnerable to: GHSA-f49c-87jh-g47q",
                        "Warn: Project is vulnerable to: GHSA-f4rr-5m7v-wxcw",
                        "Warn: Project is vulnerable to: GHSA-f4w6-h4f5-wx45",
                        "Warn: Project is vulnerable to: GHSA-f54p-f6jp-4rhr / PYSEC-2021-415",
                        "Warn: Project is vulnerable to: GHSA-f5cx-5wr3-5qrc",
                        "Warn: Project is vulnerable to: GHSA-f637-vh3r-vfh2",
                        "Warn: Project is vulnerable to: GHSA-f78g-q7r4-9wcv / PYSEC-2021-187",
                        "Warn: Project is vulnerable to: GHSA-f7r5-q7cx-h668",
                        "Warn: Project is vulnerable to: GHSA-f8h4-7rgh-q2gm",
                        "Warn: Project is vulnerable to: GHSA-fcwc-p4fc-c5cc",
                        "Warn: Project is vulnerable to: GHSA-ffjm-4qwc-7cmf",
                        "Warn: Project is vulnerable to: GHSA-fhfc-2q7x-929f",
                        "Warn: Project is vulnerable to: GHSA-fpcp-9h7m-ffpx",
                        "Warn: Project is vulnerable to: GHSA-fphq-gw9m-ghrv / PYSEC-2021-180",
                        "Warn: Project is vulnerable to: GHSA-fq6p-6334-8gr4",
                        "Warn: Project is vulnerable to: GHSA-fq86-3f29-px2c",
                        "Warn: Project is vulnerable to: GHSA-fqm2-gh8w-gr68",
                        "Warn: Project is vulnerable to: GHSA-fqxc-pvf8-2w9v",
                        "Warn: Project is vulnerable to: GHSA-fr77-rrx3-cp7g / PYSEC-2021-404",
                        "Warn: Project is vulnerable to: GHSA-frqp-wp83-qggv",
                        "Warn: Project is vulnerable to: GHSA-fv25-wrff-wf86",
                        "Warn: Project is vulnerable to: GHSA-fv43-93gv-vm8f",
                        "Warn: Project is vulnerable to: GHSA-fx5c-h9f6-rv7c",
                        "Warn: Project is vulnerable to: GHSA-fxgc-95xx-grvq",
                        "Warn: Project is vulnerable to: GHSA-fxqh-cfjm-fp93 / PYSEC-2021-193",
                        "Warn: Project is vulnerable to: GHSA-g25h-jr74-qp5j",
                        "Warn: Project is vulnerable to: GHSA-g35r-369w-3fqp",
                        "Warn: Project is vulnerable to: GHSA-g468-qj8g-vcjc",
                        "Warn: Project is vulnerable to: GHSA-g4h2-gqm3-c9wq / PYSEC-2021-176",
                        "Warn: Project is vulnerable to: GHSA-g7p5-5759-qv46 / PYSEC-2020-128",
                        "Warn: Project is vulnerable to: GHSA-g8wg-cjwc-xhhp",
                        "Warn: Project is vulnerable to: GHSA-g9fm-r5mm-rf9f",
                        "Warn: Project is vulnerable to: GHSA-g9h5-vr8m-x2h4",
                        "Warn: Project is vulnerable to: GHSA-gcvh-66ff-4mwm",
                        "Warn: Project is vulnerable to: GHSA-gf2j-f278-xh4v",
                        "Warn: Project is vulnerable to: GHSA-gf88-j2mg-cc82",
                        "Warn: Project is vulnerable to: GHSA-gf97-q72m-7579",
                        "Warn: Project is vulnerable to: GHSA-gh6x-4whr-2qv4",
                        "Warn: Project is vulnerable to: GHSA-gh8h-7j2j-qv4f / PYSEC-2021-393",
                        "Warn: Project is vulnerable to: GHSA-gjh7-xx4r-x345",
                        "Warn: Project is vulnerable to: GHSA-gjqc-q9g6-q2j3",
                        "Warn: Project is vulnerable to: GHSA-gq2j-cr96-gvqx",
                        "Warn: Project is vulnerable to: GHSA-gv26-jpj9-c8gq / PYSEC-2021-244",
                        "Warn: Project is vulnerable to: GHSA-gvm4-h8j3-rjrq / PYSEC-2021-198",
                        "Warn: Project is vulnerable to: GHSA-gw97-ff7c-9v96",
                        "Warn: Project is vulnerable to: GHSA-h246-cgh4-7475",
                        "Warn: Project is vulnerable to: GHSA-h2wq-prv9-2f56",
                        "Warn: Project is vulnerable to: GHSA-h48f-q7rw-hvr7",
                        "Warn: Project is vulnerable to: GHSA-h4pc-gx2w-f2xv / PYSEC-2021-243",
                        "Warn: Project is vulnerable to: GHSA-h5g4-ppwx-48q2",
                        "Warn: Project is vulnerable to: GHSA-h5vq-gw2c-pq47",
                        "Warn: Project is vulnerable to: GHSA-h67m-xg8f-fxcf / PYSEC-2021-405",
                        "Warn: Project is vulnerable to: GHSA-h6fg-mjxg-hqq4 / PYSEC-2020-125",
                        "Warn: Project is vulnerable to: GHSA-h6gw-r52c-724r",
                        "Warn: Project is vulnerable to: GHSA-h6jh-7gv5-28vg",
                        "Warn: Project is vulnerable to: GHSA-h6q3-vv32-2cq5",
                        "Warn: Project is vulnerable to: GHSA-h7ff-cfc9-wmmh",
                        "Warn: Project is vulnerable to: GHSA-h9px-9vqg-222h / PYSEC-2021-190",
                        "Warn: Project is vulnerable to: GHSA-hc6c-75p4-hmq4 / PYSEC-2021-152",
                        "Warn: Project is vulnerable to: GHSA-hhvc-g5hv-48c6 / PYSEC-2020-255",
                        "Warn: Project is vulnerable to: GHSA-hmg3-c7xj-6qwm / PYSEC-2021-182",
                        "Warn: Project is vulnerable to: GHSA-hp4c-x6r7-6555",
                        "Warn: Project is vulnerable to: GHSA-hpv4-7p9c-mvfr",
                        "Warn: Project is vulnerable to: GHSA-hq7g-wwwp-q46h",
                        "Warn: Project is vulnerable to: GHSA-hrg5-737c-2p56",
                        "Warn: Project is vulnerable to: GHSA-hwr7-8gxx-fj5p",
                        "Warn: Project is vulnerable to: GHSA-hx9q-2mx4-m4pg",
                        "Warn: Project is vulnerable to: GHSA-j3mj-fhpq-qqjj",
                        "Warn: Project is vulnerable to: GHSA-j43h-pgmg-5hjq",
                        "Warn: Project is vulnerable to: GHSA-j47f-4232-hvv8 / PYSEC-2021-169",
                        "Warn: Project is vulnerable to: GHSA-j5w9-hmfh-4cr6",
                        "Warn: Project is vulnerable to: GHSA-j7rm-8ww4-xx2g / PYSEC-2021-224",
                        "Warn: Project is vulnerable to: GHSA-j86v-p27c-73fm / PYSEC-2021-394",
                        "Warn: Project is vulnerable to: GHSA-j8c8-67vp-6mx7 / PYSEC-2021-419",
                        "Warn: Project is vulnerable to: GHSA-j8qc-5fqr-52fp / PYSEC-2021-175",
                        "Warn: Project is vulnerable to: GHSA-j8qh-3xrq-c825 / PYSEC-2021-237",
                        "Warn: Project is vulnerable to: GHSA-jf7h-7m85-w2v2 / PYSEC-2021-242",
                        "Warn: Project is vulnerable to: GHSA-jfp7-4j67-8r3q / PYSEC-2021-166",
                        "Warn: Project is vulnerable to: GHSA-jhq9-wm9m-cf89 / PYSEC-2021-189",
                        "Warn: Project is vulnerable to: GHSA-jjm6-4vf7-cjh4",
                        "Warn: Project is vulnerable to: GHSA-jjr8-m8g8-p6wv / PYSEC-2021-229",
                        "Warn: Project is vulnerable to: GHSA-jq6x-99hj-q636",
                        "Warn: Project is vulnerable to: GHSA-jqm7-m5q7-3hm5",
                        "Warn: Project is vulnerable to: GHSA-jvhc-5hhr-w3v5",
                        "Warn: Project is vulnerable to: GHSA-jwf9-w5xm-f437",
                        "Warn: Project is vulnerable to: GHSA-m342-ff57-4jcc / PYSEC-2021-402",
                        "Warn: Project is vulnerable to: GHSA-m34j-p8rj-wjxq / PYSEC-2021-183",
                        "Warn: Project is vulnerable to: GHSA-m3f9-w3p3-p669 / PYSEC-2021-172",
                        "Warn: Project is vulnerable to: GHSA-m4hf-j54p-p353",
                        "Warn: Project is vulnerable to: GHSA-m539-j985-hcr8 / PYSEC-2021-389",
                        "Warn: Project is vulnerable to: GHSA-m648-33qf-v3gp / PYSEC-2020-256",
                        "Warn: Project is vulnerable to: GHSA-m6cv-4fmf-66xf",
                        "Warn: Project is vulnerable to: GHSA-m6vp-8q9j-whx4",
                        "Warn: Project is vulnerable to: GHSA-m7fm-4jfh-jrg6",
                        "Warn: Project is vulnerable to: GHSA-mg66-qvc5-rm93",
                        "Warn: Project is vulnerable to: GHSA-mgmh-g2v6-mqw5",
                        "Warn: Project is vulnerable to: GHSA-mh3m-62v7-68xg",
                        "Warn: Project is vulnerable to: GHSA-mhhc-q96p-mfm9",
                        "Warn: Project is vulnerable to: GHSA-mmq6-q8r3-48fm / PYSEC-2021-254",
                        "Warn: Project is vulnerable to: GHSA-mq5c-prh3-3f3h / PYSEC-2021-247",
                        "Warn: Project is vulnerable to: GHSA-mqh2-9wrp-vx84 / PYSEC-2021-195",
                        "Warn: Project is vulnerable to: GHSA-mv77-9g28-cwg3",
                        "Warn: Project is vulnerable to: GHSA-mv78-g7wq-mhp4 / PYSEC-2021-222",
                        "Warn: Project is vulnerable to: GHSA-mv8m-8x97-937q",
                        "Warn: Project is vulnerable to: GHSA-mw6j-hh29-h379",
                        "Warn: Project is vulnerable to: GHSA-mxjj-953w-2c2v / PYSEC-2020-131",
                        "Warn: Project is vulnerable to: GHSA-p2xf-8hgm-hpw5",
                        "Warn: Project is vulnerable to: GHSA-p45v-v4pw-77jr / PYSEC-2021-185",
                        "Warn: Project is vulnerable to: GHSA-p7hr-f446-x6qf",
                        "Warn: Project is vulnerable to: GHSA-p9rc-rmr5-529j",
                        "Warn: Project is vulnerable to: GHSA-pf36-r9c6-h97j",
                        "Warn: Project is vulnerable to: GHSA-pfjj-m3jj-9jc9",
                        "Warn: Project is vulnerable to: GHSA-pgcq-h79j-2f69 / PYSEC-2021-843",
                        "Warn: Project is vulnerable to: GHSA-ph87-fvjr-v33w / PYSEC-2021-200",
                        "Warn: Project is vulnerable to: GHSA-pmpr-55fj-r229 / PYSEC-2021-235",
                        "Warn: Project is vulnerable to: GHSA-pqhm-4wvf-2jg8",
                        "Warn: Project is vulnerable to: GHSA-pqrv-8r2f-7278",
                        "Warn: Project is vulnerable to: GHSA-prcg-wp5q-rv7p / PYSEC-2021-390",
                        "Warn: Project is vulnerable to: GHSA-pvrc-hg3f-58r6 / PYSEC-2021-203",
                        "Warn: Project is vulnerable to: GHSA-pxrw-j2fv-hx3h",
                        "Warn: Project is vulnerable to: GHSA-q263-fvxm-m5mw / PYSEC-2020-257",
                        "Warn: Project is vulnerable to: GHSA-q2c3-jpmc-gfjx",
                        "Warn: Project is vulnerable to: GHSA-q3g3-h9r4-prrc",
                        "Warn: Project is vulnerable to: GHSA-q4qf-3fc6-8x34 / PYSEC-2020-130",
                        "Warn: Project is vulnerable to: GHSA-q5jv-m6qw-5g37",
                        "Warn: Project is vulnerable to: GHSA-q7f7-544h-67h9",
                        "Warn: Project is vulnerable to: GHSA-q85f-69q7-55h2",
                        "Warn: Project is vulnerable to: GHSA-q8gv-q7wr-9jf8 / PYSEC-2020-127",
                        "Warn: Project is vulnerable to: GHSA-qfpc-5pjr-mh26",
                        "Warn: Project is vulnerable to: GHSA-qh32-6jjc-qprm / PYSEC-2020-132",
                        "Warn: Project is vulnerable to: GHSA-qhw4-wwr7-gjc5",
                        "Warn: Project is vulnerable to: GHSA-qhxx-j73r-qpm2 / PYSEC-2020-254",
                        "Warn: Project is vulnerable to: GHSA-qj5r-f9mv-rffh",
                        "Warn: Project is vulnerable to: GHSA-qjj8-32p7-h289",
                        "Warn: Project is vulnerable to: GHSA-qjqc-vqcf-5qvj",
                        "Warn: Project is vulnerable to: GHSA-qr82-2c78-4m8h",
                        "Warn: Project is vulnerable to: GHSA-qw5h-7f53-xrp6 / PYSEC-2021-252",
                        "Warn: Project is vulnerable to: GHSA-qx3f-p745-w4hr",
                        "Warn: Project is vulnerable to: GHSA-qxpx-j395-pw36",
                        "Warn: Project is vulnerable to: GHSA-r26c-679w-mrjm",
                        "Warn: Project is vulnerable to: GHSA-r35g-4525-29fq / PYSEC-2021-192",
                        "Warn: Project is vulnerable to: GHSA-r4c4-5fpq-56wg",
                        "Warn: Project is vulnerable to: GHSA-r4pj-74mg-8868 / PYSEC-2021-161",
                        "Warn: Project is vulnerable to: GHSA-r6jx-9g48-2r5r",
                        "Warn: Project is vulnerable to: GHSA-r6pg-pjwc-j585 / PYSEC-2021-202",
                        "Warn: Project is vulnerable to: GHSA-rc9w-5c64-9vqq",
                        "Warn: Project is vulnerable to: GHSA-rcf8-g8jv-vg6p",
                        "Warn: Project is vulnerable to: GHSA-rf3h-xgv5-2q39 / PYSEC-2021-239",
                        "Warn: Project is vulnerable to: GHSA-rg3m-hqc5-344v / PYSEC-2021-416",
                        "Warn: Project is vulnerable to: GHSA-rgvq-pcvf-hx75 / PYSEC-2021-245",
                        "Warn: Project is vulnerable to: GHSA-rh87-q4vg-m45j",
                        "Warn: Project is vulnerable to: GHSA-rhrq-64mq-hf9h",
                        "Warn: Project is vulnerable to: GHSA-rjx6-v474-2ch9",
                        "Warn: Project is vulnerable to: GHSA-rmg2-f698-wq35",
                        "Warn: Project is vulnerable to: GHSA-rrfp-j2mp-hq9c / PYSEC-2020-138",
                        "Warn: Project is vulnerable to: GHSA-rrx2-r989-2c43",
                        "Warn: Project is vulnerable to: GHSA-rww7-2gpw-fv6j",
                        "Warn: Project is vulnerable to: GHSA-v3f7-j968-4h5f",
                        "Warn: Project is vulnerable to: GHSA-v52p-hfjf-wg88 / PYSEC-2021-234",
                        "Warn: Project is vulnerable to: GHSA-v5xg-3q2c-c2r4",
                        "Warn: Project is vulnerable to: GHSA-v6h3-348g-6h5x",
                        "Warn: Project is vulnerable to: GHSA-v6r6-84gr-92rm / PYSEC-2021-214",
                        "Warn: Project is vulnerable to: GHSA-v768-w7m9-2vmm",
                        "Warn: Project is vulnerable to: GHSA-v7vw-577f-vp8x",
                        "Warn: Project is vulnerable to: GHSA-v82p-hv3v-p6qp",
                        "Warn: Project is vulnerable to: GHSA-vcjj-9vg7-vf68",
                        "Warn: Project is vulnerable to: GHSA-vf94-36g5-69v8 / PYSEC-2021-232",
                        "Warn: Project is vulnerable to: GHSA-vfr4-x8j2-3rf9 / PYSEC-2021-225",
                        "Warn: Project is vulnerable to: GHSA-vgvh-2pf4-jr2x",
                        "Warn: Project is vulnerable to: GHSA-vjg4-v33c-ggc4",
                        "Warn: Project is vulnerable to: GHSA-vm7x-4qhj-rrcq",
                        "Warn: Project is vulnerable to: GHSA-vmjw-c2vp-p33c",
                        "Warn: Project is vulnerable to: GHSA-vq2r-5xvm-3hc3 / PYSEC-2021-218",
                        "Warn: Project is vulnerable to: GHSA-vqw6-72r7-fgw7 / PYSEC-2021-188",
                        "Warn: Project is vulnerable to: GHSA-vvg4-vgrv-xfr7 / PYSEC-2021-250",
                        "Warn: Project is vulnerable to: GHSA-vwhq-49r4-gj9v / PYSEC-2021-406",
                        "Warn: Project is vulnerable to: GHSA-vxv8-r8q2-63xw",
                        "Warn: Project is vulnerable to: GHSA-w4xf-2pqw-5mq7",
                        "Warn: Project is vulnerable to: GHSA-w5gh-2wr2-pm6g / PYSEC-2020-129",
                        "Warn: Project is vulnerable to: GHSA-w62h-8xjm-fv49",
                        "Warn: Project is vulnerable to: GHSA-w74j-v8xh-3w5h",
                        "Warn: Project is vulnerable to: GHSA-wc4g-r73w-x8mm",
                        "Warn: Project is vulnerable to: GHSA-wcv5-qrj6-9pfm / PYSEC-2021-157",
                        "Warn: Project is vulnerable to: GHSA-wcv5-vrvr-3rx2",
                        "Warn: Project is vulnerable to: GHSA-wf5p-c75w-w3wh",
                        "Warn: Project is vulnerable to: GHSA-whr9-vfh2-7hm6 / PYSEC-2021-208",
                        "Warn: Project is vulnerable to: GHSA-wm93-f238-7v37",
                        "Warn: Project is vulnerable to: GHSA-wp3c-xw9g-gpcg / PYSEC-2021-204",
                        "Warn: Project is vulnerable to: GHSA-wp77-4gmm-7cq8",
                        "Warn: Project is vulnerable to: GHSA-wq6q-6m32-9rv9",
                        "Warn: Project is vulnerable to: GHSA-wqmc-pm8c-2jhc",
                        "Warn: Project is vulnerable to: GHSA-wr9v-g9vf-c74v",
                        "Warn: Project is vulnerable to: GHSA-wvjw-p9f5-vq28 / PYSEC-2021-256",
                        "Warn: Project is vulnerable to: GHSA-wxjj-cgcx-r3vq",
                        "Warn: Project is vulnerable to: GHSA-x3v8-c8qx-3j3r / PYSEC-2021-407",
                        "Warn: Project is vulnerable to: GHSA-x4g7-fvjj-prg8 / PYSEC-2021-164",
                        "Warn: Project is vulnerable to: GHSA-x4qx-4fjv-hmw6",
                        "Warn: Project is vulnerable to: GHSA-x83m-p7pv-ch8v / PYSEC-2021-186",
                        "Warn: Project is vulnerable to: GHSA-x8h6-xgqx-jqgp / PYSEC-2021-217",
                        "Warn: Project is vulnerable to: GHSA-x989-q2pq-4q5x",
                        "Warn: Project is vulnerable to: GHSA-x9j7-x98r-r4w2 / PYSEC-2020-133",
                        "Warn: Project is vulnerable to: GHSA-xcwj-wfcm-m23c / PYSEC-2021-167",
                        "Warn: Project is vulnerable to: GHSA-xf83-q765-xm6m",
                        "Warn: Project is vulnerable to: GHSA-xgc3-m89p-vr3x / PYSEC-2021-177",
                        "Warn: Project is vulnerable to: GHSA-xm2v-8rrw-w9pm / PYSEC-2021-162",
                        "Warn: Project is vulnerable to: GHSA-xmq7-7fxm-rr79 / PYSEC-2020-126",
                        "Warn: Project is vulnerable to: GHSA-xqfj-35wv-m3cr / PYSEC-2021-178",
                        "Warn: Project is vulnerable to: GHSA-xqfj-cr6q-pc8w / PYSEC-2021-255",
                        "Warn: Project is vulnerable to: GHSA-xrp2-fhq4-4q3w",
                        "Warn: Project is vulnerable to: GHSA-xrqm-fpgr-6hhx / PYSEC-2021-395",
                        "Warn: Project is vulnerable to: GHSA-xvjm-fvxx-q3hv / PYSEC-2021-221",
                        "Warn: Project is vulnerable to: GHSA-xvwp-h6jv-7472",
                        "Warn: Project is vulnerable to: GHSA-xw93-v57j-fcgh / PYSEC-2021-194",
                        "Warn: Project is vulnerable to: GHSA-xwhf-g6j5-j5gc / PYSEC-2020-139",
                        "Warn: Project is vulnerable to: GHSA-xxcj-rhqg-m46g",
                        "Warn: Project is vulnerable to: PYSEC-2020-114",
                        "Warn: Project is vulnerable to: PYSEC-2020-115",
                        "Warn: Project is vulnerable to: PYSEC-2020-116",
                        "Warn: Project is vulnerable to: PYSEC-2020-119",
                        "Warn: Project is vulnerable to: PYSEC-2020-120",
                        "Warn: Project is vulnerable to: PYSEC-2020-121",
                        "Warn: Project is vulnerable to: PYSEC-2020-122",
                        "Warn: Project is vulnerable to: PYSEC-2020-123",
                        "Warn: Project is vulnerable to: PYSEC-2020-124",
                        "Warn: Project is vulnerable to: PYSEC-2021-151",
                        "Warn: Project is vulnerable to: PYSEC-2021-181",
                        "Warn: Project is vulnerable to: PYSEC-2021-191",
                        "Warn: Project is vulnerable to: PYSEC-2021-248",
                        "Warn: Project is vulnerable to: GHSA-v3c5-jqr6-7qm8 / PYSEC-2022-42991",
                        "Warn: Project is vulnerable to: GHSA-3f63-hfp8-52jq",
                        "Warn: Project is vulnerable to: GHSA-3wvg-mj6g-m9cv / PYSEC-2021-41",
                        "Warn: Project is vulnerable to: GHSA-3xv8-3j54-hgrp",
                        "Warn: Project is vulnerable to: GHSA-43fq-w8qq-v88h / PYSEC-2020-80",
                        "Warn: Project is vulnerable to: GHSA-44wm-f244-xhp3",
                        "Warn: Project is vulnerable to: GHSA-4fx9-vc88-q2xc",
                        "Warn: Project is vulnerable to: GHSA-56pw-mpj4-fxww",
                        "Warn: Project is vulnerable to: GHSA-57h3-9rgr-c24m / PYSEC-2021-35",
                        "Warn: Project is vulnerable to: GHSA-5gm3-px64-rw72 / PYSEC-2020-172",
                        "Warn: Project is vulnerable to: GHSA-7534-mm45-c74v / PYSEC-2021-331",
                        "Warn: Project is vulnerable to: GHSA-77gc-v2xv-rvvh / PYSEC-2021-137",
                        "Warn: Project is vulnerable to: GHSA-7r7m-5h27-29hp / PYSEC-2021-92",
                        "Warn: Project is vulnerable to: GHSA-8843-m7mw-mxqm",
                        "Warn: Project is vulnerable to: GHSA-8ghj-p4vj-mr35 / PYSEC-2023-227",
                        "Warn: Project is vulnerable to: GHSA-8vj2-vxx3-667w / PYSEC-2022-10",
                        "Warn: Project is vulnerable to: GHSA-8xjq-8fcg-g5hw / PYSEC-2021-36",
                        "Warn: Project is vulnerable to: GHSA-95q3-8gr9-gm8w / PYSEC-2021-42",
                        "Warn: Project is vulnerable to: GHSA-9j59-75qj-795w / PYSEC-2022-168",
                        "Warn: Project is vulnerable to: GHSA-cqhg-xjhh-p8hf / PYSEC-2020-76",
                        "Warn: Project is vulnerable to: GHSA-f4w8-cv6p-x6r5 / PYSEC-2021-40",
                        "Warn: Project is vulnerable to: GHSA-f5g8-5qq7-938w / PYSEC-2021-69",
                        "Warn: Project is vulnerable to: GHSA-g6rj-rv7j-xwp4 / PYSEC-2021-139",
                        "Warn: Project is vulnerable to: GHSA-hj69-c76v-86wr / PYSEC-2020-84",
                        "Warn: Project is vulnerable to: GHSA-j7hp-h8jx-5ppr",
                        "Warn: Project is vulnerable to: GHSA-j7mj-748x-7p78 / PYSEC-2019-110",
                        "Warn: Project is vulnerable to: GHSA-jgpv-4h4c-xhw3",
                        "Warn: Project is vulnerable to: GHSA-m2vv-5vj5-2hm7 / PYSEC-2022-42979",
                        "Warn: Project is vulnerable to: GHSA-mvg9-xffr-p774 / PYSEC-2021-37",
                        "Warn: Project is vulnerable to: GHSA-p49h-hjvm-jg3h / PYSEC-2020-83",
                        "Warn: Project is vulnerable to: GHSA-pw3c-h7wp-cvhx / PYSEC-2022-8",
                        "Warn: Project is vulnerable to: GHSA-q5hq-fp76-qmrc / PYSEC-2021-93",
                        "Warn: Project is vulnerable to: GHSA-r7rm-8j6h-r933 / PYSEC-2020-82",
                        "Warn: Project is vulnerable to: GHSA-rwv7-3v45-hg29 / PYSEC-2021-138",
                        "Warn: Project is vulnerable to: GHSA-vcqg-3p29-xw73 / PYSEC-2020-81",
                        "Warn: Project is vulnerable to: GHSA-vj42-xq3r-hr3r / PYSEC-2020-79",
                        "Warn: Project is vulnerable to: GHSA-vqcj-wrf2-7v73 / PYSEC-2021-70",
                        "Warn: Project is vulnerable to: GHSA-xrcv-f9gm-v42c / PYSEC-2022-9",
                        "Warn: Project is vulnerable to: PYSEC-2020-77",
                        "Warn: Project is vulnerable to: PYSEC-2020-78",
                        "Warn: Project is vulnerable to: PYSEC-2021-317",
                        "Warn: Project is vulnerable to: PYSEC-2021-38",
                        "Warn: Project is vulnerable to: PYSEC-2021-39",
                        "Warn: Project is vulnerable to: PYSEC-2021-94",
                        "Warn: Project is vulnerable to: PYSEC-2023-175",
                        "Warn: Project is vulnerable to: GHSA-qfc5-mcwq-26q8 / PYSEC-2019-41",
                        "Warn: Project is vulnerable to: GHSA-6757-jp84-gxfx",
                        "Warn: Project is vulnerable to: GHSA-8q59-q68h-6hv4 / PYSEC-2021-142",
                        "Warn: Project is vulnerable to: GHSA-rprw-h62v-c2w7 / PYSEC-2018-49",
                        "Warn: Project is vulnerable to: GHSA-9wx4-h78v-vm56",
                        "Warn: Project is vulnerable to: GHSA-j8r2-6x86-q33q / PYSEC-2023-74",
                        "Warn: Project is vulnerable to: GHSA-34jh-p97f-mpxf",
                        "Warn: Project is vulnerable to: GHSA-g4mx-q9vg-27p4 / PYSEC-2023-212",
                        "Warn: Project is vulnerable to: GHSA-gwvm-45gx-3cf8 / PYSEC-2023-207",
                        "Warn: Project is vulnerable to: GHSA-mh33-7rrq-662w / PYSEC-2019-133",
                        "Warn: Project is vulnerable to: GHSA-r64q-w8jr-g9qp / PYSEC-2019-132",
                        "Warn: Project is vulnerable to: GHSA-v845-jxx5-vc9f / PYSEC-2023-192",
                        "Warn: Project is vulnerable to: GHSA-wqvq-5m8c-6g24 / PYSEC-2020-148",
                        "Warn: Project is vulnerable to: GHSA-www2-v7xj-xrc6 / PYSEC-2018-32",
                        "Warn: Project is vulnerable to: PYSEC-2021-108"
                    ],
                    "score": 0,
                    "reason": "481 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/allegroai/clearml/contents/SECURITY.md",
        "SecurityPolicy_content": "## Reporting Security Issues\n\nThanks for taking the time to make ClearML more secure!\n\nTo carry on the discussion more securely - Please send your report to [security@clear.ml](mailto:security@clear.ml).",
        "project_all_labels": [
            "bug",
            "dependencies",
            "documentation",
            "duplicate",
            "enhancement",
            "FAQ",
            "Feature Request",
            "help wanted",
            "invalid",
            "question",
            "wontfix"
        ],
        "README_content": "<div align=\"center\" style=\"text-align: center\">\n\n<p style=\"text-align: center\">\n  <img align=\"center\" src=\"docs/clearml-logo.svg#gh-light-mode-only\" alt=\"Clear|ML\"><img align=\"center\" src=\"docs/clearml-logo-dark.svg#gh-dark-mode-only\" alt=\"Clear|ML\">\n</p>\n\n**[ClearML](https://clear.ml) - Auto-Magical Suite of tools to streamline your AI workflow\n</br>Experiment Manager, MLOps/LLMOps and Data-Management**\n\n[![GitHub license](https://img.shields.io/github/license/allegroai/clearml.svg)](https://img.shields.io/github/license/allegroai/clearml.svg) [![PyPI pyversions](https://img.shields.io/pypi/pyversions/clearml.svg)](https://img.shields.io/pypi/pyversions/clearml.svg) [![PyPI version shields.io](https://img.shields.io/pypi/v/clearml.svg)](https://pypi.org/project/clearml/) [![Conda version shields.io](https://img.shields.io/conda/v/clearml/clearml)](https://anaconda.org/clearml/clearml) [![Optuna](https://img.shields.io/badge/Optuna-integrated-blue)](https://optuna.org)<br>\n[![PyPI Downloads](https://static.pepy.tech/badge/clearml/month)](https://pypi.org/project/clearml/) [![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/allegroai)](https://artifacthub.io/packages/search?repo=allegroai) [![Youtube](https://img.shields.io/badge/ClearML-DD0000?logo=youtube&logoColor=white)](https://www.youtube.com/c/clearml) [![Slack Channel](https://img.shields.io/badge/slack-%23clearml--community-blueviolet?logo=slack)](https://joinslack.clear.ml) [![Signup](https://img.shields.io/badge/Clear%7CML-Signup-brightgreen)](https://app.clear.ml)\n\n\n` ClearML is open-source - Leave a star to support the project! `\n\n</div>\n\n---\n### ClearML\n<sup>*Formerly known as Allegro Trains*<sup>\n\nClearML is a ML/DL development and production suite. It contains FIVE main modules:\n\n- [Experiment Manager](#clearml-experiment-manager) - Automagical experiment tracking, environments and results\n- [MLOps / LLMOps](https://github.com/allegroai/clearml-agent) - Orchestration, Automation & Pipelines solution for ML/DL/GenAI jobs (Kubernetes / Cloud / bare-metal)  \n- [Data-Management](https://github.com/allegroai/clearml/blob/master/docs/datasets.md) - Fully differentiable data management & version control solution on top of object-storage \n  (S3 / GS / Azure / NAS)  \n- [Model-Serving](https://github.com/allegroai/clearml-serving) - *cloud-ready* Scalable model serving solution! \n  - **Deploy new model endpoints in under 5 minutes** \n  - Includes optimized GPU serving support backed by Nvidia-Triton \n  - **with out-of-the-box  Model Monitoring** \n- [Reports](https://clear.ml/docs/latest/docs/webapp/webapp_reports) - Create and share rich MarkDown documents supporting embeddable online content \n- :fire: [Orchestration Dashboard](https://clear.ml/docs/latest/docs/webapp/webapp_orchestration_dash/) - Live rich dashboard for your entire compute cluster (Cloud / Kubernetes / On-Prem)\n- **NEW**  [Fractional GPUs](https://github.com/allegroai/clearml-fractional-gpu) - Container based, driver level GPU memory limitation  !!!\n  \n\nInstrumenting these components is the **ClearML-server**, see [Self-Hosting](https://clear.ml/docs/latest/docs/deploying_clearml/clearml_server) & [Free tier Hosting](https://app.clear.ml)  \n\n\n---\n<div align=\"center\">\n\n**[Sign up](https://app.clear.ml)  &  [Start using](https://clear.ml/docs/) in under 2 minutes**\n\n---\n**Friendly tutorials to get you started**\n\n<table>\n<tbody>\n  <tr>\n    <td><a href=\"https://github.com/allegroai/clearml/blob/master/docs/tutorials/Getting_Started_1_Experiment_Management.ipynb\"><b>Step 1</b></a> - Experiment Management</td>\n    <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/allegroai/clearml/blob/master/docs/tutorials/Getting_Started_1_Experiment_Management.ipynb\">\n  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a></td>\n  </tr>\n  <tr>\n    <td><a href=\"https://github.com/allegroai/clearml/blob/master/docs/tutorials/Getting_Started_2_Setting_Up_Agent.ipynb\"><b>Step 2</b></a> - Remote Execution Agent Setup</td>\n    <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/allegroai/clearml/blob/master/docs/tutorials/Getting_Started_2_Setting_Up_Agent.ipynb\">\n  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a></td>\n  </tr>\n  <tr>\n    <td><a href=\"https://github.com/allegroai/clearml/blob/master/docs/tutorials/Getting_Started_3_Remote_Execution.ipynb\"><b>Step 3</b></a> - Remotely Execute Tasks</td>\n    <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/allegroai/clearml/blob/master/docs/tutorials/Getting_Started_3_Remote_Execution.ipynb\">\n  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a></td>\n  </tr>\n</tbody>\n</table>\n\n</div>\n\n---\n\n<table>\n<tbody>\n  <tr>\n    <td>Experiment Management</td>\n    <td>Datasets</td>\n  </tr>\n  <tr>\n    <td><a href=\"https://app.clear.ml\"><img src=\"https://github.com/allegroai/clearml/blob/master/docs/experiment_manager.gif?raw=true\" width=\"100%\"></a></td>\n    <td><a href=\"https://app.clear.ml/datasets\"><img src=\"https://github.com/allegroai/clearml/blob/master/docs/datasets.gif?raw=true\" width=\"100%\"></a></td>\n  </tr>\n  <tr>\n    <td colspan=\"2\" height=\"24px\"></td>\n  </tr>\n  <tr>\n    <td>Orchestration</td>\n    <td>Pipelines</td>\n  </tr>\n  <tr>\n    <td><a href=\"https://app.clear.ml/workers-and-queues/autoscalers\"><img src=\"https://github.com/allegroai/clearml/blob/master/docs/orchestration.gif?raw=true\" width=\"100%\"></a></td>\n    <td><a href=\"https://app.clear.ml/pipelines\"><img src=\"https://github.com/allegroai/clearml/blob/master/docs/pipelines.gif?raw=true\" width=\"100%\"></a></td>\n  </tr>\n</tbody>\n</table>\n\n\n## ClearML Experiment Manager\n\n**Adding only 2 lines to your code gets you the following**\n\n* Complete experiment setup log\n    * Full source control info, including non-committed local changes\n    * Execution environment (including specific packages & versions)\n    * Hyper-parameters\n        * [`argparse`](https://docs.python.org/3/library/argparse.html)/[Click](https://github.com/pallets/click/)/[PythonFire](https://github.com/google/python-fire) for command line parameters with currently used values\n        * Explicit parameters dictionary\n        * Tensorflow Defines (absl-py)\n        * [Hydra](https://github.com/facebookresearch/hydra) configuration and overrides\n    * Initial model weights file\n* Full experiment output automatic capture\n    * stdout and stderr\n    * Resource Monitoring (CPU/GPU utilization, temperature, IO, network, etc.)\n    * Model snapshots (With optional automatic upload to central storage: Shared folder, S3, GS, Azure, Http)\n    * Artifacts log & store (Shared folder, S3, GS, Azure, Http)\n    * Tensorboard/[TensorboardX](https://github.com/allegroai/clearml/tree/master/examples/frameworks/tensorboardx) scalars, metrics, histograms, **images, audio and video samples**\n    * [Matplotlib & Seaborn](https://github.com/allegroai/clearml/tree/master/examples/frameworks/matplotlib)\n    * [ClearML Logger](https://clear.ml/docs/latest/docs/fundamentals/logger) interface for complete flexibility.\n* Extensive platform support and integrations\n    * Supported ML/DL frameworks: [PyTorch](https://github.com/allegroai/clearml/tree/master/examples/frameworks/pytorch) (incl' [ignite](https://github.com/allegroai/clearml/tree/master/examples/frameworks/ignite) / [lightning](https://github.com/allegroai/clearml/tree/master/examples/frameworks/pytorch-lightning)), [Tensorflow](https://github.com/allegroai/clearml/tree/master/examples/frameworks/tensorflow), [Keras](https://github.com/allegroai/clearml/tree/master/examples/frameworks/keras), [AutoKeras](https://github.com/allegroai/clearml/tree/master/examples/frameworks/autokeras), [FastAI](https://github.com/allegroai/clearml/tree/master/examples/frameworks/fastai), [XGBoost](https://github.com/allegroai/clearml/tree/master/examples/frameworks/xgboost), [LightGBM](https://github.com/allegroai/clearml/tree/master/examples/frameworks/lightgbm), [MegEngine](https://github.com/allegroai/clearml/tree/master/examples/frameworks/megengine) and [Scikit-Learn](https://github.com/allegroai/clearml/tree/master/examples/frameworks/scikit-learn)\n    * Seamless integration (including version control) with [**Jupyter Notebook**](https://jupyter.org/)\n    and [*PyCharm* remote debugging](https://github.com/allegroai/trains-pycharm-plugin)\n      \n#### [Start using ClearML](https://clear.ml/docs/latest/docs/getting_started/ds/ds_first_steps) \n\n\n1. Sign up for free to the [ClearML Hosted Service](https://app.clear.ml) (alternatively, you can set up your own server, see [here](https://clear.ml/docs/latest/docs/deploying_clearml/clearml_server)).\n\n    > **_ClearML Demo Server:_** ClearML no longer uses the demo server by default. To enable the demo server, set the `CLEARML_NO_DEFAULT_SERVER=0`\n    > environment variable. Credentials aren't needed, but experiments launched to the demo server are public, so make sure not \n    > to launch sensitive experiments if using the demo server.\n\n1. Install the `clearml` python package:\n\n    ```bash\n    pip install clearml\n    ```\n\n1. Connect the ClearML SDK to the server by [creating credentials](https://app.clear.ml/settings/workspace-configuration), then execute the command\nbelow and follow the instructions: \n\n    ```bash\n    clearml-init\n    ```\n\n1. Add two lines to your code:\n    ```python\n    from clearml import Task\n    task = Task.init(project_name='examples', task_name='hello world')\n    ```\n\nAnd you are done! Everything your process outputs is now automagically logged into ClearML.\n\nNext step, automation! **Learn more about ClearML's two-click automation [here](https://clear.ml/docs/latest/docs/getting_started/mlops/mlops_first_steps)**. \n\n## ClearML Architecture\n\nThe ClearML run-time components:\n\n* The ClearML Python Package - for integrating ClearML into your existing scripts by adding just two lines of code, and optionally extending your experiments and other workflows with ClearML's powerful and versatile set of classes and methods.\n* The ClearML Server - for storing experiment, model, and workflow data; supporting the Web UI experiment manager and MLOps automation for reproducibility and tuning. It is available as a hosted service and open source for you to deploy your own ClearML Server.\n* The ClearML Agent - for MLOps orchestration, experiment and workflow reproducibility, and scalability.\n\n<img src=\"https://raw.githubusercontent.com/allegroai/clearml-docs/main/docs/img/clearml_architecture.png\" width=\"100%\" alt=\"clearml-architecture\">\n\n## Additional Modules \n\n- [clearml-session](https://github.com/allegroai/clearml-session) - **Launch remote JupyterLab / VSCode-server inside any docker, on Cloud/On-Prem machines**\n- [clearml-task](https://github.com/allegroai/clearml/blob/master/docs/clearml-task.md) - Run any codebase on remote machines with full remote logging of Tensorboard, Matplotlib & Console outputs \n- [clearml-data](https://github.com/allegroai/clearml/blob/master/docs/datasets.md) - **CLI for managing and versioning your datasets, including creating / uploading / downloading of data from S3/GS/Azure/NAS** \n- [AWS Auto-Scaler](https://clear.ml/docs/latest/docs/guides/services/aws_autoscaler) - Automatically spin EC2 instances based on your workloads with preconfigured budget! No need for AKE!\n- [Hyper-Parameter Optimization](https://clear.ml/docs/latest/docs/guides/optimization/hyper-parameter-optimization/examples_hyperparam_opt) - Optimize any code with black-box approach and state-of-the-art Bayesian optimization algorithms\n- [Automation Pipeline](https://clear.ml/docs/latest/docs/guides/pipeline/pipeline_controller) - Build pipelines based on existing experiments / jobs, supports building pipelines of pipelines!  \n- [Slack Integration](https://clear.ml/docs/latest/docs/guides/services/slack_alerts) - Report experiments progress / failure directly to Slack (fully customizable!)  \n\n## Why ClearML?\n\nClearML is our solution to a problem we share with countless other researchers and developers in the machine\nlearning/deep learning universe: Training production-grade deep learning models is a glorious but messy process.\nClearML tracks and controls the process by associating code version control, research projects,\nperformance metrics, and model provenance.\n\nWe designed ClearML specifically to require effortless integration so that teams can preserve their existing methods\nand practices. \n\n  - Use it on a daily basis to boost collaboration and visibility in your team \n  - Create a remote job from any experiment with a click of a button\n  - Automate processes and create pipelines to collect your experimentation logs, outputs, and data\n  - Store all your data on any object-storage solution, with the most straightforward interface possible\n  - Make your data transparent by cataloging it all on the ClearML platform\n\nWe believe ClearML is ground-breaking. We wish to establish new standards of true seamless integration between\nexperiment management, MLOps, and data management.\n\n## Who We Are\n\nClearML is supported by you and the [clear.ml](https://clear.ml) team, which helps enterprise companies build scalable MLOps. \n\nWe built ClearML to track and control the glorious but messy process of training production-grade deep learning models.\nWe are committed to vigorously supporting and expanding the capabilities of ClearML.\n\nWe promise to always be backwardly compatible, making sure all your logs, data, and pipelines will always upgrade with you.\n\n## License\n\nApache License, Version 2.0 (see the [LICENSE](https://www.apache.org/licenses/LICENSE-2.0.html) for more information)\n\nIf ClearML is part of your development process / project / publication, please cite us :heart: : \n```\n@misc{clearml,\ntitle = {ClearML - Your entire MLOps stack in one open-source tool},\nyear = {2024},\nnote = {Software available from http://github.com/allegroai/clearml},\nurl={https://clear.ml/},\nauthor = {ClearML},\n}\n```\n\n## Documentation, Community & Support\n\nFor more information, see the [official documentation](https://clear.ml/docs) and [on YouTube](https://www.youtube.com/c/ClearML).\n\nFor examples and use cases, check the [examples folder](https://github.com/allegroai/clearml/tree/master/examples) and [corresponding documentation](https://clear.ml/docs/latest/docs/guides).\n\nIf you have any questions: post on our [Slack Channel](https://joinslack.clear.ml), or tag your questions on [stackoverflow](https://stackoverflow.com/questions/tagged/clearml) with '**[clearml](https://stackoverflow.com/questions/tagged/clearml)**' tag (*previously [trains](https://stackoverflow.com/questions/tagged/trains) tag*).\n\nFor feature requests or bug reports, please use [GitHub issues](https://github.com/allegroai/clearml/issues).\n\nAdditionally, you can always find us at *info@clear.ml*\n\n## Contributing\n\n**PRs are always welcome** :heart: See more details in the ClearML [Guidelines for Contributing](https://github.com/allegroai/clearml/blob/master/docs/contributing.md).\n\n\n_May the force (and the goddess of learning rates) be with you!_\n",
        "num_commits": 2436,
        "project_age_days": 1968,
        "project_created_at": "2019-06-10",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-27",
        "num_contributors": 95,
        "num_pull": 273,
        "num_issues": 1330,
        "num_opening_issue": 497,
        "project_size(kB)": 49667,
        "num_stargazers": 5653,
        "num_watchers": 5653,
        "num_forks": 651,
        "num_subscribers": 95,
        "SecurityPolicy_created_at": "2023-11-07 15:03:49",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "c4bf20c294fe2f64757588851c4c85b5b6b5014a",
                "url": "https://github.com/allegroai/clearml/commit/c4bf20c294fe2f64757588851c4c85b5b6b5014a",
                "date": "2023-11-11 20:52:56"
            },
            {
                "commit_id": "e6f1cc8a5c65f7007cf6452745d09795e776a548",
                "url": "https://github.com/allegroai/clearml/commit/e6f1cc8a5c65f7007cf6452745d09795e776a548",
                "date": "2023-11-07 15:03:49"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "aaugustin/websockets",
        "project_url": "https://github.com/aaugustin/websockets",
        "SSF": {
            "date": "2024-10-29T23:26:13+07:00",
            "repo": {
                "name": "github.com/aaugustin/websockets",
                "commit": "018d2e5cf56ff03690bcbf271d188e76d59c62f3"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.5,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'main'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "4 out of 4 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 5,
                    "reason": "badge detected: Passing",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 0/28 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: django contributor org/company found, qonto contributor org/company found, pypa contributor org/company found, python contributor org/company found, sfopenvoting contributor org/company found, OSVTAC contributor org/company found, python-http contributor org/company found, python-websockets contributor org/company found, shotwell-labs contributor org/company found, shotwell labs contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 10 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Info: PythonAtherisFuzzer integration found: fuzzing/fuzz_http11_request_parser.py:3",
                        "Info: PythonAtherisFuzzer integration found: fuzzing/fuzz_http11_response_parser.py:3",
                        "Info: PythonAtherisFuzzer integration found: fuzzing/fuzz_websocket_parser.py:3"
                    ],
                    "score": 10,
                    "reason": "project is fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: BSD 3-Clause \"New\" or \"Revised\" License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 28 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/release.yml:65"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/python-websockets/websockets/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/python-websockets/websockets/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/python-websockets/websockets/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/python-websockets/websockets/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:47: update your workflow using https://app.stepsecurity.io/secureworkflow/python-websockets/websockets/release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release.yml:52: update your workflow using https://app.stepsecurity.io/secureworkflow/python-websockets/websockets/release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release.yml:56: update your workflow using https://app.stepsecurity.io/secureworkflow/python-websockets/websockets/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:60: update your workflow using https://app.stepsecurity.io/secureworkflow/python-websockets/websockets/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:79: update your workflow using https://app.stepsecurity.io/secureworkflow/python-websockets/websockets/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:85: update your workflow using https://app.stepsecurity.io/secureworkflow/python-websockets/websockets/release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release.yml:89: update your workflow using https://app.stepsecurity.io/secureworkflow/python-websockets/websockets/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/python-websockets/websockets/tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/python-websockets/websockets/tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/python-websockets/websockets/tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/python-websockets/websockets/tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:74: update your workflow using https://app.stepsecurity.io/secureworkflow/python-websockets/websockets/tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:76: update your workflow using https://app.stepsecurity.io/secureworkflow/python-websockets/websockets/tests.yml/main?enable=pin",
                        "Warn: containerImage not pinned by hash: example/deployment/kubernetes/Dockerfile:1: pin your Docker image by updating python:3.9-alpine to python:3.9-alpine@sha256:2ae855d07a137e4e39f9da8995f2fcd938c5bcddce466f9a8ac437b2de68e1b1",
                        "Warn: pipCommand not pinned by hash: example/deployment/kubernetes/Dockerfile:3",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release.yml:22",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:27",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:44",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:82",
                        "Info:   0 out of  14 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   3 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   1 containerImage dependencies pinned",
                        "Info:   0 out of   5 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 6 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/release.yml:76",
                        "Warn: no topLevel permission defined: .github/workflows/release.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/tests.yml:1"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/aaugustin/websockets/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security\n\n## Policy\n\nOnly the latest version receives security updates.\n\n## Contact information\n\nPlease report security vulnerabilities to the\n[Tidelift security team](https://tidelift.com/security).\n\nTidelift will coordinate the fix and disclosure.\n",
        "project_all_labels": [
            "blocked",
            "bug",
            "dependencies",
            "documentation",
            "duplicate",
            "easy",
            "enhancement",
            "has patch",
            "help wanted",
            "high priority",
            "invalid",
            "low priority",
            "question",
            "review wanted",
            "reviewed",
            "rewrite",
            "wontfix"
        ],
        "README_content": ".. image:: logo/horizontal.svg\n   :width: 480px\n   :alt: websockets\n\n|licence| |version| |pyversions| |tests| |docs| |openssf|\n\n.. |licence| image:: https://img.shields.io/pypi/l/websockets.svg\n    :target: https://pypi.python.org/pypi/websockets\n\n.. |version| image:: https://img.shields.io/pypi/v/websockets.svg\n    :target: https://pypi.python.org/pypi/websockets\n\n.. |pyversions| image:: https://img.shields.io/pypi/pyversions/websockets.svg\n    :target: https://pypi.python.org/pypi/websockets\n\n.. |tests| image:: https://img.shields.io/github/checks-status/python-websockets/websockets/main?label=tests\n   :target: https://github.com/python-websockets/websockets/actions/workflows/tests.yml\n\n.. |docs| image:: https://img.shields.io/readthedocs/websockets.svg\n   :target: https://websockets.readthedocs.io/\n\n.. |openssf| image:: https://bestpractices.coreinfrastructure.org/projects/6475/badge\n   :target: https://bestpractices.coreinfrastructure.org/projects/6475\n\nWhat is ``websockets``?\n-----------------------\n\nwebsockets is a library for building WebSocket_ servers and clients in Python\nwith a focus on correctness, simplicity, robustness, and performance.\n\n.. _WebSocket: https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API\n\nBuilt on top of ``asyncio``, Python's standard asynchronous I/O framework, the\ndefault implementation provides an elegant coroutine-based API.\n\nAn implementation on top of ``threading`` and a Sans-I/O implementation are also\navailable.\n\n`Documentation is available on Read the Docs. <https://websockets.readthedocs.io/>`_\n\n.. copy-pasted because GitHub doesn't support the include directive\n\nHere's an echo server with the ``asyncio`` API:\n\n.. code:: python\n\n    #!/usr/bin/env python\n\n    import asyncio\n    from websockets.server import serve\n\n    async def echo(websocket):\n        async for message in websocket:\n            await websocket.send(message)\n\n    async def main():\n        async with serve(echo, \"localhost\", 8765):\n            await asyncio.get_running_loop().create_future()  # run forever\n\n    asyncio.run(main())\n\nHere's how a client sends and receives messages with the ``threading`` API:\n\n.. code:: python\n\n    #!/usr/bin/env python\n\n    from websockets.sync.client import connect\n\n    def hello():\n        with connect(\"ws://localhost:8765\") as websocket:\n            websocket.send(\"Hello world!\")\n            message = websocket.recv()\n            print(f\"Received: {message}\")\n\n    hello()\n\n\nDoes that look good?\n\n`Get started with the tutorial! <https://websockets.readthedocs.io/en/stable/intro/index.html>`_\n\n.. raw:: html\n\n    <hr>\n    <img align=\"left\" height=\"150\" width=\"150\" src=\"https://raw.githubusercontent.com/python-websockets/websockets/main/logo/tidelift.png\">\n    <h3 align=\"center\"><i>websockets for enterprise</i></h3>\n    <p align=\"center\"><i>Available as part of the Tidelift Subscription</i></p>\n    <p align=\"center\"><i>The maintainers of websockets and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. <a href=\"https://tidelift.com/subscription/pkg/pypi-websockets?utm_source=pypi-websockets&utm_medium=referral&utm_campaign=readme\">Learn more.</a></i></p>\n    <hr>\n    <p>(If you contribute to <code>websockets</code> and would like to become an official support provider, <a href=\"https://fractalideas.com/\">let me know</a>.)</p>\n\nWhy should I use ``websockets``?\n--------------------------------\n\nThe development of ``websockets`` is shaped by four principles:\n\n1. **Correctness**: ``websockets`` is heavily tested for compliance with\n   :rfc:`6455`. Continuous integration fails under 100% branch coverage.\n\n2. **Simplicity**: all you need to understand is ``msg = await ws.recv()`` and\n   ``await ws.send(msg)``. ``websockets`` takes care of managing connections\n   so you can focus on your application.\n\n3. **Robustness**: ``websockets`` is built for production. For example, it was\n   the only library to `handle backpressure correctly`_ before the issue\n   became widely known in the Python community.\n\n4. **Performance**: memory usage is optimized and configurable. A C extension\n   accelerates expensive operations. It's pre-compiled for Linux, macOS and\n   Windows and packaged in the wheel format for each system and Python version.\n\nDocumentation is a first class concern in the project. Head over to `Read the\nDocs`_ and see for yourself.\n\n.. _Read the Docs: https://websockets.readthedocs.io/\n.. _handle backpressure correctly: https://vorpus.org/blog/some-thoughts-on-asynchronous-api-design-in-a-post-asyncawait-world/#websocket-servers\n\nWhy shouldn't I use ``websockets``?\n-----------------------------------\n\n* If you prefer callbacks over coroutines: ``websockets`` was created to\n  provide the best coroutine-based API to manage WebSocket connections in\n  Python. Pick another library for a callback-based API.\n\n* If you're looking for a mixed HTTP / WebSocket library: ``websockets`` aims\n  at being an excellent implementation of :rfc:`6455`: The WebSocket Protocol\n  and :rfc:`7692`: Compression Extensions for WebSocket. Its support for HTTP\n  is minimal  just enough for an HTTP health check.\n\n  If you want to do both in the same server, look at HTTP frameworks that\n  build on top of ``websockets`` to support WebSocket connections, like\n  Sanic_.\n\n.. _Sanic: https://sanicframework.org/en/\n\nWhat else?\n----------\n\nBug reports, patches and suggestions are welcome!\n\nTo report a security vulnerability, please use the `Tidelift security\ncontact`_. Tidelift will coordinate the fix and disclosure.\n\n.. _Tidelift security contact: https://tidelift.com/security\n\nFor anything else, please open an issue_ or send a `pull request`_.\n\n.. _issue: https://github.com/python-websockets/websockets/issues/new\n.. _pull request: https://github.com/python-websockets/websockets/compare/\n\nParticipants must uphold the `Contributor Covenant code of conduct`_.\n\n.. _Contributor Covenant code of conduct: https://github.com/python-websockets/websockets/blob/main/CODE_OF_CONDUCT.md\n\n``websockets`` is released under the `BSD license`_.\n\n.. _BSD license: https://github.com/python-websockets/websockets/blob/main/LICENSE\n",
        "num_commits": 1528,
        "project_age_days": 4231,
        "project_created_at": "2013-03-30",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-27",
        "num_contributors": 66,
        "num_pull": 400,
        "num_issues": 1526,
        "num_opening_issue": 22,
        "project_size(kB)": 3674,
        "num_stargazers": 5196,
        "num_watchers": 5196,
        "num_forks": 515,
        "num_subscribers": 106,
        "SecurityPolicy_created_at": "2021-09-09 20:01:09",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "3015447f5afbe5e6c913bf0a353777ce3dc45f80",
                "url": "https://github.com/python-websockets/websockets/commit/3015447f5afbe5e6c913bf0a353777ce3dc45f80",
                "date": "2023-01-08 07:47:56"
            },
            {
                "commit_id": "8a58de259381f82036ab624255d01a8fbc6234de",
                "url": "https://github.com/python-websockets/websockets/commit/8a58de259381f82036ab624255d01a8fbc6234de",
                "date": "2022-04-17 07:01:01"
            },
            {
                "commit_id": "c8428ced9850b0838edd185605b076b4b28ad406",
                "url": "https://github.com/python-websockets/websockets/commit/c8428ced9850b0838edd185605b076b4b28ad406",
                "date": "2021-09-09 20:01:09"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "codingjoe/django-s3file",
        "project_url": "https://github.com/codingjoe/django-s3file",
        "SSF": {
            "date": "2024-10-29T23:02:25+07:00",
            "repo": {
                "name": "github.com/codingjoe/django-s3file",
                "commit": "b852632194253170e339dbc396ccf48dadc4d507"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.3,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'main'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "29 out of 29 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 2,
                    "reason": "Found 1/4 approved changesets -- score normalized to 2",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: github-beta contributor org/company found, jazzband contributor org/company found, FussyFox contributor org/company found, voiio contributor org/company found, pyupio contributor org/company found, shining panda s.a.s. contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 6 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 9,
                    "reason": "9 commit(s) and 2 issue activity found in the last 90 days -- score normalized to 9",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:77: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:79: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:109: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:117: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yml:122: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:142: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:145: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:151: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:155: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:52: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:12: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/codingjoe/django-s3file/release.yml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:19",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:58",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:94",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:95",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:121",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release.yml:17",
                        "Info:   0 out of  18 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   6 pipCommand dependencies pinned",
                        "Info:   2 out of   2 npmCommand dependencies pinned"
                    ],
                    "score": 1,
                    "reason": "dependency not pinned by hash detected -- score normalized to 1",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: all commits (29) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/ci.yml:131",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/ci.yml:132",
                        "Warn: no topLevel permission defined: .github/workflows/ci.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-c2qf-rxjj-qqgw"
                    ],
                    "score": 9,
                    "reason": "1 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/codingjoe/django-s3file/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Security Considerations\n\nThe wake of CVE-2022-24840 revealed the importance to document security considerations.\nThe following attack vectors have been considered during development. Should there be\na possible vector or consideration missing, please contact the maintainers, as described\nbelow.\n\nWe use [pre-signed POST URLs](s3-pre-signed-url) to upload files to AWS S3.\n[Django's internal signer](django-signing) is used to sign the upload path and validate\nit before fetching files from S3.\n\nPlease note, that Django's signer uses the `SECRET_KEY`, rotating the key will void all\nsignatures. Should you rotate the secret key, between a form GET and POST request, the\nform will fail. Similarly, Django will expire all sessions if you rotate the key.\n\n[s3-pre-signed-url]: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-presigned-urls.html\n[django-signing]: https://docs.djangoproject.com/en/stable/topics/signing/\n\n### Upload of malicious files\n\nAWS S3 supports MIME type detection and content-type enforcement.\nYou can limit the upload of malicious files via the MIME type [accept][accept].\nHowever, this is not a security measure, and you should always validate files before\nprocessing them.\n\n[accept]: https://developer.mozilla.org/en-US/docs/Web/HTML/Attributes/accept\n\n### Request file injection\n\nThough files can always be included in a request, CVE-2022-24840 revealed that we need\nto consider people injecting any files that reside on your S3 bucket. However, we do\npresign the upload location and validate it before fetching files from S3.\n\n### Path traversal & timing attacks\n\nWe fetch files from your S3 bucket. This behavior could be used to brute force valid\nfile names. We mitigate this by signing the allowed upload path and validating it.\nThe upload path is unique for each file input and request. Therefore, an attacker can\nnot escape and access any files but the one uploaded by the attacker.\n\n## Reporting a Vulnerability\n\nNEVER open an issue or discussion to report a vulnerability.\n\nTo report a security vulnerability, please use the\n[Tidelift security contact](https://tidelift.com/security).\nTidelift will coordinate the fix and disclosure.\n\nYou may also contact one of the maintainers of the project either via email or Telegram:\n\n* Email: [johannes@maron.family](mailto:johannes@maron.family)\n* Telegram: [@codingjoe](https://t.me/codingjoe)\n",
        "project_all_labels": [
            "bug",
            "dependencies",
            "duplicate",
            "enhancement",
            "github_actions",
            "help wanted",
            "invalid",
            "javascript",
            "python",
            "question",
            "wontfix"
        ],
        "README_content": "# django-s3file\n\nA lightweight file upload input for Django and Amazon S3.\n\nDjango-S3File allows you to upload files directly AWS S3 effectively\nbypassing your application server. This allows you to avoid long running\nrequests from large file uploads. This is particularly helpful for if\nyou run your service on AWS Lambda or Heroku where you have a hard\nrequest limit.\n\n[![PyPi\nVersion](https://img.shields.io/pypi/v/django-s3file.svg)](https://pypi.python.org/pypi/django-s3file/)\n[![Test\nCoverage](https://codecov.io/gh/codingjoe/django-s3file/branch/main/graph/badge.svg)](https://codecov.io/gh/codingjoe/django-s3file)\n[![GitHub\nlicense](https://img.shields.io/badge/license-MIT-blue.svg)](https://raw.githubusercontent.com/codingjoe/django-s3file/main/LICENSE)\n\n## Features\n\n-   lightweight: less 200 lines\n-   no JavaScript or Python dependencies (no jQuery)\n-   easy integration\n-   works just like the built-in\n-   extendable JavaScript API\n\n## For the Nerds\n\n```mermaid\nsequenceDiagram\n    autonumber\n    actor Browser\n    participant S3\n    participant Middleware\n    Browser->>Django: GET form view\n    activate Django\n    Django->>Browser: RESPONSE w/ presigned POST URL & signed middleware key\n    deactivate Django\n    Browser->>S3: POST large file\n    activate S3\n    S3->>Browser: RESPONSE AWS S3 key\n    Browser->>Middleware: POST AWS S3 key (signed)\n    activate Middleware\n    Middleware->>S3: GET AWS S3 key\n    S3->>Middleware: RESPONSE large file promise\n    deactivate S3\n    Middleware->>Django: request incl. large file promise\n    deactivate Middleware\n    activate Django\n    opt only if files is procssed by Django\n        Django-->>S3: GET large file\n        activate S3\n        S3-->>Django: RESPONSE large file\n        deactivate S3\n    end\n    Django->>Browser: RESPONSE success\n    deactivate Django\n```\n\nIn a nutshell, we can bypass Django completely and have AWS handle\nthe upload or any processing. Of course, if you want to do something\nwith your file in Django, you can do so, just like before, with the\nadded advantage, that your file is served from within your datacenter.\n\n## Installation\n\nMake sure you have [Amazon S3\nstorage](http://django-storages.readthedocs.io/en/latest/backends/amazon-S3.html)\nsetup correctly.\n\nJust install S3file using `pip`.\n\n```bash\npip install django-s3file\n# or\npipenv install django-s3file\n```\n\nAdd the S3File app and middleware in your settings:\n\n```python\n# settings.py\n\nINSTALLED_APPS = (\n    '...',\n    's3file',\n    '...',\n)\n\nMIDDLEWARE = (\n    '...',\n    's3file.middleware.S3FileMiddleware',\n    '...',\n)\n```\n\n## Usage\n\nS3File automatically replaces Django's `ClearableFileInput` widget, you\ndo not need to alter your code at all.\n\nThe `ClearableFileInput` widget is only than automatically replaced when\nthe `STORAGES[\"default\"]` setting is set to `django-storages`'\n`S3Boto3Storage` or the dummy `FileSystemStorage` is enabled.\n\n### Setting up the AWS S3 bucket\n\n#### Upload folder\n\nS3File uploads to a single folder. Files are later moved by Django when\nthey are saved to the `upload_to` location.\n\nIt is recommended to [setup\nexpiration](http://docs.aws.amazon.com/AmazonS3/latest/dev/intro-lifecycle-rules.html)\nfor that folder, to ensure that old and unused file uploads don't add up\nand produce costs.\n\nThe default folder name is: `tmp/s3file` You can change it by changing\nthe `S3FILE_UPLOAD_PATH` setting.\n\n#### CORS policy\n\nYou will need to allow `POST` from all origins. Just add the following\nto your CORS policy.\n\n```json\n[\n  {\n    \"AllowedHeaders\": [\n        \"*\"\n    ],\n    \"AllowedMethods\": [\n        \"POST\"\n    ],\n    \"AllowedOrigins\": [\n        \"*\"\n    ],\n    \"ExposeHeaders\": [],\n    \"MaxAgeSeconds\": 3000\n  }\n]\n```\n\n### Progress Bar\n\nS3File does emit progress signals that can be used to display some kind\nof progress bar. Signals named `progress` are emitted for both each\nindividual file input as well as for the form as a whole.\n\nThe progress signal carries the following details:\n\n```javascript\nconsole.log(event.detail)\n\n{\n    progress: 0.4725307607171312  // total upload progress of either a form or single input\n    loaded: 1048576  // total upload progress of either a form or single input\n    total: 2219064  // total bytes to upload\n    currentFile: File {}  // file object\n    currentFileName: \"text.txt\"  // file name of the file currently uploaded\n    currentFileProgress: 0.47227834703299176  // upload progress of that file\n    originalEvent: ProgressEvent {} // the original XHR onprogress event\n}\n```\n\nThe following example implements a Boostrap progress bar for upload\nprogress of an entire form.\n\n```html\n<div class=\"progress\">\n  <div class=\"progress-bar\" role=\"progressbar\" style=\"width: 0%;\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\">0%</div>\n</div>\n```\n\n```javascript\n(function () {\n    var form = document.getElementsByTagName('form')[0]\n    var progressBar = document.getElementsByClassName('progress-bar')[0]\n\n    form.addEventListener('progress', function (event) {\n        // event.detail.progress is a value between 0 and 1\n        var percent = Math.round(event.detail.progress * 100)\n\n        progressBar.setAttribute('style', 'width:' + percent + '%')\n        progressBar.setAttribute('aria-valuenow', percent)\n        progressBar.innerText = percent + '%'\n    })\n})()\n```\n\n### Using S3File in development\n\nUsing S3File in development can be helpful especially if you want to use\nthe progress signals described above. Therefore, S3File comes with a AWS\nS3 dummy backend. It behaves similar to the real S3 storage backend. It\nis automatically enabled, if the `DEFAULT_FILE_STORAGE` setting is set\nto `FileSystemStorage`.\n\nTo prevent users from accidentally using the `FileSystemStorage` and the\ninsecure S3 dummy backend in production, there is also an additional\ndeployment check that will error if you run Django\\'s deployment check\nsuite:\n\n```shell\npython manage.py check --deploy\n```\n\nWe recommend always running the deployment check suite as part of your\ndeployment pipeline.\n\n### Uploading multiple files\n\nDjango does have limited support for [uploading multiple\nfiles](https://docs.djangoproject.com/en/stable/topics/http/file-uploads/#uploading-multiple-files).\nS3File fully supports this feature. The custom middleware makes ensure\nthat files are accessible via `request.FILES`, even though they have\nbeen uploaded to AWS S3 directly and not to your Django application\nserver.\n\n### Using optimized S3Boto3Storage\n\nSince `S3Boto3Storage` supports storing data from any other fileobj, it\nuses a generalized `_save` function. This leads to the frontend\nuploading the file to S3 and then copying it byte-by-byte to perform a\nmove operation just to rename the uploaded object. For large files this\nleads to additional loading times for the user.\n\nThat\\'s why S3File provides an optimized version of this method at\n`storages_optimized.S3OptimizedUploadStorage`. It uses the more\nefficient `copy` method from S3, given that we know that we only copy\nfrom one S3 location to another.\n\n```python\nfrom s3file.storages_optimized import S3OptimizedUploadStorage\n\nclass MyStorage(S3OptimizedUploadStorage):  # Subclass and use like any other storage\n    default_acl = 'private'\n```\n",
        "num_commits": 353,
        "project_age_days": 3641,
        "project_created_at": "2014-11-10",
        "latest_updated_at": "2024-10-10",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 14,
        "num_pull": 271,
        "num_issues": 307,
        "num_opening_issue": 5,
        "project_size(kB)": 708,
        "num_stargazers": 79,
        "num_watchers": 79,
        "num_forks": 16,
        "num_subscribers": 10,
        "SecurityPolicy_created_at": "2022-06-06 10:38:02",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "3e17d58d523323cf60476478119e65e73b514d7b",
                "url": "https://github.com/codingjoe/django-s3file/commit/3e17d58d523323cf60476478119e65e73b514d7b",
                "date": "2022-10-14 08:38:45"
            },
            {
                "commit_id": "d3d3dbcd3cc7cd869bdbc676dce8ce5da0d11b09",
                "url": "https://github.com/codingjoe/django-s3file/commit/d3d3dbcd3cc7cd869bdbc676dce8ce5da0d11b09",
                "date": "2022-06-06 10:38:02"
            },
            {
                "commit_id": "b0d007e06167e03bde3bc1697c730764ce0a0a33",
                "url": "https://github.com/codingjoe/django-s3file/commit/b0d007e06167e03bde3bc1697c730764ce0a0a33",
                "date": "2022-06-06 10:38:02"
            },
            {
                "commit_id": "10ec9d9af6d5bc7f5e7f3d3369815c4348b24240",
                "url": "https://github.com/codingjoe/django-s3file/commit/10ec9d9af6d5bc7f5e7f3d3369815c4348b24240",
                "date": "2022-06-06 10:38:02"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email_external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "celery/celery",
        "project_url": "https://github.com/celery/celery",
        "SSF": {
            "date": "2024-10-29T22:47:14+07:00",
            "repo": {
                "name": "github.com/celery/celery",
                "commit": "fb39f230fb25d7ca885de533d66b373c363df1a5"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.2,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: branch 'main' does not require approvers",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Warn: no status checks found to merge onto branch 'main'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 out of 30 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 5,
                    "reason": "badge detected: Passing",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 6,
                    "reason": "Found 15/24 approved changesets -- score normalized to 6",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: robinhoodmarkets contributor org/company found, python-trio contributor org/company found, zml contributor org/company found, katz consulting group ltd contributor org/company found, celery @psf @apache @encode contributor org/company found, PyBackendBoilerplate contributor org/company found, pyupio contributor org/company found, python-arq contributor org/company found, gunicorn contributor org/company found, precise.ly contributor org/company found, 360netlab contributor org/company found, session-type-provider contributor org/company found, nose-devs contributor org/company found, dask contributor org/company found, readthedocs contributor org/company found, pypa contributor org/company found, cookiecutter contributor org/company found, scribble contributor org/company found, colladoc contributor org/company found, pgRouting contributor org/company found, celery contributor org/company found, pytest-dev contributor org/company found, alvaria-io contributor org/company found, didcot-data contributor org/company found, django-commons contributor org/company found, katz-consulting-group contributor org/company found, liveblocks contributor org/company found, py-bson contributor org/company found, pawamoy-insiders contributor org/company found, encode @pydantic contributor org/company found, Geoportail-Luxembourg contributor org/company found, 3rdcloud contributor org/company found, pydantic contributor org/company found, iccsw contributor org/company found, grid contributor org/company found, jazzband contributor org/company found, irssi contributor org/company found, smok-serwis contributor org/company found, hylang contributor org/company found, CrowdJustice contributor org/company found, encode contributor org/company found, RoPython contributor org/company found, strawberry-graphql contributor org/company found, Shootime-co contributor org/company found, geoadmin contributor org/company found, swissgeol contributor org/company found, sqlalchemy-redshift contributor org/company found, python contributor org/company found, openlayers contributor org/company found, psf contributor org/company found, camptocamp contributor org/company found, MTU-AeroEngines contributor org/company found, smok.co contributor org/company found, pypy contributor org/company found, apache contributor org/company found, digiverse contributor org/company found, fastapi contributor org/company found, geoext contributor org/company found, twisted contributor org/company found, PyCQA contributor org/company found, canvg contributor org/company found, platformsh contributor org/company found, testing-cabal contributor org/company found, testsuite contributor org/company found, TrendBreaker contributor org/company found, asnible contributor org/company found, sitn contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 67 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 12 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:42: update your workflow using https://app.stepsecurity.io/secureworkflow/celery/celery/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/celery/celery/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:57: update your workflow using https://app.stepsecurity.io/secureworkflow/celery/celery/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:71: update your workflow using https://app.stepsecurity.io/secureworkflow/celery/celery/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docker.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/celery/celery/docker.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docker.yml:48: update your workflow using https://app.stepsecurity.io/secureworkflow/celery/celery/docker.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docker.yml:56: update your workflow using https://app.stepsecurity.io/secureworkflow/celery/celery/docker.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docker.yml:64: update your workflow using https://app.stepsecurity.io/secureworkflow/celery/celery/docker.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docker.yml:72: update your workflow using https://app.stepsecurity.io/secureworkflow/celery/celery/docker.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docker.yml:32: update your workflow using https://app.stepsecurity.io/secureworkflow/celery/celery/docker.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/linter.yml:11: update your workflow using https://app.stepsecurity.io/secureworkflow/celery/celery/linter.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/linter.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/celery/celery/linter.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-package.yml:55: update your workflow using https://app.stepsecurity.io/secureworkflow/celery/celery/python-package.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-package.yml:57: update your workflow using https://app.stepsecurity.io/secureworkflow/celery/celery/python-package.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-package.yml:73: update your workflow using https://app.stepsecurity.io/secureworkflow/celery/celery/python-package.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-package.yml:114: update your workflow using https://app.stepsecurity.io/secureworkflow/celery/celery/python-package.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-package.yml:116: update your workflow using https://app.stepsecurity.io/secureworkflow/celery/celery/python-package.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-package.yml:165: update your workflow using https://app.stepsecurity.io/secureworkflow/celery/celery/python-package.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-package.yml:167: update your workflow using https://app.stepsecurity.io/secureworkflow/celery/celery/python-package.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/semgrep.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/celery/celery/semgrep.yml/main?enable=pin",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile:1: pin your Docker image by updating debian:bookworm-slim to debian:bookworm-slim@sha256:36e591f228bb9b99348f584e83f16e012c33ba5cad44ef5981a1d7c0a93eca22",
                        "Warn: containerImage not pinned by hash: docker/docs/Dockerfile:1: pin your Docker image by updating python:3.12-slim-bookworm to python:3.12-slim-bookworm@sha256:032c52613401895aa3d418a4c563d2d05f993bc3ecc065c8f4e2280978acd249",
                        "Warn: downloadThenRun not pinned by hash: docker/Dockerfile:65",
                        "Warn: pipCommand not pinned by hash: docker/docs/Dockerfile:23",
                        "Warn: pipCommand not pinned by hash: docker/docs/Dockerfile:27",
                        "Warn: downloadThenRun not pinned by hash: docker/scripts/install-pyenv.sh:3",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python-package.yml:176",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python-package.yml:66",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python-package.yml:124",
                        "Info:   0 out of  15 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   5 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   2 downloadThenRun dependencies pinned",
                        "Info:   0 out of   5 pipCommand dependencies pinned",
                        "Info:   0 out of   2 containerImage dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: all commits (30) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql-analysis.yml:29",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql-analysis.yml:30",
                        "Warn: no topLevel permission defined: .github/workflows/codeql-analysis.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/docker.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/linter.yml:1",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/python-package.yml:27",
                        "Warn: no topLevel permission defined: .github/workflows/semgrep.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-q4xr-rc97-m4xx / PYSEC-2021-858",
                        "Warn: Project is vulnerable to: GHSA-2gwj-7jmv-h26r / PYSEC-2022-190",
                        "Warn: Project is vulnerable to: GHSA-2m34-jcjv-45xf / PYSEC-2020-32",
                        "Warn: Project is vulnerable to: GHSA-3gh2-xw74-jmcw / PYSEC-2020-36",
                        "Warn: Project is vulnerable to: GHSA-53qw-q765-4fww / PYSEC-2022-1",
                        "Warn: Project is vulnerable to: GHSA-68w8-qjq3-2gfm / PYSEC-2021-98",
                        "Warn: Project is vulnerable to: GHSA-6c3j-c64m-qhgq",
                        "Warn: Project is vulnerable to: GHSA-6c7v-2f49-8h26 / PYSEC-2019-10",
                        "Warn: Project is vulnerable to: GHSA-6cw3-g6wv-c2xv / PYSEC-2022-20",
                        "Warn: Project is vulnerable to: GHSA-6r97-cj55-9hrq / PYSEC-2019-13",
                        "Warn: Project is vulnerable to: GHSA-7rp2-fm2h-wchj / PYSEC-2019-79",
                        "Warn: Project is vulnerable to: GHSA-8c5j-9r9f-c6w8 / PYSEC-2022-2",
                        "Warn: Project is vulnerable to: GHSA-8x94-hmjh-97hq",
                        "Warn: Project is vulnerable to: GHSA-95rw-fx8r-36v6 / PYSEC-2022-19",
                        "Warn: Project is vulnerable to: GHSA-c4qh-4vgv-qc6g / PYSEC-2019-11",
                        "Warn: Project is vulnerable to: GHSA-fr28-569j-53c4 / PYSEC-2020-34",
                        "Warn: Project is vulnerable to: GHSA-fvgf-6h6h-3322 / PYSEC-2021-9",
                        "Warn: Project is vulnerable to: GHSA-h5jv-4p7w-64jg / PYSEC-2019-12",
                        "Warn: Project is vulnerable to: GHSA-hmr4-m2h5-33qx / PYSEC-2020-35",
                        "Warn: Project is vulnerable to: GHSA-hvmf-r92r-27hr / PYSEC-2019-15",
                        "Warn: Project is vulnerable to: GHSA-jrh2-hc4r-7jwx / PYSEC-2022-3",
                        "Warn: Project is vulnerable to: GHSA-m6gj-h9gm-gw44 / PYSEC-2020-33",
                        "Warn: Project is vulnerable to: GHSA-p99v-5w3c-jqq9 / PYSEC-2021-99",
                        "Warn: Project is vulnerable to: GHSA-qm57-vhq3-3fwf / PYSEC-2021-8",
                        "Warn: Project is vulnerable to: GHSA-rrqc-c2jx-6jgv",
                        "Warn: Project is vulnerable to: GHSA-rxjp-mfm9-w4wr / PYSEC-2021-7",
                        "Warn: Project is vulnerable to: GHSA-v6rh-hp5x-86rv / PYSEC-2021-439",
                        "Warn: Project is vulnerable to: GHSA-v9qg-3j8p-r63v / PYSEC-2019-14",
                        "Warn: Project is vulnerable to: GHSA-vfq6-hq5r-27r6 / PYSEC-2019-16",
                        "Warn: Project is vulnerable to: GHSA-w24h-v9qh-8gxj / PYSEC-2022-191",
                        "Warn: Project is vulnerable to: GHSA-wpjr-j57x-wxfw / PYSEC-2020-31",
                        "Warn: Project is vulnerable to: GHSA-xgxc-v2qg-chmh / PYSEC-2021-6",
                        "Warn: Project is vulnerable to: GHSA-38fc-9xqv-7f7q"
                    ],
                    "score": 0,
                    "reason": "33 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/celery/celery/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nUse this section to tell people about which versions of your project are\ncurrently being supported with security updates.\n\n| Version | Supported          |\n| ------- | ------------------ |\n| 5.3.x   | :white_check_mark: |\n| 5.2.x   | :x:                |\n| 5.1.x   | :x: |\n| < 5.0   | :x:                |\n\n## Reporting a Vulnerability\n\nPlease reach out to auvipy@gmail.com & omer.drow@gmail.com for reporting security concerns via email.\n",
        "project_all_labels": [
            "AMQP 1.0",
            "Backer ",
            "Category: Deployment",
            "Category: Documentation",
            "Category: Experimental Features",
            "Category: Packaging and Release Management",
            "Category: Performance",
            "Category: Project Governance",
            "Category: Results Backend",
            "Category: Tests",
            "CI",
            "Component: Amazon SQS Broker",
            "Component: AMQP Results Backend",
            "Component: App",
            "Component: ArangoDB Results Backend",
            "Component: Auth Serializer",
            "Component: Autoreload",
            "Component: Autoscaling",
            "Component: Azure Block Blob Results Backend",
            "Component: Azure Service Bus",
            "Component: Azure Storage Queues Broker",
            "Component: Beanstalk Broker",
            "Component: Billiard",
            "Component: Cache Results Backend",
            "Component: Canvas",
            "Component: Cassandra Results Backend",
            "Component: Celery Master",
            "Component: Celerybeat",
            "Component: CLI",
            "Component: CloudAMQP broker",
            "Component: Configuration",
            "Component: Consul Results Backend",
            "Component: Consumer",
            "Component: Couchbase Results Backend",
            "Component: Couchdb Results Backend",
            "Component: Django",
            "Component: Docker Image",
            "Component: DynamoDB Results Backend",
            "Component: Eager mode",
            "Component: ElasticSearch Results Backend",
            "Component: ETA/Countdown",
            "Component: Eventlet Workers Pool",
            "Component: Filesystem Result Backend",
            "Component: Gevent Workers Pool",
            "Component: Google Cloud Storage Backend",
            "Component: Gossip",
            "Component: Iron MQ Broker",
            "Component: IronCache Results Backend",
            "Component: Kombu",
            "Component: Logging",
            "Component: Memcached Results Backend",
            "Component: MongoDB Broker",
            "Component: MongoDB Results Backend",
            "Component: Prefork Workers Pool",
            "Component: Pytest Integration",
            "Component: QPid Broker",
            "Component: RabbitMQ Broker",
            "Component: Redis Broker",
            "Component: Redis Results Backend",
            "Component: Remote Debugger",
            "Component: Result Backend",
            "Component: RPC Results Backend",
            "Component: Signals",
            "Component: Solo Worker Pool",
            "Component: Sphinx Contrib",
            "Component: SQLAlchemy",
            "Component: SQLAlchemy Database Results Backend",
            "Component: Task Execution",
            "Component: Task Routing",
            "Component: Task Serialization",
            "Component: Threadpool Workers Pool",
            "Component: Zookeeper Broker",
            "Cython",
            "dependencies",
            "DEV-VERSION",
            "events",
            "Flask",
            "github_actions",
            "good first issue",
            "greenlet",
            "hacktoberfest-accepted",
            "HAProxy",
            "HeartBeat",
            "hiredis",
            "inspect",
            "Issue Type: Bug Report",
            "Issue Type: Documentation",
            "Issue Type: Enhancement",
            "Issue Type: Feature Request",
            "Issue Type: Optimization",
            "Issue Type: Question",
            "Issue Type: Regression",
            "Issue Type: Task",
            "memory leak",
            "msgpack",
            "multi",
            "NEEDS HELP",
            "Not Funded",
            "Operating System: BSD",
            "Operating System: Linux",
            "Operating System: macOS",
            "Operating System: Windows",
            "PR Type: Backport",
            "PR Type: Bugfix",
            "PR Type: Cleanup",
            "PR Type: Enhancement",
            "PR Type: Feature",
            "PR Type: Test Case",
            "Priority: Blocker",
            "Priority: Critical",
            "Priority: Low",
            "Priority: Major",
            "Priority: None (no current effort)",
            "Priority: Normal",
            "Priority: Trivial",
            "pucurl",
            "pyamqp",
            "pycurl",
            "python",
            "Python Version: Jython",
            "Python Version: PyPy",
            "Python Version: PyPy 3",
            "Python Version: Python 2",
            "Python Version: Python 3",
            "redis-py",
            "Result",
            "S3 Result backend",
            "serializer",
            "Severity: Blocker",
            "Severity: Critical",
            "Severity: Low",
            "Severity: Major",
            "Severity: Normal",
            "Severity: Trivial",
            "Sponsor ",
            "Sprint Candidate",
            "Status: Cannot Reproduce ",
            "Status: Confirmed ",
            "Status: Design Decision Needed ",
            "Status: Duplicate ",
            "Status: Feedback Needed ",
            "Status: Has Documentation",
            "Status: Has Test Coverage ",
            "Status: Has Testcase ",
            "Status: In Progress",
            "Status: Invalid ",
            "Status: Needs Backporting",
            "Status: Needs Documentation ",
            "Status: Needs Rebase ",
            "Status: Needs Test Coverage ",
            "Status: Needs Testcase ",
            "Status: Needs Verification ",
            "Status: Not a Bug",
            "Status: Ready For Merge ",
            "Status: Won't Fix",
            "Status: Works For Me",
            "Todo",
            "upstream bug",
            "Version: 3.0",
            "Version: 3.1",
            "Version: 4.0",
            "Version: 4.1",
            "Version: 4.2",
            "Version: 4.4",
            "Version: 5.0",
            "Worker",
            "Worker Crashes",
            "Worker Hangs"
        ],
        "README_content": ".. image:: https://docs.celeryq.dev/en/latest/_images/celery-banner-small.png\n\n|build-status| |coverage| |license| |wheel| |semgrep| |pyversion| |pyimp| |ocbackerbadge| |ocsponsorbadge|\n\n:Version: 5.5.0rc1 (immunity)\n:Web: https://docs.celeryq.dev/en/stable/index.html\n:Download: https://pypi.org/project/celery/\n:Source: https://github.com/celery/celery/\n:Keywords: task, queue, job, async, rabbitmq, amqp, redis,\n  python, distributed, actors\n\nDonations\n=========\n\nThis project relies on your generous donations.\n\nIf you are using Celery to create a commercial product, please consider becoming our `backer`_ or our `sponsor`_ to ensure Celery's future.\n\n.. _`backer`: https://opencollective.com/celery#backer\n.. _`sponsor`: https://opencollective.com/celery#sponsor\n\nFor enterprise\n==============\n\nAvailable as part of the Tidelift Subscription.\n\nThe maintainers of ``celery`` and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. `Learn more. <https://tidelift.com/subscription/pkg/pypi-celery?utm_source=pypi-celery&utm_medium=referral&utm_campaign=enterprise&utm_term=repo>`_\n\n\nSponsor\n=======\n\n`Dragonfly <https://www.dragonflydb.io/>`_ is a drop-in Redis replacement that cuts costs and boosts performance. Designed to fully utilize the power of modern cloud hardware and deliver on the data demands of modern applications, Dragonfly frees developers from the limits of traditional in-memory data stores.\n\n\n.. image:: https://github.com/celery/celery/raw/main/docs/images/dragonfly.png\n   :alt: Dragonfly logo\n   :width: 150px \n\n\n\n\n\nWhat's a Task Queue?\n====================\n\nTask queues are used as a mechanism to distribute work across threads or\nmachines.\n\nA task queue's input is a unit of work, called a task, dedicated worker\nprocesses then constantly monitor the queue for new work to perform.\n\nCelery communicates via messages, usually using a broker\nto mediate between clients and workers. To initiate a task a client puts a\nmessage on the queue, the broker then delivers the message to a worker.\n\nA Celery system can consist of multiple workers and brokers, giving way\nto high availability and horizontal scaling.\n\nCelery is written in Python, but the protocol can be implemented in any\nlanguage. In addition to Python there's node-celery_ for Node.js,\na `PHP client`_, `gocelery`_, gopher-celery_ for Go, and rusty-celery_ for Rust.\n\nLanguage interoperability can also be achieved by using webhooks\nin such a way that the client enqueues an URL to be requested by a worker.\n\n.. _node-celery: https://github.com/mher/node-celery\n.. _`PHP client`: https://github.com/gjedeer/celery-php\n.. _`gocelery`: https://github.com/gocelery/gocelery\n.. _gopher-celery: https://github.com/marselester/gopher-celery\n.. _rusty-celery: https://github.com/rusty-celery/rusty-celery\n\nWhat do I need?\n===============\n\nCelery version 5.5.x runs on:\n\n- Python (3.8, 3.9, 3.10, 3.11, 3.12, 3.13)\n- PyPy3.9+ (v7.3.12+)\n\n\nThis is the version of celery which will support Python 3.8 or newer.\n\nIf you're running an older version of Python, you need to be running\nan older version of Celery:\n\n- Python 3.7: Celery 5.2 or earlier.\n- Python 3.6: Celery 5.1 or earlier.\n- Python 2.7: Celery 4.x series.\n- Python 2.6: Celery series 3.1 or earlier.\n- Python 2.5: Celery series 3.0 or earlier.\n- Python 2.4: Celery series 2.2 or earlier.\n\nCelery is a project with minimal funding,\nso we don't support Microsoft Windows but it should be working.\nPlease don't open any issues related to that platform.\n\n*Celery* is usually used with a message broker to send and receive messages.\nThe RabbitMQ, Redis transports are feature complete,\nbut there's also experimental support for a myriad of other solutions, including\nusing SQLite for local development.\n\n*Celery* can run on a single machine, on multiple machines, or even\nacross datacenters.\n\nGet Started\n===========\n\nIf this is the first time you're trying to use Celery, or you're\nnew to Celery v5.5.x coming from previous versions then you should read our\ngetting started tutorials:\n\n- `First steps with Celery`_\n\n    Tutorial teaching you the bare minimum needed to get started with Celery.\n\n- `Next steps`_\n\n    A more complete overview, showing more features.\n\n.. _`First steps with Celery`:\n    https://docs.celeryq.dev/en/stable/getting-started/first-steps-with-celery.html\n\n.. _`Next steps`:\n    https://docs.celeryq.dev/en/stable/getting-started/next-steps.html\n\n You can also get started with Celery by using a hosted broker transport CloudAMQP. The largest hosting provider of RabbitMQ is a proud sponsor of Celery.\n\nCelery is...\n=============\n\n- **Simple**\n\n    Celery is easy to use and maintain, and does *not need configuration files*.\n\n    It has an active, friendly community you can talk to for support,\n    like at our `mailing-list`_, or the IRC channel.\n\n    Here's one of the simplest applications you can make:\n\n    .. code-block:: python\n\n        from celery import Celery\n\n        app = Celery('hello', broker='amqp://guest@localhost//')\n\n        @app.task\n        def hello():\n            return 'hello world'\n\n- **Highly Available**\n\n    Workers and clients will automatically retry in the event\n    of connection loss or failure, and some brokers support\n    HA in way of *Primary/Primary* or *Primary/Replica* replication.\n\n- **Fast**\n\n    A single Celery process can process millions of tasks a minute,\n    with sub-millisecond round-trip latency (using RabbitMQ,\n    py-librabbitmq, and optimized settings).\n\n- **Flexible**\n\n    Almost every part of *Celery* can be extended or used on its own,\n    Custom pool implementations, serializers, compression schemes, logging,\n    schedulers, consumers, producers, broker transports, and much more.\n\nIt supports...\n================\n\n    - **Message Transports**\n\n        - RabbitMQ_, Redis_, Amazon SQS, Google Pub/Sub\n\n    - **Concurrency**\n\n        - Prefork, Eventlet_, gevent_, single threaded (``solo``)\n\n    - **Result Stores**\n\n        - AMQP, Redis\n        - memcached\n        - SQLAlchemy, Django ORM\n        - Apache Cassandra, IronCache, Elasticsearch\n        - Google Cloud Storage\n\n    - **Serialization**\n\n        - *pickle*, *json*, *yaml*, *msgpack*.\n        - *zlib*, *bzip2* compression.\n        - Cryptographic message signing.\n\n.. _`Eventlet`: http://eventlet.net/\n.. _`gevent`: http://gevent.org/\n\n.. _RabbitMQ: https://rabbitmq.com\n.. _Redis: https://redis.io\n.. _SQLAlchemy: http://sqlalchemy.org\n\nFramework Integration\n=====================\n\nCelery is easy to integrate with web frameworks, some of which even have\nintegration packages:\n\n    +--------------------+------------------------+\n    | `Django`_          | not needed             |\n    +--------------------+------------------------+\n    | `Pyramid`_         | `pyramid_celery`_      |\n    +--------------------+------------------------+\n    | `Pylons`_          | `celery-pylons`_       |\n    +--------------------+------------------------+\n    | `Flask`_           | not needed             |\n    +--------------------+------------------------+\n    | `web2py`_          | `web2py-celery`_       |\n    +--------------------+------------------------+\n    | `Tornado`_         | `tornado-celery`_      |\n    +--------------------+------------------------+\n    | `FastAPI`_         | not needed             |\n    +--------------------+------------------------+\n\nThe integration packages aren't strictly necessary, but they can make\ndevelopment easier, and sometimes they add important hooks like closing\ndatabase connections at ``fork``.\n\n.. _`Django`: https://djangoproject.com/\n.. _`Pylons`: http://pylonsproject.org/\n.. _`Flask`: https://flask.palletsprojects.com/\n.. _`web2py`: http://web2py.com/\n.. _`Bottle`: https://bottlepy.org/\n.. _`Pyramid`: https://docs.pylonsproject.org/projects/pyramid/en/latest/\n.. _`pyramid_celery`: https://pypi.org/project/pyramid_celery/\n.. _`celery-pylons`: https://pypi.org/project/celery-pylons/\n.. _`web2py-celery`: https://code.google.com/p/web2py-celery/\n.. _`Tornado`: https://www.tornadoweb.org/\n.. _`tornado-celery`: https://github.com/mher/tornado-celery/\n.. _`FastAPI`: https://fastapi.tiangolo.com/\n\n.. _celery-documentation:\n\nDocumentation\n=============\n\nThe `latest documentation`_ is hosted at Read The Docs, containing user guides,\ntutorials, and an API reference.\n\n.. _`latest documentation`: https://docs.celeryq.dev/en/latest/\n\n.. _celery-installation:\n\nInstallation\n============\n\nYou can install Celery either via the Python Package Index (PyPI)\nor from source.\n\nTo install using ``pip``:\n\n::\n\n\n    $ pip install -U Celery\n\n.. _bundles:\n\nBundles\n-------\n\nCelery also defines a group of bundles that can be used\nto install Celery and the dependencies for a given feature.\n\nYou can specify these in your requirements or on the ``pip``\ncommand-line by using brackets. Multiple bundles can be specified by\nseparating them by commas.\n\n::\n\n\n    $ pip install \"celery[redis]\"\n\n    $ pip install \"celery[redis,auth,msgpack]\"\n\nThe following bundles are available:\n\nSerializers\n~~~~~~~~~~~\n\n:``celery[auth]``:\n    for using the ``auth`` security serializer.\n\n:``celery[msgpack]``:\n    for using the msgpack serializer.\n\n:``celery[yaml]``:\n    for using the yaml serializer.\n\nConcurrency\n~~~~~~~~~~~\n\n:``celery[eventlet]``:\n    for using the ``eventlet`` pool.\n\n:``celery[gevent]``:\n    for using the ``gevent`` pool.\n\nTransports and Backends\n~~~~~~~~~~~~~~~~~~~~~~~\n\n:``celery[amqp]``:\n    for using the RabbitMQ amqp python library.\n\n:``celery[redis]``:\n    for using Redis as a message transport or as a result backend.\n\n:``celery[sqs]``:\n    for using Amazon SQS as a message transport.\n\n:``celery[tblib``]:\n    for using the ``task_remote_tracebacks`` feature.\n\n:``celery[memcache]``:\n    for using Memcached as a result backend (using ``pylibmc``)\n\n:``celery[pymemcache]``:\n    for using Memcached as a result backend (pure-Python implementation).\n\n:``celery[cassandra]``:\n    for using Apache Cassandra/Astra DB as a result backend with the DataStax driver.\n\n:``celery[azureblockblob]``:\n    for using Azure Storage as a result backend (using ``azure-storage``)\n\n:``celery[s3]``:\n    for using S3 Storage as a result backend.\n\n:``celery[gcs]``:\n    for using Google Cloud Storage as a result backend.\n\n:``celery[couchbase]``:\n    for using Couchbase as a result backend.\n\n:``celery[arangodb]``:\n    for using ArangoDB as a result backend.\n\n:``celery[elasticsearch]``:\n    for using Elasticsearch as a result backend.\n\n:``celery[riak]``:\n    for using Riak as a result backend.\n\n:``celery[cosmosdbsql]``:\n    for using Azure Cosmos DB as a result backend (using ``pydocumentdb``)\n\n:``celery[zookeeper]``:\n    for using Zookeeper as a message transport.\n\n:``celery[sqlalchemy]``:\n    for using SQLAlchemy as a result backend (*supported*).\n\n:``celery[pyro]``:\n    for using the Pyro4 message transport (*experimental*).\n\n:``celery[slmq]``:\n    for using the SoftLayer Message Queue transport (*experimental*).\n\n:``celery[consul]``:\n    for using the Consul.io Key/Value store as a message transport or result backend (*experimental*).\n\n:``celery[django]``:\n    specifies the lowest version possible for Django support.\n\n    You should probably not use this in your requirements, it's here\n    for informational purposes only.\n\n:``celery[gcpubsub]``:\n    for using Google Pub/Sub as a message transport.\n\n\n\n.. _celery-installing-from-source:\n\nDownloading and installing from source\n--------------------------------------\n\nDownload the latest version of Celery from PyPI:\n\nhttps://pypi.org/project/celery/\n\nYou can install it by doing the following:\n\n::\n\n\n    $ tar xvfz celery-0.0.0.tar.gz\n    $ cd celery-0.0.0\n    $ python setup.py build\n    # python setup.py install\n\nThe last command must be executed as a privileged user if\nyou aren't currently using a virtualenv.\n\n.. _celery-installing-from-git:\n\nUsing the development version\n-----------------------------\n\nWith pip\n~~~~~~~~\n\nThe Celery development version also requires the development\nversions of ``kombu``, ``amqp``, ``billiard``, and ``vine``.\n\nYou can install the latest snapshot of these using the following\npip commands:\n\n::\n\n\n    $ pip install https://github.com/celery/celery/zipball/main#egg=celery\n    $ pip install https://github.com/celery/billiard/zipball/main#egg=billiard\n    $ pip install https://github.com/celery/py-amqp/zipball/main#egg=amqp\n    $ pip install https://github.com/celery/kombu/zipball/main#egg=kombu\n    $ pip install https://github.com/celery/vine/zipball/main#egg=vine\n\nWith git\n~~~~~~~~\n\nPlease see the Contributing section.\n\n.. _getting-help:\n\nGetting Help\n============\n\n.. _mailing-list:\n\nMailing list\n------------\n\nFor discussions about the usage, development, and future of Celery,\nplease join the `celery-users`_ mailing list.\n\n.. _`celery-users`: https://groups.google.com/group/celery-users/\n\n.. _irc-channel:\n\nIRC\n---\n\nCome chat with us on IRC. The **#celery** channel is located at the\n`Libera Chat`_ network.\n\n.. _`Libera Chat`: https://libera.chat/\n\n.. _bug-tracker:\n\nBug tracker\n===========\n\nIf you have any suggestions, bug reports, or annoyances please report them\nto our issue tracker at https://github.com/celery/celery/issues/\n\n.. _wiki:\n\nWiki\n====\n\nhttps://github.com/celery/celery/wiki\n\nCredits\n=======\n\n.. _contributing-short:\n\nContributors\n------------\n\nThis project exists thanks to all the people who contribute. Development of\n`celery` happens at GitHub: https://github.com/celery/celery\n\nYou're highly encouraged to participate in the development\nof `celery`. If you don't like GitHub (for some reason) you're welcome\nto send regular patches.\n\nBe sure to also read the `Contributing to Celery`_ section in the\ndocumentation.\n\n.. _`Contributing to Celery`:\n    https://docs.celeryq.dev/en/stable/contributing.html\n\n|oc-contributors|\n\n.. |oc-contributors| image:: https://opencollective.com/celery/contributors.svg?width=890&button=false\n    :target: https://github.com/celery/celery/graphs/contributors\n\nBackers\n-------\n\nThank you to all our backers!  [`Become a backer`_]\n\n.. _`Become a backer`: https://opencollective.com/celery#backer\n\n|oc-backers|\n\n.. |oc-backers| image:: https://opencollective.com/celery/backers.svg?width=890\n    :target: https://opencollective.com/celery#backers\n\nSponsors\n--------\n\nSupport this project by becoming a sponsor. Your logo will show up here with a\nlink to your website. [`Become a sponsor`_]\n\n.. _`Become a sponsor`: https://opencollective.com/celery#sponsor\n\n|oc-sponsor-1| |oc-sponsor-2| |oc-sponsor-3|\n\n.. |oc-sponsor-1| image:: https://opencollective.com/celery/sponsor/0/avatar.svg\n    :target: https://opencollective.com/celery/sponsor/0/website\n\n.. |oc-sponsor-2| image:: ./docs/images/blacksmith-logo-white-on-black.svg\n    :target: https://www.blacksmith.sh/\n    :alt: Blacksmith.sh\n    :width: 240\n    :height: 57\n\n.. |oc-sponsor-3| image:: https://upstash.com/logo/upstash-dark-bg.svg\n    :target: http://upstash.com/?code=celery\n    :alt: Upstash\n    :width: 200\n    :height: 57\n\n.. _license:\n\nLicense\n=======\n\nThis software is licensed under the `New BSD License`. See the ``LICENSE``\nfile in the top distribution directory for the full license text.\n\n.. # vim: syntax=rst expandtab tabstop=4 shiftwidth=4 shiftround\n\n.. |build-status| image:: https://github.com/celery/celery/actions/workflows/python-package.yml/badge.svg\n    :alt: Build status\n    :target: https://github.com/celery/celery/actions/workflows/python-package.yml\n\n.. |coverage| image:: https://codecov.io/github/celery/celery/coverage.svg?branch=main\n    :target: https://codecov.io/github/celery/celery?branch=main\n\n.. |license| image:: https://img.shields.io/pypi/l/celery.svg\n    :alt: BSD License\n    :target: https://opensource.org/licenses/BSD-3-Clause\n\n.. |wheel| image:: https://img.shields.io/pypi/wheel/celery.svg\n    :alt: Celery can be installed via wheel\n    :target: https://pypi.org/project/celery/\n\n.. |semgrep| image:: https://img.shields.io/badge/semgrep-security-green.svg\n    :alt: Semgrep security\n    :target: https://go.semgrep.dev/home\n\n.. |pyversion| image:: https://img.shields.io/pypi/pyversions/celery.svg\n    :alt: Supported Python versions.\n    :target: https://pypi.org/project/celery/\n\n.. |pyimp| image:: https://img.shields.io/pypi/implementation/celery.svg\n    :alt: Supported Python implementations.\n    :target: https://pypi.org/project/celery/\n\n.. |ocbackerbadge| image:: https://opencollective.com/celery/backers/badge.svg\n    :alt: Backers on Open Collective\n    :target: #backers\n\n.. |ocsponsorbadge| image:: https://opencollective.com/celery/sponsors/badge.svg\n    :alt: Sponsors on Open Collective\n    :target: #sponsors\n\n.. |downloads| image:: https://pepy.tech/badge/celery\n    :alt: Downloads\n    :target: https://pepy.tech/project/celery\n",
        "num_commits": 12707,
        "project_age_days": 5667,
        "project_created_at": "2009-04-24",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 395,
        "num_pull": 3568,
        "num_issues": 8673,
        "num_opening_issue": 723,
        "project_size(kB)": 35282,
        "num_stargazers": 24776,
        "num_watchers": 24776,
        "num_forks": 4664,
        "num_subscribers": 472,
        "SecurityPolicy_created_at": "2021-11-19 05:47:26",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "458d06cb48e174ff439b55ace0104155c9fea877",
                "url": "https://github.com/celery/celery/commit/458d06cb48e174ff439b55ace0104155c9fea877",
                "date": "2023-06-18 13:54:43"
            },
            {
                "commit_id": "b7473f9cb0610c91177b8492753c24f463ea558c",
                "url": "https://github.com/celery/celery/commit/b7473f9cb0610c91177b8492753c24f463ea558c",
                "date": "2021-11-19 05:47:26"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "pylons/colander",
        "project_url": "https://github.com/pylons/colander",
        "SSF": {
            "date": "2024-10-29T23:13:25+07:00",
            "repo": {
                "name": "github.com/pylons/colander",
                "commit": "4557c017658eb4f6a5dc289078af1a6f850f3f97"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 4.9,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'main'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 2,
                    "reason": "1 out of 4 merged PRs checked by a CI test -- score normalized to 2",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 2,
                    "reason": "Found 2/10 approved changesets -- score normalized to 2",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: MIDOSS contributor org/company found, 43ravens @salishseacast @ubc-moad @midoss @swcarpentry contributor org/company found, fanstatic contributor org/company found, himaxwell contributor org/company found, Piapp contributor org/company found, zms-publishing contributor org/company found, repoze contributor org/company found, indypy contributor org/company found, aio-libs contributor org/company found, Lasagne contributor org/company found, skorch-dev contributor org/company found, pgolf contributor org/company found, knop-project contributor org/company found, clusterflunk contributor org/company found, rain.com contributor org/company found, RBINS contributor org/company found, simplistix contributor org/company found, SalishSeaCast contributor org/company found, mediadrop contributor org/company found, theasylum contributor org/company found, ito-org contributor org/company found, python contributor org/company found, python-excel contributor org/company found, Kotti contributor org/company found, collective contributor org/company found, makinacorpus contributor org/company found, LiberTIC contributor org/company found, bookalope contributor org/company found, 43ravens contributor org/company found, UBC-MOAD contributor org/company found, pyramid-collective contributor org/company found, ptahproject contributor org/company found, zopefoundation contributor org/company found, colossaldynamics contributor org/company found, usingnamespace contributor org/company found, dracut-crypt-ssh contributor org/company found, Pylons contributor org/company found, agendaless consulting contributor org/company found, clinical ink contributor org/company found, plone contributor org/company found, minitage-dependencies contributor org/company found, Mortar contributor org/company found, Supervisor contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 43 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.txt:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 1,
                    "reason": "2 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 1",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:55: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/colander/ci-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:57: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/colander/ci-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:68: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/colander/ci-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:70: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/colander/ci-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:80: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/colander/ci-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:82: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/colander/ci-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:42: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/colander/ci-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:44: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/colander/ci-tests.yml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci-tests.yml:49",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci-tests.yml:63",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci-tests.yml:75",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci-tests.yml:87",
                        "Info:   0 out of   8 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   4 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 24 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/Pylons/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/Pylons/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/Pylons/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/Pylons/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/ci-tests.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/Pylons/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\nTo report security issues with projects under the Pylons Project, send email to: pylons-project-security@googlegroups.com.\nIf we determine that your report may be a security issue with the project, we may contact you for further information.\nWe volunteers ask that you delay public disclosure of your report for at least ninety (90) days from the date you report it to us.\nThis will allow sufficient time for us to process your report and coordinate disclosure with you.\n\nOnce verified and fixed, the following steps will be taken.\n\n-   We will use GitHub's Security Advisory tool to report the issue.\n-   GitHub will review our Security Advisory report for compliance with Common Vulnerabilities and Exposures (CVE) rules.\n    If it is compliant, they will submit it to the MITRE Corporation to generate a [CVE](https://www.cve.org/).\n    This in turn submits the CVE to the [National Vulnerability Database (NVD)](https://nvd.nist.gov/vuln/search).\n    GitHub notifies us of their decision.\n-   Assuming it is compliant, we then publish our Security Advisory on GitHub, which triggers the next steps.\n-   GitHub will publish the CVE to the CVE List.\n-   GitHub will broadcast our Security Advisory via the [GitHub Advisory Database](https://github.com/advisories).\n-   GitHub will send [security alerts](https://docs.github.com/en/code-security/supply-chain-security/managing-vulnerabilities-in-your-projects-dependencies/about-alerts-for-vulnerable-dependencies) to all repositories that use our package (and have opted into security alerts).\n    This includes Dependabot alerts.\n-   We will make a bug-fix release.\n-   We will send an announcement through our usual channels, including those listed on the Pylons Project website's [Contact](https://pylonsproject.org/about-contact.html) page.\n-   We will provide credit to the reporter or researcher in the vulnerability notice.\n",
        "project_all_labels": [
            "bug",
            "dependencies",
            "docs",
            "enhancement",
            "question",
            "sprintable"
        ],
        "README_content": "Colander\n========\n\n.. image:: https://img.shields.io/pypi/v/colander.svg\n    :target: https://pypi.python.org/pypi/colander\n\n.. image:: https://github.com/Pylons/colander/actions/workflows/ci-tests.yml/badge.svg?branch=main\n    :target: https://github.com/Pylons/colander/actions/workflows/ci-tests.yml?query=branch%3Amain\n\n.. image:: https://readthedocs.org/projects/colander/badge/?version=latest\n    :target: https://readthedocs.org/projects/colander/?badge=latest\n    :alt: Documentation Status\n\nAn extensible package which can be used to:\n\n- deserialize and validate a data structure composed of strings,\n  mappings, and lists.\n\n- serialize an arbitrary data structure to a data structure composed\n  of strings, mappings, and lists.\n\nIt is tested on Python 3.7, 3.8, 3.9, 3.10, and 3.11, and PyPy 3.8.\n\nPlease see https://docs.pylonsproject.org/projects/colander/en/latest/\nfor documentation.\n\nSee https://github.com/Pylons/colander for in-development version.\n",
        "num_commits": 1082,
        "project_age_days": 5004,
        "project_created_at": "2011-02-16",
        "latest_updated_at": "2024-10-25",
        "latest_pushed_at": "2024-08-15",
        "num_contributors": 87,
        "num_pull": 228,
        "num_issues": 366,
        "num_opening_issue": 34,
        "project_size(kB)": 2268,
        "num_stargazers": 449,
        "num_watchers": 449,
        "num_forks": 145,
        "num_subscribers": 28,
        "SecurityPolicy_created_at": "2022-03-13 08:20:20",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "ab14abef44c69ff35e9b9cc58379a8c97c71eaf8",
                "url": "https://github.com/Pylons/.github/commit/ab14abef44c69ff35e9b9cc58379a8c97c71eaf8",
                "date": "2022-03-17 01:20:43"
            },
            {
                "commit_id": "a066e581a373c17e7a9ce58b215b2308272c940e",
                "url": "https://github.com/Pylons/.github/commit/a066e581a373c17e7a9ce58b215b2308272c940e",
                "date": "2022-03-16 05:35:12"
            },
            {
                "commit_id": "ce347b2da70eae5aad5c99c563e7835df4addb31",
                "url": "https://github.com/Pylons/.github/commit/ce347b2da70eae5aad5c99c563e7835df4addb31",
                "date": "2022-03-13 08:20:20"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": false
    },
    {
        "project_name": "sh4nks/flask-caching",
        "project_url": "https://github.com/sh4nks/flask-caching",
        "SSF": {
            "date": "2024-10-29T23:52:53+07:00",
            "repo": {
                "name": "github.com/sh4nks/flask-caching",
                "commit": "494d49882537a6cbcfe3cb41c4df05ae8acf60ce"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.1,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'master'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 7,
                    "reason": "23 out of 30 merged PRs checked by a CI test -- score normalized to 7",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 5,
                    "reason": "Found 9/16 approved changesets -- score normalized to 5",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: pallets-eco contributor org/company found, lens contributor org/company found, msgpack contributor org/company found, fluent contributor org/company found, pytest-dev contributor org/company found, tractian contributor org/company found, atlassian contributor org/company found, KLab contributor org/company found, go-sql-driver contributor org/company found, deutsche telekom ag @telekom contributor org/company found, flaskbb contributor org/company found, benchmark.games contributor org/company found, PyMySQL contributor org/company found, klab inc contributor org/company found, requests contributor org/company found, python contributor org/company found, Homebrew contributor org/company found, lektor contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 18 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "0 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 0",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/lock.yaml:11: update your workflow using https://app.stepsecurity.io/secureworkflow/pallets-eco/flask-caching/lock.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/pallets-eco/flask-caching/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/pallets-eco/flask-caching/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:52: update your workflow using https://app.stepsecurity.io/secureworkflow/pallets-eco/flask-caching/tests.yml/master?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:45",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:46",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:47",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:57",
                        "Info:   0 out of   3 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   4 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/pallets-eco/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/pallets-eco/.github/SECURITY.md:1",
                        "Warn: One or no descriptive hints of disclosure, vulnerability, and/or timelines in security policy",
                        "Info: Found text in security policy: github.com/pallets-eco/.github/SECURITY.md:1"
                    ],
                    "score": 9,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/lock.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/tests.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/pallets-eco/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\nIf you believe you have identified a security issue with a Pallets-Eco project,\n**do not open a public issue**. To responsibly report a security issue, use\nGitHub's [security advisory system][gh-docs]. From the project's repository,\nclick \"Security\" at the top, then click \"Advisories\" at the left, then click the\ngreen \"New draft security advisory\" button. Alternatively, you may email\n[security@palletsprojects.com](mailto:security@palletsprojects.com), and we will\nconvert that to a GitHub security advisory.\n\nBe sure to include as much detail as necessary in your report. As with reporting\nnormal issues, a minimal reproducible example will help the maintainers address\nthe issue faster. Information about why the issue is a security issue is also\nhelpful. If you are able, you may also provide a fix for the issue.\n\nA maintainer will reply acknowledging the report and how to continue. We will\nobtain a CVE id as well, please do not do this on your own. We will work with\nyou to attempt to understand the issue and decide on its validity. Maintainers\nare volunteers working in their free time, and therefore cannot guarantee any\nspecific timeline. Please be patient during this process.\n\nThe current feature release will receive security fixes. Fixes to older versions\nmay be considered based on usage information and severity, but are not\nguaranteed. After fixing an issue, we will make a new release.\n\n[gh-docs]: https://docs.github.com/en/code-security/security-advisories/working-with-repository-security-advisories/creating-a-repository-security-advisory\n",
        "project_all_labels": [
            "awaiting response",
            "backend",
            "bug",
            "cachelib integration",
            "dependencies",
            "documentation",
            "duplicate",
            "enhancement",
            "good first issue",
            "help wanted",
            "invalid",
            "needs info",
            "no response",
            "question",
            "release",
            "stale",
            "wontfix"
        ],
        "README_content": "Flask-Caching\n=============\n\nA fork of the `Flask-cache`_ extension which adds easy cache support to Flask.\n\n.. _Flask-cache: https://github.com/thadeusb/flask-cache\n\n\nInstalling\n----------\n\nInstall and update using `pip`_:\n\n.. code-block:: text\n\n    $ pip install -U flask-caching\n\n.. _pip: https://pip.pypa.io/en/stable/getting-started/\n\n\nDonate\n------\n\nThe Pallets organization develops and supports Flask and the libraries\nit uses. In order to grow the community of contributors and users, and\nallow the maintainers to devote more time to the projects, `please\ndonate today`_.\n\n.. _please donate today: https://palletsprojects.com/donate\n\n\nLinks\n-----\n\n-   Documentation: https://flask-caching.readthedocs.io\n-   Changes: https://flask-caching.readthedocs.io/en/latest/changelog.html\n-   PyPI Releases: https://pypi.org/project/Flask-Caching/\n-   Source Code: https://github.com/pallets-eco/flask-caching\n-   Issue Tracker: https://github.com/pallets-eco/flask-caching/issues\n-   Twitter: https://twitter.com/PalletsTeam\n-   Chat: https://discord.gg/pallets\n",
        "num_commits": 755,
        "project_age_days": 3039,
        "project_created_at": "2016-07-04",
        "latest_updated_at": "2024-10-13",
        "latest_pushed_at": "2024-08-01",
        "num_contributors": 96,
        "num_pull": 342,
        "num_issues": 578,
        "num_opening_issue": 77,
        "project_size(kB)": 1090,
        "num_stargazers": 894,
        "num_watchers": 894,
        "num_forks": 194,
        "num_subscribers": 17,
        "SecurityPolicy_created_at": "2024-02-09 20:30:27",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "694b7027e532f049c3c2e305f101af5eeae51af3",
                "url": "https://github.com/pallets-eco/.github/commit/694b7027e532f049c3c2e305f101af5eeae51af3",
                "date": "2024-02-09 20:30:27"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email_advisory",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "materialsproject/pymatgen",
        "project_url": "https://github.com/materialsproject/pymatgen",
        "SSF": {
            "date": "2024-10-29T21:07:27+07:00",
            "repo": {
                "name": "github.com/materialsproject/pymatgen",
                "commit": "77195153effda5dc97e28a47507ab64a52246ffb"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 7.0,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: branch 'master' does not require approvers",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Info: status check found to merge onto on branch 'master'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "7 out of 7 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 2,
                    "reason": "Found 6/29 approved changesets -- score normalized to 2",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: Lee-Group contributor org/company found, lawrence berkeley national lab contributor org/company found, Quantum-Accelerators contributor org/company found, abinit contributor org/company found, hackingmaterials contributor org/company found, princeton university contributor org/company found, BlauGroup contributor org/company found, lawrence berkeley lab contributor org/company found, university of stuttgart contributor org/company found, SMTG-Bham contributor org/company found, materialsproject contributor org/company found, sbsev contributor org/company found, KingsburyLab contributor org/company found, microsoft quantum contributor org/company found, virtualatoms contributor org/company found, humboldt-universitt zu berlin contributor org/company found, radical-ai contributor org/company found, materials virtual lab contributor org/company found, univ catholique de louvain contributor org/company found, imec contributor org/company found, microsoftresearch contributor org/company found, radical ai contributor org/company found, federal institute for materials research and testing contributor org/company found, henniggroup contributor org/company found, coreacter carnegie mellon university contributor org/company found, lbnl contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 26 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: :0"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 6 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/release.yml:65"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/issue-metrics.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/materialsproject/pymatgen/issue-metrics.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/issue-metrics.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/materialsproject/pymatgen/issue-metrics.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/jekyll-gh-pages.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/materialsproject/pymatgen/jekyll-gh-pages.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/jekyll-gh-pages.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/materialsproject/pymatgen/jekyll-gh-pages.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/jekyll-gh-pages.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/materialsproject/pymatgen/jekyll-gh-pages.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/jekyll-gh-pages.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/materialsproject/pymatgen/jekyll-gh-pages.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/jekyll-gh-pages.yml:50: update your workflow using https://app.stepsecurity.io/secureworkflow/materialsproject/pymatgen/jekyll-gh-pages.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/materialsproject/pymatgen/lint.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/materialsproject/pymatgen/lint.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/materialsproject/pymatgen/release.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/materialsproject/pymatgen/release.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/materialsproject/pymatgen/release.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:52: update your workflow using https://app.stepsecurity.io/secureworkflow/materialsproject/pymatgen/release.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release.yml:55: update your workflow using https://app.stepsecurity.io/secureworkflow/materialsproject/pymatgen/release.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:60: update your workflow using https://app.stepsecurity.io/secureworkflow/materialsproject/pymatgen/release.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:73: update your workflow using https://app.stepsecurity.io/secureworkflow/materialsproject/pymatgen/release.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:78: update your workflow using https://app.stepsecurity.io/secureworkflow/materialsproject/pymatgen/release.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release.yml:85: update your workflow using https://app.stepsecurity.io/secureworkflow/materialsproject/pymatgen/release.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:62: update your workflow using https://app.stepsecurity.io/secureworkflow/materialsproject/pymatgen/test.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:65: update your workflow using https://app.stepsecurity.io/secureworkflow/materialsproject/pymatgen/test.yml/master?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint.yml:25",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release.yml:36",
                        "Info:   0 out of  16 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   4 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   2 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 1 commits out of 7 are checked with a SAST tool"
                    ],
                    "score": 1,
                    "reason": "SAST tool is not run on all commits -- score normalized to 1",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'pull-requests' permission set to 'read': .github/workflows/issue-metrics.yml:18",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/issue-metrics.yml:8",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/jekyll-gh-pages.yml:10",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/lint.yml:10",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/release.yml:15",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/test.yml:16",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 10,
                    "reason": "GitHub workflow tokens follow principle of least privilege",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-248v-346w-9cwc"
                    ],
                    "score": 9,
                    "reason": "1 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/materialsproject/pymatgen/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nWe only provide active support for the [latest release](https://pypi.org/project/pymatgen).\n\n## Reporting a Vulnerability\n\nPlease submit any vulnerabilities or bug reports via [GitHub private vulnerability reporting](https://github.com/materialsproject/pymatgen/security/advisories/new).\n\n## Previously Known Vulnerabilities\n\n* [CVE-2024-23346](https://github.com/materialsproject/pymatgen/security/advisories/GHSA-vgv8-5cpj-qj2f)\n",
        "project_all_labels": [
            "analysis",
            "api",
            "ase",
            "awaiting user",
            "best practice",
            "breaking",
            "bug",
            "charge",
            "ci",
            "cif",
            "cli",
            "compatability",
            "contributing",
            "core",
            "cp2k",
            "critical",
            "cython",
            "data viz",
            "dependencies",
            "deprecation",
            "discussion",
            "docs",
            "duplicate",
            "dx",
            "ecosystem",
            "electronic structure",
            "enhancement",
            "ext",
            "feature",
            "feature request",
            "fix",
            "github actions",
            "good first issue",
            "hash",
            "help",
            "help wanted",
            "housekeeping",
            "imports",
            "install",
            "invalid",
            "io",
            "lammps",
            "license",
            "linting",
            "linux",
            "lobster",
            "magmoms",
            "md",
            "memory",
            "mixing-schemes",
            "ml",
            "molecules",
            "needs discussion",
            "needs file dedup",
            "needs investigation",
            "needs repro",
            "needs testing",
            "nn",
            "out of scope",
            "outdated",
            "performance",
            "phonon",
            "pkg",
            "provenance",
            "python",
            "qchem",
            "question",
            "refactor",
            "release",
            "ruby",
            "security",
            "serialization",
            "stale",
            "surfaces",
            "symmetry",
            "tests",
            "trafos",
            "types",
            "upstream",
            "urgent",
            "ux",
            "vasp",
            "windows",
            "wip",
            "wont fix"
        ],
        "README_content": "<h1 align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/materialsproject/pymatgen/raw/master/docs/assets/pymatgen-white.svg\">\n    <img alt=\"Logo\" src=\"https://github.com/materialsproject/pymatgen/raw/master/docs/assets/pymatgen.svg\"\nheight=\"70\">\n  </picture>\n</h1>\n\n<h4 align=\"center\">\n\n[![CI Status](https://github.com/materialsproject/pymatgen/actions/workflows/test.yml/badge.svg)](https://github.com/materialsproject/pymatgen/actions/workflows/test.yml)\n[![codecov](https://codecov.io/gh/materialsproject/pymatgen/branch/master/graph/badge.svg?token=XC47Un1LV2)](https://codecov.io/gh/materialsproject/pymatgen)\n[![PyPI Downloads](https://img.shields.io/pypi/dm/pymatgen?logo=pypi&logoColor=white&color=blue&label=PyPI)](https://pypi.org/project/pymatgen)\n[![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/pymatgen?logo=condaforge&color=blue&label=Conda)](https://anaconda.org/conda-forge/pymatgen)\n[![Requires Python 3.10+](https://img.shields.io/badge/Python-3.10+-blue.svg?logo=python&logoColor=white)](https://python.org/downloads)\n[![Paper](https://img.shields.io/badge/J.ComMatSci-2012.10.028-blue?logo=elsevier&logoColor=white)](https://doi.org/10.1016/j.commatsci.2012.10.028)\n\n</h4>\n\nPymatgen (Python Materials Genomics) is a robust, open-source Python\nlibrary for materials analysis. These are some of the main features:\n\n1. Highly flexible classes for the representation of `Element`, `Site`, `Molecule` and `Structure` objects.\n2. Extensive input/output support, including support for [VASP](https://cms.mpi.univie.ac.at/vasp), [ABINIT](https://abinit.org), [CIF](https://wikipedia.org/wiki/Crystallographic_Information_File), [Gaussian](https://gaussian.com), [XYZ](https://wikipedia.org/wiki/XYZ_file_format), and many other file formats.\n3. Powerful analysis tools, including generation of phase diagrams, Pourbaix diagrams, diffusion analyses, reactions, etc.\n4. Electronic structure analyses, such as density of states and band structure.\n5. Integration with the [Materials Project] REST API.\n\nPymatgen is free to use. However, we also welcome your help to improve this library by making your contributions. These contributions can be in the form of additional tools or modules you develop, or feature requests and bug reports. The following are resources for `pymatgen`:\n\n- [Official documentation][`pymatgen` docs]\n- Bug reports or feature requests: Please submit a [GitHub issue].\n- Code contributions via [pull request] are welcome.\n- For questions that are not bugs or feature requests, please use the `pymatgen` [MatSci forum](https://matsci.org/pymatgen) or open a [GitHub discussion].\n- [`matgenb`](https://github.com/materialsvirtuallab/matgenb#introduction) provides some example Jupyter notebooks that demonstrate how to use `pymatgen` functionality.\n\n[pull request]: https://github.com/materialsproject/pymatgen/pulls\n[github issue]: https://github.com/materialsproject/pymatgen/issues\n[github discussion]: https://github.com/materialsproject/pymatgen/discussions\n\n## Why use `pymatgen`?\n\n1. **It is (fairly) robust.** Pymatgen is used by thousands of researchers and is the analysis code powering the [Materials Project]. The analysis it produces survives rigorous scrutiny every single day. Bugs tend to be found and corrected quickly. Pymatgen also uses Github Actions for continuous integration, which ensures that every new code passes a comprehensive suite of unit tests.\n2. **It is well documented.** A fairly comprehensive documentation has been written to help you get to grips with it quickly.\n3. **It is open.** You are free to use and contribute to `pymatgen`. It also means that `pymatgen` is continuously being improved. We will attribute any code you contribute to any publication you specify. Contributing to `pymatgen` means your research becomes more visible, which translates to greater impact.\n4. **It is fast.** Many of the core numerical methods in `pymatgen` have been optimized by vectorizing in `numpy`/`scipy`. This means that coordinate manipulations are fast. Pymatgen also comes with a complete system for handling periodic boundary conditions.\n5. **It will be around.** Pymatgen is not a pet research project. It is used in the well-established Materials Project. It is also actively being developed and maintained by the [Materials Virtual Lab], the ABINIT group and many other research groups.\n6. **A growing ecosystem of developers and add-ons**. Pymatgen has contributions from materials scientists all over the world. We also now have an architecture to support add-ons that expand `pymatgen`'s functionality even further. Check out the [contributing page](https://pymatgen.org/contributing) and [add-ons page](https://pymatgen.org/addons) for details and examples.\n\n## Installation\n\nThe version at the Python Package Index [PyPI] is always the latest stable release that is relatively bug-free and can be installed via `pip`:\n\n[pypi]: https://pypi.org/project/pymatgen\n\n```sh\npip install pymatgen\n```\n\nIf you'd like to use the latest unreleased changes on the main branch, you can install directly from GitHub:\n\n```sh\npip install -U git+https://github.com/materialsproject/pymatgen\n```\n\nThe minimum Python version is 3.10. Some extra functionality (e.g., generation of POTCARs) does require additional setup (see the [`pymatgen` docs]).\n\n## Change Log\n\nSee [GitHub releases](https://github.com/materialsproject/pymatgen/releases), [`docs/CHANGES.md`](docs/CHANGES.md) or [commit history](https://github.com/materialsproject/pymatgen/commits/master) in increasing order of details.\n\n## Using pymatgen\n\nPlease refer to the official [`pymatgen` docs] for tutorials and examples.\n\n## How to cite pymatgen\n\nIf you use `pymatgen` in your research, please consider citing the following work:\n\n> Shyue Ping Ong, William Davidson Richards, Anubhav Jain, Geoffroy\n> Hautier, Michael Kocher, Shreyas Cholia, Dan Gunter, Vincent Chevrier,\n> Kristin A. Persson, Gerbrand Ceder. *Python Materials Genomics\n> (pymatgen): A Robust, Open-Source Python Library for Materials\n> Analysis.* Computational Materials Science, 2013, 68, 314-319.\n> [doi:10.1016/j.commatsci.2012.10.028](https://doi.org/10.1016/j.commatsci.2012.10.028)\n\nIn addition, some of `pymatgen`'s functionality is based on scientific advances/principles developed by the computational materials scientists in our team. Please refer to the [`pymatgen` docs] on how to cite them.\n\n### Soliciting contributions to 2nd `pymatgen` paper\n\nIf you are a long-standing `pymatgen` contributor and would like to be involved in working on an updated `pymatgen` publication,\nplease fill out this [co-author registration form](https://docs.google.com/forms/d/e/1FAIpQLSecIhD2YjdPGldrRTM8Go3VxVg_vjKjZAOXtIKDG7qckHLYaQ/viewform) or contact [@shyuep, @mkhorton and @janosh](mailto:ongsp@ucsd.edu,m.k.horton@gmail.com,janosh@lbl.gov?subject=Contributing%20to%20updated%20pymatgen%20paper) with questions.\n\n## License\n\nPymatgen is released under the MIT License. The terms of the license are as follows:\n\n> The MIT License (MIT) Copyright (c) 2011-2012 MIT & LBNL\n>\n> Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n>\n> The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n>\n> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n## About the Pymatgen Development Team\n\nShyue Ping Ong (@shyuep) of the [Materials Virtual Lab] started Pymatgen in 2011 and is still the project lead.\nJanosh Riebesell (@janosh) and Matthew Horton (@mkhorton) are co-maintainers.\n\nThe [`pymatgen` development team] is the set of all contributors to the `pymatgen` project, including all subprojects.\n\n## Our Copyright Policy\n\nPymatgen uses a shared copyright model. Each contributor maintains copyright over their contributions to `pymatgen`. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the `pymatgen` source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire [`pymatgen` Development Team]. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the `pymatgen` repositories.\n\n[`pymatgen` docs]: https://pymatgen.org\n[materials project]: https://materialsproject.org\n[`pymatgen` development team]: https://pymatgen.org/team\n[materials virtual lab]: https://materialsvirtuallab.org\n",
        "num_commits": 25725,
        "project_age_days": 4755,
        "project_created_at": "2011-10-23",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 248,
        "num_pull": 2704,
        "num_issues": 4048,
        "num_opening_issue": 211,
        "project_size(kB)": 1077344,
        "num_stargazers": 1505,
        "num_watchers": 1505,
        "num_forks": 864,
        "num_subscribers": 111,
        "SecurityPolicy_created_at": "2020-08-19 19:57:47",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "ae36a842229d0245672457f4d3a30632f967a2b5",
                "url": "https://github.com/materialsproject/pymatgen/commit/ae36a842229d0245672457f4d3a30632f967a2b5",
                "date": "2024-02-21 15:51:08"
            },
            {
                "commit_id": "ca94c306b320d6b7c885d614c4e16150647968f9",
                "url": "https://github.com/materialsproject/pymatgen/commit/ca94c306b320d6b7c885d614c4e16150647968f9",
                "date": "2024-02-21 15:49:20"
            },
            {
                "commit_id": "7c1d780148019e9d62e96a44991300f3b703b49d",
                "url": "https://github.com/materialsproject/pymatgen/commit/7c1d780148019e9d62e96a44991300f3b703b49d",
                "date": "2023-08-02 20:07:42"
            },
            {
                "commit_id": "3efc25bca68ce381ba21fedf5578f1d40c50878c",
                "url": "https://github.com/materialsproject/pymatgen/commit/3efc25bca68ce381ba21fedf5578f1d40c50878c",
                "date": "2020-08-19 19:57:47"
            }
        ],
        "project_security_labels": [
            "security"
        ],
        "security_issues": [
            {
                "url": "https://github.com/materialsproject/pymatgen/pull/4021",
                "title": "Replace HTTP URLs with HTTPS, avoid `from pytest import raises/mark`",
                "labels": [
                    "docs",
                    "security"
                ],
                "user": "DanielYang59",
                "issue_author_association": "CONTRIBUTOR",
                "number": 4021,
                "id": 2492056599,
                "state": "closed",
                "project_created_at": "2024-08-28T13:17:33Z",
                "closed_at": "2024-08-30T06:01:32Z",
                "body": "### Summary\r\n\r\n- Replace HTTP URLs with HTTPS\r\n- Replace some expired URLs\r\n- Avoid `from pytest import raises/mark` (a bit unsure about `MonkeyPatch` so just use `pytest.MonkeyPatch` if `pytest` is already imported)\r\n- [ ] Regenerate documents",
                "comments": [
                    {
                        "body": "@janosh  Please review this. Looks like we might need to regenerate docs, thanks!\r\n\r\nI reverted the rebuild doc commit because it makes it impossible to review. Would let you do this, appreciate that!",
                        "user": "DanielYang59",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-08-28T13:50:45Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/4021#issuecomment-2315377467"
                    },
                    {
                        "body": "Currently on my phone. Could you apply the docs commit again?",
                        "user": "janosh",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-08-28T14:23:20Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/4021#issuecomment-2315483070"
                    },
                    {
                        "body": "> ideally, we should have a link checker CI [similar to pymativz](https://github.com/janosh/pymatviz/blob/1de350a146b53ae03f343ff9a78454ba7c976186/.github/workflows/link-check.yml) to make sure all the new (and old links) are actually still alive. but i'm happy to leave that to a future PR. maybe something to open an issue for so it's not forgotton\r\n\r\nWonderful. Added to my TODO list (which is not very long at this moment :) ). I would need some investigation on that because [markdown-link-check](https://github.com/tcort/markdown-link-check) seemingly just check markdown files.\r\n\r\nCan you regenerate documents after reviewing? Thanks!",
                        "user": "DanielYang59",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-08-30T05:42:53Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/4021#issuecomment-2320124649"
                    },
                    {
                        "body": "@DanielYang59 do you want to reapply the docs update commit before i merge?",
                        "user": "janosh",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-08-30T05:49:56Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/4021#issuecomment-2320135991"
                    },
                    {
                        "body": "@janosh certainly, got two warnings at the start, not sure if we should worry about that or not (it seems `favicon.ico` and `html_static_path = [\"assets\"]` don't exist?):\r\n```\r\n>>> invoke make-doc\r\nrm: pymatgen.*.rst: No such file or directory\r\nRunning Sphinx v7.4.7\r\nloading translations [en]... done\r\nmaking output directory... done\r\nWARNING: html_static_path entry 'assets' does not exist\r\nWARNING: favicon file 'favicon.ico' does not exist\r\nConverting `source_suffix = '.rst'` to `source_suffix = {'.rst': 'restructuredtext'}`.\r\nbuilding [mo]: targets for 0 po files that are out of date\r\nwriting output... \r\nbuilding [html]: targets for 49 source files that are out of date\r\nupdating environment: [new config] 49 added, 0 changed, 0 removed\r\n```",
                        "user": "DanielYang59",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-08-30T05:55:25Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/4021#issuecomment-2320145018"
                    },
                    {
                        "body": "> @janosh certainly, got two warnings at the start, not sure if we should worry about that or not (it seems favicon.ico and html_static_path = [\"assets\"] don't exist?):\r\n\r\nsafe to ignore for now. the docs need some more work at some point but that would be a bigger project",
                        "user": "janosh",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-08-30T06:01:18Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/4021#issuecomment-2320156329"
                    },
                    {
                        "body": "Great to know! Thanks.",
                        "user": "DanielYang59",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-08-30T06:03:38Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/4021#issuecomment-2320161208"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/materialsproject/pymatgen/pulls/4021",
                    "merged_at": "2024-08-30T06:01:32Z"
                }
            },
            {
                "url": "https://github.com/materialsproject/pymatgen/issues/4016",
                "title": "[Dev] Remove `mysql` dependency from `ext.cod` and fix S608",
                "labels": [
                    "security",
                    "help wanted",
                    "ext"
                ],
                "user": "DanielYang59",
                "issue_author_association": "CONTRIBUTOR",
                "number": 4016,
                "id": 2485718242,
                "state": "closed",
                "project_created_at": "2024-08-26T02:36:09Z",
                "closed_at": "2024-09-09T21:09:43Z",
                "body": "- Resolve following `mysql` dependency issue: https://github.com/materialsproject/pymatgen/blob/41e4c69911f2b724734e0917c436ee5a1de63091/src/pymatgen/ext/cod.py#L70\r\n- Also need to fix two `S608` violations (SQL injection): https://github.com/materialsproject/pymatgen/blob/41e4c69911f2b724734e0917c436ee5a1de63091/src/pymatgen/ext/cod.py#L73\r\n https://github.com/materialsproject/pymatgen/blob/41e4c69911f2b724734e0917c436ee5a1de63091/src/pymatgen/ext/cod.py#L109\r\n\r\nHelp needed.\r\n",
                "comments": [
                    {
                        "body": "> * Resolve following `mysql` dependency issue:\r\n\r\ni think `mysql` can be replaced with https://pypi.org/project/mysqlclient (based on [the advice here](https://pypi.org/project/mysql/))",
                        "user": "janosh",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-09-06T22:40:49Z",
                        "url": "https://github.com/materialsproject/pymatgen/issues/4016#issuecomment-2334905410"
                    },
                    {
                        "body": "Why bother? This is a small feature within pymatgen and we probably can count on a few fingers the number of people who use it. Those who use it can install mysql. In fact, the onus should be on COD to offer a REST API rather than an SQL one. Pls focus efforts on more impactful changes.",
                        "user": "shyuep",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-09-09T21:09:43Z",
                        "url": "https://github.com/materialsproject/pymatgen/issues/4016#issuecomment-2339095635"
                    },
                    {
                        "body": "> This is a small feature within pymatgen and we probably can count on a few fingers the number of people who use it. Those who use it can install mysql.\r\n\r\nThat's true, I posted this in case someone who need to use SQL might be interested to take over and fix this?\r\n\r\n> Pls focus efforts on more impactful changes.\r\n\r\nThat's the reason I opened this instead of fixing it myself. Can we reopen this? This looks like a good first issue if anyone is interested in getting involved in open source.\r\n\r\n\r\n",
                        "user": "DanielYang59",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-09-10T01:10:26Z",
                        "url": "https://github.com/materialsproject/pymatgen/issues/4016#issuecomment-2339416915"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/materialsproject/pymatgen/pull/3739",
                "title": "Avoid using `eval`, replace manual offset in `enumerate` and rename single letter variables",
                "labels": [
                    "linting",
                    "security"
                ],
                "user": "DanielYang59",
                "issue_author_association": "CONTRIBUTOR",
                "number": 3739,
                "id": 2229650014,
                "state": "closed",
                "project_created_at": "2024-04-07T09:22:07Z",
                "closed_at": "2024-04-07T10:51:29Z",
                "body": "## Summary\r\n\r\n- Replace `eval` with safer alternatives\r\n- Replace manual offset in `enumerate` with the `start` argument\r\n- Minor format tweaks\r\n",
                "comments": [
                    {
                        "body": "<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- This is an auto-generated comment: skip review by coderabbit.ai -->\n\n> [!IMPORTANT]\n> ## Auto Review Skipped\n> \n> More than 25% of the files skipped due to max files limit. The review is being skipped to prevent a low-quality review.\n> \n> 26 files out of 83 files are above the max files limit of 50. Please upgrade to Pro plan to get higher limits.\n\n<!-- end of auto-generated comment: skip review by coderabbit.ai --><!-- walkthrough_start -->\n\n## Walkthrough\n\nThe recent updates across various components of the pymatgen library focus on enhancing code safety, efficiency, and readability. Notable improvements include the optimization of loop logic and conditionals, safer handling of dynamic expressions, and more precise and clear documentation. These changes collectively aim to refine the library's usability and maintainability, ensuring it remains a robust tool for materials science research.\n\n## Changes\n\n| Files                             | Summary                                                                                                                                                      |\n|-----------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `.../analysis/magnetism/heisenberg.py` | - Adjusted loop logic and conditionals<br>- Simplified filename condition<br>- Optimized energy rounding and duplicate removal<br>- Replaced `eval` with `literal_eval` |\n| `.../electronic_structure/boltztrap2.py` | - Unified `dosweight` assignment based on spin polarization<br>- Simplified `structure` assignment<br>- Refined calculation and property access methods       |\n| `.../io/vasp/inputs.py`           | - Changed parameter type comparison and assignment methods<br>- Removed integer value handling for hashing<br>- Updated docstring for clarity                  |\n\n>   \n> In the realm of pymatgen, where atoms dance,  \n> CodeRabbit hopped through, improving at a glance.  \n> Loops were tightened, and safety enhanced,  \n> With every line, the code advanced.  \n> 'Twas a leap for science, in every stance.  \n> \n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: raw summary by coderabbit.ai -->\n<!--\n\n\npymatgen/analysis/magnetism/heisenberg.py: ## Short summary\n\n- In the `_get_nn_dict` method, the loop logic was adjusted to start from index 1 and compare the current element with the next one.\n- In the `get_interaction_graph` method, the condition for adding \".json\" to the filename was simplified.\n- In the `_do_cleanup` method, the tolerance value for energy rounding was moved outside the loop, and the condition for removing duplicates was simplified.\n- In the `from_dict` class method, the use of `eval` was replaced with `literal_eval` for safety.\n\n---\n\npymatgen/electronic_structure/boltztrap2.py: ## Short summary\n\n- Consolidated the assignment of `dosweight` based on `is_spin_polarized`.\n- Simplified conditional assignment for `structure`.\n- Refactored the calculation of `h` in `bandana` method.\n- Updated the assignment of `dosweight` based on `is_spin_polarized`.\n- Modified property access in `plot_props` method.\n\n---\n\npymatgen/io/vasp/inputs.py: ## Short summary\n\n- In the `check_params` method, the comparison for parameter type has been changed to use `type(val).__name__` instead of `isinstance`.\n- In the `from_str` method, the assignment of `m` has been changed to use the walrus operator `:=`.\n- In the `md5_header_hash` method, the handling of integer values for hashing has been removed.\n- The docstring for the `__iter__` method in the `Potcar` class has been updated for clarity.\n\n-->\n<!-- end of auto-generated comment: raw summary by coderabbit.ai --><!-- This is an auto-generated comment: short summary by coderabbit.ai -->\n<!--\n\n\n### PR Objectives\n\nThe primary objective of Pull Request (PR) #3739 is to enhance the security and maintainability of the codebase by eliminating the use of the `eval` function, which is known for its potential security vulnerabilities. Instead, safer alternatives are employed to achieve the same functionality without compromising security. This PR encompasses modifications across several files within the project, specifically targeting areas where `eval` was previously used and replacing it with `literal_eval` or other safer methods. Additionally, the PR introduces minor formatting tweaks to improve the readability and consistency of the code. These changes span across multiple modules, including `pymatgen/analysis/magnetism/heisenberg.py`, `pymatgen/electronic_structure/boltztrap2.py`, and `pymatgen/io/vasp/inputs.py`, indicating a broad and impactful set of improvements aimed at enhancing the code's overall quality and security posture.\n\n### AI-generated Summary of Generated Summaries\n\nThe Pull Request introduces several key changes across different modules to improve security, readability, and efficiency. Notably, the unsafe `eval` function has been replaced with `literal_eval` in the `from_dict` class method within `pymatgen/analysis/magnetism/heisenberg.py`, directly addressing the primary objective of enhancing security. This module also sees adjustments in loop logic, condition simplifications, and the optimization of tolerance value handling and duplicate removals, contributing to cleaner and more efficient code.\n\nIn `pymatgen/electronic_structure/boltztrap2.py`, the changes focus on refining the logic related to spin polarization and structural assignments, alongside methodological refinements in property access and calculation processes. These modifications streamline the handling of spin-polarized calculations and improve the clarity and performance of property plotting and band analysis methods.\n\nThe `pymatgen/io/vasp/inputs.py` module experiences enhancements in parameter type checking, utilizing the walrus operator for more concise assignment operations, and the removal of unnecessary integer value handling for hashing. Additionally, the documentation for the `__iter__` method in the `Potcar` class has been clarified, aiding in better understanding and usage of the method.\n\nCollectively, these changes across the three modules not only address the critical security concerns associated with the use of `eval` but also introduce several optimizations and clarifications that contribute to the overall maintainability, readability, and efficiency of the codebase. The PR effectively moves the project away from potentially hazardous practices while streamlining various aspects of the code, demonstrating a comprehensive approach to improving the project's quality and security.\n\n-->\n<!-- end of auto-generated comment: short summary by coderabbit.ai --><!-- commit_ids_reviewed_start -->\n\n<!-- 5ca3aff1b81589ca37b03279f1cf6a3f716a4085 -->\n\n<!-- commit_ids_reviewed_end --><!-- tweet_start -->\n\nThank you for using CodeRabbit. We offer it for free to the OSS community and would appreciate your support in helping us grow. If you find it useful, would you consider giving us a shout-out on your favorite social media?\n\n<details>\n<summary>Share</summary>\n\n- [X](https://twitter.com/intent/tweet?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A&url=https%3A//coderabbit.ai)\n- [Mastodon](https://mastodon.social/share?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A%20https%3A%2F%2Fcoderabbit.ai)\n- [Reddit](https://www.reddit.com/submit?title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&text=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code.%20Check%20it%20out%3A%20https%3A//coderabbit.ai)\n- [LinkedIn](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcoderabbit.ai&mini=true&title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&summary=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code)\n\n</details>\n\n<!-- tweet_end --><!-- tips_start -->\n\n---\n\n<details>\n<summary>Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n- Review comments: Directly reply to a review comment made by CodeRabbit. Example:\n\t- `I pushed a fix in commit <commit_id>.`\n\t- `Generate unit testing code for this file.`\n\t- `Open a follow-up GitHub issue for this discussion.`\n- Files and specific lines of code (under the \"Files changed\" tab): Tag `@coderabbitai` in a new review comment at the desired location with your query. Examples:\n\t- `@coderabbitai generate unit testing code for this file.`\n\t-\t`@coderabbitai modularize this function.`\n- PR comments: Tag `@coderabbitai` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n\t- `@coderabbitai generate interesting stats about this repository and render them as a table.`\n\t- `@coderabbitai show all the console.log statements in this repository.`\n\t- `@coderabbitai read src/utils.ts and generate unit testing code.`\n\t- `@coderabbitai read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (invoked as PR comments)\n\n- `@coderabbitai pause` to pause the reviews on a PR.\n- `@coderabbitai resume` to resume the paused reviews.\n- `@coderabbitai review` to trigger a review. This is useful when automatic reviews are disabled for the repository.\n- `@coderabbitai resolve` resolve all the CodeRabbit review comments.\n- `@coderabbitai help` to get help.\n\n\nAdditionally, you can add `@coderabbitai ignore` anywhere in the PR description to prevent this PR from being reviewed.\n\n### CodeRabbit Configration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](https://discord.com/invite/GsXnASn26c) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-04-07T09:22:15Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/3739#issuecomment-2041383389"
                    },
                    {
                        "body": "> sorry for hijacking this PR \r\n\r\nNo worries at all. I'm going off topic a bit too (Just cannot resist the pulse to change them, I understand that).\r\n\r\n> but i'd be interested to get your opinion on these variable renames. single-letter variables are a pet peeve of mine for hurting code readability so been trying to get rid of them for a while\r\n\r\nI would fully support such improvements, which makes the code much more readable (especially without reading the full code block). \r\n\r\nBut for some simple cases, I sometimes think it might not be necessary \r\n- Very simple and widely accepted cases like `i/j` for index, `k/v` for `key/value`\r\n- Where the var is immediately returned (mostly list comprehensions like `[idx for idx, site in enumerate(structure) if condition]`)\r\n\r\nFor some cases, using a more detailed var name is much better\r\n- When similar name could occur, which could be very confusing, for example the `core.surface` I'm currently cleaning up, I need to guess `c` stands for cluster or c-coordinate\r\n- When the var name is carried for a long distance (I would easily forget what it stands for if it needs to go dozens lines forward)\r\n- When people don't want to read the full code block\r\n",
                        "user": "DanielYang59",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-07T10:17:53Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/3739#issuecomment-2041407330"
                    },
                    {
                        "body": "@janosh Please review. Thanks!",
                        "user": "DanielYang59",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-07T10:37:57Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/3739#issuecomment-2041417070"
                    },
                    {
                        "body": "`ruff` has had [limited auto-typing ability](https://docs.astral.sh/ruff/rules/missing-return-type-special-method) for a while.\r\n\r\ni just ran\r\n\r\n```sh\r\nruff check . --select ANN204 --unsafe-fixes\r\nFound 674 errors.\r\n[*] 550 fixable with the --fix option.\r\n```\r\n\r\nwould you be interested in submitting a PR with those changes as a followup to #3705?",
                        "user": "janosh",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-04-07T10:59:30Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/3739#issuecomment-2041429466"
                    },
                    {
                        "body": "> `ruff` has had [limited auto-typing ability](https://docs.astral.sh/ruff/rules/missing-return-type-special-method) for a while.\r\n> \r\n> i just ran\r\n> \r\n> ```shell\r\n> ruff check . --select ANN204 --unsafe-fixes\r\n> Found 674 errors.\r\n> [*] 550 fixable with the --fix option.\r\n> ```\r\n> \r\n> would you be interested in submitting a PR with those changes as a followup to #3705?\r\n\r\nWow this sounds very interesting (always amazed how much you know about all kinds of stuff). I would have a go at this after I finish cleaning up `core.surface`. Thanks for the useful input.",
                        "user": "DanielYang59",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-07T11:46:57Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/3739#issuecomment-2041442625"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/materialsproject/pymatgen/pulls/3739",
                    "merged_at": "2024-04-07T10:51:28Z"
                }
            },
            {
                "url": "https://github.com/materialsproject/pymatgen/pull/3736",
                "title": "Avoid using `exec` in code",
                "labels": [
                    "linting",
                    "security"
                ],
                "user": "DanielYang59",
                "issue_author_association": "CONTRIBUTOR",
                "number": 3736,
                "id": 2226844109,
                "state": "closed",
                "project_created_at": "2024-04-05T02:34:50Z",
                "closed_at": "2024-04-05T06:10:26Z",
                "body": "## Summary\r\n\r\n- Avoid using `exec`, especially from potentially untrusted source (external filename in this case) to avoid potential security issue (alerted by the `xz` backdoor)\r\n- Minor `sourcery` fixes\r\n\r\n",
                "comments": [
                    {
                        "body": "<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe recent update across `pymatgen` LAMMPS-related modules brings improvements in file handling, data manipulation, and code robustness. Changes include adopting Unicode encoding, refining dictionary operations, ensuring default values, enhancing assignments for clarity, and optimizing file processing for efficiency.\n\n## Changes\n\n| Files | Summary |\n|-------|---------|\n| `pymatgen/io/lammps/data.py`, `pymatgen/io/lammps/inputs.py` | - Added `encoding=\"utf-8\"` in file operations.<br>- Simplified dictionary updates.<br>- Managed default values for specific data fields.<br>- Clarified variable assignments for improved readability.<br>- Optimized file parsing and error handling. |\n| `pymatgen/io/lammps/outputs.py` | - Updated file sorting based on a pattern.<br>- Adjusted regular expression handling for file access. |\n\n>   \n> To the code we hop and leap,  \n> Through the files, our changes seep.  \n> With each line, we aim to enhance,  \n> Unicode and syntax dance.  \n> A rabbit's touch, so light and deft,  \n> Leaves the codebase improved and left.  \n> \n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: raw summary by coderabbit.ai -->\n<!--\n\n\npymatgen/io/lammps/data.py: ## Short summary\n\n- Added `encoding=\"utf-8\"` parameter in `open` function calls.\n- Changed dictionary update syntax from `body.update({name: section})` to `body[name] = section`.\n- Modified the handling of `topo.charges` to use a default value if `topo.charges` is empty.\n- Updated assignment of `self.force_field` to use `ff_dfs or None` for clarity.\n- Revised the `from_files` method to handle file parsing and clustering more efficiently.\n- Improved error handling for different atom styles in files.\n- Updated type annotations in `from_files` method parameters.\n\npymatgen/io/lammps/inputs.py: ### Short Summary\n\n- In the `ncomments` method, the variable `_args` is used instead of `args` in the list comprehension.\n- In the `merge_stages` method, the condition is changed to check if any stage is not in `self.stages_names` instead of all stages.\n- In the `from_str` method, the construction of the `header` variable is optimized using a list comprehension.\n- In the `_add_comment` method, the condition for inline comments is simplified.\n- In the `md` method, the file is opened with explicit encoding specified.\n- In the `write_lammps_inputs` method, the assignment of `data_filename` is updated using the walrus operator.\n\npymatgen/io/lammps/outputs.py: ### Short Summary\n\nIn the `pymatgen/io/lammps/outputs.py` file, the changes involve modifying how files are sorted based on a pattern and accessing matched groups in regular expressions. Specifically, the sorting of files based on a key function and accessing matched groups in regular expressions have been adjusted to simplify the code logic.\n\n-->\n<!-- end of auto-generated comment: raw summary by coderabbit.ai --><!-- This is an auto-generated comment: short summary by coderabbit.ai -->\n<!--\n\n\n### PR Objectives\n\nPR #3736 aims to bolster security and code quality in the `pymatgen` library by eliminating the use of `exec`, particularly from untrusted sources like external filenames, to mitigate security risks such as the `xz` backdoor. Additionally, minor enhancements suggested by `sourcery` are applied to refine the codebase.\n\n### Comments Summary\n\n- Request for review by `DanielYang59` directed to `@janosh`.\n- Code changes in `pymatgen/io/lammps/data.py`, `pymatgen/io/lammps/inputs.py`, and `pymatgen/io/lammps/outputs.py` include:\n  - Standardizing file operations with `encoding=\"utf-8\"`.\n  - Refactoring dictionary updates for clarity.\n  - Improving default value handling for specific cases.\n  - Enhancing code readability and error handling.\n  - Optimizing methods for efficiency and error prevention.\n\n### AI-generated Summary of Generated Summaries\n\nKey changes in PR #3736 for `pymatgen/io/lammps`:\n\n- Enhanced security by removing `exec` usage to mitigate risks from untrusted sources.\n- Standardized file operations with `encoding=\"utf-8\"` for consistency.\n- Improved dictionary operations by switching to direct assignment.\n- Enhanced default value handling for specific scenarios.\n- Clarified code for better readability and maintenance.\n- Optimized methods for improved efficiency and error handling.\n\nThese modifications collectively aim to fortify security, efficiency, and maintainability in the `pymatgen` library's LAMMPS data processing support.\n\n-->\n<!-- end of auto-generated comment: short summary by coderabbit.ai --><!-- commit_ids_reviewed_start -->\n\n<!-- febea7894c8565c22a1bf948b6ba3d570e6c6f6e -->\n<!-- 0be94350a16df060162d0d43c088b3a36ee0b4b0 -->\n<!-- ebd1184d10421ba2f5e4d7011d371f0b9613c54a -->\n\n<!-- commit_ids_reviewed_end --><!-- tweet_start -->\n\nThank you for using CodeRabbit. We offer it for free to the OSS community and would appreciate your support in helping us grow. If you find it useful, would you consider giving us a shout-out on your favorite social media?\n\n<details>\n<summary>Share</summary>\n\n- [X](https://twitter.com/intent/tweet?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A&url=https%3A//coderabbit.ai)\n- [Mastodon](https://mastodon.social/share?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A%20https%3A%2F%2Fcoderabbit.ai)\n- [Reddit](https://www.reddit.com/submit?title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&text=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code.%20Check%20it%20out%3A%20https%3A//coderabbit.ai)\n- [LinkedIn](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcoderabbit.ai&mini=true&title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&summary=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code)\n\n</details>\n\n<!-- tweet_end --><!-- tips_start -->\n\n---\n\n<details>\n<summary>Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n- Review comments: Directly reply to a review comment made by CodeRabbit. Example:\n\t- `I pushed a fix in commit <commit_id>.`\n\t- `Generate unit testing code for this file.`\n\t- `Open a follow-up GitHub issue for this discussion.`\n- Files and specific lines of code (under the \"Files changed\" tab): Tag `@coderabbitai` in a new review comment at the desired location with your query. Examples:\n\t- `@coderabbitai generate unit testing code for this file.`\n\t-\t`@coderabbitai modularize this function.`\n- PR comments: Tag `@coderabbitai` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n\t- `@coderabbitai generate interesting stats about this repository and render them as a table.`\n\t- `@coderabbitai show all the console.log statements in this repository.`\n\t- `@coderabbitai read src/utils.ts and generate unit testing code.`\n\t- `@coderabbitai read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (invoked as PR comments)\n\n- `@coderabbitai pause` to pause the reviews on a PR.\n- `@coderabbitai resume` to resume the paused reviews.\n- `@coderabbitai review` to trigger a review. This is useful when automatic reviews are disabled for the repository.\n- `@coderabbitai resolve` resolve all the CodeRabbit review comments.\n- `@coderabbitai help` to get help.\n\n\nAdditionally, you can add `@coderabbitai ignore` anywhere in the PR description to prevent this PR from being reviewed.\n\n### CodeRabbit Configration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/coderabbit-overrides.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](https://discord.com/invite/GsXnASn26c) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-04-05T02:34:57Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/3736#issuecomment-2038654739"
                    },
                    {
                        "body": "Can you please review this @janosh. Thanks!",
                        "user": "DanielYang59",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-05T02:49:57Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/3736#issuecomment-2038706222"
                    },
                    {
                        "body": "Thanks for reviewing! This is the only occurrence of `exec` cross the whole code base AFAIK.",
                        "user": "DanielYang59",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-05T06:14:45Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/3736#issuecomment-2039024581"
                    },
                    {
                        "body": "I noticed several usage of `eval` across the code base. I would open an PR to avoid them if possible very soon.",
                        "user": "DanielYang59",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-06T14:00:41Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/3736#issuecomment-2041096668"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/materialsproject/pymatgen/pulls/3736",
                    "merged_at": "2024-04-05T06:10:26Z"
                }
            }
        ],
        "SecurityPolicy_reporting_mechanism": "advisory",
        "num_security_issues_after_policy": 4,
        "num_security_issue_and_pull": 4,
        "security_issues_created_after_policy": [
            {
                "url": "https://github.com/materialsproject/pymatgen/pull/4021",
                "title": "Replace HTTP URLs with HTTPS, avoid `from pytest import raises/mark`",
                "labels": [
                    "docs",
                    "security"
                ],
                "user": "DanielYang59",
                "issue_author_association": "CONTRIBUTOR",
                "number": 4021,
                "id": 2492056599,
                "state": "closed",
                "project_created_at": "2024-08-28T13:17:33Z",
                "closed_at": "2024-08-30T06:01:32Z",
                "body": "### Summary\r\n\r\n- Replace HTTP URLs with HTTPS\r\n- Replace some expired URLs\r\n- Avoid `from pytest import raises/mark` (a bit unsure about `MonkeyPatch` so just use `pytest.MonkeyPatch` if `pytest` is already imported)\r\n- [ ] Regenerate documents",
                "comments": [
                    {
                        "body": "@janosh  Please review this. Looks like we might need to regenerate docs, thanks!\r\n\r\nI reverted the rebuild doc commit because it makes it impossible to review. Would let you do this, appreciate that!",
                        "user": "DanielYang59",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-08-28T13:50:45Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/4021#issuecomment-2315377467"
                    },
                    {
                        "body": "Currently on my phone. Could you apply the docs commit again?",
                        "user": "janosh",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-08-28T14:23:20Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/4021#issuecomment-2315483070"
                    },
                    {
                        "body": "> ideally, we should have a link checker CI [similar to pymativz](https://github.com/janosh/pymatviz/blob/1de350a146b53ae03f343ff9a78454ba7c976186/.github/workflows/link-check.yml) to make sure all the new (and old links) are actually still alive. but i'm happy to leave that to a future PR. maybe something to open an issue for so it's not forgotton\r\n\r\nWonderful. Added to my TODO list (which is not very long at this moment :) ). I would need some investigation on that because [markdown-link-check](https://github.com/tcort/markdown-link-check) seemingly just check markdown files.\r\n\r\nCan you regenerate documents after reviewing? Thanks!",
                        "user": "DanielYang59",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-08-30T05:42:53Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/4021#issuecomment-2320124649"
                    },
                    {
                        "body": "@DanielYang59 do you want to reapply the docs update commit before i merge?",
                        "user": "janosh",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-08-30T05:49:56Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/4021#issuecomment-2320135991"
                    },
                    {
                        "body": "@janosh certainly, got two warnings at the start, not sure if we should worry about that or not (it seems `favicon.ico` and `html_static_path = [\"assets\"]` don't exist?):\r\n```\r\n>>> invoke make-doc\r\nrm: pymatgen.*.rst: No such file or directory\r\nRunning Sphinx v7.4.7\r\nloading translations [en]... done\r\nmaking output directory... done\r\nWARNING: html_static_path entry 'assets' does not exist\r\nWARNING: favicon file 'favicon.ico' does not exist\r\nConverting `source_suffix = '.rst'` to `source_suffix = {'.rst': 'restructuredtext'}`.\r\nbuilding [mo]: targets for 0 po files that are out of date\r\nwriting output... \r\nbuilding [html]: targets for 49 source files that are out of date\r\nupdating environment: [new config] 49 added, 0 changed, 0 removed\r\n```",
                        "user": "DanielYang59",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-08-30T05:55:25Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/4021#issuecomment-2320145018"
                    },
                    {
                        "body": "> @janosh certainly, got two warnings at the start, not sure if we should worry about that or not (it seems favicon.ico and html_static_path = [\"assets\"] don't exist?):\r\n\r\nsafe to ignore for now. the docs need some more work at some point but that would be a bigger project",
                        "user": "janosh",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-08-30T06:01:18Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/4021#issuecomment-2320156329"
                    },
                    {
                        "body": "Great to know! Thanks.",
                        "user": "DanielYang59",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-08-30T06:03:38Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/4021#issuecomment-2320161208"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/materialsproject/pymatgen/pulls/4021",
                    "merged_at": "2024-08-30T06:01:32Z"
                }
            },
            {
                "url": "https://github.com/materialsproject/pymatgen/issues/4016",
                "title": "[Dev] Remove `mysql` dependency from `ext.cod` and fix S608",
                "labels": [
                    "security",
                    "help wanted",
                    "ext"
                ],
                "user": "DanielYang59",
                "issue_author_association": "CONTRIBUTOR",
                "number": 4016,
                "id": 2485718242,
                "state": "closed",
                "project_created_at": "2024-08-26T02:36:09Z",
                "closed_at": "2024-09-09T21:09:43Z",
                "body": "- Resolve following `mysql` dependency issue: https://github.com/materialsproject/pymatgen/blob/41e4c69911f2b724734e0917c436ee5a1de63091/src/pymatgen/ext/cod.py#L70\r\n- Also need to fix two `S608` violations (SQL injection): https://github.com/materialsproject/pymatgen/blob/41e4c69911f2b724734e0917c436ee5a1de63091/src/pymatgen/ext/cod.py#L73\r\n https://github.com/materialsproject/pymatgen/blob/41e4c69911f2b724734e0917c436ee5a1de63091/src/pymatgen/ext/cod.py#L109\r\n\r\nHelp needed.\r\n",
                "comments": [
                    {
                        "body": "> * Resolve following `mysql` dependency issue:\r\n\r\ni think `mysql` can be replaced with https://pypi.org/project/mysqlclient (based on [the advice here](https://pypi.org/project/mysql/))",
                        "user": "janosh",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-09-06T22:40:49Z",
                        "url": "https://github.com/materialsproject/pymatgen/issues/4016#issuecomment-2334905410"
                    },
                    {
                        "body": "Why bother? This is a small feature within pymatgen and we probably can count on a few fingers the number of people who use it. Those who use it can install mysql. In fact, the onus should be on COD to offer a REST API rather than an SQL one. Pls focus efforts on more impactful changes.",
                        "user": "shyuep",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-09-09T21:09:43Z",
                        "url": "https://github.com/materialsproject/pymatgen/issues/4016#issuecomment-2339095635"
                    },
                    {
                        "body": "> This is a small feature within pymatgen and we probably can count on a few fingers the number of people who use it. Those who use it can install mysql.\r\n\r\nThat's true, I posted this in case someone who need to use SQL might be interested to take over and fix this?\r\n\r\n> Pls focus efforts on more impactful changes.\r\n\r\nThat's the reason I opened this instead of fixing it myself. Can we reopen this? This looks like a good first issue if anyone is interested in getting involved in open source.\r\n\r\n\r\n",
                        "user": "DanielYang59",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-09-10T01:10:26Z",
                        "url": "https://github.com/materialsproject/pymatgen/issues/4016#issuecomment-2339416915"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/materialsproject/pymatgen/pull/3739",
                "title": "Avoid using `eval`, replace manual offset in `enumerate` and rename single letter variables",
                "labels": [
                    "linting",
                    "security"
                ],
                "user": "DanielYang59",
                "issue_author_association": "CONTRIBUTOR",
                "number": 3739,
                "id": 2229650014,
                "state": "closed",
                "project_created_at": "2024-04-07T09:22:07Z",
                "closed_at": "2024-04-07T10:51:29Z",
                "body": "## Summary\r\n\r\n- Replace `eval` with safer alternatives\r\n- Replace manual offset in `enumerate` with the `start` argument\r\n- Minor format tweaks\r\n",
                "comments": [
                    {
                        "body": "<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- This is an auto-generated comment: skip review by coderabbit.ai -->\n\n> [!IMPORTANT]\n> ## Auto Review Skipped\n> \n> More than 25% of the files skipped due to max files limit. The review is being skipped to prevent a low-quality review.\n> \n> 26 files out of 83 files are above the max files limit of 50. Please upgrade to Pro plan to get higher limits.\n\n<!-- end of auto-generated comment: skip review by coderabbit.ai --><!-- walkthrough_start -->\n\n## Walkthrough\n\nThe recent updates across various components of the pymatgen library focus on enhancing code safety, efficiency, and readability. Notable improvements include the optimization of loop logic and conditionals, safer handling of dynamic expressions, and more precise and clear documentation. These changes collectively aim to refine the library's usability and maintainability, ensuring it remains a robust tool for materials science research.\n\n## Changes\n\n| Files                             | Summary                                                                                                                                                      |\n|-----------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `.../analysis/magnetism/heisenberg.py` | - Adjusted loop logic and conditionals<br>- Simplified filename condition<br>- Optimized energy rounding and duplicate removal<br>- Replaced `eval` with `literal_eval` |\n| `.../electronic_structure/boltztrap2.py` | - Unified `dosweight` assignment based on spin polarization<br>- Simplified `structure` assignment<br>- Refined calculation and property access methods       |\n| `.../io/vasp/inputs.py`           | - Changed parameter type comparison and assignment methods<br>- Removed integer value handling for hashing<br>- Updated docstring for clarity                  |\n\n>   \n> In the realm of pymatgen, where atoms dance,  \n> CodeRabbit hopped through, improving at a glance.  \n> Loops were tightened, and safety enhanced,  \n> With every line, the code advanced.  \n> 'Twas a leap for science, in every stance.  \n> \n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: raw summary by coderabbit.ai -->\n<!--\n\n\npymatgen/analysis/magnetism/heisenberg.py: ## Short summary\n\n- In the `_get_nn_dict` method, the loop logic was adjusted to start from index 1 and compare the current element with the next one.\n- In the `get_interaction_graph` method, the condition for adding \".json\" to the filename was simplified.\n- In the `_do_cleanup` method, the tolerance value for energy rounding was moved outside the loop, and the condition for removing duplicates was simplified.\n- In the `from_dict` class method, the use of `eval` was replaced with `literal_eval` for safety.\n\n---\n\npymatgen/electronic_structure/boltztrap2.py: ## Short summary\n\n- Consolidated the assignment of `dosweight` based on `is_spin_polarized`.\n- Simplified conditional assignment for `structure`.\n- Refactored the calculation of `h` in `bandana` method.\n- Updated the assignment of `dosweight` based on `is_spin_polarized`.\n- Modified property access in `plot_props` method.\n\n---\n\npymatgen/io/vasp/inputs.py: ## Short summary\n\n- In the `check_params` method, the comparison for parameter type has been changed to use `type(val).__name__` instead of `isinstance`.\n- In the `from_str` method, the assignment of `m` has been changed to use the walrus operator `:=`.\n- In the `md5_header_hash` method, the handling of integer values for hashing has been removed.\n- The docstring for the `__iter__` method in the `Potcar` class has been updated for clarity.\n\n-->\n<!-- end of auto-generated comment: raw summary by coderabbit.ai --><!-- This is an auto-generated comment: short summary by coderabbit.ai -->\n<!--\n\n\n### PR Objectives\n\nThe primary objective of Pull Request (PR) #3739 is to enhance the security and maintainability of the codebase by eliminating the use of the `eval` function, which is known for its potential security vulnerabilities. Instead, safer alternatives are employed to achieve the same functionality without compromising security. This PR encompasses modifications across several files within the project, specifically targeting areas where `eval` was previously used and replacing it with `literal_eval` or other safer methods. Additionally, the PR introduces minor formatting tweaks to improve the readability and consistency of the code. These changes span across multiple modules, including `pymatgen/analysis/magnetism/heisenberg.py`, `pymatgen/electronic_structure/boltztrap2.py`, and `pymatgen/io/vasp/inputs.py`, indicating a broad and impactful set of improvements aimed at enhancing the code's overall quality and security posture.\n\n### AI-generated Summary of Generated Summaries\n\nThe Pull Request introduces several key changes across different modules to improve security, readability, and efficiency. Notably, the unsafe `eval` function has been replaced with `literal_eval` in the `from_dict` class method within `pymatgen/analysis/magnetism/heisenberg.py`, directly addressing the primary objective of enhancing security. This module also sees adjustments in loop logic, condition simplifications, and the optimization of tolerance value handling and duplicate removals, contributing to cleaner and more efficient code.\n\nIn `pymatgen/electronic_structure/boltztrap2.py`, the changes focus on refining the logic related to spin polarization and structural assignments, alongside methodological refinements in property access and calculation processes. These modifications streamline the handling of spin-polarized calculations and improve the clarity and performance of property plotting and band analysis methods.\n\nThe `pymatgen/io/vasp/inputs.py` module experiences enhancements in parameter type checking, utilizing the walrus operator for more concise assignment operations, and the removal of unnecessary integer value handling for hashing. Additionally, the documentation for the `__iter__` method in the `Potcar` class has been clarified, aiding in better understanding and usage of the method.\n\nCollectively, these changes across the three modules not only address the critical security concerns associated with the use of `eval` but also introduce several optimizations and clarifications that contribute to the overall maintainability, readability, and efficiency of the codebase. The PR effectively moves the project away from potentially hazardous practices while streamlining various aspects of the code, demonstrating a comprehensive approach to improving the project's quality and security.\n\n-->\n<!-- end of auto-generated comment: short summary by coderabbit.ai --><!-- commit_ids_reviewed_start -->\n\n<!-- 5ca3aff1b81589ca37b03279f1cf6a3f716a4085 -->\n\n<!-- commit_ids_reviewed_end --><!-- tweet_start -->\n\nThank you for using CodeRabbit. We offer it for free to the OSS community and would appreciate your support in helping us grow. If you find it useful, would you consider giving us a shout-out on your favorite social media?\n\n<details>\n<summary>Share</summary>\n\n- [X](https://twitter.com/intent/tweet?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A&url=https%3A//coderabbit.ai)\n- [Mastodon](https://mastodon.social/share?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A%20https%3A%2F%2Fcoderabbit.ai)\n- [Reddit](https://www.reddit.com/submit?title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&text=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code.%20Check%20it%20out%3A%20https%3A//coderabbit.ai)\n- [LinkedIn](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcoderabbit.ai&mini=true&title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&summary=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code)\n\n</details>\n\n<!-- tweet_end --><!-- tips_start -->\n\n---\n\n<details>\n<summary>Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n- Review comments: Directly reply to a review comment made by CodeRabbit. Example:\n\t- `I pushed a fix in commit <commit_id>.`\n\t- `Generate unit testing code for this file.`\n\t- `Open a follow-up GitHub issue for this discussion.`\n- Files and specific lines of code (under the \"Files changed\" tab): Tag `@coderabbitai` in a new review comment at the desired location with your query. Examples:\n\t- `@coderabbitai generate unit testing code for this file.`\n\t-\t`@coderabbitai modularize this function.`\n- PR comments: Tag `@coderabbitai` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n\t- `@coderabbitai generate interesting stats about this repository and render them as a table.`\n\t- `@coderabbitai show all the console.log statements in this repository.`\n\t- `@coderabbitai read src/utils.ts and generate unit testing code.`\n\t- `@coderabbitai read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (invoked as PR comments)\n\n- `@coderabbitai pause` to pause the reviews on a PR.\n- `@coderabbitai resume` to resume the paused reviews.\n- `@coderabbitai review` to trigger a review. This is useful when automatic reviews are disabled for the repository.\n- `@coderabbitai resolve` resolve all the CodeRabbit review comments.\n- `@coderabbitai help` to get help.\n\n\nAdditionally, you can add `@coderabbitai ignore` anywhere in the PR description to prevent this PR from being reviewed.\n\n### CodeRabbit Configration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](https://discord.com/invite/GsXnASn26c) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-04-07T09:22:15Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/3739#issuecomment-2041383389"
                    },
                    {
                        "body": "> sorry for hijacking this PR \r\n\r\nNo worries at all. I'm going off topic a bit too (Just cannot resist the pulse to change them, I understand that).\r\n\r\n> but i'd be interested to get your opinion on these variable renames. single-letter variables are a pet peeve of mine for hurting code readability so been trying to get rid of them for a while\r\n\r\nI would fully support such improvements, which makes the code much more readable (especially without reading the full code block). \r\n\r\nBut for some simple cases, I sometimes think it might not be necessary \r\n- Very simple and widely accepted cases like `i/j` for index, `k/v` for `key/value`\r\n- Where the var is immediately returned (mostly list comprehensions like `[idx for idx, site in enumerate(structure) if condition]`)\r\n\r\nFor some cases, using a more detailed var name is much better\r\n- When similar name could occur, which could be very confusing, for example the `core.surface` I'm currently cleaning up, I need to guess `c` stands for cluster or c-coordinate\r\n- When the var name is carried for a long distance (I would easily forget what it stands for if it needs to go dozens lines forward)\r\n- When people don't want to read the full code block\r\n",
                        "user": "DanielYang59",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-07T10:17:53Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/3739#issuecomment-2041407330"
                    },
                    {
                        "body": "@janosh Please review. Thanks!",
                        "user": "DanielYang59",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-07T10:37:57Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/3739#issuecomment-2041417070"
                    },
                    {
                        "body": "`ruff` has had [limited auto-typing ability](https://docs.astral.sh/ruff/rules/missing-return-type-special-method) for a while.\r\n\r\ni just ran\r\n\r\n```sh\r\nruff check . --select ANN204 --unsafe-fixes\r\nFound 674 errors.\r\n[*] 550 fixable with the --fix option.\r\n```\r\n\r\nwould you be interested in submitting a PR with those changes as a followup to #3705?",
                        "user": "janosh",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-04-07T10:59:30Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/3739#issuecomment-2041429466"
                    },
                    {
                        "body": "> `ruff` has had [limited auto-typing ability](https://docs.astral.sh/ruff/rules/missing-return-type-special-method) for a while.\r\n> \r\n> i just ran\r\n> \r\n> ```shell\r\n> ruff check . --select ANN204 --unsafe-fixes\r\n> Found 674 errors.\r\n> [*] 550 fixable with the --fix option.\r\n> ```\r\n> \r\n> would you be interested in submitting a PR with those changes as a followup to #3705?\r\n\r\nWow this sounds very interesting (always amazed how much you know about all kinds of stuff). I would have a go at this after I finish cleaning up `core.surface`. Thanks for the useful input.",
                        "user": "DanielYang59",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-07T11:46:57Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/3739#issuecomment-2041442625"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/materialsproject/pymatgen/pulls/3739",
                    "merged_at": "2024-04-07T10:51:28Z"
                }
            },
            {
                "url": "https://github.com/materialsproject/pymatgen/pull/3736",
                "title": "Avoid using `exec` in code",
                "labels": [
                    "linting",
                    "security"
                ],
                "user": "DanielYang59",
                "issue_author_association": "CONTRIBUTOR",
                "number": 3736,
                "id": 2226844109,
                "state": "closed",
                "project_created_at": "2024-04-05T02:34:50Z",
                "closed_at": "2024-04-05T06:10:26Z",
                "body": "## Summary\r\n\r\n- Avoid using `exec`, especially from potentially untrusted source (external filename in this case) to avoid potential security issue (alerted by the `xz` backdoor)\r\n- Minor `sourcery` fixes\r\n\r\n",
                "comments": [
                    {
                        "body": "<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe recent update across `pymatgen` LAMMPS-related modules brings improvements in file handling, data manipulation, and code robustness. Changes include adopting Unicode encoding, refining dictionary operations, ensuring default values, enhancing assignments for clarity, and optimizing file processing for efficiency.\n\n## Changes\n\n| Files | Summary |\n|-------|---------|\n| `pymatgen/io/lammps/data.py`, `pymatgen/io/lammps/inputs.py` | - Added `encoding=\"utf-8\"` in file operations.<br>- Simplified dictionary updates.<br>- Managed default values for specific data fields.<br>- Clarified variable assignments for improved readability.<br>- Optimized file parsing and error handling. |\n| `pymatgen/io/lammps/outputs.py` | - Updated file sorting based on a pattern.<br>- Adjusted regular expression handling for file access. |\n\n>   \n> To the code we hop and leap,  \n> Through the files, our changes seep.  \n> With each line, we aim to enhance,  \n> Unicode and syntax dance.  \n> A rabbit's touch, so light and deft,  \n> Leaves the codebase improved and left.  \n> \n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: raw summary by coderabbit.ai -->\n<!--\n\n\npymatgen/io/lammps/data.py: ## Short summary\n\n- Added `encoding=\"utf-8\"` parameter in `open` function calls.\n- Changed dictionary update syntax from `body.update({name: section})` to `body[name] = section`.\n- Modified the handling of `topo.charges` to use a default value if `topo.charges` is empty.\n- Updated assignment of `self.force_field` to use `ff_dfs or None` for clarity.\n- Revised the `from_files` method to handle file parsing and clustering more efficiently.\n- Improved error handling for different atom styles in files.\n- Updated type annotations in `from_files` method parameters.\n\npymatgen/io/lammps/inputs.py: ### Short Summary\n\n- In the `ncomments` method, the variable `_args` is used instead of `args` in the list comprehension.\n- In the `merge_stages` method, the condition is changed to check if any stage is not in `self.stages_names` instead of all stages.\n- In the `from_str` method, the construction of the `header` variable is optimized using a list comprehension.\n- In the `_add_comment` method, the condition for inline comments is simplified.\n- In the `md` method, the file is opened with explicit encoding specified.\n- In the `write_lammps_inputs` method, the assignment of `data_filename` is updated using the walrus operator.\n\npymatgen/io/lammps/outputs.py: ### Short Summary\n\nIn the `pymatgen/io/lammps/outputs.py` file, the changes involve modifying how files are sorted based on a pattern and accessing matched groups in regular expressions. Specifically, the sorting of files based on a key function and accessing matched groups in regular expressions have been adjusted to simplify the code logic.\n\n-->\n<!-- end of auto-generated comment: raw summary by coderabbit.ai --><!-- This is an auto-generated comment: short summary by coderabbit.ai -->\n<!--\n\n\n### PR Objectives\n\nPR #3736 aims to bolster security and code quality in the `pymatgen` library by eliminating the use of `exec`, particularly from untrusted sources like external filenames, to mitigate security risks such as the `xz` backdoor. Additionally, minor enhancements suggested by `sourcery` are applied to refine the codebase.\n\n### Comments Summary\n\n- Request for review by `DanielYang59` directed to `@janosh`.\n- Code changes in `pymatgen/io/lammps/data.py`, `pymatgen/io/lammps/inputs.py`, and `pymatgen/io/lammps/outputs.py` include:\n  - Standardizing file operations with `encoding=\"utf-8\"`.\n  - Refactoring dictionary updates for clarity.\n  - Improving default value handling for specific cases.\n  - Enhancing code readability and error handling.\n  - Optimizing methods for efficiency and error prevention.\n\n### AI-generated Summary of Generated Summaries\n\nKey changes in PR #3736 for `pymatgen/io/lammps`:\n\n- Enhanced security by removing `exec` usage to mitigate risks from untrusted sources.\n- Standardized file operations with `encoding=\"utf-8\"` for consistency.\n- Improved dictionary operations by switching to direct assignment.\n- Enhanced default value handling for specific scenarios.\n- Clarified code for better readability and maintenance.\n- Optimized methods for improved efficiency and error handling.\n\nThese modifications collectively aim to fortify security, efficiency, and maintainability in the `pymatgen` library's LAMMPS data processing support.\n\n-->\n<!-- end of auto-generated comment: short summary by coderabbit.ai --><!-- commit_ids_reviewed_start -->\n\n<!-- febea7894c8565c22a1bf948b6ba3d570e6c6f6e -->\n<!-- 0be94350a16df060162d0d43c088b3a36ee0b4b0 -->\n<!-- ebd1184d10421ba2f5e4d7011d371f0b9613c54a -->\n\n<!-- commit_ids_reviewed_end --><!-- tweet_start -->\n\nThank you for using CodeRabbit. We offer it for free to the OSS community and would appreciate your support in helping us grow. If you find it useful, would you consider giving us a shout-out on your favorite social media?\n\n<details>\n<summary>Share</summary>\n\n- [X](https://twitter.com/intent/tweet?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A&url=https%3A//coderabbit.ai)\n- [Mastodon](https://mastodon.social/share?text=I%20just%20used%20%40coderabbitai%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20the%20proprietary%20code.%20Check%20it%20out%3A%20https%3A%2F%2Fcoderabbit.ai)\n- [Reddit](https://www.reddit.com/submit?title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&text=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code.%20Check%20it%20out%3A%20https%3A//coderabbit.ai)\n- [LinkedIn](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fcoderabbit.ai&mini=true&title=Great%20tool%20for%20code%20review%20-%20CodeRabbit&summary=I%20just%20used%20CodeRabbit%20for%20my%20code%20review%2C%20and%20it%27s%20fantastic%21%20It%27s%20free%20for%20OSS%20and%20offers%20a%20free%20trial%20for%20proprietary%20code)\n\n</details>\n\n<!-- tweet_end --><!-- tips_start -->\n\n---\n\n<details>\n<summary>Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n- Review comments: Directly reply to a review comment made by CodeRabbit. Example:\n\t- `I pushed a fix in commit <commit_id>.`\n\t- `Generate unit testing code for this file.`\n\t- `Open a follow-up GitHub issue for this discussion.`\n- Files and specific lines of code (under the \"Files changed\" tab): Tag `@coderabbitai` in a new review comment at the desired location with your query. Examples:\n\t- `@coderabbitai generate unit testing code for this file.`\n\t-\t`@coderabbitai modularize this function.`\n- PR comments: Tag `@coderabbitai` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n\t- `@coderabbitai generate interesting stats about this repository and render them as a table.`\n\t- `@coderabbitai show all the console.log statements in this repository.`\n\t- `@coderabbitai read src/utils.ts and generate unit testing code.`\n\t- `@coderabbitai read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (invoked as PR comments)\n\n- `@coderabbitai pause` to pause the reviews on a PR.\n- `@coderabbitai resume` to resume the paused reviews.\n- `@coderabbitai review` to trigger a review. This is useful when automatic reviews are disabled for the repository.\n- `@coderabbitai resolve` resolve all the CodeRabbit review comments.\n- `@coderabbitai help` to get help.\n\n\nAdditionally, you can add `@coderabbitai ignore` anywhere in the PR description to prevent this PR from being reviewed.\n\n### CodeRabbit Configration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/coderabbit-overrides.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](https://discord.com/invite/GsXnASn26c) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->",
                        "user": "coderabbitai[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-04-05T02:34:57Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/3736#issuecomment-2038654739"
                    },
                    {
                        "body": "Can you please review this @janosh. Thanks!",
                        "user": "DanielYang59",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-05T02:49:57Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/3736#issuecomment-2038706222"
                    },
                    {
                        "body": "Thanks for reviewing! This is the only occurrence of `exec` cross the whole code base AFAIK.",
                        "user": "DanielYang59",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-05T06:14:45Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/3736#issuecomment-2039024581"
                    },
                    {
                        "body": "I noticed several usage of `eval` across the code base. I would open an PR to avoid them if possible very soon.",
                        "user": "DanielYang59",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-06T14:00:41Z",
                        "url": "https://github.com/materialsproject/pymatgen/pull/3736#issuecomment-2041096668"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/materialsproject/pymatgen/pulls/3736",
                    "merged_at": "2024-04-05T06:10:26Z"
                }
            }
        ],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism",
            "History of vulnerability"
        ],
        "num_noncompliant_security_discuss_issue": 1,
        "num_noncompliant_security_pull": 3,
        "has_generic_policy": true
    },
    {
        "project_name": "litestar-org/litestar",
        "project_url": "https://github.com/litestar-org/litestar",
        "SSF": {
            "date": "2024-10-29T19:20:22+07:00",
            "repo": {
                "name": "github.com/litestar-org/litestar",
                "commit": "017464f95bfb64a74ccaf32862352bdccdefd4c3"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 7.4,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'allow deletion' disabled on branch 'release-2.9.1'",
                        "Info: 'allow deletion' disabled on branch 'release-1.51'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'release-2.9.1'",
                        "Info: 'force pushes' disabled on branch 'release-1.51'",
                        "Warn: required approving review count is 1 on branch 'main'",
                        "Warn: branch 'release-2.9.1' does not require approvers",
                        "Warn: branch 'release-1.51' does not require approvers",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Warn: codeowners review is not required on branch 'release-2.9.1'",
                        "Warn: codeowners review is not required on branch 'release-1.51'",
                        "Info: status check found to merge onto on branch 'main'",
                        "Warn: no status checks found to merge onto branch 'release-2.9.1'",
                        "Warn: no status checks found to merge onto branch 'release-1.51'",
                        "Info: PRs are required in order to make changes on branch 'main'"
                    ],
                    "score": 4,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 out of 30 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: danger contributor org/company found, cogeotiff contributor org/company found, googlers contributor org/company found, pytest-dev contributor org/company found, remarkjs contributor org/company found, HypothesisWorks contributor org/company found, reviewdog contributor org/company found, alex-healthcare contributor org/company found, alex healthcare gmbh contributor org/company found, none contributor org/company found, litestar-org contributor org/company found, tilery contributor org/company found, rasterio contributor org/company found, oneleif contributor org/company found, ueberauth contributor org/company found, ExHammer contributor org/company found, Bichbros contributor org/company found, vestra software contributor org/company found, smc3 contributor org/company found, RemotePixel contributor org/company found, genzai | verdify | agrowizard | azami | boostingalpha contributor org/company found, jolt-org contributor org/company found, basemind-ai contributor org/company found, psf contributor org/company found, python-reddit contributor org/company found, wemake-services contributor org/company found, encode contributor org/company found, obscuritylabs contributor org/company found, raiffeisen-dgtl contributor org/company found, devlingo contributor org/company found, psf | @litestar-org contributor org/company found, python-trio contributor org/company found, PyCon contributor org/company found, topsport-com-au contributor org/company found, python contributor org/company found, lona-web-org contributor org/company found, sat-utils contributor org/company found, typeddjango contributor org/company found, philipps & byrne gmbh contributor org/company found, pypi contributor org/company found, PyCQA contributor org/company found, conda-forge contributor org/company found, py-mine contributor org/company found, cvat-ai contributor org/company found, snok contributor org/company found, dry-python contributor org/company found, PcapPlusPlus contributor org/company found, developmentseed contributor org/company found, stac-utils contributor org/company found, tool-belt contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 50 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 18 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/publish.yml:10"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yml:44: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:87: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:89: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yml:94: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:209: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:212: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yml:217: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:242: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:257: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:260: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yml:264: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:332: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:333: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:338: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yml:352: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:26: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:128: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:131: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yml:135: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:175: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yml:178: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:192: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:195: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:200: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:289: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:292: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yml:296: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:320: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:62: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:64: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yml:69: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/ci.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:12: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/codeql.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/codeql.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/codeql.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs-preview.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/docs-preview.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docs-preview.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/docs-preview.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docs-preview.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/docs-preview.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs-preview.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/docs-preview.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/docs.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/docs.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docs.yml:23: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/docs.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docs.yml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/docs.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/notify-released-issues.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/notify-released-issues.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/notify-released-issues.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/notify-released-issues.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/notify-released-issues.yml:26: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/notify-released-issues.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pr-labeler.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/pr-labeler.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pr-labeler.yml:26: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/pr-labeler.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pr-merged.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/pr-merged.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pr-title.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/pr-title.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/publish.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/publish.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/publish.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/publish.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:65: update your workflow using https://app.stepsecurity.io/secureworkflow/litestar-org/litestar/test.yml/main?enable=pin",
                        "Warn: containerImage not pinned by hash: .devcontainer/Dockerfile:3",
                        "Warn: pipCommand not pinned by hash: .devcontainer/Dockerfile:8",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:23",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:147",
                        "Info:   0 out of  43 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of  18 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   1 containerImage dependencies pinned",
                        "Info:   0 out of   3 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: SAST configuration detected: CodeQL",
                        "Warn: 29 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 9,
                    "reason": "SAST tool detected but not run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/litestar-org/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/litestar-org/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/litestar-org/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/litestar-org/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/docs.yml:14",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/pr-labeler.yml:9",
                        "Warn: jobLevel 'checks' permission set to 'write': .github/workflows/pr-labeler.yml:11",
                        "Warn: jobLevel 'statuses' permission set to 'write': .github/workflows/pr-labeler.yml:12",
                        "Warn: no topLevel permission defined: .github/workflows/ci.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/codeql.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/docs-preview.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/docs.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/notify-released-issues.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/pr-labeler.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/pr-merged.yml:1",
                        "Info: topLevel 'pull-requests' permission set to 'read': .github/workflows/pr-title.yml:11",
                        "Warn: no topLevel permission defined: .github/workflows/publish.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/test.yml:1"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/litestar-org/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\nThanks for helping make Litestar safe for everyone.\n\n## Security\n\nLitestar takes the security of our projects and services seriously, including all of the repositories managed by the [litestar organization](https://github.com/litestar-org).\n\nWe will ensure that your finding gets escalated to the appropriate maintainer(s) for remediation.\n\n## Reporting Security Issues\n\n**Please do not report security vulnerabilities through public GitHub issues, discussions, or pull requests.**\n\n[Click to Open a Security Advisory Privately](https://github.com/litestar-org/litestar/security/advisories/new)\n\nIf you believe you have found a security vulnerability in any Litestar-managed repository, please report it to us through coordinated disclosure:\n\n- In the affected repository, browse to the **Security** tab, select **Advisories**, select \"Report a vulnerability\"\n  - ![image](https://user-images.githubusercontent.com/45884264/217041010-8fd6b96b-329d-4d8e-8838-9b5bf4e1a78d.png)\n- Please do **NOT** create an issue in the affected repository\n- Please do **NOT** send a private message to and/or tag the \"@maintainer\" role on our [Discord server](https://discord.gg/MmcwxztmQb)\n\nPlease include as much of the information listed below as you can to help us better understand and resolve the issue:\n\n- The type of issue (e.g., buffer overflow, SQL injection, or cross-site scripting)\n- Full paths of source file(s) related to the manifestation of the issue\n- The location of the affected source code (tag/branch/commit or direct URL)\n- Any special configuration required to reproduce the issue\n- Step-by-step instructions to reproduce the issue\n- Proof-of-concept or exploit code (if possible)\n- Impact of the issue, including how an attacker might exploit the issue\n\nThis information will help us triage your report more quickly.\n",
        "project_all_labels": [
            ":no_entry: Not Planned",
            "(De)serialization",
            "1.x Bug",
            "3.x",
            "area/asgi",
            "area/channels",
            "area/ci",
            "area/connection",
            "area/constants",
            "area/contrib",
            "area/controller",
            "area/datastructures",
            "area/dependencies",
            "area/docs",
            "area/dto",
            "area/enums",
            "area/exceptions",
            "area/handlers",
            "area/kwargs",
            "area/logging",
            "area/middleware",
            "area/openapi",
            "area/params",
            "area/parsers",
            "area/plugins",
            "area/private-api",
            "area/response",
            "area/router",
            "area/security",
            "area/serialization",
            "area/signature",
            "area/static-files",
            "area/stores",
            "area/template",
            "area/testing",
            "area/types",
            "Blocked :no_entry_sign:",
            "Breaking ",
            "Bug :bug:",
            "build-ignore",
            "Channels",
            "CI",
            "CLI",
            "Compatibility",
            "Databases / ORMs",
            "Dependencies",
            "Dependency Injection",
            "do not merge",
            "Documentation :books:",
            "DTOs",
            "Duplicate",
            "Enhancement",
            "github_actions",
            "Good First Issue",
            "Good Intermediate Issue",
            "Great MCVE",
            "Great Writeup",
            "Help Wanted :sos:",
            "High Priority",
            "Infrastructure",
            "Invalid",
            "Logging",
            "Low Priority",
            "Meta",
            "Middleware",
            "Needs MCVE",
            "Needs Response :warning:",
            "no changelog",
            "OpenAPI",
            "Package",
            "Plugin",
            "polar",
            "pr/external",
            "pr/internal",
            "Question",
            "Refactor",
            "Responses",
            "Routing",
            "Security",
            "size: large",
            "size: medium",
            "size: small",
            "Stale",
            "Starlite",
            "Static Files",
            "Templating",
            "test platform compat",
            "Testing",
            "tests-issue",
            "translations",
            "Triage Required :hospital:",
            "Triage Required ",
            "type/bug",
            "type/docs",
            "type/feat",
            "Typing",
            "Upcoming Feature",
            "Upstream",
            "WIP",
            "wontfix"
        ],
        "README_content": "<!-- markdownlint-disable -->\n<p align=\"center\">\n  <!-- github-banner-start -->\n  <img src=\"https://raw.githubusercontent.com/litestar-org/branding/main/assets/Branding%20-%20SVG%20-%20Transparent/Logo%20-%20Banner%20-%20Inline%20-%20Light.svg#gh-light-mode-only\" alt=\"Litestar Logo - Light\" width=\"100%\" height=\"auto\" />\n  <img src=\"https://raw.githubusercontent.com/litestar-org/branding/main/assets/Branding%20-%20SVG%20-%20Transparent/Logo%20-%20Banner%20-%20Inline%20-%20Dark.svg#gh-dark-mode-only\" alt=\"Litestar Logo - Dark\" width=\"100%\" height=\"auto\" />\n  <!-- github-banner-end -->\n</p>\n<!-- markdownlint-restore -->\n\n<div align=\"center\">\n\n<!-- prettier-ignore-start -->\n\n| Project   |     | Status                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n|-----------|:----|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| CI/CD     |     | [![Latest Release](https://github.com/litestar-org/litestar/actions/workflows/publish.yml/badge.svg)](https://github.com/litestar-org/litestar/actions/workflows/publish.yml) [![ci](https://github.com/litestar-org/litestar/actions/workflows/ci.yml/badge.svg)](https://github.com/litestar-org/litestar/actions/workflows/ci.yml) [![Documentation Building](https://github.com/litestar-org/litestar/actions/workflows/docs.yml/badge.svg?branch=main)](https://github.com/litestar-org/litestar/actions/workflows/docs.yml)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| Quality   |     | [![Coverage](https://codecov.io/github/litestar-org/litestar/graph/badge.svg?token=vKez4Pycrc)](https://codecov.io/github/litestar-org/litestar) [![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=litestar-org_litestar&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=litestar-org_litestar) [![Maintainability Rating](https://sonarcloud.io/api/project_badges/measure?project=litestar-org_litestar&metric=sqale_rating)](https://sonarcloud.io/summary/new_code?id=litestar-org_litestar) [![Reliability Rating](https://sonarcloud.io/api/project_badges/measure?project=litestar-org_litestar&metric=reliability_rating)](https://sonarcloud.io/summary/new_code?id=litestar-org_litestar) [![Security Rating](https://sonarcloud.io/api/project_badges/measure?project=litestar-org_litestar&metric=security_rating)](https://sonarcloud.io/summary/new_code?id=litestar-org_litestar)                                                                                                                                                                                                                                                                                                                               |\n| Package   |     | [![PyPI - Version](https://img.shields.io/pypi/v/litestar?labelColor=202235&color=edb641&logo=python&logoColor=edb641)](https://badge.fury.io/py/litestar) ![PyPI - Support Python Versions](https://img.shields.io/pypi/pyversions/litestar?labelColor=202235&color=edb641&logo=python&logoColor=edb641) ![Starlite PyPI - Downloads](https://img.shields.io/pypi/dm/starlite?logo=python&label=starlite%20downloads&labelColor=202235&color=edb641&logoColor=edb641) ![Litestar PyPI - Downloads](https://img.shields.io/pypi/dm/litestar?logo=python&label=litestar%20downloads&labelColor=202235&color=edb641&logoColor=edb641)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n| Community |     | [![Reddit](https://img.shields.io/reddit/subreddit-subscribers/litestarapi?label=r%2FLitestar&logo=reddit&labelColor=202235&color=edb641&logoColor=edb641)](https://reddit.com/r/litestarapi) [![Discord](https://img.shields.io/discord/919193495116337154?labelColor=202235&color=edb641&label=chat%20on%20discord&logo=discord&logoColor=edb641)](https://discord.gg/litestar) [![Matrix](https://img.shields.io/badge/chat%20on%20Matrix-bridged-202235?labelColor=202235&color=edb641&logo=matrix&logoColor=edb641)](https://matrix.to/#/#litestar:matrix.org) [![Medium](https://img.shields.io/badge/Medium-202235?labelColor=202235&color=edb641&logo=medium&logoColor=edb641)](https://blog.litestar.dev) [![Twitter](https://img.shields.io/twitter/follow/LitestarAPI?labelColor=202235&color=edb641&logo=twitter&logoColor=edb641&style=flat)](https://twitter.com/LitestarAPI) [![Blog](https://img.shields.io/badge/Blog-litestar.dev-202235?logo=blogger&labelColor=202235&color=edb641&logoColor=edb641)](https://blog.litestar.dev)                                                                                                                                                                                                       |\n| Meta      |     | [![Litestar Project](https://img.shields.io/badge/Litestar%20Org-%E2%AD%90%20Litestar-202235.svg?logo=python&labelColor=202235&color=edb641&logoColor=edb641)](https://github.com/litestar-org/litestar) [![types - Mypy](https://img.shields.io/badge/types-Mypy-202235.svg?logo=python&labelColor=202235&color=edb641&logoColor=edb641)](https://github.com/python/mypy) [![License - MIT](https://img.shields.io/badge/license-MIT-202235.svg?logo=python&labelColor=202235&color=edb641&logoColor=edb641)](https://spdx.org/licenses/) [![Litestar Sponsors](https://img.shields.io/badge/Sponsor-%E2%9D%A4-%23edb641.svg?&logo=github&logoColor=edb641&labelColor=202235)](https://github.com/sponsors/litestar-org) [![linting - Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/charliermarsh/ruff/main/assets/badge/v2.json&labelColor=202235)](https://github.com/astral-sh/ruff) [![code style - Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/format.json&labelColor=202235)](https://github.com/psf/black) [![All Contributors](https://img.shields.io/github/all-contributors/litestar-org/litestar?labelColor=202235&color=edb641&logoColor=edb641)](#contributors-) |\n\n<!-- prettier-ignore-end -->\n</div>\n\n<hr>\n\nLitestar is a powerful, flexible yet opinionated ASGI framework, focused on\nbuilding APIs, and offers high-performance data validation and parsing,\ndependency injection, first-class ORM integration, authorization primitives, and much\nmore that's needed to get applications up and running.\n\nCheck out the [documentation ](https://docs.litestar.dev/) for a detailed overview of\nits features!\n\nAdditionally, the [Litestar fullstack repository](https://github.com/litestar-org/litestar-fullstack)\ncan give you a good impression how a fully fledged Litestar application may look.\n\n<details>\n<summary>Table of Contents</summary>\n\n- [Installation](#installation)\n  - [Quick Start](#quick-start)\n- [Core Features](#core-features)\n  - [Example Applications](#example-applications)\n- [Features](#features)\n  - [Class-based Controllers](#class-based-controllers)\n  - [Data Parsing, Type Hints, and Msgspec](#data-parsing-type-hints-and-msgspec)\n  - [Plugin System, ORM support, and DTOs](#plugin-system-orm-support-and-dtos)\n  - [OpenAPI](#openapi)\n  - [Dependency Injection](#dependency-injection)\n  - [Middleware](#middleware)\n  - [Route Guards](#route-guards)\n  - [Request Life Cycle Hooks](#request-life-cycle-hooks)\n- [Performance](#performance)\n- [Contributing](#contributing)\n\n</details>\n\n## Installation\n\n```shell\npip install litestar\n```\n\n## Quick Start\n\n```python\nfrom litestar import Litestar, get\n\n\n@get(\"/\")\ndef hello_world() -> dict[str, str]:\n    \"\"\"Keeping the tradition alive with hello world.\"\"\"\n    return {\"hello\": \"world\"}\n\n\napp = Litestar(route_handlers=[hello_world])\n```\n\n## Core Features\n\n- [Class based controllers](#class-based-controllers)\n- [Dependency Injection](#dependency-injection)\n- [Layered Middleware](#middleware)\n- [Plugin System](#plugin-system-orm-support-and-dtos)\n- [OpenAPI 3.1 schema generation](#openapi)\n- [Life Cycle Hooks](#request-life-cycle-hooks)\n- [Route Guards based Authorization](#route-guards)\n- Support for `dataclasses`, `TypedDict`, [pydantic version 1 and version 2](https://docs.pydantic.dev/latest/),\n  [msgspec](https://github.com/jcrist/msgspec) and [attrs](https://www.attrs.org/en/stable/)\n- Layered parameter declaration\n- Support for [RFC 9457](https://datatracker.ietf.org/doc/html/rfc9457) standardized \"Problem Detail\" error responses\n- [Automatic API documentation with](#redoc-swagger-ui-and-stoplight-elements-api-documentation):\n  - [Scalar](https://github.com/scalar/scalar/)\n  - [RapiDoc](https://github.com/rapi-doc/RapiDoc)\n  - [Redoc](https://github.com/Redocly/redoc)\n  - [Stoplight Elements](https://github.com/stoplightio/elements)\n  - [Swagger-UI](https://swagger.io/tools/swagger-ui/)\n- [Trio](https://trio.readthedocs.io/en/stable/) support (built-in, via [AnyIO](https://anyio.readthedocs.io/))\n- Ultra-fast validation, serialization and deserialization using [msgspec](https://github.com/jcrist/msgspec)\n- SQLAlchemy integration\n- Piccolo ORM Support\n\n## Example Applications\n\n<details>\n<summary>Pre-built Example Apps</summary>\n\n- [litestar-hello-world](https://github.com/litestar-org/litestar-hello-world): A bare-minimum application setup. Great\nfor testing and POC work.\n- [litestar-fullstack](https://github.com/litestar-org/litestar-fullstack): A reference application that contains most of the boilerplate required for a web application.\n  It features a Litestar app configured with best practices, SQLAlchemy 2.0 and SAQ, a frontend integrated with Vitejs and Jinja2 templates, Docker, and more. Like all\n  Litestar projects, this application is open to contributions, big and small.\n</details>\n\n## Sponsors\n\nLitestar is an open-source project, and we enjoy the support of our sponsors to help fund the exciting\nwork we do.\n\nA **huge** thanks to our sponsors:\n\n[//]: # \"Note to maintainers: Highest sponsors first; no more than 3 per row - create new div if needed\"\n\n<a href=\"https://github.com/scalar/scalar/?utm_source=litestar&utm_medium=website&utm_campaign=main-badge\" target=\"_blank\" title=\"Scalar.com - Document, Discover and Test APIs with Scalar.\"><img src=\"https://raw.githubusercontent.com/litestar-org/branding/main/assets/sponsors/scalar.svg\" width=\"180\" alt=\"Scalar.com\"></a>\n<a href=\"https://telemetrysports.com/\" title=\"Telemetry Sports - Changing the way data influences the sports experience\"><img src=\"https://raw.githubusercontent.com/litestar-org/branding/main/assets/sponsors/telemetry-sports/unofficial-telemetry-whitebg.svg\" width=\"150\" alt=\"Telemetry Sports\"></a>\n<a href=\"https://www.stok.kr/\" title=\"Stok - Stack Up Your Assets!\"><img src=\"https://avatars.githubusercontent.com/u/144093421?s=400&v=4\" width=\"150\" alt=\"Stok\"></a>\n\n<a href=\"https://docs.litestar.dev/dev/#sponsors\" class=\"external-link\" target=\"_blank\">Check out our sponsors in the docs</a>\n\nIf you would like to support the work that we do please consider [becoming a sponsor][sponsor-polar]\nvia [Polar.sh][sponsor-polar] (preferred), [GitHub][sponsor-github] or [Open Collective][sponsor-oc].\n\nAlso, exclusively with [Polar][sponsor-polar], you can engage in pledge-based sponsorships.\n\n[sponsor-github]: https://github.com/sponsors/litestar-org\n[sponsor-oc]: https://opencollective.com/litestar\n[sponsor-polar]: https://polar.sh/litestar-org\n\n## Features\n\n### Class-based Controllers\n\nWhile supporting function-based route handlers, Litestar also supports and promotes python OOP using class based\ncontrollers:\n\n<details>\n<summary>Example for class-based controllers</summary>\n\n```python title=\"my_app/controllers/user.py\"\nfrom typing import List, Optional\nfrom datetime import datetime\n\nfrom litestar import Controller, get, post, put, patch, delete\nfrom litestar.dto import DTOData\nfrom pydantic import UUID4\n\nfrom my_app.models import User, PartialUserDTO\n\n\nclass UserController(Controller):\n    path = \"/users\"\n\n    @post()\n    async def create_user(self, data: User) -> User: ...\n\n    @get()\n    async def list_users(self) -> List[User]: ...\n\n    @get(path=\"/{date:int}\")\n    async def list_new_users(self, date: datetime) -> List[User]: ...\n\n    @patch(path=\"/{user_id:uuid}\", dto=PartialUserDTO)\n    async def partial_update_user(\n        self, user_id: UUID4, data: DTOData[PartialUserDTO]\n    ) -> User: ...\n\n    @put(path=\"/{user_id:uuid}\")\n    async def update_user(self, user_id: UUID4, data: User) -> User: ...\n\n    @get(path=\"/{user_name:str}\")\n    async def get_user_by_name(self, user_name: str) -> Optional[User]: ...\n\n    @get(path=\"/{user_id:uuid}\")\n    async def get_user(self, user_id: UUID4) -> User: ...\n\n    @delete(path=\"/{user_id:uuid}\")\n    async def delete_user(self, user_id: UUID4) -> None: ...\n```\n\n</details>\n\n### Data Parsing, Type Hints, and Msgspec\n\nLitestar is rigorously typed, and it enforces typing. For example, if you forget to type a return value for a route\nhandler, an exception will be raised. The reason for this is that Litestar uses typing data to generate OpenAPI specs,\nas well as to validate and parse data. Thus, typing is essential to the framework.\n\nFurthermore, Litestar allows extending its support using plugins.\n\n### Plugin System, ORM support, and DTOs\n\nLitestar has a plugin system that allows the user to extend serialization/deserialization, OpenAPI generation, and other\nfeatures.\n\nIt ships with a builtin plugin for SQL Alchemy, which allows the user to use SQLAlchemy declarative classes \"natively\"\ni.e., as type parameters that will be serialized/deserialized and to return them as values from route\nhandlers.\n\nLitestar also supports the programmatic creation of DTOs with a `DTOFactory` class, which also supports the use of\nplugins.\n\n### OpenAPI\n\nLitestar has custom logic to generate OpenAPI 3.1.0 schema, include optional generation of examples using the\n[`polyfactory`](https://pypi.org/project/polyfactory/) library.\n\n#### ReDoc, Swagger-UI and Stoplight Elements API Documentation\n\nLitestar serves the documentation from the generated OpenAPI schema with:\n\n- [ReDoc](https://redoc.ly/)\n- [Swagger-UI](https://swagger.io/tools/swagger-ui/)\n- [Stoplight Elements](https://github.com/stoplightio/elements)\n- [RapiDoc](https://rapidocweb.com/)\n\nAll these are available and enabled by default.\n\n### Dependency Injection\n\nLitestar has a simple but powerful DI system inspired by pytest. You can define named dependencies - sync or async - at\ndifferent levels of the application, and then selective use or overwrite them.\n\n<details>\n<summary>Example for DI</summary>\n\n```python\nfrom litestar import Litestar, get\nfrom litestar.di import Provide\n\n\nasync def my_dependency() -> str: ...\n\n\n@get(\"/\")\nasync def index(injected: str) -> str:\n    return injected\n\n\napp = Litestar([index], dependencies={\"injected\": Provide(my_dependency)})\n```\n\n</details>\n\n### Middleware\n\nLitestar supports typical ASGI middleware and ships with middlewares to handle things such as\n\n- CORS\n- CSRF\n- Rate limiting\n- GZip and Brotli compression\n- Client- and server-side sessions\n\n### Route Guards\n\nLitestar has an authorization mechanism called `guards`, which allows the user to define guard functions at different\nlevel of the application (app, router, controller etc.) and validate the request before hitting the route handler\nfunction.\n\n<details>\n<summary>Example for route guards</summary>\n\n```python\nfrom litestar import Litestar, get\n\nfrom litestar.connection import ASGIConnection\nfrom litestar.handlers.base import BaseRouteHandler\nfrom litestar.exceptions import NotAuthorizedException\n\n\nasync def is_authorized(connection: ASGIConnection, handler: BaseRouteHandler) -> None:\n    # validate authorization\n    # if not authorized, raise NotAuthorizedException\n    raise NotAuthorizedException()\n\n\n@get(\"/\", guards=[is_authorized])\nasync def index() -> None: ...\n\n\napp = Litestar([index])\n```\n\n</details>\n\n### Request Life Cycle Hooks\n\nLitestar supports request life cycle hooks, similarly to Flask - i.e. `before_request` and `after_request`\n\n## Performance\n\nLitestar is fast. It is on par with, or significantly faster than comparable ASGI frameworks.\n\nYou can see and run the benchmarks [here](https://github.com/litestar-org/api-performance-tests),\nor read more about it [here](https://docs.litestar.dev/latest/benchmarks) in our documentation.\n\n## Contributing\n\nLitestar is open to contributions big and small. You can always [join our discord](https://discord.gg/X3FJqy8d2j) server\nor [join our Matrix](https://matrix.to/#/#litestar:matrix.org) space\nto discuss contributions and project maintenance. For guidelines on how to contribute, please\nsee [the contribution guide](CONTRIBUTING.rst).\n\n<!-- contributors-start -->\n\n## Contributors \n\n<details>\n\n<summary>Thanks goes to these wonderful people:</summary>\n<a href=\"https://allcontributors.org/docs/en/emoji-key\">Emoji Key </a>\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/nhirschfeld/\"><img src=\"https://avatars.githubusercontent.com/u/30733348?v=4?s=100\" width=\"100px;\" alt=\"Na'aman Hirschfeld\"/><br /><sub><b>Na'aman Hirschfeld</b></sub></a><br /><a href=\"#maintenance-Goldziher\" title=\"Maintenance\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=Goldziher\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=Goldziher\" title=\"Documentation\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=Goldziher\" title=\"Tests\"></a> <a href=\"#ideas-Goldziher\" title=\"Ideas, Planning, & Feedback\"></a> <a href=\"#example-Goldziher\" title=\"Examples\"></a> <a href=\"https://github.com/litestar-org/litestar/issues?q=author%3AGoldziher\" title=\"Bug reports\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/peterschutt\"><img src=\"https://avatars.githubusercontent.com/u/20659309?v=4?s=100\" width=\"100px;\" alt=\"Peter Schutt\"/><br /><sub><b>Peter Schutt</b></sub></a><br /><a href=\"#maintenance-peterschutt\" title=\"Maintenance\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=peterschutt\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=peterschutt\" title=\"Documentation\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=peterschutt\" title=\"Tests\"></a> <a href=\"#ideas-peterschutt\" title=\"Ideas, Planning, & Feedback\"></a> <a href=\"#example-peterschutt\" title=\"Examples\"></a> <a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Apeterschutt\" title=\"Bug reports\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://ashwinvin.github.io\"><img src=\"https://avatars.githubusercontent.com/u/38067089?v=4?s=100\" width=\"100px;\" alt=\"Ashwin Vinod\"/><br /><sub><b>Ashwin Vinod</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=ashwinvin\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=ashwinvin\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.damiankress.de\"><img src=\"https://avatars.githubusercontent.com/u/28515387?v=4?s=100\" width=\"100px;\" alt=\"Damian\"/><br /><sub><b>Damian</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=dkress59\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://remotepixel.ca\"><img src=\"https://avatars.githubusercontent.com/u/10407788?v=4?s=100\" width=\"100px;\" alt=\"Vincent Sarago\"/><br /><sub><b>Vincent Sarago</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=vincentsarago\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://hotfix.guru\"><img src=\"https://avatars.githubusercontent.com/u/5310116?v=4?s=100\" width=\"100px;\" alt=\"Jonas Krger Svensson\"/><br /><sub><b>Jonas Krger Svensson</b></sub></a><br /><a href=\"#platform-JonasKs\" title=\"Packaging/porting to new platform\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sondrelg\"><img src=\"https://avatars.githubusercontent.com/u/25310870?v=4?s=100\" width=\"100px;\" alt=\"Sondre Lilleb Gundersen\"/><br /><sub><b>Sondre Lilleb Gundersen</b></sub></a><br /><a href=\"#platform-sondrelg\" title=\"Packaging/porting to new platform\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/vrslev\"><img src=\"https://avatars.githubusercontent.com/u/75225148?v=4?s=100\" width=\"100px;\" alt=\"Lev\"/><br /><sub><b>Lev</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=vrslev\" title=\"Code\"></a> <a href=\"#ideas-vrslev\" title=\"Ideas, Planning, & Feedback\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/timwedde\"><img src=\"https://avatars.githubusercontent.com/u/20231751?v=4?s=100\" width=\"100px;\" alt=\"Tim Wedde\"/><br /><sub><b>Tim Wedde</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=timwedde\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tclasen\"><img src=\"https://avatars.githubusercontent.com/u/11999013?v=4?s=100\" width=\"100px;\" alt=\"Tory Clasen\"/><br /><sub><b>Tory Clasen</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=tclasen\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://t.me/Bobronium\"><img src=\"https://avatars.githubusercontent.com/u/36469655?v=4?s=100\" width=\"100px;\" alt=\"Arseny Boykov\"/><br /><sub><b>Arseny Boykov</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=Bobronium\" title=\"Code\"></a> <a href=\"#ideas-Bobronium\" title=\"Ideas, Planning, & Feedback\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/yudjinn\"><img src=\"https://avatars.githubusercontent.com/u/7493084?v=4?s=100\" width=\"100px;\" alt=\"Jacob Rodgers\"/><br /><sub><b>Jacob Rodgers</b></sub></a><br /><a href=\"#example-yudjinn\" title=\"Examples\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/danesolberg\"><img src=\"https://avatars.githubusercontent.com/u/25882507?v=4?s=100\" width=\"100px;\" alt=\"Dane Solberg\"/><br /><sub><b>Dane Solberg</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=danesolberg\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/madlad33\"><img src=\"https://avatars.githubusercontent.com/u/54079440?v=4?s=100\" width=\"100px;\" alt=\"madlad33\"/><br /><sub><b>madlad33</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=madlad33\" title=\"Code\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://matthewtyleraylward.com\"><img src=\"https://avatars.githubusercontent.com/u/19205392?v=4?s=100\" width=\"100px;\" alt=\"Matthew Aylward \"/><br /><sub><b>Matthew Aylward </b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=Butch78\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Joko013\"><img src=\"https://avatars.githubusercontent.com/u/30841710?v=4?s=100\" width=\"100px;\" alt=\"Jan Klima\"/><br /><sub><b>Jan Klima</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=Joko013\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/i404788\"><img src=\"https://avatars.githubusercontent.com/u/50617709?v=4?s=100\" width=\"100px;\" alt=\"C2D\"/><br /><sub><b>C2D</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=i404788\" title=\"Tests\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/to-ph\"><img src=\"https://avatars.githubusercontent.com/u/84818322?v=4?s=100\" width=\"100px;\" alt=\"to-ph\"/><br /><sub><b>to-ph</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=to-ph\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://imbev.gitlab.io/site\"><img src=\"https://avatars.githubusercontent.com/u/105524473?v=4?s=100\" width=\"100px;\" alt=\"imbev\"/><br /><sub><b>imbev</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=imbev\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://git.roboces.dev/catalin\"><img src=\"https://avatars.githubusercontent.com/u/45485069?v=4?s=100\" width=\"100px;\" alt=\"ctlin\"/><br /><sub><b>ctlin</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=185504a9\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Seon82\"><img src=\"https://avatars.githubusercontent.com/u/46298009?v=4?s=100\" width=\"100px;\" alt=\"Seon82\"/><br /><sub><b>Seon82</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=Seon82\" title=\"Documentation\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/slavugan\"><img src=\"https://avatars.githubusercontent.com/u/8457612?v=4?s=100\" width=\"100px;\" alt=\"Slava\"/><br /><sub><b>Slava</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=slavugan\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Harry-Lees\"><img src=\"https://avatars.githubusercontent.com/u/52263746?v=4?s=100\" width=\"100px;\" alt=\"Harry\"/><br /><sub><b>Harry</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=Harry-Lees\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=Harry-Lees\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/cofin\"><img src=\"https://avatars.githubusercontent.com/u/204685?v=4?s=100\" width=\"100px;\" alt=\"Cody Fincher\"/><br /><sub><b>Cody Fincher</b></sub></a><br /><a href=\"#maintenance-cofin\" title=\"Maintenance\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=cofin\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=cofin\" title=\"Documentation\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=cofin\" title=\"Tests\"></a> <a href=\"#ideas-cofin\" title=\"Ideas, Planning, & Feedback\"></a> <a href=\"#example-cofin\" title=\"Examples\"></a> <a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Acofin\" title=\"Bug reports\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.patreon.com/cclauss\"><img src=\"https://avatars.githubusercontent.com/u/3709715?v=4?s=100\" width=\"100px;\" alt=\"Christian Clauss\"/><br /><sub><b>Christian Clauss</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=cclauss\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/josepdaniel\"><img src=\"https://avatars.githubusercontent.com/u/36941460?v=4?s=100\" width=\"100px;\" alt=\"josepdaniel\"/><br /><sub><b>josepdaniel</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=josepdaniel\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/devtud\"><img src=\"https://avatars.githubusercontent.com/u/6808024?v=4?s=100\" width=\"100px;\" alt=\"devtud\"/><br /><sub><b>devtud</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Adevtud\" title=\"Bug reports\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nramos0\"><img src=\"https://avatars.githubusercontent.com/u/35410160?v=4?s=100\" width=\"100px;\" alt=\"Nicholas Ramos\"/><br /><sub><b>Nicholas Ramos</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=nramos0\" title=\"Code\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/seladb\"><img src=\"https://avatars.githubusercontent.com/u/9059541?v=4?s=100\" width=\"100px;\" alt=\"seladb\"/><br /><sub><b>seladb</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=seladb\" title=\"Documentation\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=seladb\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/aedify-swi\"><img src=\"https://avatars.githubusercontent.com/u/66629131?v=4?s=100\" width=\"100px;\" alt=\"Simon Wienhfer\"/><br /><sub><b>Simon Wienhfer</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=aedify-swi\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mobiusxs\"><img src=\"https://avatars.githubusercontent.com/u/57055149?v=4?s=100\" width=\"100px;\" alt=\"MobiusXS\"/><br /><sub><b>MobiusXS</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=mobiusxs\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://aidansimard.dev\"><img src=\"https://avatars.githubusercontent.com/u/73361895?v=4?s=100\" width=\"100px;\" alt=\"Aidan Simard\"/><br /><sub><b>Aidan Simard</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=Aidan-Simard\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/waweber\"><img src=\"https://avatars.githubusercontent.com/u/714224?v=4?s=100\" width=\"100px;\" alt=\"wweber\"/><br /><sub><b>wweber</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=waweber\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://scolvin.com\"><img src=\"https://avatars.githubusercontent.com/u/4039449?v=4?s=100\" width=\"100px;\" alt=\"Samuel Colvin\"/><br /><sub><b>Samuel Colvin</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=samuelcolvin\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/toudi\"><img src=\"https://avatars.githubusercontent.com/u/81148?v=4?s=100\" width=\"100px;\" alt=\"Mateusz Mikoajczyk\"/><br /><sub><b>Mateusz Mikoajczyk</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=toudi\" title=\"Code\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Alex-CodeLab\"><img src=\"https://avatars.githubusercontent.com/u/1678423?v=4?s=100\" width=\"100px;\" alt=\"Alex \"/><br /><sub><b>Alex </b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=Alex-CodeLab\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/odiseo0\"><img src=\"https://avatars.githubusercontent.com/u/87550035?v=4?s=100\" width=\"100px;\" alt=\"Odiseo\"/><br /><sub><b>Odiseo</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=odiseo0\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ingjavierpinilla\"><img src=\"https://avatars.githubusercontent.com/u/36714646?v=4?s=100\" width=\"100px;\" alt=\"Javier  Pinilla\"/><br /><sub><b>Javier  Pinilla</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=ingjavierpinilla\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Chaoyingz\"><img src=\"https://avatars.githubusercontent.com/u/32626585?v=4?s=100\" width=\"100px;\" alt=\"Chaoying\"/><br /><sub><b>Chaoying</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=Chaoyingz\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/infohash\"><img src=\"https://avatars.githubusercontent.com/u/46137868?v=4?s=100\" width=\"100px;\" alt=\"infohash\"/><br /><sub><b>infohash</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=infohash\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/john-ingles/\"><img src=\"https://avatars.githubusercontent.com/u/35442886?v=4?s=100\" width=\"100px;\" alt=\"John Ingles\"/><br /><sub><b>John Ingles</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=john-ingles\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/h0rn3t\"><img src=\"https://avatars.githubusercontent.com/u/1213719?v=4?s=100\" width=\"100px;\" alt=\"Eugene\"/><br /><sub><b>Eugene</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=h0rn3t\" title=\"Tests\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=h0rn3t\" title=\"Code\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jonadaly\"><img src=\"https://avatars.githubusercontent.com/u/26462826?v=4?s=100\" width=\"100px;\" alt=\"Jon Daly\"/><br /><sub><b>Jon Daly</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=jonadaly\" title=\"Documentation\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=jonadaly\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://harshallaheri.me/\"><img src=\"https://avatars.githubusercontent.com/u/73422191?v=4?s=100\" width=\"100px;\" alt=\"Harshal Laheri\"/><br /><sub><b>Harshal Laheri</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=Harshal6927\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=Harshal6927\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sorasful\"><img src=\"https://avatars.githubusercontent.com/u/32820423?v=4?s=100\" width=\"100px;\" alt=\"Tva KRIEF\"/><br /><sub><b>Tva KRIEF</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=sorasful\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jtraub\"><img src=\"https://avatars.githubusercontent.com/u/153191?v=4?s=100\" width=\"100px;\" alt=\"Konstantin Mikhailov\"/><br /><sub><b>Konstantin Mikhailov</b></sub></a><br /><a href=\"#maintenance-jtraub\" title=\"Maintenance\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=jtraub\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=jtraub\" title=\"Documentation\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=jtraub\" title=\"Tests\"></a> <a href=\"#ideas-jtraub\" title=\"Ideas, Planning, & Feedback\"></a> <a href=\"#example-jtraub\" title=\"Examples\"></a> <a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Ajtraub\" title=\"Bug reports\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://linkedin.com/in/mitchell-henry334/\"><img src=\"https://avatars.githubusercontent.com/u/17354727?v=4?s=100\" width=\"100px;\" alt=\"Mitchell Henry\"/><br /><sub><b>Mitchell Henry</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=devmitch\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/chbndrhnns\"><img src=\"https://avatars.githubusercontent.com/u/7534547?v=4?s=100\" width=\"100px;\" alt=\"chbndrhnns\"/><br /><sub><b>chbndrhnns</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=chbndrhnns\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nielsvanhooy\"><img src=\"https://avatars.githubusercontent.com/u/40770348?v=4?s=100\" width=\"100px;\" alt=\"nielsvanhooy\"/><br /><sub><b>nielsvanhooy</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=nielsvanhooy\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Anielsvanhooy\" title=\"Bug reports\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=nielsvanhooy\" title=\"Tests\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/provinzkraut\"><img src=\"https://avatars.githubusercontent.com/u/25355197?v=4?s=100\" width=\"100px;\" alt=\"provinzkraut\"/><br /><sub><b>provinzkraut</b></sub></a><br /><a href=\"#maintenance-provinzkraut\" title=\"Maintenance\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=provinzkraut\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=provinzkraut\" title=\"Documentation\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=provinzkraut\" title=\"Tests\"></a> <a href=\"#ideas-provinzkraut\" title=\"Ideas, Planning, & Feedback\"></a> <a href=\"#example-provinzkraut\" title=\"Examples\"></a> <a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Aprovinzkraut\" title=\"Bug reports\"></a> <a href=\"#design-provinzkraut\" title=\"Design\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jab\"><img src=\"https://avatars.githubusercontent.com/u/64992?v=4?s=100\" width=\"100px;\" alt=\"Joshua Bronson\"/><br /><sub><b>Joshua Bronson</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=jab\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://linkedin.com/in/roman-reznikov\"><img src=\"https://avatars.githubusercontent.com/u/44291988?v=4?s=100\" width=\"100px;\" alt=\"Roman Reznikov\"/><br /><sub><b>Roman Reznikov</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=ReznikovRoman\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://mookrs.com\"><img src=\"https://avatars.githubusercontent.com/u/985439?v=4?s=100\" width=\"100px;\" alt=\"mookrs\"/><br /><sub><b>mookrs</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=mookrs\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://mike.depalatis.net\"><img src=\"https://avatars.githubusercontent.com/u/2805515?v=4?s=100\" width=\"100px;\" alt=\"Mike DePalatis\"/><br /><sub><b>Mike DePalatis</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=mivade\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pemocarlo\"><img src=\"https://avatars.githubusercontent.com/u/7297323?v=4?s=100\" width=\"100px;\" alt=\"Carlos Alberto Prez-Molano\"/><br /><sub><b>Carlos Alberto Prez-Molano</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=pemocarlo\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.bestcryptocodes.com\"><img src=\"https://avatars.githubusercontent.com/u/114229148?v=4?s=100\" width=\"100px;\" alt=\"ThinksFast\"/><br /><sub><b>ThinksFast</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=ThinksFast\" title=\"Tests\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=ThinksFast\" title=\"Documentation\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ottermata\"><img src=\"https://avatars.githubusercontent.com/u/9451844?v=4?s=100\" width=\"100px;\" alt=\"Christopher Krause\"/><br /><sub><b>Christopher Krause</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=ottermata\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.kylesmith.me\"><img src=\"https://avatars.githubusercontent.com/u/1161424?v=4?s=100\" width=\"100px;\" alt=\"Kyle Smith\"/><br /><sub><b>Kyle Smith</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=smithk86\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=smithk86\" title=\"Documentation\"></a> <a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Asmithk86\" title=\"Bug reports\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/scott2b\"><img src=\"https://avatars.githubusercontent.com/u/307713?v=4?s=100\" width=\"100px;\" alt=\"Scott Bradley\"/><br /><sub><b>Scott Bradley</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Ascott2b\" title=\"Bug reports\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/srikanthccv/\"><img src=\"https://avatars.githubusercontent.com/u/22846633?v=4?s=100\" width=\"100px;\" alt=\"Srikanth Chekuri\"/><br /><sub><b>Srikanth Chekuri</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=srikanthccv\" title=\"Tests\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=srikanthccv\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://lonelyviking.com\"><img src=\"https://avatars.githubusercontent.com/u/78952809?v=4?s=100\" width=\"100px;\" alt=\"Michael Bosch\"/><br /><sub><b>Michael Bosch</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=LonelyVikingMichael\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sssssss340\"><img src=\"https://avatars.githubusercontent.com/u/8406195?v=4?s=100\" width=\"100px;\" alt=\"sssssss340\"/><br /><sub><b>sssssss340</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Asssssss340\" title=\"Bug reports\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ste-pool\"><img src=\"https://avatars.githubusercontent.com/u/17198460?v=4?s=100\" width=\"100px;\" alt=\"ste-pool\"/><br /><sub><b>ste-pool</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=ste-pool\" title=\"Code\"></a> <a href=\"#infra-ste-pool\" title=\"Infrastructure (Hosting, Build-Tools, etc)\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Alc-Alc\"><img src=\"https://avatars.githubusercontent.com/u/45509143?v=4?s=100\" width=\"100px;\" alt=\"Alc-Alc\"/><br /><sub><b>Alc-Alc</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=Alc-Alc\" title=\"Documentation\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=Alc-Alc\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=Alc-Alc\" title=\"Tests\"></a> <a href=\"#infra-Alc-Alc\" title=\"Infrastructure (Hosting, Build-Tools, etc)\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://asomethings.com\"><img src=\"https://avatars.githubusercontent.com/u/16171942?v=4?s=100\" width=\"100px;\" alt=\"asomethings\"/><br /><sub><b>asomethings</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=asomethings\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/garburator\"><img src=\"https://avatars.githubusercontent.com/u/14207857?v=4?s=100\" width=\"100px;\" alt=\"Garry Bullock\"/><br /><sub><b>Garry Bullock</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=garburator\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/NiclasHaderer\"><img src=\"https://avatars.githubusercontent.com/u/109728711?v=4?s=100\" width=\"100px;\" alt=\"Niclas Haderer\"/><br /><sub><b>Niclas Haderer</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=NiclasHaderer\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dialvarezs\"><img src=\"https://avatars.githubusercontent.com/u/13831919?v=4?s=100\" width=\"100px;\" alt=\"Diego Alvarez\"/><br /><sub><b>Diego Alvarez</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=dialvarezs\" title=\"Documentation\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=dialvarezs\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=dialvarezs\" title=\"Tests\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.rgare.com\"><img src=\"https://avatars.githubusercontent.com/u/51208317?v=4?s=100\" width=\"100px;\" alt=\"Jason Nance\"/><br /><sub><b>Jason Nance</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=rgajason\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/spikenn\"><img src=\"https://avatars.githubusercontent.com/u/32995595?v=4?s=100\" width=\"100px;\" alt=\"Igor Kapadze\"/><br /><sub><b>Igor Kapadze</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=spikenn\" title=\"Documentation\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://jarmos.vercel.app\"><img src=\"https://avatars.githubusercontent.com/u/31373860?v=4?s=100\" width=\"100px;\" alt=\"Somraj Saha\"/><br /><sub><b>Somraj Saha</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=Jarmos-san\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://skulason.me\"><img src=\"https://avatars.githubusercontent.com/u/11139514?v=4?s=100\" width=\"100px;\" alt=\"Magns gst Sklason\"/><br /><sub><b>Magns gst Sklason</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=maggias\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=maggias\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://alessioparma.xyz/\"><img src=\"https://avatars.githubusercontent.com/u/4697032?v=4?s=100\" width=\"100px;\" alt=\"Alessio Parma\"/><br /><sub><b>Alessio Parma</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=pomma89\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Lugoues\"><img src=\"https://avatars.githubusercontent.com/u/372610?v=4?s=100\" width=\"100px;\" alt=\"Peter Brunner\"/><br /><sub><b>Peter Brunner</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=Lugoues\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://scriptr.dev/\"><img src=\"https://avatars.githubusercontent.com/u/45884264?v=4?s=100\" width=\"100px;\" alt=\"Jacob Coffee\"/><br /><sub><b>Jacob Coffee</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=JacobCoffee\" title=\"Documentation\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=JacobCoffee\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=JacobCoffee\" title=\"Tests\"></a> <a href=\"#infra-JacobCoffee\" title=\"Infrastructure (Hosting, Build-Tools, etc)\"></a> <a href=\"#ideas-JacobCoffee\" title=\"Ideas, Planning, & Feedback\"></a> <a href=\"#maintenance-JacobCoffee\" title=\"Maintenance\"></a> <a href=\"#business-JacobCoffee\" title=\"Business development\"></a> <a href=\"#design-JacobCoffee\" title=\"Design\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Gamazic\"><img src=\"https://avatars.githubusercontent.com/u/33692402?v=4?s=100\" width=\"100px;\" alt=\"Gamazic\"/><br /><sub><b>Gamazic</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=Gamazic\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kareemmahlees\"><img src=\"https://avatars.githubusercontent.com/u/89863279?v=4?s=100\" width=\"100px;\" alt=\"Kareem Mahlees\"/><br /><sub><b>Kareem Mahlees</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=kareemmahlees\" title=\"Code\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/abdulhaq-e\"><img src=\"https://avatars.githubusercontent.com/u/2532125?v=4?s=100\" width=\"100px;\" alt=\"Abdulhaq Emhemmed\"/><br /><sub><b>Abdulhaq Emhemmed</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=abdulhaq-e\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=abdulhaq-e\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jenish2014\"><img src=\"https://avatars.githubusercontent.com/u/9599888?v=4?s=100\" width=\"100px;\" alt=\"Jenish\"/><br /><sub><b>Jenish</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=jenish2014\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=jenish2014\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/chris-telemetry\"><img src=\"https://avatars.githubusercontent.com/u/78052999?v=4?s=100\" width=\"100px;\" alt=\"chris-telemetry\"/><br /><sub><b>chris-telemetry</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=chris-telemetry\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://wardpearce.com\"><img src=\"https://avatars.githubusercontent.com/u/27844174?v=4?s=100\" width=\"100px;\" alt=\"Ward\"/><br /><sub><b>Ward</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/issues?q=author%3AWardPearce\" title=\"Bug reports\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://knowsuchagency.com\"><img src=\"https://avatars.githubusercontent.com/u/11974795?v=4?s=100\" width=\"100px;\" alt=\"Stephan Fitzpatrick\"/><br /><sub><b>Stephan Fitzpatrick</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Aknowsuchagency\" title=\"Bug reports\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://codepen.io/ekeric13/\"><img src=\"https://avatars.githubusercontent.com/u/6489651?v=4?s=100\" width=\"100px;\" alt=\"Eric Kennedy\"/><br /><sub><b>Eric Kennedy</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=ekeric13\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/wassafshahzad\"><img src=\"https://avatars.githubusercontent.com/u/25094157?v=4?s=100\" width=\"100px;\" alt=\"wassaf shahzad\"/><br /><sub><b>wassaf shahzad</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=wassafshahzad\" title=\"Code\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://nilsso.github.io\"><img src=\"https://avatars.githubusercontent.com/u/567181?v=4?s=100\" width=\"100px;\" alt=\"Nils Olsson\"/><br /><sub><b>Nils Olsson</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=nilsso\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Anilsso\" title=\"Bug reports\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://rileychase.net\"><img src=\"https://avatars.githubusercontent.com/u/1491530?v=4?s=100\" width=\"100px;\" alt=\"Riley Chase\"/><br /><sub><b>Riley Chase</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=Nadock\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://gh.arielle.codes\"><img src=\"https://avatars.githubusercontent.com/u/71233171?v=4?s=100\" width=\"100px;\" alt=\"arl\"/><br /><sub><b>arl</b></sub></a><br /><a href=\"#maintenance-onerandomusername\" title=\"Maintenance\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Galdanwing\"><img src=\"https://avatars.githubusercontent.com/u/29492757?v=4?s=100\" width=\"100px;\" alt=\"Antoine van der Horst\"/><br /><sub><b>Antoine van der Horst</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=Galdanwing\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://nick.groenen.me\"><img src=\"https://avatars.githubusercontent.com/u/145285?v=4?s=100\" width=\"100px;\" alt=\"Nick Groenen\"/><br /><sub><b>Nick Groenen</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=zoni\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/giorgiovilardo\"><img src=\"https://avatars.githubusercontent.com/u/56472600?v=4?s=100\" width=\"100px;\" alt=\"Giorgio Vilardo\"/><br /><sub><b>Giorgio Vilardo</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=giorgiovilardo\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/bollwyvl\"><img src=\"https://avatars.githubusercontent.com/u/45380?v=4?s=100\" width=\"100px;\" alt=\"Nicholas Bollweg\"/><br /><sub><b>Nicholas Bollweg</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=bollwyvl\" title=\"Code\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tompin82\"><img src=\"https://avatars.githubusercontent.com/u/47041409?v=4?s=100\" width=\"100px;\" alt=\"Tomas Jonsson\"/><br /><sub><b>Tomas Jonsson</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=tompin82\" title=\"Tests\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=tompin82\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/khiem-doan/\"><img src=\"https://avatars.githubusercontent.com/u/15646249?v=4?s=100\" width=\"100px;\" alt=\"Khiem Doan\"/><br /><sub><b>Khiem Doan</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=khiemdoan\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kedod\"><img src=\"https://avatars.githubusercontent.com/u/35638715?v=4?s=100\" width=\"100px;\" alt=\"kedod\"/><br /><sub><b>kedod</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=kedod\" title=\"Documentation\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=kedod\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=kedod\" title=\"Tests\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sonpro1296\"><img src=\"https://avatars.githubusercontent.com/u/17319142?v=4?s=100\" width=\"100px;\" alt=\"sonpro1296\"/><br /><sub><b>sonpro1296</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=sonpro1296\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=sonpro1296\" title=\"Tests\"></a> <a href=\"#infra-sonpro1296\" title=\"Infrastructure (Hosting, Build-Tools, etc)\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=sonpro1296\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://patrickarmengol.com\"><img src=\"https://avatars.githubusercontent.com/u/42473149?v=4?s=100\" width=\"100px;\" alt=\"Patrick Armengol\"/><br /><sub><b>Patrick Armengol</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=patrickarmengol\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://sanderwegter.nl\"><img src=\"https://avatars.githubusercontent.com/u/7465799?v=4?s=100\" width=\"100px;\" alt=\"Sander\"/><br /><sub><b>Sander</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=SanderWegter\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/erhuabushuo\"><img src=\"https://avatars.githubusercontent.com/u/1642364?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b></b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=erhuabushuo\" title=\"Documentation\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/aviral-nayya\"><img src=\"https://avatars.githubusercontent.com/u/121891493?v=4?s=100\" width=\"100px;\" alt=\"aviral-nayya\"/><br /><sub><b>aviral-nayya</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=aviral-nayya\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/whiskeyriver\"><img src=\"https://avatars.githubusercontent.com/u/162092?v=4?s=100\" width=\"100px;\" alt=\"whiskeyriver\"/><br /><sub><b>whiskeyriver</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=whiskeyriver\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://hexcode.tech\"><img src=\"https://avatars.githubusercontent.com/u/419606?v=4?s=100\" width=\"100px;\" alt=\"Phyo Arkar Lwin\"/><br /><sub><b>Phyo Arkar Lwin</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=v3ss0n\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/MatthewNewland\"><img src=\"https://avatars.githubusercontent.com/u/9618670?v=4?s=100\" width=\"100px;\" alt=\"MatthewNewland\"/><br /><sub><b>MatthewNewland</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/issues?q=author%3AMatthewNewland\" title=\"Bug reports\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=MatthewNewland\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=MatthewNewland\" title=\"Tests\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/vtarchon\"><img src=\"https://avatars.githubusercontent.com/u/1598170?v=4?s=100\" width=\"100px;\" alt=\"Tom Kuo\"/><br /><sub><b>Tom Kuo</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Avtarchon\" title=\"Bug reports\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/LeckerenSirupwaffeln\"><img src=\"https://avatars.githubusercontent.com/u/83568015?v=4?s=100\" width=\"100px;\" alt=\"LeckerenSirupwaffeln\"/><br /><sub><b>LeckerenSirupwaffeln</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/issues?q=author%3ALeckerenSirupwaffeln\" title=\"Bug reports\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/eldano1995\"><img src=\"https://avatars.githubusercontent.com/u/24553679?v=4?s=100\" width=\"100px;\" alt=\"Daniel Gonzlez Fernndez\"/><br /><sub><b>Daniel Gonzlez Fernndez</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=eldano1995\" title=\"Documentation\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/01EK98\"><img src=\"https://avatars.githubusercontent.com/u/101988390?v=4?s=100\" width=\"100px;\" alt=\"01EK98\"/><br /><sub><b>01EK98</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=01EK98\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sarbor\"><img src=\"https://avatars.githubusercontent.com/u/15257226?v=4?s=100\" width=\"100px;\" alt=\"Sarbo Roy\"/><br /><sub><b>Sarbo Roy</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=sarbor\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rseeley\"><img src=\"https://avatars.githubusercontent.com/u/5397221?v=4?s=100\" width=\"100px;\" alt=\"Ryan Seeley\"/><br /><sub><b>Ryan Seeley</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=rseeley\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ctrl-Felix\"><img src=\"https://avatars.githubusercontent.com/u/62290842?v=4?s=100\" width=\"100px;\" alt=\"Felix\"/><br /><sub><b>Felix</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=ctrl-Felix\" title=\"Documentation\"></a> <a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Actrl-Felix\" title=\"Bug reports\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/gsakkis\"><img src=\"https://avatars.githubusercontent.com/u/291289?v=4?s=100\" width=\"100px;\" alt=\"George Sakkis\"/><br /><sub><b>George Sakkis</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=gsakkis\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/floxay\"><img src=\"https://avatars.githubusercontent.com/u/57007485?v=4?s=100\" width=\"100px;\" alt=\"Huba Tuba\"/><br /><sub><b>Huba Tuba</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=floxay\" title=\"Documentation\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=floxay\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=floxay\" title=\"Tests\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://fermigier.com/\"><img src=\"https://avatars.githubusercontent.com/u/271079?v=4?s=100\" width=\"100px;\" alt=\"Stefane Fermigier\"/><br /><sub><b>Stefane Fermigier</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=sfermigier\" title=\"Documentation\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/r4gesingh47\"><img src=\"https://avatars.githubusercontent.com/u/71139938?v=4?s=100\" width=\"100px;\" alt=\"r4ge\"/><br /><sub><b>r4ge</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=r4gesingh47\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=r4gesingh47\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jaykv\"><img src=\"https://avatars.githubusercontent.com/u/18240054?v=4?s=100\" width=\"100px;\" alt=\"Jay\"/><br /><sub><b>Jay</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=jaykv\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sinisaos\"><img src=\"https://avatars.githubusercontent.com/u/30960668?v=4?s=100\" width=\"100px;\" alt=\"sinisaos\"/><br /><sub><b>sinisaos</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=sinisaos\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Tsdevendra1\"><img src=\"https://avatars.githubusercontent.com/u/38055748?v=4?s=100\" width=\"100px;\" alt=\"Tharuka Devendra\"/><br /><sub><b>Tharuka Devendra</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=Tsdevendra1\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/euri10\"><img src=\"https://avatars.githubusercontent.com/u/1104190?v=4?s=100\" width=\"100px;\" alt=\"euri10\"/><br /><sub><b>euri10</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=euri10\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=euri10\" title=\"Documentation\"></a> <a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Aeuri10\" title=\"Bug reports\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/su-shubham\"><img src=\"https://avatars.githubusercontent.com/u/75021117?v=4?s=100\" width=\"100px;\" alt=\"Shubham\"/><br /><sub><b>Shubham</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=su-shubham\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/erik-hasse\"><img src=\"https://avatars.githubusercontent.com/u/37126755?v=4?s=100\" width=\"100px;\" alt=\"Erik Hasse\"/><br /><sub><b>Erik Hasse</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Aerik-hasse\" title=\"Bug reports\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=erik-hasse\" title=\"Code\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://sobolevn.me\"><img src=\"https://avatars.githubusercontent.com/u/4660275?v=4?s=100\" width=\"100px;\" alt=\"Nikita Sobolev\"/><br /><sub><b>Nikita Sobolev</b></sub></a><br /><a href=\"#infra-sobolevn\" title=\"Infrastructure (Hosting, Build-Tools, etc)\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=sobolevn\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lazyc97\"><img src=\"https://avatars.githubusercontent.com/u/8538104?v=4?s=100\" width=\"100px;\" alt=\"Nguyn Hong c\"/><br /><sub><b>Nguyn Hong c</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Alazyc97\" title=\"Bug reports\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/RavanaBhrama\"><img src=\"https://avatars.githubusercontent.com/u/131459969?v=4?s=100\" width=\"100px;\" alt=\"RavanaBhrama\"/><br /><sub><b>RavanaBhrama</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=RavanaBhrama\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mj0nez\"><img src=\"https://avatars.githubusercontent.com/u/20128340?v=4?s=100\" width=\"100px;\" alt=\"Marcel Johannesmann\"/><br /><sub><b>Marcel Johannesmann</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=mj0nez\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://zanfar.com/\"><img src=\"https://avatars.githubusercontent.com/u/10294685?v=4?s=100\" width=\"100px;\" alt=\"Matthew\"/><br /><sub><b>Matthew</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=therealzanfar\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Mattwmaster58\"><img src=\"https://avatars.githubusercontent.com/u/26337069?v=4?s=100\" width=\"100px;\" alt=\"Mattwmaster58\"/><br /><sub><b>Mattwmaster58</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/issues?q=author%3AMattwmaster58\" title=\"Bug reports\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=Mattwmaster58\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=Mattwmaster58\" title=\"Tests\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://es.linkedin.com/in/manusp\"><img src=\"https://avatars.githubusercontent.com/u/5411704?v=4?s=100\" width=\"100px;\" alt=\"Manuel Sanchez Pinar\"/><br /><sub><b>Manuel Sanchez Pinar</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=aorith\" title=\"Documentation\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/juan-riveros\"><img src=\"https://avatars.githubusercontent.com/u/1297567?v=4?s=100\" width=\"100px;\" alt=\"Juan Riveros\"/><br /><sub><b>Juan Riveros</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=juan-riveros\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/davidbrochart\"><img src=\"https://avatars.githubusercontent.com/u/4711805?v=4?s=100\" width=\"100px;\" alt=\"David Brochart\"/><br /><sub><b>David Brochart</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=davidbrochart\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sean-donoghue\"><img src=\"https://avatars.githubusercontent.com/u/64597271?v=4?s=100\" width=\"100px;\" alt=\"Sean Donoghue\"/><br /><sub><b>Sean Donoghue</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=sean-donoghue\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://sykloid.org/\"><img src=\"https://avatars.githubusercontent.com/u/22753?v=4?s=100\" width=\"100px;\" alt=\"P.C. Shyamshankar\"/><br /><sub><b>P.C. Shyamshankar</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Asykloid\" title=\"Bug reports\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=sykloid\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=sykloid\" title=\"Tests\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/wevonosky\"><img src=\"https://avatars.githubusercontent.com/u/19598171?v=4?s=100\" width=\"100px;\" alt=\"William Evonosky\"/><br /><sub><b>William Evonosky</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=wevonosky\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/geeshta\"><img src=\"https://avatars.githubusercontent.com/u/61031243?v=4?s=100\" width=\"100px;\" alt=\"geeshta\"/><br /><sub><b>geeshta</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=geeshta\" title=\"Documentation\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=geeshta\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Ageeshta\" title=\"Bug reports\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://fosstodon.org/@robertrosca\"><img src=\"https://avatars.githubusercontent.com/u/32569096?v=4?s=100\" width=\"100px;\" alt=\"Robert Rosca\"/><br /><sub><b>Robert Rosca</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=RobertRosca\" title=\"Documentation\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/syshenyu\"><img src=\"https://avatars.githubusercontent.com/u/92897003?v=4?s=100\" width=\"100px;\" alt=\"DICE_Lab\"/><br /><sub><b>DICE_Lab</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=syshenyu\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lsanpablo\"><img src=\"https://avatars.githubusercontent.com/u/7145688?v=4?s=100\" width=\"100px;\" alt=\"Luis San Pablo\"/><br /><sub><b>Luis San Pablo</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=lsanpablo\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=lsanpablo\" title=\"Tests\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=lsanpablo\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Lancetnik\"><img src=\"https://avatars.githubusercontent.com/u/44573917?v=4?s=100\" width=\"100px;\" alt=\"Pastukhov Nikita\"/><br /><sub><b>Pastukhov Nikita</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=Lancetnik\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://jamesoclaire.com\"><img src=\"https://avatars.githubusercontent.com/u/7601451?v=4?s=100\" width=\"100px;\" alt=\"James O'Claire\"/><br /><sub><b>James O'Claire</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=ddxv\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pbaletkeman\"><img src=\"https://avatars.githubusercontent.com/u/22402240?v=4?s=100\" width=\"100px;\" alt=\"Pete\"/><br /><sub><b>Pete</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=pbaletkeman\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.hera.cc\"><img src=\"https://avatars.githubusercontent.com/u/534840?v=4?s=100\" width=\"100px;\" alt=\"Alexandre Richonnier\"/><br /><sub><b>Alexandre Richonnier</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=heralight\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=heralight\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/betaboon\"><img src=\"https://avatars.githubusercontent.com/u/7346933?v=4?s=100\" width=\"100px;\" alt=\"betaboon\"/><br /><sub><b>betaboon</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=betaboon\" title=\"Code\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/brakhane\"><img src=\"https://avatars.githubusercontent.com/u/541637?v=4?s=100\" width=\"100px;\" alt=\"Dennis Brakhane\"/><br /><sub><b>Dennis Brakhane</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=brakhane\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Abrakhane\" title=\"Bug reports\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://mind.wiki\"><img src=\"https://avatars.githubusercontent.com/u/7423639?v=4?s=100\" width=\"100px;\" alt=\"Pragy Agarwal\"/><br /><sub><b>Pragy Agarwal</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=AgarwalPragy\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dybi\"><img src=\"https://avatars.githubusercontent.com/u/36961162?v=4?s=100\" width=\"100px;\" alt=\"Piotr Dybowski\"/><br /><sub><b>Piotr Dybowski</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=dybi\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/myslak71\"><img src=\"https://avatars.githubusercontent.com/u/43068450?v=4?s=100\" width=\"100px;\" alt=\"Konrad Szczurek\"/><br /><sub><b>Konrad Szczurek</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=myslak71\" title=\"Documentation\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=myslak71\" title=\"Tests\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/orgarten\"><img src=\"https://avatars.githubusercontent.com/u/10799869?v=4?s=100\" width=\"100px;\" alt=\"Orell Garten\"/><br /><sub><b>Orell Garten</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=orgarten\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=orgarten\" title=\"Documentation\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=orgarten\" title=\"Tests\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Kumzy\"><img src=\"https://avatars.githubusercontent.com/u/5995441?v=4?s=100\" width=\"100px;\" alt=\"Julien\"/><br /><sub><b>Julien</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=Kumzy\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/leejayhsu\"><img src=\"https://avatars.githubusercontent.com/u/37034741?v=4?s=100\" width=\"100px;\" alt=\"Leejay Hsu\"/><br /><sub><b>Leejay Hsu</b></sub></a><br /><a href=\"#maintenance-leejayhsu\" title=\"Maintenance\"></a> <a href=\"#infra-leejayhsu\" title=\"Infrastructure (Hosting, Build-Tools, etc)\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=leejayhsu\" title=\"Documentation\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://x14.nl\"><img src=\"https://avatars.githubusercontent.com/u/659504?v=4?s=100\" width=\"100px;\" alt=\"Michiel W. Beijen\"/><br /><sub><b>Michiel W. Beijen</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=mbeijen\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/baoliay2008\"><img src=\"https://avatars.githubusercontent.com/u/13620348?v=4?s=100\" width=\"100px;\" alt=\"L. Bao\"/><br /><sub><b>L. Bao</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=baoliay2008\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://jarredglaser.com\"><img src=\"https://avatars.githubusercontent.com/u/32422167?v=4?s=100\" width=\"100px;\" alt=\"Jarred Glaser\"/><br /><sub><b>Jarred Glaser</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=jdglaser\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/hunterjsb\"><img src=\"https://avatars.githubusercontent.com/u/69213737?v=4?s=100\" width=\"100px;\" alt=\"Hunter Boyd\"/><br /><sub><b>Hunter Boyd</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=hunterjsb\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/cesarmg1980\"><img src=\"https://avatars.githubusercontent.com/u/38872121?v=4?s=100\" width=\"100px;\" alt=\"Cesar Giulietti\"/><br /><sub><b>Cesar Giulietti</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=cesarmg1980\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://gitlab.com/marcuslimdw/\"><img src=\"https://avatars.githubusercontent.com/u/42759889?v=4?s=100\" width=\"100px;\" alt=\"Marcus Lim\"/><br /><sub><b>Marcus Lim</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=marcuslimdw\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/hzhou0\"><img src=\"https://avatars.githubusercontent.com/u/43188301?v=4?s=100\" width=\"100px;\" alt=\"Henry Zhou\"/><br /><sub><b>Henry Zhou</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Ahzhou0\" title=\"Bug reports\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=hzhou0\" title=\"Code\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/WilliamStam\"><img src=\"https://avatars.githubusercontent.com/u/182800?v=4?s=100\" width=\"100px;\" alt=\"William Stam\"/><br /><sub><b>William Stam</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=WilliamStam\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/andrewdoh\"><img src=\"https://avatars.githubusercontent.com/u/7662358?v=4?s=100\" width=\"100px;\" alt=\"andrew do\"/><br /><sub><b>andrew do</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=andrewdoh\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=andrewdoh\" title=\"Tests\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=andrewdoh\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/cbscsm\"><img src=\"https://avatars.githubusercontent.com/u/31615733?v=4?s=100\" width=\"100px;\" alt=\"Boseong Choi\"/><br /><sub><b>Boseong Choi</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=cbscsm\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=cbscsm\" title=\"Tests\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/wer153\"><img src=\"https://avatars.githubusercontent.com/u/23370765?v=4?s=100\" width=\"100px;\" alt=\"Kim Minki\"/><br /><sub><b>Kim Minki</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=wer153\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=wer153\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://velog.io/@azzurri21\"><img src=\"https://avatars.githubusercontent.com/u/86508420?v=4?s=100\" width=\"100px;\" alt=\"Jeongseop Lim\"/><br /><sub><b>Jeongseop Lim</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=jseop-lim\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/FergusMok\"><img src=\"https://avatars.githubusercontent.com/u/10182564?v=4?s=100\" width=\"100px;\" alt=\"FergusMok\"/><br /><sub><b>FergusMok</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=FergusMok\" title=\"Documentation\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=FergusMok\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=FergusMok\" title=\"Tests\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/manusinghal19\"><img src=\"https://avatars.githubusercontent.com/u/8455587?v=4?s=100\" width=\"100px;\" alt=\"Manu Singhal\"/><br /><sub><b>Manu Singhal</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=manusinghal19\" title=\"Documentation\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://cv.ycwu.space\"><img src=\"https://avatars.githubusercontent.com/u/67060418?v=4?s=100\" width=\"100px;\" alt=\"Jerry Wu\"/><br /><sub><b>Jerry Wu</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=jrycw\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/horo-fox\"><img src=\"https://avatars.githubusercontent.com/u/143025439?v=4?s=100\" width=\"100px;\" alt=\"horo\"/><br /><sub><b>horo</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Ahoro-fox\" title=\"Bug reports\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/rosstitmarsh\"><img src=\"https://avatars.githubusercontent.com/u/23349806?v=4?s=100\" width=\"100px;\" alt=\"Ross Titmarsh\"/><br /><sub><b>Ross Titmarsh</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=rosstitmarsh\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/korneevm\"><img src=\"https://avatars.githubusercontent.com/u/743250?v=4?s=100\" width=\"100px;\" alt=\"Mike Korneev\"/><br /><sub><b>Mike Korneev</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=korneevm\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/patrickneise\"><img src=\"https://avatars.githubusercontent.com/u/6312074?v=4?s=100\" width=\"100px;\" alt=\"Patrick Neise\"/><br /><sub><b>Patrick Neise</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=patrickneise\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/JeanArhancet\"><img src=\"https://avatars.githubusercontent.com/u/10811879?v=4?s=100\" width=\"100px;\" alt=\"Jean Arhancet\"/><br /><sub><b>Jean Arhancet</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/issues?q=author%3AJeanArhancet\" title=\"Bug reports\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://dnquark.com\"><img src=\"https://avatars.githubusercontent.com/u/338250?v=4?s=100\" width=\"100px;\" alt=\"Leo Alekseyev\"/><br /><sub><b>Leo Alekseyev</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=betaprior\" title=\"Code\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/aranvir\"><img src=\"https://avatars.githubusercontent.com/u/75439739?v=4?s=100\" width=\"100px;\" alt=\"aranvir\"/><br /><sub><b>aranvir</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=aranvir\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/bunny-therapist\"><img src=\"https://avatars.githubusercontent.com/u/87039365?v=4?s=100\" width=\"100px;\" alt=\"bunny-therapist\"/><br /><sub><b>bunny-therapist</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=bunny-therapist\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.benluo.cc\"><img src=\"https://avatars.githubusercontent.com/u/70398?v=4?s=100\" width=\"100px;\" alt=\"Ben Luo\"/><br /><sub><b>Ben Luo</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=benluo\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/hugovk\"><img src=\"https://avatars.githubusercontent.com/u/1324225?v=4?s=100\" width=\"100px;\" alt=\"Hugo van Kemenade\"/><br /><sub><b>Hugo van Kemenade</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=hugovk\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://error418.github.io\"><img src=\"https://avatars.githubusercontent.com/u/7716544?v=4?s=100\" width=\"100px;\" alt=\"Michael Gerbig\"/><br /><sub><b>Michael Gerbig</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=error418\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/crisog\"><img src=\"https://avatars.githubusercontent.com/u/40803711?v=4?s=100\" width=\"100px;\" alt=\"CrisOG\"/><br /><sub><b>CrisOG</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Acrisog\" title=\"Bug reports\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=crisog\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=crisog\" title=\"Tests\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/haryle\"><img src=\"https://avatars.githubusercontent.com/u/64817481?v=4?s=100\" width=\"100px;\" alt=\"harryle\"/><br /><sub><b>harryle</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=haryle\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=haryle\" title=\"Tests\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.b-list.org/\"><img src=\"https://avatars.githubusercontent.com/u/12384?v=4?s=100\" width=\"100px;\" alt=\"James Bennett\"/><br /><sub><b>James Bennett</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Aubernostrum\" title=\"Bug reports\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sherbang\"><img src=\"https://avatars.githubusercontent.com/u/275015?v=4?s=100\" width=\"100px;\" alt=\"sherbang\"/><br /><sub><b>sherbang</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=sherbang\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/carlsmedstad\"><img src=\"https://avatars.githubusercontent.com/u/6952324?v=4?s=100\" width=\"100px;\" alt=\"Carl Smedstad\"/><br /><sub><b>Carl Smedstad</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=carlsmedstad\" title=\"Tests\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/maintain0404\"><img src=\"https://avatars.githubusercontent.com/u/50428534?v=4?s=100\" width=\"100px;\" alt=\"Taein Min\"/><br /><sub><b>Taein Min</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=maintain0404\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/wallseat\"><img src=\"https://avatars.githubusercontent.com/u/26143672?v=4?s=100\" width=\"100px;\" alt=\"Stanislav Lyu.\"/><br /><sub><b>Stanislav Lyu.</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/issues?q=author%3Awallseat\" title=\"Bug reports\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tibor-reiss\"><img src=\"https://avatars.githubusercontent.com/u/75096465?v=4?s=100\" width=\"100px;\" alt=\"Tibor Reiss\"/><br /><sub><b>Tibor Reiss</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=tibor-reiss\" title=\"Tests\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=tibor-reiss\" title=\"Documentation\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=tibor-reiss\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://pogrom.dev\"><img src=\"https://avatars.githubusercontent.com/u/11032969?v=4?s=100\" width=\"100px;\" alt=\"Alex\"/><br /><sub><b>Alex</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/issues?q=author%3A0xE111\" title=\"Bug reports\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=0xE111\" title=\"Code\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://0110.be\"><img src=\"https://avatars.githubusercontent.com/u/60453?v=4?s=100\" width=\"100px;\" alt=\"Joren Six\"/><br /><sub><b>Joren Six</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=JorenSix\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jderrien\"><img src=\"https://avatars.githubusercontent.com/u/145396?v=4?s=100\" width=\"100px;\" alt=\"jderrien\"/><br /><sub><b>jderrien</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=jderrien\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://possiblepanda.me\"><img src=\"https://avatars.githubusercontent.com/u/85448494?v=4?s=100\" width=\"100px;\" alt=\"PossiblePanda\"/><br /><sub><b>PossiblePanda</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=PossiblePanda\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/evstratbg\"><img src=\"https://avatars.githubusercontent.com/u/10176401?v=4?s=100\" width=\"100px;\" alt=\"evstrat\"/><br /><sub><b>evstrat</b></sub></a><br /><a href=\"#infra-evstratbg\" title=\"Infrastructure (Hosting, Build-Tools, etc)\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://speakerdeck.com/eltociear\"><img src=\"https://avatars.githubusercontent.com/u/22633385?v=4?s=100\" width=\"100px;\" alt=\"Ikko Eltociear Ashimine\"/><br /><sub><b>Ikko Eltociear Ashimine</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=eltociear\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/taihim\"><img src=\"https://avatars.githubusercontent.com/u/13764071?v=4?s=100\" width=\"100px;\" alt=\"Taimur Ibrahim\"/><br /><sub><b>Taimur Ibrahim</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=taihim\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/l-armstrong\"><img src=\"https://avatars.githubusercontent.com/u/43922258?v=4?s=100\" width=\"100px;\" alt=\"l-armstrong\"/><br /><sub><b>l-armstrong</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=l-armstrong\" title=\"Documentation\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Anu-cool-007\"><img src=\"https://avatars.githubusercontent.com/u/16525919?v=4?s=100\" width=\"100px;\" alt=\"Anuranjan Srivastava\"/><br /><sub><b>Anuranjan Srivastava</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=Anu-cool-007\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Zimzozaur\"><img src=\"https://avatars.githubusercontent.com/u/106471045?v=4?s=100\" width=\"100px;\" alt=\"Simon Joseph\"/><br /><sub><b>Simon Joseph</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=Zimzozaur\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/abelkm99\"><img src=\"https://avatars.githubusercontent.com/u/41730180?v=4?s=100\" width=\"100px;\" alt=\"Abel Kidanemariam\"/><br /><sub><b>Abel Kidanemariam</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=abelkm99\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=abelkm99\" title=\"Tests\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=abelkm99\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://blog.trim21.me/\"><img src=\"https://avatars.githubusercontent.com/u/13553903?v=4?s=100\" width=\"100px;\" alt=\"Trim21\"/><br /><sub><b>Trim21</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=trim21\" title=\"Code\"></a> <a href=\"https://github.com/litestar-org/litestar/commits?author=trim21\" title=\"Tests\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://aarcex3.github.io\"><img src=\"https://avatars.githubusercontent.com/u/59893355?v=4?s=100\" width=\"100px;\" alt=\"Agustin Arce\"/><br /><sub><b>Agustin Arce</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=aarcex3\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/FarhanAliRaza\"><img src=\"https://avatars.githubusercontent.com/u/62690310?v=4?s=100\" width=\"100px;\" alt=\"Farhan Ali Raza\"/><br /><sub><b>Farhan Ali Raza</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=FarhanAliRaza\" title=\"Documentation\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pogopaule\"><img src=\"https://avatars.githubusercontent.com/u/576949?v=4?s=100\" width=\"100px;\" alt=\"Fabian\"/><br /><sub><b>Fabian</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=pogopaule\" title=\"Code\"></a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mohammedbabelly20\"><img src=\"https://avatars.githubusercontent.com/u/104768048?v=4?s=100\" width=\"100px;\" alt=\"Mohammed Babelly\"/><br /><sub><b>Mohammed Babelly</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=mohammedbabelly20\" title=\"Code\"></a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://keybase.io/charlesdyfisnet\"><img src=\"https://avatars.githubusercontent.com/u/22370?v=4?s=100\" width=\"100px;\" alt=\"Charles Duffy\"/><br /><sub><b>Charles Duffy</b></sub></a><br /><a href=\"https://github.com/litestar-org/litestar/commits?author=charles-dyfis-net\" title=\"Code\"></a></td>\n    </tr>\n  </tbody>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n\nThis project follows the [all-contributors](https://github.com/all-contributors/all-contributors) specification.\nContributions of any kind welcome!\n\n</details>\n\n<!-- contributors-end -->\n",
        "num_commits": 2945,
        "project_age_days": 1058,
        "project_created_at": "2021-12-06",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 208,
        "num_pull": 2457,
        "num_issues": 3597,
        "num_opening_issue": 194,
        "project_size(kB)": 121093,
        "num_stargazers": 5493,
        "num_watchers": 5493,
        "num_forks": 374,
        "num_subscribers": 40,
        "SecurityPolicy_created_at": "2023-02-05 18:19:48",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "6eab985871806d2222b5c40e8a8f5bda02fc4ba8",
                "url": "https://github.com/litestar-org/.github/commit/6eab985871806d2222b5c40e8a8f5bda02fc4ba8",
                "date": "2023-04-19 19:01:02"
            },
            {
                "commit_id": "ba01e3707ff0f8a780f9db31c608e654c8ac5828",
                "url": "https://github.com/litestar-org/.github/commit/ba01e3707ff0f8a780f9db31c608e654c8ac5828",
                "date": "2023-02-13 19:47:38"
            },
            {
                "commit_id": "808a22a56b2b2eb16e4daea0759d4fdd1d538b02",
                "url": "https://github.com/litestar-org/.github/commit/808a22a56b2b2eb16e4daea0759d4fdd1d538b02",
                "date": "2023-02-07 16:14:17"
            },
            {
                "commit_id": "bc0aecc4b751fcd841e42581a48db98dcb2c06c0",
                "url": "https://github.com/litestar-org/.github/commit/bc0aecc4b751fcd841e42581a48db98dcb2c06c0",
                "date": "2023-02-06 17:40:39"
            },
            {
                "commit_id": "afcb7d950953453f2cf1375a1184fceb9a34bb2d",
                "url": "https://github.com/litestar-org/.github/commit/afcb7d950953453f2cf1375a1184fceb9a34bb2d",
                "date": "2023-02-06 17:39:10"
            },
            {
                "commit_id": "60ae63b46f7ace51f361a7168f30d2ccf70f49a4",
                "url": "https://github.com/litestar-org/.github/commit/60ae63b46f7ace51f361a7168f30d2ccf70f49a4",
                "date": "2023-02-06 17:12:31"
            },
            {
                "commit_id": "fb51e3e4876d189fb79a61c113813f344792f6dc",
                "url": "https://github.com/litestar-org/.github/commit/fb51e3e4876d189fb79a61c113813f344792f6dc",
                "date": "2023-02-05 18:19:48"
            }
        ],
        "project_security_labels": [
            "Security",
            "area/security",
            "Needs MCVE",
            "Great MCVE"
        ],
        "security_issues": [
            {
                "url": "https://github.com/litestar-org/litestar/issues/3829",
                "title": "Enhancement: provide security middleware",
                "labels": [
                    "Enhancement",
                    "Middleware",
                    "Security"
                ],
                "user": "sobolevn",
                "issue_author_association": "MEMBER",
                "number": 3829,
                "id": 2596576465,
                "state": "open",
                "project_created_at": "2024-10-18T06:43:35Z",
                "closed_at": null,
                "body": "### Summary\n\nDjango has a middleware that should always be used: https://docs.djangoproject.com/en/3.0/ref/middleware/#module-django.middleware.security\r\n\r\nI think that Litestar should also have it out of the box. \r\n\r\nWhat it does? It provide security-related headers for the responses.\r\n- [`X-Content-Type-Options: nosniff`](https://docs.djangoproject.com/en/3.0/ref/middleware/#x-content-type-options)\r\n- Secure SSL settings: https://docs.djangoproject.com/en/3.0/ref/middleware/#http-strict-transport-security\r\n- `Referrer-Policy: no-referrer` header (also supports other values: https://docs.djangoproject.com/en/3.0/ref/middleware/#referrer-policy)\r\n\r\nThere are also 3rd party django libs that also work in the same field:\r\n- https://github.com/adamchainz/django-permissions-policy which sets `Permissions-Policy` header\r\n\r\nMaybe something else that I forgot about?\r\n\r\nAll things should be customizable and work the regular way Litestar middleware works.\r\n\r\nIf others agree, I can work on this :)\n\n### Basic Example\n\n_No response_\n\n### Drawbacks and Impact\n\n_No response_\n\n### Unresolved questions\n\n_No response_\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n> [!NOTE]  \n> While we are open for sponsoring on [GitHub Sponsors](https://github.com/sponsors/litestar-org/) and \n> [OpenCollective](https://opencollective.com/litestar), we also utilize [Polar.sh](https://polar.sh/) to engage in pledge-based sponsorship.\n>\n> Check out all issues funded or available for funding [on our Polar.sh dashboard](https://polar.sh/litestar-org)\n> * If you would like to see an issue prioritized, make a pledge towards it!\n> * We receive the pledge once the issue is completed & verified\n> * This, along with engagement in the community, helps us know which features are a priority to our users.\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/3829\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/3829/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/3829/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/pull/3824",
                "title": "chore(mypy): enable `truthy-bool` error code",
                "labels": [
                    "Triage Required :hospital:",
                    "pr/external",
                    "pr/internal",
                    "size: small",
                    "area/private-api",
                    "area/dependencies",
                    "area/security"
                ],
                "user": "sobolevn",
                "issue_author_association": "MEMBER",
                "number": 3824,
                "id": 2593953691,
                "state": "open",
                "project_created_at": "2024-10-17T08:01:52Z",
                "closed_at": null,
                "body": "Docs: https://mypy.readthedocs.io/en/stable/error_code_list2.html#check-that-expression-is-not-implicitly-true-in-boolean-context-truthy-bool\r\n\r\nI am using `# type: ignore[truthy-bool]` for `.components` check, because I see that it is treated specially for some reason (like `pragma: no cover`). Is this correct?\r\n\r\nI also removed configs that are part of the `--strict` flag from settings.",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/litestar-org/litestar/pull/3824?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=litestar-org) Report\nAll modified and coverable lines are covered by tests :white_check_mark:\n> Project coverage is 98.42%. Comparing base [(`ffcecb1`)](https://app.codecov.io/gh/litestar-org/litestar/commit/ffcecb127fcca372df3474c0f465db4a257a3e51?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=litestar-org) to head [(`eb26f81`)](https://app.codecov.io/gh/litestar-org/litestar/commit/eb26f812de481c47634cfc5eebdb1b346526d71b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=litestar-org).\n\n<details><summary>Additional details and impacted files</summary>\n\n\n```diff\n@@            Coverage Diff             @@\n##             main    #3824      +/-   ##\n==========================================\n+ Coverage   98.41%   98.42%   +0.01%     \n==========================================\n  Files         332      332              \n  Lines       15500    15498       -2     \n  Branches     1703     1702       -1     \n==========================================\n  Hits        15254    15254              \n+ Misses        113      112       -1     \n+ Partials      133      132       -1     \n```\n\n</details>\n\n[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/litestar-org/litestar/pull/3824?dropdown=coverage&src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=litestar-org).   \n:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=litestar-org).\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-10-17T08:07:02Z",
                        "url": "https://github.com/litestar-org/litestar/pull/3824#issuecomment-2418852604"
                    },
                    {
                        "body": "Please, take a look at these lines:\r\n<img width=\"1299\" alt=\"  2024-10-17  11 43 46\" src=\"https://github.com/user-attachments/assets/fe6a142d-6718-4796-be45-44a54b8674ba\">\r\n\r\nLooks like `else` is never actually reached. Should I remove this branch?",
                        "user": "sobolevn",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-10-17T08:44:34Z",
                        "url": "https://github.com/litestar-org/litestar/pull/3824#issuecomment-2418930857"
                    },
                    {
                        "body": "> Looks like `else` is never actually reached. Should I remove this branch?\r\n\r\nSeems to be a missing test case?\r\n",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-10-19T08:34:57Z",
                        "url": "https://github.com/litestar-org/litestar/pull/3824#issuecomment-2423694828"
                    },
                    {
                        "body": "> Seems to be a missing test case?\r\n\r\nI am not quite sure, to be honest :)\r\nHere's why. Here's the code in question: https://github.com/litestar-org/litestar/blob/f7b258f97592626934b4224e52c030983c9bf41b/litestar/security/base.py#L90-L95\r\n\r\nWhere `app_config.openapi_config.components` has a type of `Components | list[Components]` https://github.com/litestar-org/litestar/blob/f7b258f97592626934b4224e52c030983c9bf41b/litestar/openapi/config.py#L91 `Components` can never be false (it does not have `__bool__` or `__len__` defined).\r\n\r\nSo, mypy raises an error for this case. We either have:\r\n- Missing `None` annotation for `components` and a missing test case ?\r\n- Extra `else` branch in this `if` ?",
                        "user": "sobolevn",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-10-19T09:30:53Z",
                        "url": "https://github.com/litestar-org/litestar/pull/3824#issuecomment-2423719479"
                    },
                    {
                        "body": ">     * Extra `else` branch in this `if` ?\r\n\r\nIsn't it the `elif` branch that's extra then, and should be an `else` instead?\r\n",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-10-19T09:52:35Z",
                        "url": "https://github.com/litestar-org/litestar/pull/3824#issuecomment-2423730131"
                    },
                    {
                        "body": "## [![Quality Gate Passed](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/QualityGateBadge/qg-passed-20px.png 'Quality Gate Passed')](https://sonarcloud.io/dashboard?id=litestar-org_litestar&pullRequest=3824) **Quality Gate passed**  \nIssues  \n![](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/passed-16px.png '') [0 New issues](https://sonarcloud.io/project/issues?id=litestar-org_litestar&pullRequest=3824&issueStatuses=OPEN,CONFIRMED&sinceLeakPeriod=true)  \n![](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/accepted-16px.png '') [0 Accepted issues](https://sonarcloud.io/project/issues?id=litestar-org_litestar&pullRequest=3824&issueStatuses=ACCEPTED)\n\nMeasures  \n![](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/passed-16px.png '') [0 Security Hotspots](https://sonarcloud.io/project/security_hotspots?id=litestar-org_litestar&pullRequest=3824&issueStatuses=OPEN,CONFIRMED&sinceLeakPeriod=true)  \n![](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/passed-16px.png '') [0.0% Coverage on New Code](https://sonarcloud.io/component_measures?id=litestar-org_litestar&pullRequest=3824&metric=new_coverage&view=list)  \n![](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/passed-16px.png '') [0.0% Duplication on New Code](https://sonarcloud.io/component_measures?id=litestar-org_litestar&pullRequest=3824&metric=new_duplicated_lines_density&view=list)  \n  \n[See analysis details on SonarCloud](https://sonarcloud.io/dashboard?id=litestar-org_litestar&pullRequest=3824)\n\n",
                        "user": "sonarcloud[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-10-24T01:51:48Z",
                        "url": "https://github.com/litestar-org/litestar/pull/3824#issuecomment-2434061889"
                    },
                    {
                        "body": "Documentation preview will be available shortly at https://litestar-org.github.io/litestar-docs-preview/3824",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-10-24T01:53:23Z",
                        "url": "https://github.com/litestar-org/litestar/pull/3824#issuecomment-2434063475"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/litestar-org/litestar/pulls/3824",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/3451",
                "title": "Bug: Litestar instance or factory not found",
                "labels": [
                    "Bug :bug:",
                    "Needs MCVE"
                ],
                "user": "glickums",
                "issue_author_association": "NONE",
                "number": 3451,
                "id": 2269585407,
                "state": "closed",
                "project_created_at": "2024-04-29T17:34:09Z",
                "closed_at": "2024-07-30T05:11:52Z",
                "body": "Hi, every time I try to run litestar from vscode I get a \"Could not find Litestar instance or factory\"\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n> [!NOTE]  \n> While we are open for sponsoring on [GitHub Sponsors](https://github.com/sponsors/litestar-org/) and \n> [OpenCollective](https://opencollective.com/litestar), we also utilize [Polar.sh](https://polar.sh/) to engage in pledge-based sponsorship.\n>\n> Check out all issues funded or available for funding [on our Polar.sh dashboard](https://polar.sh/litestar-org)\n> * If you would like to see an issue prioritized, make a pledge towards it!\n> * We receive the pledge once the issue is completed & verified\n> * This, along with engagement in the community, helps us know which features are a priority to our users.\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/3451\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/3451/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/3451/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [
                    {
                        "body": "Can you provide an MCVE of your project structure? You can see *how* Litestar discovers things in https://docs.litestar.dev/latest/usage/cli.html#autodiscovery, and you error indicates those criteria are not met.\r\n\r\nIf it is not in your current directory, or discoverable otherwise as listed in the documentation, you have to provide the path via something like:\r\n```\r\nlitestar --app-dir \"/Users/jacob/Library/Application Support/JetBrains/PyCharm2023.3/scratches/\" run\r\n```\r\nor \r\n```\r\nlitestar --app module.path.to.examples.basic:app run\r\n```",
                        "user": "JacobCoffee",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-04-29T19:18:54Z",
                        "url": "https://github.com/litestar-org/litestar/issues/3451#issuecomment-2083487580"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/3397",
                "title": "Bug: Using asyncio.create_subprocess_shell / _exec in lifespan raises NotImplementedError",
                "labels": [
                    "Question",
                    "Compatibility",
                    "Needs MCVE",
                    "Needs Response :warning:"
                ],
                "user": "tim-hilt",
                "issue_author_association": "NONE",
                "number": 3397,
                "id": 2246860525,
                "state": "closed",
                "project_created_at": "2024-04-16T20:48:33Z",
                "closed_at": "2024-04-17T06:45:43Z",
                "body": "### Description\n\nNot a whole lot more to say. I want to have a long running process that updates some data periodically in the background. With FastAPI I could use the lifespan-function as presented below, but with Litestar the following exception is raised:\r\n\r\n```\r\n      | Traceback (most recent call last):\r\n      |   File \"C:\\<disguised>\\app.py\", line 112, in update_data\r\n      |     data = await exec_shell_command()\r\n      |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n      |   File \"C:\\<disguised>\\app.py\", line 17, in exec_shell_command\r\n      |     proc = await asyncio.create_subprocess_shell(\r\n      |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n      |   File \"C:\\Appl\\Python\\Lib\\asyncio\\subprocess.py\", line 208, in create_subprocess_shell\r\n      |     transport, protocol = await loop.subprocess_shell(\r\n      |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n      |   File \"C:\\Appl\\Python\\Lib\\asyncio\\base_events.py\", line 1661, in subprocess_shell\r\n      |     transport = await self._make_subprocess_transport(\r\n      |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n      |   File \"C:\\Appl\\Python\\Lib\\asyncio\\base_events.py\", line 502, in _make_subprocess_transport\r\n      |     raise NotImplementedError\r\n      | NotImplementedError\r\n      +------------------------------------\r\n```\r\n\r\nI think it has something to do with the event-loop being used, but I don't know enough to find out the cause fully on my own.\n\n### URL to code causing the issue\n\n_No response_\n\n### MCVE\n\n```python\nfrom contextlib import asynccontextmanager\r\nfrom typing import AsyncGenerator\r\n\r\nfrom litestar import Litestar, get\r\nimport anyio\r\n\r\nasync def update_data() -> None:\r\n    while True:\r\n        proc = await asyncio.create_subprocess_shell(\r\n            \"ls -l\",\r\n            stdout=asyncio.subprocess.PIPE,\r\n            stderr=asyncio.subprocess.PIPE,\r\n        )\r\n\r\n        stdout, _ = await proc.communicate()\r\n        asyncio.sleep(60)\r\n\r\n@asynccontextmanager\r\nasync def lifespan(_: Litestar) -> AsyncGenerator[None, None]:\r\n    async with anyio.create_task_group() as tg:\r\n        tg.start_soon(update_data)\r\n        yield\r\n        tg.cancel_scope.cancel()\r\n\r\n@get(\"/\")\r\nasync def root() -> dict[str, str]:\r\n    return {\"Hello\": \"World\"}\r\n\r\napp = Litestar(route_handlers=[root], lifespan=[lifespan])\n```\n\n\n### Steps to reproduce\n\n```bash\nJust run the code presented above\n```\n\n\n### Screenshots\n\n```bash\n\"![SCREENSHOT_DESCRIPTION](SCREENSHOT_LINK.png)\"\n```\n\n\n### Logs\n\n_No response_\n\n### Litestar Version\n\n2.8.2\n\n### Platform\n\n- [ ] Linux\n- [ ] Mac\n- [X] Windows\n- [ ] Other (Please specify in the description above)\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n> [!NOTE]  \n> While we are open for sponsoring on [GitHub Sponsors](https://github.com/sponsors/litestar-org/) and \n> [OpenCollective](https://opencollective.com/litestar), we also utilize [Polar.sh](https://polar.sh/) to engage in pledge-based sponsorship.\n>\n> Check out all issues funded or available for funding [on our Polar.sh dashboard](https://polar.sh/litestar-org)\n> * If you would like to see an issue prioritized, make a pledge towards it!\n> * We receive the pledge once the issue is completed & verified\n> * This, along with engagement in the community, helps us know which features are a priority to our users.\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/3397\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/3397/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/3397/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [
                    {
                        "body": "Can you please provide the exact command that you use to run the application, e.g., `litestar run ...` or `uvicorn ...` or something else? Do you have `--reload` enabled, or are you useing multiple workers?\r\n\r\nFrom [Subprocess Support on Windows](https://docs.python.org/3/library/asyncio-platforms.html#subprocess-support-on-windows):\r\n\r\n> On Windows, the default event loop [`ProactorEventLoop`](https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.ProactorEventLoop) supports subprocesses, whereas [`SelectorEventLoop`](https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.SelectorEventLoop) does not.\r\n\r\nUvicorn explicitly set the event loop to be `SelectorEventLoop` if reloading enabled, or multiple workers ([ref](https://github.com/encode/uvicorn/blob/0efd3835da6dcc713f74aadf7b52779d0d1fa17d/uvicorn/loops/asyncio.py#L8-L10)).\r\n\r\n> With FastAPI I could use the lifespan-function as presented below\r\n\r\nI can find the same issue mentioned in the fastapi repo:\r\n\r\n- https://github.com/tiangolo/fastapi/issues/4361\r\n- https://github.com/tiangolo/fastapi/issues/964\r\n\r\nSo there has to be some difference in the configuration at the server level that is causing the `SelectorEventLoop` to be enabled in this case, and not in the FastAPI case.",
                        "user": "peterschutt",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-17T00:14:33Z",
                        "url": "https://github.com/litestar-org/litestar/issues/3397#issuecomment-2060102617"
                    },
                    {
                        "body": "Indeed it seems to be connected to enabling multiple workers. I think I added the `workers=4` attribute to the `uvicorn.run` call when using FastAPI without even trying it out. Then I switched to Litestar and it crashed :D So: My bad. But still interesting to learn more about event-loops.",
                        "user": "tim-hilt",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-04-17T06:45:43Z",
                        "url": "https://github.com/litestar-org/litestar/issues/3397#issuecomment-2060496902"
                    },
                    {
                        "body": "the tl;dr would be imho to use linux :)\r\n\r\nnow from my poor memory, uvicorn aims at supporting both windows and linux and in doing so has to deal with 2 different default event loops. both of those loop default support subprocesses, but uvicorn overrides the default one to SelectorEventLoop.\r\nI think the override of the loop in windows is a way to let windows subprocess reload the app, with the iocp loop it wasn't working.\r\nso in essence on windows we force the loop to be the non-default one to suport the reload thing (better dx experience) at the cost of what you encounter : being unable to use subprocesses\r\n\r\nnow this may need a rethink on uvicorn's side I'm not too sure.",
                        "user": "euri10",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-17T07:58:51Z",
                        "url": "https://github.com/litestar-org/litestar/issues/3397#issuecomment-2060642041"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2992",
                "title": "Enhancement: Multiple TestClients / explicit test app running",
                "labels": [
                    "Enhancement",
                    "Needs MCVE"
                ],
                "user": "mtvx",
                "issue_author_association": "NONE",
                "number": 2992,
                "id": 2087001446,
                "state": "open",
                "project_created_at": "2024-01-17T21:20:25Z",
                "closed_at": null,
                "body": "### Summary\r\n\r\nSometimes, it would be nice to initialize multiple `Testclient`s, but only do the blocking portal magic once. The request routing magic lives in `TestClient(Transport)` so simply copying the `base_url` to a `httpx.Client` won't work (found out by trying).\r\n\r\nAn example where this could be needed is when testing the API from the perspective of 2 different users. Using just one client might not be feasible due to cookies that server could set (should be different for the two users) and in general it would be nice to have the two separated.\r\n\r\n```py\r\nclient = TestClient(app=app)\r\nclient.get(..., auth=user1_auth)  # requires also...\r\nclient.get(..., auth=user2_auth)  # ...this repetition\r\n```\r\n\r\n### Basic Example\r\n\r\nMaybe something like:\r\n\r\n```py\r\nwith create_portal(app) as portal:\r\n    user1 = TestClient(portal=portal, auth=...)\r\n    user2 = TestClient(portal=portal, auth=...)\r\n    user1.get(...)\r\n    user2.get(...)\r\n```\r\n\r\n### Drawbacks and Impact\r\n\r\n_No response_\r\n\r\n### Unresolved questions\r\n\r\n_No response_\r\n\r\n<!-- POLAR PLEDGE BADGE START -->\r\n---\r\n> [!NOTE]  \r\n> While we are open for sponsoring on [GitHub Sponsors](https://github.com/sponsors/litestar-org/) and \r\n> [OpenCollective](https://opencollective.com/litestar), we also utilize [Polar.sh](https://polar.sh/) to engage in pledge-based sponsorship.\r\n>\r\n> Check out all issues funded or available for funding [on our Polar.sh dashboard](https://polar.sh/litestar-org)\r\n> * If you would like to see an issue prioritized, make a pledge towards it!\r\n> * We receive the pledge once the issue is completed & verified\r\n> * This, along with engagement in the community, helps us know which features are a priority to our users.\r\n\r\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2992\">\r\n<picture>\r\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2992/pledge.svg?darkmode=1\">\r\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2992/pledge.svg\">\r\n</picture>\r\n</a>\r\n<!-- POLAR PLEDGE BADGE END -->\r\n",
                "comments": [
                    {
                        "body": "Can you provide an example use case where two client instances would be useful?",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-01-18T19:13:53Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2992#issuecomment-1899062380"
                    },
                    {
                        "body": "Hi, I did try to give an example up there - are you saying it doesn't make sense or is unclear?\r\n\r\nIt's just to reduce boilerplate - when you're testing an endpoint with two (or multiple) different users, it's helpful to create client per-user, and avoid having to pass `auth=...` and maybe something else each time.\r\n\r\nAlso technically/semantically I'd say it makes sense to separate the a) test app \"running\" from b) test client that calls it.",
                        "user": "mtvx",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-01-19T07:36:29Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2992#issuecomment-1899907359"
                    },
                    {
                        "body": "> Hi, I did try to give an example up there - are you saying it doesn't make sense or is unclear?\r\n\r\nI can't speak for @provinzkraut but it makes it a lot easier to consider the problem if there's a copy/paste example.\r\n",
                        "user": "peterschutt",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-30T05:06:52Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2992#issuecomment-2084390000"
                    },
                    {
                        "body": "I get that same issue a while back if I get OP correctly. Let me try to explain.\r\n\r\nyou have an app with buyers/sellers: depending on this role you can do different things, sellers can add products, edit, delete them etc, buyers can list then only, put then in a cart living in a session, etc...\r\n\r\nnow let's say you want to test the buyer putting product X on his cart, but before the order button is pressed the seller deleted the item : you'd need two TestClient and the portal will fuck you up iirc\r\n\r\n\r\n",
                        "user": "euri10",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-30T06:49:47Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2992#issuecomment-2084507792"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2902",
                "title": "Bug: DTO support empty payload",
                "labels": [
                    "Bug :bug:",
                    "Great MCVE",
                    "High Priority",
                    "DTOs"
                ],
                "user": "peterschutt",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2902,
                "id": 2042831823,
                "state": "closed",
                "project_created_at": "2023-12-15T03:32:39Z",
                "closed_at": "2023-12-15T23:52:27Z",
                "body": "### Description\n\nDTO supported data fails if no body is sent with the request, even if a default value is provided for the parameter.\n\n### URL to code causing the issue\n\n_No response_\n\n### MCVE\n\n```python\nfrom dataclasses import dataclass\r\nfrom typing import Optional\r\n\r\nfrom litestar import Litestar, post\r\nfrom litestar.contrib.pydantic import PydanticPlugin\r\nfrom litestar.dto import DataclassDTO\r\nfrom litestar.logging import LoggingConfig\r\n\r\n\r\n@dataclass\r\nclass Foo:\r\n    foo: str\r\n\r\n\r\n@post(path=\"/\", dto=DataclassDTO[Foo])\r\ndef test(data: Optional[Foo] = None) -> dict:\r\n    return {\"foo\": data}\r\n\r\n\r\napp = Litestar(\r\n    route_handlers=[test],\r\n    logging_config=LoggingConfig(),\r\n    middleware=[],\r\n    plugins=[PydanticPlugin(prefer_alias=True)],\r\n)\n```\n\n\n### Steps to reproduce\n\n```bash\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\n```\n\n\n### Screenshots\n\n```bash\n\"![SCREENSHOT_DESCRIPTION](SCREENSHOT_LINK.png)\"\n```\n\n\n### Logs\n\n```bash\nFO:     127.0.0.1:38110 - \"POST / HTTP/1.1\" 400 Bad Request\r\nERROR - 2023-12-15 02:27:22,851 - litestar - config - exception raised on http connection to route /\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/serialization/msgspec_hooks.py\", line 187, in decode_json\r\n    return msgspec.json.decode(\r\nmsgspec.DecodeError: Input data was truncated\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/routes/http.py\", line 177, in _get_response_data\r\n    kwargs[\"data\"] = await kwargs[\"data\"]\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/_kwargs/extractors.py\", line 450, in dto_extractor\r\n    return data_dto(connection).decode_bytes(body)\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/dto/base_dto.py\", line 97, in decode_bytes\r\n    return backend.populate_data_from_raw(value, self.asgi_connection)\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/dto/_backend.py\", line 301, in populate_data_from_raw\r\n    source_data=self.parse_raw(raw, asgi_connection),\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/dto/_backend.py\", line 208, in parse_raw\r\n    result = decode_json(value=raw, target_type=self.annotation, type_decoders=type_decoders)\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/serialization/msgspec_hooks.py\", line 191, in decode_json\r\n    raise SerializationException(str(msgspec_error)) from msgspec_error\r\nlitestar.exceptions.base_exceptions.SerializationException: Input data was truncated\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/middleware/exceptions/middleware.py\", line 191, in __call__\r\n    await self.app(scope, receive, send)\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/routes/http.py\", line 81, in handle\r\n    response = await self._get_response_for_request(\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/routes/http.py\", line 133, in _get_response_for_request\r\n    return await self._call_handler_function(\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/routes/http.py\", line 153, in _call_handler_function\r\n    response_data, cleanup_group = await self._get_response_data(\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/routes/http.py\", line 179, in _get_response_data\r\n    raise ClientException(str(e)) from e\r\nlitestar.exceptions.http_exceptions.ClientException: 400: Input data was truncated\r\nTraceback (most recent call last):\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/serialization/msgspec_hooks.py\", line 187, in decode_json\r\n    return msgspec.json.decode(\r\nmsgspec.DecodeError: Input data was truncated\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/routes/http.py\", line 177, in _get_response_data\r\n    kwargs[\"data\"] = await kwargs[\"data\"]\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/_kwargs/extractors.py\", line 450, in dto_extractor\r\n    return data_dto(connection).decode_bytes(body)\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/dto/base_dto.py\", line 97, in decode_bytes\r\n    return backend.populate_data_from_raw(value, self.asgi_connection)\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/dto/_backend.py\", line 301, in populate_data_from_raw\r\n    source_data=self.parse_raw(raw, asgi_connection),\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/dto/_backend.py\", line 208, in parse_raw\r\n    result = decode_json(value=raw, target_type=self.annotation, type_decoders=type_decoders)\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/serialization/msgspec_hooks.py\", line 191, in decode_json\r\n    raise SerializationException(str(msgspec_error)) from msgspec_error\r\nlitestar.exceptions.base_exceptions.SerializationException: Input data was truncated\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/middleware/exceptions/middleware.py\", line 191, in __call__\r\n    await self.app(scope, receive, send)\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/routes/http.py\", line 81, in handle\r\n    response = await self._get_response_for_request(\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/routes/http.py\", line 133, in _get_response_for_request\r\n    return await self._call_handler_function(\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/routes/http.py\", line 153, in _call_handler_function\r\n    response_data, cleanup_group = await self._get_response_data(\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/routes/http.py\", line 179, in _get_response_data\r\n    raise ClientException(str(e)) from e\r\nlitestar.exceptions.http_exceptions.ClientException: 400: Input data was truncated\n```\n\n\n### Litestar Version\n\nmain\n\n### Platform\n\n- [X] Linux\n- [ ] Mac\n- [ ] Windows\n- [ ] Other (Please specify in the description above)\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n> [!NOTE]  \n> While we are open for sponsoring on [GitHub Sponsors](https://github.com/sponsors/litestar-org/) and \n> [OpenCollective](https://opencollective.com/litestar), we also utilize [Polar.sh](https://polar.sh/) to engage in pledge-based sponsorship.\n>\n> Check out all issues funded or available for funding [on our Polar.sh dashboard](https://polar.sh/litestar-org)\n> * If you would like to see an issue prioritized, make a pledge towards it!\n> * We receive the pledge once the issue is completed & verified\n> * This, along with engagement in the community, helps us know which features are a priority to our users.\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2902\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2902/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2902/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2721",
                "title": "Bug: Renaming in DTOs with nested fields will rename all occurrences.",
                "labels": [
                    "Bug :bug:",
                    "Great MCVE"
                ],
                "user": "simon-lund",
                "issue_author_association": "NONE",
                "number": 2721,
                "id": 2001748427,
                "state": "closed",
                "project_created_at": "2023-11-20T09:32:28Z",
                "closed_at": "2023-11-27T04:30:55Z",
                "body": "### Description\r\n\r\nIn the example below, we have two models: 'Chat' and 'Message', each with an 'id' field. We also define a ResponseDTO for the Chat model, using DTOConfig to rename its 'id' field to 'chat_id'. \r\n\r\nThe intention is to only rename the 'id' of the Chat model. However, this configuration unexpectedly renames the 'id' field in the nested Message objects as well. As a result, the response output is \r\n\r\n`{\"chat_id\":\"1\",\"messages\":[{\"chat_id\":\"1\",\"created_at\":\"1\",\"user_id\":\"1\"}]}`, \r\n\r\nwhere both Chat and Message 'id' fields are affected, contrary to the intended behavior.\r\n\r\n\r\n### URL to code causing the issue\r\n\r\n_No response_\r\n\r\n### MCVE\r\n\r\n```python\r\nfrom typing_extensions import List\r\nfrom litestar import get, Litestar\r\nfrom pydantic import BaseModel\r\nfrom litestar.dto import DTOConfig\r\nfrom litestar.contrib.pydantic import PydanticDTO\r\n\r\nclass Message(BaseModel):\r\n    id: str\r\n    created_at: str\r\n    user_id: str\r\n\r\nclass Chat(BaseModel):\r\n    id: str\r\n    messages: List[Message]\r\n\r\nclass ResponseDTO(PydanticDTO[Chat]):\r\n    config = DTOConfig(rename_fields={\"id\": \"chat_id\"})\r\n\r\n@get(return_dto=ResponseDTO)\r\nasync def get_chat() -> Chat:\r\n    return Chat(id=\"1\", messages=[Message(id=\"1\", created_at=\"1\", user_id=\"1\")])\r\n\r\napp = Litestar([get_chat])\r\n```\r\n\r\n\r\n### Steps to reproduce\r\n\r\n```bash\r\n1. Start Litestar\r\n2. Make API call `curl localhost:8000`\r\n3. Observe :bug:\r\n```\r\n\r\n\r\n### Screenshots\r\n\r\n_No response_\r\n\r\n### Logs\r\n\r\n_No response_\r\n\r\n### Litestar Version\r\n\r\n2.2.1\r\n\r\n### Platform\r\n\r\n- [X] Linux\r\n- [ ] Mac\r\n- [ ] Windows\r\n- [ ] Other (Please specify in the description above)\r\n\r\n<!-- POLAR PLEDGE BADGE START -->\r\n---\r\n> [!NOTE]  \r\n> While we are open for sponsoring on [GitHub Sponsors](https://github.com/sponsors/litestar-org/) and \r\n> [OpenCollective](https://opencollective.com/litestar), we also utilize [Polar.sh](https://polar.sh/) to engage in pledge-based sponsorship.\r\n>\r\n> Check out all issues funded or available for funding [on our Polar.sh Litestar dashboard](https://polar.sh/litestar-org)\r\n> * If you would like to see an issue prioritized, make a pledge towards it!\r\n> * We receive the pledge once the issue is completed & verified\r\n> * This, along with engagement in the community, helps us know which features are a priority to our users.\r\n\r\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2721\">\r\n<picture>\r\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2721/pledge.svg?darkmode=1\">\r\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2721/pledge.svg\">\r\n</picture>\r\n</a>\r\n<!-- POLAR PLEDGE BADGE END -->\r\n",
                "comments": [
                    {
                        "body": "@peterschutt Haven't really investigated yet, but it happens on both the regular and the codegen backend",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-26T13:01:32Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2721#issuecomment-1826778706"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2635",
                "title": "Bug: Schema generation partially broken since litestar version 2.3.0",
                "labels": [
                    "Bug :bug:",
                    "Great MCVE"
                ],
                "user": "euthuppan",
                "issue_author_association": "NONE",
                "number": 2635,
                "id": 1984601950,
                "state": "closed",
                "project_created_at": "2023-11-09T00:17:28Z",
                "closed_at": "2023-11-11T04:21:24Z",
                "body": "### Description\n\n2.2.1 is my last working version of litestar. \r\n\r\nBefore:\r\n<img width=\"467\" alt=\"image\" src=\"https://github.com/litestar-org/litestar/assets/85191795/dc9594b1-4b09-4607-9061-dcd65bf0a09f\">\r\n\r\nAfter:\r\nI first get this `internal server error` when i first try to go to my Swagger URL\r\n\r\n<img width=\"436\" alt=\"image\" src=\"https://github.com/litestar-org/litestar/assets/85191795/90112884-907e-4ee0-a14c-a92c338ef761\">\r\n\r\nAnd then when i refresh once more, it goes to my swagger page, but only 2/3 of it.\r\n\r\n\r\n\r\n<img width=\"217\" alt=\"image\" src=\"https://github.com/litestar-org/litestar/assets/85191795/74f16208-e80a-46de-b580-3dd566e0f14b\">\r\n\r\nWith no changes in my code, the problems just start at version 2.3.0 and beyond. Just wanted to bring attention to this, as I will now be sticking to litestar 2.2.1 until this is resolved.\n\n### URL to code causing the issue\n\n_No response_\n\n### MCVE\n\n```python\nHow my app code looks like when passing in my controllers:\r\n\r\napp = Litestar(\r\n    route_handlers=[\r\n        read_root,\r\n        refresh_templates,\r\n        LinuxPXEController,\r\n        WindowsPXEController,\r\n        ESXiPXEController\r\n    ],\r\n ...\n```\n\n\n### Steps to reproduce\n\n_No response_\n\n### Screenshots\n\n```bash\n\"![SCREENSHOT_DESCRIPTION](SCREENSHOT_LINK.png)\"\n```\n\n\n### Logs\n\n_No response_\n\n### Litestar Version\n\n2.3.0\n\n### Platform\n\n- [X] Linux\n- [X] Mac\n- [ ] Windows\n- [ ] Other (Please specify in the description above)\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n> [!NOTE]  \n> While we are open for sponsoring on [GitHub Sponsors](https://github.com/sponsors/litestar-org/) and \n> [OpenCollective](https://opencollective.com/litestar), we also utilize [Polar.sh](https://polar.sh/) to engage in pledge-based sponsorship.\n>\n> Check out all issues funded or available for funding [on our Polar.sh Litestar dashboard](https://polar.sh/litestar-org)\n> * If you would like to see an issue prioritized, make a pledge towards it!\n> * We receive the pledge once the issue is completed & verified\n> * This, along with engagement in the community, helps us know which features are a priority to our users.\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2635\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2635/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2635/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [
                    {
                        "body": "@euthuppan could you please enable `debug` mode on the application and let us know if that gives you additional output?\r\n\r\n```python\r\napp = Litestar(\r\n    debug=True,\r\n    route_handlers=[\r\n        read_root,\r\n        refresh_templates,\r\n        LinuxPXEController,\r\n        WindowsPXEController,\r\n        ESXiPXEController\r\n    ],\r\n    ```",
                        "user": "cofin",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-09T02:59:50Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2635#issuecomment-1803087926"
                    },
                    {
                        "body": "I've also started running into this issue with v2.3, find a screenshot of the error in debug mode below:\r\n![Screenshot 2023-11-09 at 11 39 54](https://github.com/litestar-org/litestar/assets/20231751/6eb6b953-781c-4f86-8d96-a947ff92128c)\r\n\r\n\r\nThis also happens for ReDoc and Elements, so it's consistent across all OpenAPI renderers.",
                        "user": "timwedde",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-11-09T10:43:29Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2635#issuecomment-1803588469"
                    },
                    {
                        "body": "@timwedde @euthuppan could one of you provide an MCVE that reproduces this?\r\n\r\nAlso, which Pydantic version are you using?",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-09T20:04:07Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2635#issuecomment-1804576606"
                    },
                    {
                        "body": "Took me a little while to track this down, but here you go:\r\n```py\r\n# pip install pydantic==2.4.2 litestar==2.3.2\r\n\r\nfrom litestar import Litestar, get\r\nfrom pydantic import BaseModel, Field\r\n\r\n\r\nclass Model(BaseModel):\r\n    id: int\r\n    fail: dict = {}  # fails\r\n    # fail: dict = Field(default={})  # fails\r\n    # fail: dict = Field(default_factory=dict)  # works\r\n\r\n\r\n@get(\"/\")\r\nasync def mcve() -> Model:\r\n    return Model(id=1)\r\n\r\n\r\napp = Litestar(\r\n    debug=True,\r\n    route_handlers=[mcve],\r\n)\r\n```\r\n\r\nSeems that this may now be semi-intended behavior since the `default_factory` approach is likely the objectively correct one anyway, but it does somewhat smell like a breaking change in a minor version update. For reference, this does work properly on Litestar versions before 2.3.x, with the same pydantic version.",
                        "user": "timwedde",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-11-10T11:57:11Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2635#issuecomment-1805608693"
                    },
                    {
                        "body": "So things seems to have broken on 46ea14bf045f1804e0a1623407ec525179acbfb4 (#2553) for the MCVE above (`fail: dict = {}`). Bisected all the way from a7fe0f306e541253351fb1ad373bf6ff590eef9a (v2.2.0) to 0c6a57f8454838572aa6eaffd89123c778d638df (current main)",
                        "user": "Alc-Alc",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-11-10T12:16:54Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2635#issuecomment-1805636304"
                    },
                    {
                        "body": "So change this https://github.com/litestar-org/litestar/blob/0c6a57f8454838572aa6eaffd89123c778d638df/litestar/contrib/pydantic/utils.py#L164-L165\r\n\r\n```py\r\ndef is_pydantic_undefined(value: Any) -> bool:\r\n    return any(v is value for v in PYDANTIC_UNDEFINED_SENTINELS)\r\n```\r\n\r\nso that it is the same as this (avoid the hash)?\r\n\r\nhttps://github.com/litestar-org/litestar/blob/0c6a57f8454838572aa6eaffd89123c778d638df/litestar/utils/predicates.py#L314-L323\r\n\r\n",
                        "user": "Alc-Alc",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-11-10T12:54:07Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2635#issuecomment-1805681312"
                    },
                    {
                        "body": "Thanks for the effort @Alc-Alc! The proposed change looks good to me, do you want to implement it (and add a test case to reproduce)?",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-10T17:49:54Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2635#issuecomment-1806165561"
                    },
                    {
                        "body": "Also thanks @timwedde for the great mcve! This is really helpful! :)",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-10T17:51:14Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2635#issuecomment-1806166972"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2503",
                "title": "Litestar consumes high amount of CPU",
                "labels": [
                    "Question",
                    "Needs MCVE"
                ],
                "user": "bpereto",
                "issue_author_association": "NONE",
                "number": 2503,
                "id": 1957867543,
                "state": "closed",
                "project_created_at": "2023-10-23T19:19:18Z",
                "closed_at": "2023-10-23T19:59:46Z",
                "body": "### Description\r\n\r\nRunning litestar `litestar app run` with uvicorn consumes in an idling state on my machines 40-45% CPU.\r\n\r\nIs this normal or is there a way to reduce the idling CPU consumption?\r\n\r\nAttached a picture of cProfile. `python -m cProfile -o litestar.pstats ./.venv/bin/litestar run`\r\n\r\n![litestar_profile](https://github.com/litestar-org/litestar/assets/1131885/ab23a525-f85e-479e-8a5d-981fe68c46e3)\r\n\r\n### URL to code causing the issue\r\n\r\n_No response_\r\n\r\n### MCVE\r\n\r\n```python\r\nUVICORN_LOOP=uvloop litestar run                            \r\nUsing Litestar app from env: 'app.asgi:create_app'\r\nStarting server process \r\n\r\n Litestar version              2.2.1                                                                                                        \r\n Debug mode                    Disabled                                                                                                     \r\n Python Debugger on exception  Disabled                                                                                                     \r\n CORS                          Enabled                                                                                                      \r\n CSRF                          Disabled                                                                                                     \r\n OpenAPI                       Enabled path=/schema                                                                                         \r\n Compression                   Disabled                                                                                                     \r\n Template engine               ViteTemplateEngine                                                                                           \r\n Static files                  path=/static dirs=.../src/app/domain/web/public html_mode=Enabled \r\n Middlewares                   JWTCookieAuthenticationMiddleware, SentryLitestarASGIMiddleware, middleware_factory                          \r\n\r\n2023-10-23T19:12:38.780745Z [info     ] Started server process [4257]  [uvicorn.error] \r\n2023-10-23T19:12:38.781923Z [info     ] Waiting for application startup. [uvicorn.error] \r\n2023-10-23T19:12:38.789916Z [info     ] Application startup complete.  [uvicorn.error] \r\n2023-10-23T19:12:38.792650Z [info     ] Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit) [uvicorn.error] \r\n^C2023-10-23T19:15:04.770399Z [info     ] Shutting down                  [uvicorn.error] \r\n^C2023-10-23T19:15:04.910332Z [info     ] Finished server process [4257] [uvicorn.error] \r\n^C2023-10-23T19:15:04.974529Z [info     ] ASGI 'lifespan' protocol appears unsupported. [uvicorn.error] \r\n```\r\n```\r\n\r\n\r\n### Steps to reproduce\r\n\r\n```bash\r\n- Run `litestar run`\r\n- Look process ressources\r\n```\r\n\r\n\r\n### Screenshots\r\n\r\n![litestar_profile](https://github.com/litestar-org/litestar/assets/1131885/ab23a525-f85e-479e-8a5d-981fe68c46e3)\r\r\n\r\n\r\n### Logs\r\n\r\n_No response_\r\n\r\n### Litestar Version\r\n\r\n2.2.1\r\npython3.11\r\n\r\n\r\n\r\n### Platform\r\n\r\n- [ ] Linux\r\n- [X] Mac\r\n- [ ] Windows\r\n- [ ] Other (Please specify in the description above)\r\n\r\n<!-- POLAR PLEDGE BADGE START -->\r\n---\r\n> [!NOTE]  \r\n> While we are open for sponsoring on [GitHub Sponsors](https://github.com/sponsors/litestar-org/) and \r\n> [OpenCollective](https://opencollective.com/litestar), we also utilize [Polar.sh](https://polar.sh/) to engage in pledge-based sponsorship.\r\n>\r\n> Check out all issues funded or available for funding [on our Polar.sh Litestar dashboard](https://polar.sh/litestar-org)\r\n> * If you would like to see an issue prioritized, make a pledge towards it!\r\n> * We receive the pledge once the issue is completed & verified\r\n> * This, along with engagement in the community, helps us know which features are a priority to our users.\r\n\r\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2503\">\r\n<picture>\r\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2503/pledge.svg?darkmode=1\">\r\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2503/pledge.svg\">\r\n</picture>\r\n</a>\r\n<!-- POLAR PLEDGE BADGE END -->\r\n",
                "comments": [
                    {
                        "body": "I cannot reproduce this with a basic application. Can you provide a reproducible example? Its really hard to debug this without actually know what your app looks like, but Im fairly certain that theres some kind of busy loop involved youre not aware of.",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-10-23T19:59:03Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2503#issuecomment-1775927550"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2461",
                "title": "Bug: `url_for` template callable doesn't work in Jinja macros",
                "labels": [
                    "Question",
                    "Great MCVE"
                ],
                "user": "geeshta",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2461,
                "id": 1945955396,
                "state": "closed",
                "project_created_at": "2023-10-16T19:37:49Z",
                "closed_at": "2023-10-16T20:00:10Z",
                "body": "### Description\n\nWhen using the `url_for`  template callable inside of a Jinja macro, an exception is thrown.  It seems that the `request` context variable is not injected, which is responsible for resolving URLs.\r\n\r\nSee MCVE:\r\n```\r\n<li>{{ item.name }} - <a href=\"{{ url_for('item_detail', id=item.id) }}\">Detail</a></li>\r\n```\r\nThis is inside of a Jinja macro which gets called inside of another template. This leads to an error. If you delete the `<a>` tag, the macro will work properly.\r\n```\r\n<a href=\"{{ url_for('item_list') }}\">Back to list</a>\r\n```\r\nThis is directly inside of a template string and doesn't raise an error.\r\n\n\n### URL to code causing the issue\n\n_No response_\n\n### MCVE\n\n```python\nfrom jinja2.environment import Environment\r\nfrom jinja2.loaders import DictLoader\r\nfrom litestar import Litestar, get\r\nfrom litestar.contrib.jinja import JinjaTemplateEngine\r\nfrom litestar.response import Template\r\nfrom litestar.template import TemplateConfig\r\n\r\nmacros = r\"\"\"\r\n{% macro list_items(items) %}\r\n  <ul>\r\n  {% for item in items %}\r\n    <li>{{ item.name }} - <a href=\"{{ url_for('item_detail', id=item.id) }}\">Detail</a></li>\r\n  {% endfor %}\r\n  </ul>\r\n{% endmacro %}\r\n\"\"\"\r\n\r\nitem_list_template = r\"\"\"\r\n{% import \"macros.html.j2\" as render %}\r\n<html>\r\n  <head></head>\r\n  <body>\r\n    {{ render.list_items(items) }}\r\n  </body>\r\n</html>\r\n\"\"\"\r\n\r\nitem_detail_template = r\"\"\"\r\n<html>\r\n  <head></head>\r\n  <body>\r\n    <div>\r\n      <strong>{{ item.id }}: </strong>{{ item.name }}\r\n    </div>\r\n    <div>\r\n      <a href=\"{{ url_for('item_list') }}\">Back to list</a>\r\n    </div>\r\n  </body>\r\n</html>\r\n\"\"\"\r\n\r\n\r\njinja_env = Environment(\r\n    loader=DictLoader(\r\n        {\r\n            \"macros.html.j2\": macros,\r\n            \"item_list.html.j2\": item_list_template,\r\n            \"item_detail.html.j2\": item_detail_template,\r\n        }\r\n    )\r\n)\r\ntemplate_config = TemplateConfig(engine=JinjaTemplateEngine.from_environment(jinja_env))\r\n\r\nitems = [\r\n    {\"id\": 1, \"name\": \"Alice\"},\r\n    {\"id\": 2, \"name\": \"Bob\"},\r\n    {\"id\": 3, \"name\": \"Charlie\"},\r\n]\r\n\r\n\r\n@get(\"/\", name=\"item_list\")\r\nasync def item_list() -> Template:\r\n    return Template(\"item_list.html.j2\", context={\"items\": items})\r\n\r\n\r\n@get(\"/{id:int}\", name=\"item_detail\")\r\nasync def item_detail(id: int) -> Template:\r\n    item = [item for item in items if item[\"id\"] == id][0]\r\n    return Template(\"item_detail.html.j2\", context={\"item\": item})\r\n\r\n\r\napp = Litestar(route_handlers=[item_list, item_detail], template_config=template_config)\n```\n\n\n### Steps to reproduce\n\n```bash\n1. Run the MCVE app\r\n2. Navigate to `/`\r\n3. An error is raised\r\n4. When navigating to `/1`, no error is raised\r\n5. If you delete the `<a>` tag inside of the macro and navigate to `/`, no error is raised\n```\n\n\n### Screenshots\n\n```bash\n\"![SCREENSHOT_DESCRIPTION](SCREENSHOT_LINK.png)\"\n```\n\n\n### Logs\n\n```bash\nERROR - 2023-10-16 21:31:07,972585630 - litestar - middleware - exception raised on http connection to route /\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/middleware/exceptions/middleware.py\", line 191, in __call__\r\n    await self.app(scope, receive, send)\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 79, in handle\r\n    response = await self._get_response_for_request(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 131, in _get_response_for_request\r\n    response = await self._call_handler_function(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 164, in _call_handler_function\r\n    response: ASGIApp = await route_handler.to_response(app=scope[\"app\"], data=response_data, request=request)\r\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/base.py\", line 494, in to_response\r\n    return await response_handler(app=app, data=data, request=request)  # type: ignore\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/_utils.py\", line 153, in handler\r\n    return response.to_asgi_response(  # type: ignore\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/response/template.py\", line 130, in to_asgi_response\r\n    body = template.render(**context).encode(self.encoding)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/jinja2/environment.py\", line 1301, in render\r\n    self.environment.handle_exception()\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/jinja2/environment.py\", line 936, in handle_exception\r\n    raise rewrite_traceback_stack(source=source)\r\n  File \"<template>\", line 6, in top-level template code\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/jinja2/runtime.py\", line 777, in _invoke\r\n    rv = self._func(*arguments)\r\n         ^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<template>\", line 5, in template\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/template/base.py\", line 42, in url_for\r\n    return context[\"request\"].app.route_reverse(route_name, **path_parameters)\r\n           ~~~~~~~^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/jinja2/runtime.py\", line 331, in __getitem__\r\n    raise KeyError(key)\r\nKeyError: 'request'\r\nTraceback (most recent call last):\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/middleware/exceptions/middleware.py\", line 191, in __call__\r\n    await self.app(scope, receive, send)\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 79, in handle\r\n    response = await self._get_response_for_request(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 131, in _get_response_for_request\r\n    response = await self._call_handler_function(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 164, in _call_handler_function\r\n    response: ASGIApp = await route_handler.to_response(app=scope[\"app\"], data=response_data, request=request)\r\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/base.py\", line 494, in to_response\r\n    return await response_handler(app=app, data=data, request=request)  # type: ignore\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/_utils.py\", line 153, in handler\r\n    return response.to_asgi_response(  # type: ignore\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/response/template.py\", line 130, in to_asgi_response\r\n    body = template.render(**context).encode(self.encoding)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/jinja2/environment.py\", line 1301, in render\r\n    self.environment.handle_exception()\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/jinja2/environment.py\", line 936, in handle_exception\r\n    raise rewrite_traceback_stack(source=source)\r\n  File \"<template>\", line 6, in top-level template code\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/jinja2/runtime.py\", line 777, in _invoke\r\n    rv = self._func(*arguments)\r\n         ^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<template>\", line 5, in template\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/template/base.py\", line 42, in url_for\r\n    return context[\"request\"].app.route_reverse(route_name, **path_parameters)\r\n           ~~~~~~~^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/jinja2/runtime.py\", line 331, in __getitem__\r\n    raise KeyError(key)\r\nKeyError: 'request'\n```\n\n\n### Litestar Version\n\n2.1.1\n\n### Platform\n\n- [X] Linux\n- [ ] Mac\n- [ ] Windows\n- [ ] Other (Please specify in the description above)\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n> [!NOTE]  \n> While we are open for sponsoring on [GitHub Sponsors](https://github.com/sponsors/litestar-org/) and \n> [OpenCollective](https://opencollective.com/litestar), we also utilize [Polar.sh](https://polar.sh/) to engage in pledge-based sponsorship.\n>\n> Check out all issues funded or available for funding [on our Polar.sh Litestar dashboard](https://polar.sh/litestar-org)\n> * If you would like to see an issue prioritized, make a pledge towards it!\n> * We receive the pledge once the issue is completed & verified\n> * This, along with engagement in the community, helps us know which features are a priority to our users.\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2461\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2461/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2461/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [
                    {
                        "body": "Have you tried importing the macro `with context`?\r\n\r\nSo `{% import \"macros.html.j2\" as render with context %}`",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-10-16T19:58:56Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2461#issuecomment-1765180305"
                    },
                    {
                        "body": "@provinzkraut I have not and when I did, it fixed the issue. Thanks!",
                        "user": "geeshta",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-10-16T20:00:10Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2461#issuecomment-1765181846"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2442",
                "title": "Enhancement: Auth0/Keycloak",
                "labels": [
                    "Enhancement",
                    "Security"
                ],
                "user": "Saphyel",
                "issue_author_association": "NONE",
                "number": 2442,
                "id": 1943292538,
                "state": "open",
                "project_created_at": "2023-10-14T14:25:21Z",
                "closed_at": null,
                "body": "### Summary\n\nWould be possible to include documentation for this services in the documentation ?\r\n\r\nThey are becoming more common to use them (and their competitors) so I think having a section for them it would be great\n\n### Basic Example\n\n_No response_\n\n### Drawbacks and Impact\n\n_No response_\n\n### Unresolved questions\n\n_No response_\n\n<!-- POLAR PLEDGE BADGE START -->\n> [!NOTE]  \n> Check out all issues funded or available for funding here: https://polar.sh/litestar-org\n> * If you would like to see an issue prioritized, make a pledge towards it!\n> * We receive the pledge once the issue is completed & verified\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2442\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2442/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2442/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [
                    {
                        "body": "I'm not familiar with Litestar, but there's an [MRE](https://en.wikipedia.org/wiki/Minimal_reproducible_example#:~:text=In%20computing%2C%20a%20minimal%20reproducible,to%20be%20demonstrated%20and%20reproduced.) for FastAPI here: [ilyesAj/keycloak-fastAPI-integration](https://github.com/ilyesAj/keycloak-fastAPI-integration/tree/main).",
                        "user": "codespearhead",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-03-12T13:14:06Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2442#issuecomment-1991625525"
                    },
                    {
                        "body": "Found another one, and this one uses Litestar for the backend: https://github.com/GhentCDH/nuxt-keycloak-jwt-auth .\r\n\r\nHowever, it's important to emphasize that without a well-maintained Python OAuth 2.x server implementation (covering both Authorization and Resource Servers) and a Python OpenID Connect 1.x (OIDC) client, it is impossible to securely and reliably integrate it into Litestar or into any other Python framework for that matter.\r\n\r\nThis issue is not unique to Python though: most ecosystems outside of Java and C# face the same challenge (see [Certified Relying Party Libraries and Certified OpenID Provider Libraries](https://openid.net/developers/certified-openid-connect-implementations/)).\r\n\r\nThe best approach would be to contribute to improving [Authlib](https://github.com/lepture/authlib).",
                        "user": "codespearhead",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-08-13T15:14:14Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2442#issuecomment-2286503119"
                    },
                    {
                        "body": "Re: authlib, we have an issue for tracking that impl.\r\n\r\nhttps://github.com/lepture/authlib/issues/601",
                        "user": "JacobCoffee",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-08-13T16:45:04Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2442#issuecomment-2286684215"
                    },
                    {
                        "body": "Any news on this? Migrating from FASTAPI where i use Auth0. But am stuck getting it to work in litestar.\r\n\r\n```python\r\n# app/auth/routes.py\r\n\r\nfrom urllib.parse import quote_plus, urlencode, urljoin\r\n\r\nfrom authlib.integrations.starlette_client import OAuth\r\nfrom fastapi import APIRouter, Request\r\nfrom fastapi.responses import RedirectResponse\r\n\r\nfrom app.config import settings\r\n\r\nrouter = APIRouter()\r\n\r\noauth = OAuth()\r\noauth.register(\r\n    \"auth0\",\r\n    client_id=settings.auth0_client_id,\r\n    client_secret=settings.auth0_client_secret,  # Ensure you import the secret\r\n    client_kwargs={\r\n        \"scope\": \"openid profile email\",\r\n    },\r\n    server_metadata_url=f\"https://{settings.auth0_domain}/.well-known/openid-configuration\",\r\n)\r\n\r\n\r\n@router.get(\"/callback\")\r\nasync def callback(request: Request):\r\n    token = await oauth.auth0.authorize_access_token(request)\r\n\r\n    request.session[\"user\"] = token\r\n    return RedirectResponse(url=\"/\")\r\n\r\n\r\n@router.get(\"/login\")\r\nasync def login(request: Request):\r\n    redirect_uri = request.url_for(\"callback\")\r\n    return await oauth.auth0.authorize_redirect(request, redirect_uri)\r\n\r\n\r\n@router.get(\"/logout\")\r\nasync def logout(request: Request):\r\n    request.session.clear()\r\n    return_to_url = urljoin(str(request.base_url), \"/\")\r\n    logout_url = f\"https://{settings.auth0_domain}/v2/logout?\" + urlencode(\r\n        {\r\n            \"returnTo\": return_to_url,\r\n            \"client_id\": settings.auth0_client_id,\r\n        },\r\n        quote_via=quote_plus,\r\n    )\r\n    return RedirectResponse(logout_url)\r\n```",
                        "user": "Yacobolo",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-08-24T21:18:34Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2442#issuecomment-2308541421"
                    },
                    {
                        "body": "> Any news on this? Migrating from FASTAPI where i use Auth0. But am stuck getting it to work in litestar.\r\n\r\nThe issue seems to be that you're using the `authlib` Starlette integration, so you should probably ask this question over at *authlib* regarding plans for a Litestar integration. There's not much we can do here.\r\n\r\nThat being said, Auth0 has an [SDK for Python](https://auth0-python.readthedocs.io/en/latest/), that you should be able to easily integrate into your Litestar application. You'd simply have to replace the authlib API shown in your example with the equivalent Auth0 SDK functionality :)\r\n",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-08-25T08:23:06Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2442#issuecomment-2308729442"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2368",
                "title": "Bug: using Any return type on before_request handler throws an error on schema",
                "labels": [
                    "Bug :bug:",
                    "Great MCVE"
                ],
                "user": "rseeley",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2368,
                "id": 1913978174,
                "state": "closed",
                "project_created_at": "2023-09-26T17:29:45Z",
                "closed_at": "2023-09-30T17:37:52Z",
                "body": "### Description\n\nUsing `Any` as a return type for a `before_request` handler throws an error when accessing the schema pages/openapi.json endpoints. Looking at the documentation, it should return some value or `None`, and using one or both of those as a return type is successful. The API itself runs just fine with an invalid return type, and this only seems to affect the schema routes.\r\n\r\nIt seems like maybe this is expected behavior so that you are forced to set a proper return type, but maybe a more extensive error message pointing to the location of the issue could be added? The current error I get is `litestar.exceptions.http_exceptions.ImproperlyConfiguredException: 500: Unable to serialize response content`, which took a while to figure out what caused it.\n\n### URL to code causing the issue\n\nhttps://github.com/rseeley/litestar-before-request-error-mvce/blob/main/app.py\n\n### MCVE\n\n_No response_\n\n### Steps to reproduce\n\n```bash\n1. Follow the steps in the README section titled \"Install litestar\"\r\n2. Access the schema at http://127.0.0.1:8000/schema or http://127.0.0.1:8000/schema/openapi.json\n```\n\n\n### Screenshots\n\n_No response_\n\n### Logs\n\n_No response_\n\n### Litestar Version\n\n2.1.1\n\n### Platform\n\n- [ ] Linux\n- [X] Mac\n- [ ] Windows\n- [ ] Other (Please specify in the description above)\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n\n## Funding\n* If you would like to see an issue prioritized, make a pledge towards it!\n* We receive the pledge once the issue is completed & verified\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2368\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2368/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2368/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [
                    {
                        "body": "Thanks for the great MCVE!\r\n\r\nWhat's happening here is Litestar alters the return type of the handler based on the return type of the hook if it's not `None` or ` | None`. Since the hook returns an `ASGIResponse` if you don't return anything, and we default to encode with JSON, Litestar will then attempt to encode the `ASGIResponse` as JSON.\r\n\r\nI'm not entirely sure *why* we alter the return type like this, @peterschutt do you have any insight there? I removed the code in question and it didn't seem to break anything, so I'm not even sure this is actually intentional.\r\n\r\nIn any case, I don't think we *should* be doing this, since it's extremely unexpected and I can't think of a good reason why this would be the desired behaviour. The return type of the handler should be the source of truth in any case, and it's the user's responsibility to return an appropriate type from any hooks that might be in the pipeline.",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-30T10:47:59Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2368#issuecomment-1741738740"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2314",
                "title": "Bug: Guards should not be executed for `OPTIONS` requests",
                "labels": [
                    "Bug :bug:",
                    "Security"
                ],
                "user": "v3ss0n",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2314,
                "id": 1900867425,
                "state": "closed",
                "project_created_at": "2023-09-18T12:49:57Z",
                "closed_at": "2024-03-29T16:44:50Z",
                "body": "### Description\r\n\r\nWhen guards are applied at Controller level , it is blocking the OPTIONS requests and causing error when accessing users on the guards.\r\n\r\n```py\r\n\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/connection/base.py\", line 228, in user\r\n    raise ImproperlyConfiguredException(\"'user' is not defined in scope, install an AuthMiddleware to set it\")\r\nlitestar.exceptions.http_exceptions.ImproperlyConfiguredException: 500: 'user' is not defined in scope, install an AuthMiddleware to set it\r\n\r\n```\r\n\r\n### URL to code causing the issue\r\n\r\nhttps://github.com/litestar-org/litestar-fullstack\r\n\r\n### MCVE\r\n\r\n```python\r\nTo be included\r\n```\r\n\r\n\r\n### Steps to reproduce\r\n\r\n```bash\r\ncurl 'http://0.0.0.0:9000/api/tags' \\    \r\n  -X 'OPTIONS' \\\r\n  -H 'Accept: */*' \\\r\n  -H 'Accept-Language: en-US,en;q=0.9' \\\r\n  -H 'Access-Control-Request-Headers: authorization,content-type' \\\r\n  -H 'Access-Control-Request-Method: POST' \\\r\n  -H 'Connection: keep-alive' \\\r\n  -H 'Origin: http://localhost:8000' \\\r\n  -H 'Referer: http://localhost:8000/' \\\r\n  -H 'Sec-Fetch-Mode: cors' \\\r\n```\r\n\r\n\r\n### Screenshots\r\n\r\n```bash\r\n\"![SCREENSHOT_DESCRIPTION](SCREENSHOT_LINK.png)\"\r\n```\r\n\r\n\r\n### Logs\r\n\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/middleware/exceptions/middleware.py\", line 191, in __call__\r\n    await self.app(scope, receive, send)\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 77, in handle\r\n    await route_handler.authorize_connection(connection=request)\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/handlers/base.py\", line 481, in authorize_connection\r\n    await guard(connection, copy(self))  # type: ignore\r\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/utils/sync.py\", line 65, in __call__\r\n    return await self.ref.value(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/utils/sync.py\", line 101, in wrapper\r\n    return await run_sync(applied_kwarg, *args)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\r\n    return await get_async_backend().run_sync_in_worker_thread(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2106, in run_sync_in_worker_thread\r\n    return await future\r\n           ^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 833, in run\r\n    result = context.run(func, *args)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/src/app/domain/accounts/guards.py\", line 27, in requires_active_user\r\n    if connection.user.is_active:\r\n       ^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/connection/base.py\", line 228, in user\r\n    raise ImproperlyConfiguredException(\"'user' is not defined in scope, install an AuthMiddleware to set it\")\r\nlitestar.exceptions.http_exceptions.ImproperlyConfiguredException: 500: 'user' is not defined in scope, install an AuthMiddleware to set it\r\n\r\n```\r\n\r\n\r\n### Litestar Version\r\n\r\n2.0.1\r\n\r\n### Platform\r\n\r\n- [X] Linux\r\n- [X] Mac\r\n- [X] Windows\r\n- [X] Other (Please specify in the description above)\r\n",
                "comments": [
                    {
                        "body": "@v3ss0n Does the updated title better reflect the issue?  From your error, it looks like the guard is executing when you send in an `OPTIONS` request and it should not?",
                        "user": "cofin",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-18T18:08:42Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1724126407"
                    },
                    {
                        "body": "Sorry for late reply , after raising this issue i got sick due to food poison . @guacs  already fixed it and i am marking it as closed. \r\n\r\nI am thinking if it is fit better with your title because it happens on Controller and APP level.  What if we apply directly to `options` decorator  ?  ( should not do that but for whatever reason , if someone want to do?) should this still execute?",
                        "user": "v3ss0n",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-26T11:29:58Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1735349069"
                    },
                    {
                        "body": "> Sorry for late reply , after raising this issue i got sick due to food poison . @guacs already fixed it and i am marking it as closed.\r\n> \r\n> I am thinking if it is fit better with your title because it happens on Controller and APP level. What if we apply directly to `options` decorator ? ( should not do that but for whatever reason , if someone want to do?) should this still execute?\r\n\r\nThe fix that was made in #2325 does **NOT** fix this issue by preventing guards from called for OPTIONS requests. It only prevents the middleware from being executed for OPTIONS requests by default. \r\n\r\nThere was already a mechanism for avoiding calling the middleware based on the HTTP method, but there is not an in-built mechanism for guards as of now. ",
                        "user": "guacs",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-26T13:18:36Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1735527776"
                    },
                    {
                        "body": "My workaround for now.\r\n\r\n```python\r\nasync def example_guard(connection: ASGIConnection, _: BaseRouteHandler) -> None:\r\n    if connection.scope.get(\"method\") == \"OPTIONS\":\r\n        return\r\n\r\n    # guard logic\r\n```",
                        "user": "bwalendz",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-27T16:01:55Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1737683131"
                    },
                    {
                        "body": "> My workaround for now.\r\n> \r\n> ```python\r\n> async def example_guard(connection: ASGIConnection, _: BaseRouteHandler) -> None:\r\n>     if connection.scope.get(\"method\") == \"OPTIONS\":\r\n>         return\r\n> \r\n>     # guard logic\r\n> ```\r\n\r\nis that for 2.1 ? I think 2.1 should  be fine for that now.",
                        "user": "v3ss0n",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-27T17:23:28Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1737801628"
                    },
                    {
                        "body": "> > My workaround for now.\r\n> > ```python\r\n> > async def example_guard(connection: ASGIConnection, _: BaseRouteHandler) -> None:\r\n> >     if connection.scope.get(\"method\") == \"OPTIONS\":\r\n> >         return\r\n> > \r\n> >     # guard logic\r\n> > ```\r\n> \r\n> is that for 2.1 ? I think 21 should be fine for that now.\r\n\r\nJust updated to 2.1.1final0 and still behaves the same, the preflight OPTIONS is still being passed to the guard. I think it's similar to what @guacs is describing.\r\n\r\n",
                        "user": "bwalendz",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-27T18:18:30Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1737871449"
                    },
                    {
                        "body": "> > > My workaround for now.\r\n> > > ```python\r\n> > > async def example_guard(connection: ASGIConnection, _: BaseRouteHandler) -> None:\r\n> > >     if connection.scope.get(\"method\") == \"OPTIONS\":\r\n> > >         return\r\n> > > \r\n> > >     # guard logic\r\n> > > ```\r\n> > \r\n> > \r\n> > is that for 2.1 ? I think 21 should be fine for that now.\r\n> \r\n> Just updated to 2.1.1final0 and still behaves the same, the preflight OPTIONS is still being passed to the guard. I think it's similar to what @guacs is describing.\r\n\r\nYeah, that behavior should still be there since it hasn't been fixed yet :P",
                        "user": "guacs",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-28T00:16:56Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1738269729"
                    },
                    {
                        "body": "This problem still exist  , i had tried with 2.3.1 . \r\nWhat should be the best way to fix this. ",
                        "user": "v3ss0n",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-11-06T09:44:40Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1794435764"
                    },
                    {
                        "body": "Just encountered this one today on the latest version 2.3.2",
                        "user": "Kumzy",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-26T13:21:18Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1826783313"
                    },
                    {
                        "body": "It would be easy enough to bypass calling guards for OPTIONS requests - my question is, should it only apply to the options handlers that we generate, or should it be a blanket rule for all OPTIONS method handlers, or be configurable in some manner?",
                        "user": "peterschutt",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-11-27T05:15:42Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1827138101"
                    },
                    {
                        "body": "> It would be easy enough to bypass calling guards for OPTIONS requests - my question is, should it only apply to the options handlers that we generate, or should it be a blanket rule for all OPTIONS method handlers, or be configurable in some manner?\r\n\r\nI think the ideal would be that the guard should only apply to what was defined in the controller/action. So the controller guard should only be applied to `GET /home` and `POST /profile`.\r\n\r\n```python\r\nclass Site(Controller):\r\n   guards = [permission_guard]\r\n\r\n   @get(path=\"/home\")\r\n   async def home(self) -> None:\r\n      pass\r\n\r\n   @post(path=\"/profile\")\r\n   async def profile(self) -> None:\r\n      pass\r\n```\r\n\r\nThe action guard should only apply to its respective action method handled, `GET` or `POST`.\r\n\r\n```python\r\nclass Site(Controller):\r\n   @get(\r\n      path=\"/home\",\r\n      guards=[permission_guard],\r\n   )\r\n   async def home(self) -> None:\r\n      pass\r\n\r\n   @post(\r\n      path=\"/profile\",\r\n      guards=[role_guard],\r\n   )\r\n   async def profile(self) -> None:\r\n      pass\r\n```\r\n\r\n",
                        "user": "bwalendz",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-01-24T22:08:52Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1908995865"
                    },
                    {
                        "body": "> > It would be easy enough to bypass calling guards for OPTIONS requests - my question is, should it only apply to the options handlers that we generate, or should it be a blanket rule for all OPTIONS method handlers, or be configurable in some manner?\r\n> \r\n> I think the ideal would be that the guard should only apply to what was defined in the controller/action. So the controller guard should only be applied to `GET /home` and `POST /profile`.\r\n\r\n\r\nShould we try to handle if an options handler is manually created?\r\n\r\n```py\r\nclass Site(Controller):\r\n   guards = [permission_guard]\r\n\r\n   @get(path=\"/home\")\r\n   async def home(self) -> None:\r\n      pass\r\n\r\n    @route(path=\"/home\", http_method=\"OPTIONS\")\r\n    async def home_options_handler(self) -> Response[str | None]:\r\n        ...\r\n```",
                        "user": "peterschutt",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-01-27T10:03:00Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1913102779"
                    },
                    {
                        "body": "My issue with excluding generated `OPTION` handlers by default is: What if you *want* to include guards for them? IMO all security related things should be strict by default and have an option to make it lax. Having a handler automagically generated circumvents your auth without any way to interfere or possibly even know that this is happening sounds like a potential security nightmare to me and not a good user experience.\r\n\r\nThe workaround presented in [this comment](https://github.com/litestar-org/litestar/issues/2314#issuecomment-1737683131) is the ideal way to handle this IMO; It requires you to explicitly exclude something from the authentication.\r\n",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-01-27T10:16:30Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1913106224"
                    },
                    {
                        "body": "> My issue with excluding generated `OPTION` handlers by default is: What if you _want_ to include guards for them? IMO all security related things should be strict by default and have an option to make it lax. Having a handler automagically generated circumvents your auth without any way to interfere or possibly even know that this is happening sounds like a potential security nightmare to me and not a good user experience.\r\n> \r\n> The workaround presented in [this comment](https://github.com/litestar-org/litestar/issues/2314#issuecomment-1737683131) is the ideal way to handle this IMO; It requires you to explicitly exclude something from the authentication.\r\n\r\nThe main point of my example is i am not explicitly handling OPTIONS requests but the guard is being applied. Preflight OPTIONS are a special case as well because they're forced by the browser for CORS.\r\n\r\nMost other frameworks, through middleware or whatever, will swallow the preflight OPTIONS requests so they don't even make it to your controller because this is the most common use case. So that is another approach instead of needing to workaround every guard that exists.",
                        "user": "bwalendz",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-01T21:40:56Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1922294993"
                    },
                    {
                        "body": "> > My issue with excluding generated `OPTION` handlers by default is: What if you _want_ to include guards for them? IMO all security related things should be strict by default and have an option to make it lax. Having a handler automagically generated circumvents your auth without any way to interfere or possibly even know that this is happening sounds like a potential security nightmare to me and not a good user experience.\r\n> > The workaround presented in [this comment](https://github.com/litestar-org/litestar/issues/2314#issuecomment-1737683131) is the ideal way to handle this IMO; It requires you to explicitly exclude something from the authentication.\r\n> \r\n> The main point of my example is i am not explicitly handling OPTIONS requests but the guard is being applied. Preflight OPTIONS are a special case as well because they're forced by the browser for CORS.\r\n> \r\n> Most other frameworks, through middleware or whatever, will swallow the preflight OPTIONS requests so they don't even make it to your controller because this is the most common use case. So that is another approach instead of needing to workaround every guard that exists.\r\n\r\nI agree with this as well. `OPTIONS` is a special case which means we should have special handling of `OPTIONS` requests as well. I think we should make it configurable somehow, though I'm not sure how easy that would be to implement. This way, the user should be able to specify whether to apply the guards for the automatically created `OPTIONS` handler as well as a way to specify the same for manually created `OPTIONS` handler as well.",
                        "user": "guacs",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-05T05:50:21Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1926276952"
                    },
                    {
                        "body": "We have faced the exact same issue with guards. Took us couple of hours to troubleshoot. If we are not fixing it at least can we all agree to document it?",
                        "user": "HorusTheSonOfOsiris",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-03-19T20:15:16Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-2008051689"
                    },
                    {
                        "body": "@jayantraizada thanks for reminding me to document this! I've added this to the docs and linked to this issue in #3230.",
                        "user": "guacs",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-03-22T16:42:02Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-2015483976"
                    },
                    {
                        "body": "In any case, I don't think this is a bug, since the current behaviour works as intended, and is now also explicitly documented. Closing for now. We might revisit the autogenerated OPTIONS handler behaviour in the future.",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-03-29T16:44:50Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-2027472552"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2305",
                "title": "Docs: error in AbstractAuthenticationMiddleware example",
                "labels": [
                    "Documentation :books:",
                    "Security"
                ],
                "user": "rimai4",
                "issue_author_association": "NONE",
                "number": 2305,
                "id": 1898071330,
                "state": "open",
                "project_created_at": "2023-09-15T09:38:46Z",
                "closed_at": null,
                "body": "### Summary\n\nIn the JWTAuthenticationMiddleware example, the following line gives an error:\r\n\r\n`engine = cast(\"AsyncEngine\", connection.app.state.postgres_connection)`\r\n\r\ncalling keys() on `connection.app.state` gives the following result:\r\n`['db_engine', 'session_maker_class']`\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n\n## Funding\n* If you would like to see an issue prioritized, make a pledge towards it!\n* We receive the pledge once the issue is completed & verified\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2305\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2305/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2305/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [
                    {
                        "body": "I think this entire section needs rewriting. The examples are not even moved to the `examples/` dir.",
                        "user": "geeshta",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-15T12:26:04Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2305#issuecomment-1721192490"
                    },
                    {
                        "body": "> I think this entire section needs rewriting. The examples are not even moved to the `examples/` dir.\r\n\r\nAgreed. If any of you guys want to work on that let me know and I'll assign you (=",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-15T12:36:06Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2305#issuecomment-1721207487"
                    },
                    {
                        "body": "@provinzkraut I'll give it a shot.",
                        "user": "geeshta",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-15T12:44:10Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2305#issuecomment-1721218688"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2288",
                "title": "Bug: serializer not working with misleading message ",
                "labels": [
                    "Bug :bug:",
                    "Needs MCVE"
                ],
                "user": "0xSwego",
                "issue_author_association": "NONE",
                "number": 2288,
                "id": 1887590461,
                "state": "closed",
                "project_created_at": "2023-09-08T12:27:59Z",
                "closed_at": "2023-10-01T01:19:53Z",
                "body": "### Description\r\n\r\nI had some problems with a serializer not working, and displaying an error message I couldn't decipher.\r\n\r\nThe issue was a SQLAlchemy relationship that was defined using a string type instead of the type itself:\r\n`conditions: Mapped[list[\"AlertTemplateCondition\"]] = relationship(back_populates=\"alert_template\")`\r\n\r\nWhen I was trying to serialize this object and its children, this error was raised:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/0xSwego/projects/litestar-backend-template/.venv/lib/python3.10/site-packages/litestar/serialization/msgspec_hooks.py\", line 141, in encode_json\r\n    return msgspec.json.encode(value, enc_hook=serializer) if serializer else _msgspec_json_encoder.encode(value)\r\n  File \"/home/0xSwego/projects/litestar-backend-template/.venv/lib/python3.10/site-packages/litestar/serialization/msgspec_hooks.py\", line 88, in default_serializer\r\n    raise TypeError(f\"Unsupported type: {type(value)!r}\")\r\nTypeError: Unsupported type: <class 'app.domain.alerts.models.AlertTemplateCondition'>\r\n```\r\n\r\nRemoving the quotes from the type fixed the issue:\r\n`conditions: Mapped[list[AlertTemplateCondition]] = relationship(back_populates=\"alert_template\")`\r\n\r\nIt'd be great if the right serializer was found even if the type is written in quotes.\r\n\r\n### URL to code causing the issue\r\n\r\n_No response_\r\n\r\n### MCVE\r\n\r\nModels:\r\n\r\n```py\r\nclass AlertTemplate(orm.DatabaseModel):\r\n    __tablename__ = \"alert_templates\"  # type: ignore[assignment]\r\n    \r\n    conditions: Mapped[list[\"AlertTemplateCondition\"]] = relationship(back_populates=\"alert_template\")\r\n\r\nclass AlertTemplateCondition(orm.DatabaseModel, orm.AuditColumns):\r\n    __tablename__ = \"alert_template_conditions\"  # type: ignore[assignment]\r\n\r\n    alert_template_id: Mapped[UUID] = mapped_column(ForeignKey(\"alert_templates.id\"))\r\n    alert_template: Mapped[AlertTemplate] = relationship()\r\n```\r\n\r\nDTOs:\r\n```py\r\nclass AlertTemplateDTO(SQLAlchemyDTO[AlertTemplate]):\r\n    config = dto.config(max_nested_depth=1)\r\n\r\nclass AlertTemplateConditionDTO(SQLAlchemyDTO[AlertTemplateCondition]):\r\n    config = dto.config(max_nested_depth=0)\r\n```\r\n\r\nController:\r\n```py\r\nclass AlertTemplatesController(Controller):\r\n    \"\"\"Handles the interactions within the AlertTemplate objects.\"\"\"\r\n\r\n    dependencies = {\"alert_template_service\": provide_alert_template_service}\r\n    return_dto = AlertTemplateDTO\r\n\r\n    @get(\r\n        operation_id=\"ListAlertTemplates\",\r\n        name=\"alert_templates:list\",\r\n        summary=\"List Alert Templates\",\r\n        path=urls.ALERT_TEMPLATES_LIST,\r\n    )\r\n    async def list_alert_templates(\r\n        self,\r\n        alert_template_service: AlertTemplateService,\r\n    ) -> OffsetPagination[AlertTemplate]:\r\n        \"\"\"List all alert templates\"\"\"\r\n        results = await alert_template_service.list()\r\n        return alert_template_service.to_dto(results)\r\n```\r\n\r\n### Litestar Version\r\n\r\n2.0.1\r\n\r\n### Platform\r\n\r\n- [X] Linux\r\n- [ ] Mac\r\n- [X] Windows\r\n- [ ] Other (Please specify in the description above)\r\n\r\n<!-- POLAR PLEDGE BADGE START -->\r\n---\r\n\r\n## Funding\r\n* If you would like to see an issue prioritized, make a pledge towards it!\r\n* We receive the pledge once the issue is completed & verified\r\n\r\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2288\">\r\n<picture>\r\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2288/pledge.svg?darkmode=1\">\r\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2288/pledge.svg\">\r\n</picture>\r\n</a>\r\n<!-- POLAR PLEDGE BADGE END -->\r\n",
                "comments": [
                    {
                        "body": "Could you provide a minimal reproduction of the bug?",
                        "user": "guacs",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-08T13:11:18Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2288#issuecomment-1711649522"
                    },
                    {
                        "body": "@guacs sure! I have taken the litestar-fullstack repo and added the code that is causing the problem:\r\nhttps://github.com/0xSwego/litestar-fullstack/tree/master\r\n\r\nI've also added a test that fails due to the error. Running `pytest tests/integration/test_alerts.py` will trigger it",
                        "user": "0xSwego",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-08T13:55:47Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2288#issuecomment-1711714930"
                    },
                    {
                        "body": "@0xSwego I'm having some trouble reproducing this. Could you provide a minimal example with a minimal self-contained application (not the litestar-fullstack one)?",
                        "user": "guacs",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-11T15:13:21Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2288#issuecomment-1714091158"
                    },
                    {
                        "body": "@0xSwego any updates on this?",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-17T08:20:54Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2288#issuecomment-1722422762"
                    },
                    {
                        "body": "@guacs I wouldn't know where to start from and it would take me a huge amount of time. If the issue cannot be reproduced because you have troubles with the code, I can close it.",
                        "user": "0xSwego",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-18T11:43:18Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2288#issuecomment-1723239692"
                    },
                    {
                        "body": "> @guacs I wouldn't know where to start from and it would take me a huge amount of time. If the issue cannot be reproduced because you have troubles with the code, I can close it.\r\n\r\nLet me try once more to reproduce this. If I'm not able to, then we can close it.",
                        "user": "guacs",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-18T12:57:24Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2288#issuecomment-1723354286"
                    },
                    {
                        "body": "@guacs you should be able to set up the whole project with the `make install` command (Unix friendly, unfortunately. I am on Windows and use WSL)",
                        "user": "0xSwego",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-18T13:14:46Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2288#issuecomment-1723387085"
                    },
                    {
                        "body": "@guacs any updates?",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-30T10:55:22Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2288#issuecomment-1741739814"
                    },
                    {
                        "body": "I'm closing this since I haven't been able to create an MCVE for this. If anyone faces this issue and can provide an MCVE, please feel free to reopen the issue.",
                        "user": "guacs",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-10-01T01:19:53Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2288#issuecomment-1741913400"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2118",
                "title": "Enhancement: Revoke jwt token",
                "labels": [
                    "Enhancement",
                    "Help Wanted :sos:",
                    "Good First Issue",
                    "Security"
                ],
                "user": "julio-34727",
                "issue_author_association": "NONE",
                "number": 2118,
                "id": 1836425637,
                "state": "open",
                "project_created_at": "2023-08-04T09:48:10Z",
                "closed_at": null,
                "body": "### Summary\n\nProvide a mechanism to revoke a jwt token on /logout similar to `flask-jwt-extended` (https://flask-jwt-extended.readthedocs.io/en/stable/blocklist_and_token_revoking.html).\n\n### Basic Example\n\n_No response_\n\n### Drawbacks and Impact\n\n_No response_\n\n### Unresolved questions\n\n_No response_\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n\n## Funding\n* If you would like to see an issue prioritized, make a pledge towards it!\n* We receive the pledge once the issue is completed & verified\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2118\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2118/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2118/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [
                    {
                        "body": "I would like to work on this but i'm not sure whats being asked. it doesn't seem like the example specified in the url: (https://flask-jwt-extended.readthedocs.io/en/stable/blocklist_and_token_revoking.html) does anything in particular to revoke the token for you. ",
                        "user": "andrewdoh",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-12-22T05:52:05Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2118#issuecomment-1867271755"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2071",
                "title": "Enhancement: integration with external OAuth2 provider.",
                "labels": [
                    "Enhancement",
                    "Help Wanted :sos:",
                    "polar",
                    "Security"
                ],
                "user": "cofin",
                "issue_author_association": "MEMBER",
                "number": 2071,
                "id": 1822979798,
                "state": "open",
                "project_created_at": "2023-07-26T18:55:30Z",
                "closed_at": null,
                "body": "### Summary\n\nIt would be great to have an integration with a third party library or have built in support for authenticating with OAuth2 providers such as Google or Github.\r\n\n\n### Basic Example\n\n_No response_\n\n### Drawbacks and Impact\n\n_No response_\n\n### Unresolved questions\n\n_No response_\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n\n## Funding\n* If you would like to see an issue prioritized, make a pledge towards it!\n* We receive the pledge once the issue is completed & verified\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2071\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2071/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2071/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [
                    {
                        "body": "This could/would be accomplished by developing an internal plugin via https://docs.litestar.dev/latest/usage/plugins.html#plugins.\r\n\r\nSome examples of others: \r\n- https://github.com/litestar-org/litestar/pull/3145#issuecomment-1966921258\r\n- https://github.com/cofin/litestar-granian\r\n- https://github.com/guacs/litestar-svcs",
                        "user": "JacobCoffee",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-28T00:42:56Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2071#issuecomment-1967977746"
                    },
                    {
                        "body": "I think we could develop a plugin for this, but imo it should be maintained as a seperate library (officially maintained by Litestar). Most likely we want to use something like [authlib](https://github.com/lepture/authlib/) to implement this and if this is kept separate, then users would only have to install it if they need it.",
                        "user": "guacs",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-28T00:48:08Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2071#issuecomment-1967982803"
                    },
                    {
                        "body": "By \"external OAuth2 provider\", do you mean a Python library or a separate OAuth2 provider? Because [Keycloak](https://github.com/keycloak/keycloak) is a no-brainer despite being written in Java.\r\n\r\nThere's also [python-social-auth](https://github.com/python-social-auth/social-core/blob/master/social_core/backends/github.py), which is used by [Zulip](https://github.com/zulip/zulip/blob/22bd8048b118f93758d2b0afd76acfc89eeeb3d9/zproject/backends.py#L2072) and [Sentry](https://github.com/getsentry/sentry/blob/f30cabd30a08718e26bee96a25e75e2b4ecc8b23/src/social_auth/backends/github.py#L35).\r\n\r\nHowever, it's worth noting that both projects seem to have integrated that library's source code into their own repository. Hence, their \"forks\" are maintained independently, which impacts [the library's health and integrity](https://github.com/python-social-auth/social-core/issues/445).\r\n\r\n",
                        "user": "codespearhead",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-03-13T02:01:57Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2071#issuecomment-1993107365"
                    },
                    {
                        "body": "I think at this stage, we have \"native\" support in the library and all we need to do OAuth2 connections as a client to any server.\r\n\r\nI'm not sure what we want here, but maybe some nice abstraction with some built-in common providers as a plugin that users can opt-in to?\r\n\r\n@litestar-org/maintainers ?",
                        "user": "JacobCoffee",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-03-13T03:14:06Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2071#issuecomment-1993285825"
                    },
                    {
                        "body": "Makes sense, because keeping the OAuth client and the OAuth provider in the same package is risky imo, given how much of a burden maintaining the latter actually is.\n\nFor reference: [Laravel Socialite](https://github.com/laravel/socialite) is an OAuth client with a few official adapters, whereas other adapters are [maintained by the community](https://github.com/SocialiteProviders/Providers/tree/master/src).",
                        "user": "codespearhead",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-03-13T03:22:16Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2071#issuecomment-1993305418"
                    },
                    {
                        "body": "In the Django world there is the kind of de-facto standard https://github.com/pennersr/django-allauth. Could be interesting to have a look at its implementation. Enabling authentication using regular accounts (user name + email + password or one time code) in addition to social accounts (GitHub, ) would be great. This would require to provide email service provider integration https://github.com/litestar-org/litestar/issues/3520 to enable email transmission based workflows for regular accounts (email verification email, password change email, ).",
                        "user": "fkromer",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-05-24T22:58:20Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2071#issuecomment-2130487187"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2020",
                "title": "Bug: TypeError: parse_url_encoded_dict() got some positional-only arguments passed as keyword arguments: 'qs' and 'parse_numbers'",
                "labels": [
                    "Bug :bug:",
                    "Upstream",
                    "Great MCVE"
                ],
                "user": "euri10",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2020,
                "id": 1813835813,
                "state": "closed",
                "project_created_at": "2023-07-20T12:00:46Z",
                "closed_at": "2023-07-20T13:34:48Z",
                "body": "### Description\r\n\r\nNew litestar install\r\n```\r\n poetry add git+https://github.com/litestar-org/litestar.git\r\n\r\nUpdating dependencies\r\nResolving dependencies... (1.2s)\r\n\r\nPackage operations: 7 installs, 0 updates, 0 removals\r\n\r\n   Installing python-dateutil (2.8.2)\r\n   Installing faker (19.1.0)\r\n   Installing fast-query-parsers (1.0.1)\r\n   Installing msgspec (0.17.0)\r\n   Installing multidict (6.0.4)\r\n   Installing polyfactory (2.6.2)\r\n   Installing litestar (2.0.0beta2 dc8790e)\r\n```\r\nleads to this error filling the form below:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/middleware/exceptions/middleware.py\", line 157, in __call__\r\n    await self.app(scope, receive, send)\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/routes/http.py\", line 77, in handle\r\n    response = await self._get_response_for_request(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/routes/http.py\", line 129, in _get_response_for_request\r\n    response = await self._call_handler_function(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/routes/http.py\", line 158, in _call_handler_function\r\n    response_data, cleanup_group = await self._get_response_data(\r\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/routes/http.py\", line 182, in _get_response_data\r\n    kwargs[\"data\"] = await kwargs[\"data\"]\r\n                     ^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/_kwargs/extractors.py\", line 363, in extract_url_encoded_extractor\r\n    else parse_url_encoded_form_data(await connection.body())\r\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/_parsers.py\", line 24, in parse_url_encoded_form_data\r\n    return parse_url_encoded_dict(qs=encoded_data, parse_numbers=False)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nTypeError: parse_url_encoded_dict() got some positional-only arguments passed as keyword arguments: 'qs' and 'parse_numbers'\r\nTraceback (most recent call last):\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/middleware/exceptions/middleware.py\", line 157, in __call__\r\n    await self.app(scope, receive, send)\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/routes/http.py\", line 77, in handle\r\n    response = await self._get_response_for_request(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/routes/http.py\", line 129, in _get_response_for_request\r\n    response = await self._call_handler_function(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/routes/http.py\", line 158, in _call_handler_function\r\n    response_data, cleanup_group = await self._get_response_data(\r\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/routes/http.py\", line 182, in _get_response_data\r\n    kwargs[\"data\"] = await kwargs[\"data\"]\r\n                     ^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/_kwargs/extractors.py\", line 363, in extract_url_encoded_extractor\r\n    else parse_url_encoded_form_data(await connection.body())\r\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/_parsers.py\", line 24, in parse_url_encoded_form_data\r\n    return parse_url_encoded_dict(qs=encoded_data, parse_numbers=False)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nTypeError: parse_url_encoded_dict() got some positional-only arguments passed as keyword arguments: 'qs' and 'parse_numbers'\r\nINFO:     127.0.0.1:51104 - \"POST /auth/login HTTP/1.1\" 500 Internal Server Error\r\n```\r\n\r\n### URL to code causing the issue\r\n\r\n_No response_\r\n\r\n### MCVE\r\n\r\n```python\r\n@dataclass\r\nclass LoginFormData:\r\n    username: str\r\n    password: str\r\n    captcha: str\r\n\r\n\r\n@post(\"/login\", name=\"login_post\")\r\nasync def login_post(\r\n    request: Request,\r\n    conn: BuildPgConnection,\r\n    app_settings: AppSettings,\r\n    data: Annotated[LoginFormData, Body(media_type=RequestEncodingType.URL_ENCODED)],\r\n) -> Template:\r\n    try:\r\n```\r\n\r\n\r\n### Steps to reproduce\r\n\r\n```bash\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n```\r\n\r\n\r\n### Screenshots\r\n\r\n```bash\r\n\"![SCREENSHOT_DESCRIPTION](SCREENSHOT_LINK.png)\"\r\n```\r\n\r\n\r\n### Logs\r\n\r\n_No response_\r\n\r\n### Litestar Version\r\n\r\n   Installing litestar (2.0.0beta2 dc8790e)\r\n\r\n\r\n### Platform\r\n\r\n- [X] Linux\r\n- [ ] Mac\r\n- [ ] Windows\r\n- [ ] Other (Please specify in the description above)\r\n\r\n<!-- POLAR PLEDGE BADGE START -->\r\n## Funding\r\n* If you would like to see an issue prioritized, make a pledge towards it!\r\n* We receive the pledge once the issue is completed & verified\r\n\r\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2020\">\r\n<picture>\r\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2020/pledge.svg?darkmode=1\">\r\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2020/pledge.svg\">\r\n</picture>\r\n</a>\r\n<!-- POLAR PLEDGE BADGE END -->\r\n",
                "comments": [
                    {
                        "body": "I believe this is related to a recent change in `fast-query-parsers`. @Goldziher?\r\n\r\nNot sure why this hasn't been caught in our tests though.",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-07-20T12:07:36Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2020#issuecomment-1643808008"
                    },
                    {
                        "body": "Hmm yes, seems that maturin is positional only. \n\nCan you remove `parse_numbers=` and keep the args?",
                        "user": "Goldziher",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-07-20T12:17:12Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2020#issuecomment-1643820882"
                    },
                    {
                        "body": "> Hmm yes, seems that maturin is positional only.\r\n\r\nIt does support it. I have a fix read to go for `fast-query-parsers`. PR incoming.",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-07-20T12:18:29Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2020#issuecomment-1643822709"
                    },
                    {
                        "body": "> I believe this is related to a recent change in `fast-query-parsers`. @Goldziher?\r\n> \r\n> Not sure why this hasn't been caught in our tests though.\r\n\r\nI dont know the code well enough but it seems to me that test_kwargs only uses https://github.com/litestar-org/litestar/blob/dc8790e63f0e90f1650042558a9be620bf4b1eae/tests/unit/test_kwargs/__init__.py#L4-L8 so there are no tests on other possible attrs, dataclass forms etc, might be wrong on this again I dont know the source well enough",
                        "user": "euri10",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-07-20T12:31:11Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2020#issuecomment-1643841022"
                    },
                    {
                        "body": "This should resolve it: https://github.com/litestar-org/fast-query-parsers/pull/18 by allowing positional as well as keyword arguments.",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-07-20T12:31:53Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2020#issuecomment-1643842032"
                    },
                    {
                        "body": "> so there are no tests on other possible attrs, dataclass forms etc, might be wrong on this again I dont know the source well enough\r\n\r\nThe issue is at the calling site of `parse_url_encoded_form_data`, which we definitely run during tests. We'll have to investigate that one.\r\n\r\nhttps://github.com/litestar-org/litestar/blob/dc8790e63f0e90f1650042558a9be620bf4b1eae/litestar/_parsers.py#L24",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-07-20T12:34:06Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2020#issuecomment-1643845151"
                    },
                    {
                        "body": "yep, sorry I was referring to https://github.com/litestar-org/litestar/issues/2019 and https://github.com/litestar-org/litestar/issues/1997, wrong topic",
                        "user": "euri10",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-07-20T12:36:59Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2020#issuecomment-1643849242"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/1837",
                "title": "KeyError when configuring DTO",
                "labels": [
                    "Bug :bug:",
                    "Triage Required :hospital:",
                    "Needs MCVE"
                ],
                "user": "jhert0",
                "issue_author_association": "NONE",
                "number": 1837,
                "id": 1761819429,
                "state": "closed",
                "project_created_at": "2023-06-17T12:47:59Z",
                "closed_at": "2023-06-18T02:09:39Z",
                "body": "### Description\r\n\r\nI'm getting a KeyError on startup that seems to be coming from my DTO I create with SQLAlchemyDTO. The property that is being called out in the exception is a relationship. If I try to exclude it from the DTO I still get the error.\r\n\r\n### URL to code causing the issue\r\n\r\n_No response_\r\n\r\n### MCVE\r\n\r\n_No response_\r\n\r\n### Steps to reproduce\r\n\r\n```\r\n1. Create a model for SQLAlchemy that includes a relationship to another model.\r\n2. Create a DTO for the one that has the relationship.\r\n3. Start the app.\r\n```\r\n\r\n\r\n### Screenshots\r\n\r\n_No response_\r\n\r\n### Logs\r\n\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/bin/litestar\", line 8, in <module>\r\n    sys.exit(run_cli())\r\n             ^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/__main__.py\", line 6, in run_cli\r\n    litestar_group()\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/click/core.py\", line 1130, in __call__\r\n    return self.main(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/click/core.py\", line 1055, in main\r\n    rv = self.invoke(ctx)\r\n         ^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/click/core.py\", line 1657, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/click/core.py\", line 1404, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/click/core.py\", line 760, in invoke\r\n    return __callback(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/click/decorators.py\", line 26, in new_func\r\n    return f(get_current_context(), *args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/cli/_utils.py\", line 231, in wrapped\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/cli/commands/core.py\", line 113, in run_command\r\n    env = cast(LitestarEnv, ctx.obj())\r\n                            ^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/cli/main.py\", line 51, in <lambda>\r\n    ctx.obj = lambda: LitestarEnv.from_env(app_path)\r\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/cli/_utils.py\", line 113, in from_env\r\n    loaded_app = _load_app_from_path(app_path)\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/cli/_utils.py\", line 254, in _load_app_from_path\r\n    module = importlib.import_module(module_path)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<frozen importlib._bootstrap>\", line 1206, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1178, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1149, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"/home/jhert/src/bankroller/services/vault/vault/main.py\", line 24, in <module>\r\n    app = Litestar(\r\n          ^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/app.py\", line 432, in __init__\r\n    self.register(route_handler)\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/app.py\", line 570, in register\r\n    route_handler.on_registration(self)\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/handlers/http_handlers/base.py\", line 482, in on_registration\r\n    super().on_registration(app)\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/handlers/base.py\", line 393, in on_registration\r\n    self._init_handler_dtos()\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/handlers/base.py\", line 372, in _init_handler_dtos\r\n    return_dto.on_registration(HandlerContext(\"return\", str(self), self.parsed_fn_signature.return_type))\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/dto/factory/abc.py\", line 171, in on_registration\r\n    backend = cls._type_backend_map.setdefault(key, backend_type(backend_context))\r\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/dto/factory/_backends/abc.py\", line 124, in __init__\r\n    self.parsed_field_definitions = self.parse_model(context.model_type, context.config.exclude)\r\n                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/dto/factory/_backends/abc.py\", line 162, in parse_model\r\n    for field_definition in self.context.field_definition_generator(model_type):\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/contrib/sqlalchemy/dto.py\", line 195, in generate_field_definitions\r\n    yield from cls.handle_orm_descriptor(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/lib/python3.11/functools.py\", line 946, in _method\r\n    return method.__get__(obj, cls)(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/contrib/sqlalchemy/dto.py\", line 86, in _\r\n    if (parsed_type := model_type_hints[key]).origin is Mapped:\r\n                       ~~~~~~~~~~~~~~~~^^^^^\r\nKeyError: 'prices'\r\n```\r\n\r\n\r\n### Litestar Version\r\n\r\n2.0.0b1\r\n\r\n### Platform\r\n\r\n- [X] Linux\r\n- [ ] Mac\r\n- [ ] Windows\r\n- [ ] Other (Please specify in the description above)",
                "comments": [
                    {
                        "body": "Hey @jhert0 thanks for reporting this. Can you provide a reproducible example for the behaviour you're describing?",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-06-17T12:56:43Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1837#issuecomment-1595741551"
                    },
                    {
                        "body": "As @provinzkraut suggested, an example that properly reproduces the issue is going to be a big help. Not only for identifying the source of the issue, but also for assessing whether there is some pattern of usage that we need to consider more thoroughly.\r\n\r\nThe `SQLAlchemyDTO` is tested against relationships in these tests:\r\n\r\n- https://github.com/litestar-org/litestar/blob/a1842a000f2f3639bc9d1b0875ae31da050689cd/tests/contrib/sqlalchemy/test_dto.py#L229\r\n- https://github.com/litestar-org/litestar/blob/a1842a000f2f3639bc9d1b0875ae31da050689cd/tests/contrib/sqlalchemy/test_dto.py#L270\r\n- https://github.com/litestar-org/litestar/blob/a1842a000f2f3639bc9d1b0875ae31da050689cd/tests/contrib/sqlalchemy/test_dto.py#L374\r\n- https://github.com/litestar-org/litestar/blob/a1842a000f2f3639bc9d1b0875ae31da050689cd/tests/contrib/sqlalchemy/test_dto.py#L412\r\n- https://github.com/litestar-org/litestar/blob/a1842a000f2f3639bc9d1b0875ae31da050689cd/tests/contrib/sqlalchemy/test_dto.py#L449\r\n\r\nSo perhaps you can look at those as an example of how to build an MCVE for the DTO and help us to determine what is different in your case.\r\n\r\nGiven that the exception originates as a key error from the type hints extracted from the model in this line:\r\n\r\n```\r\n    if (parsed_type := model_type_hints[key]).origin is Mapped:\r\n```\r\n\r\nI'm speculating that the relationship might be declared on the model without a type annotation. E.g.,:\r\n\r\n```py\r\nclass Market(Base):\r\n    prices = relationship(\"Price\")\r\n```\r\n\r\nInstead of something like:\r\n\r\n```py\r\nclass Market(Base):\r\n    prices: Mapped[list[Price]] = relationship()\r\n```\r\n\r\nSpeculation on my part though, so I'll wait to hear from you before going any further.\r\n\r\nCheers.",
                        "user": "peterschutt",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-06-17T22:46:34Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1837#issuecomment-1595878693"
                    },
                    {
                        "body": "Yes that was it, I was missing the type hint. Thank you.",
                        "user": "jhert0",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-06-18T02:09:39Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1837#issuecomment-1595926138"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/1761",
                "title": "DTO : TypeError: 'NoneType' object is not iterable",
                "labels": [
                    "Triage Required :hospital:",
                    "Needs MCVE"
                ],
                "user": "v3ss0n",
                "issue_author_association": "CONTRIBUTOR",
                "number": 1761,
                "id": 1731953007,
                "state": "closed",
                "project_created_at": "2023-05-30T10:14:43Z",
                "closed_at": "2023-06-07T11:18:16Z",
                "body": "### Description\r\n\r\nAfter updating to 76696a2ae243ed05c4361e9f4dda3e06d0859e16 \r\nDTOs i have , having this error .\r\n\r\n```py\r\nTypeError: 'NoneType' object is not iterable\r\n```\r\n\r\n\r\n### URL to code causing the issue\r\n\r\n_No response_\r\n\r\n### MCVE\r\nhttps://github.com/v3ss0n/starlite-pg-redis-docker/tree/repro-dto-nontype\r\n\r\n\r\n### Steps to reproduce\r\n\r\n1. Make a request to Projects API\r\n```bash\r\ncurl -X 'GET' \\\r\n  'http://localhost:8000/v1/api/projects?page=1&page-size=100' \\\r\n  -H 'accept: application/json'\r\n```\r\n2. See error\r\n\r\n\r\n### Screenshots\r\n\r\n```bash\r\n\"![SCREENSHOT_DESCRIPTION](SCREENSHOT_LINK.png)\"\r\n```\r\n\r\n\r\n### Logs\r\n\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/middleware/exceptions/middleware.py\", line 150, in __call__\r\n    await self.app(scope, receive, send)\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 77, in handle\r\n    response = await self._get_response_for_request(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 129, in _get_response_for_request\r\n    response = await self._call_handler_function(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 162, in _call_handler_function\r\n    response: ASGIApp = await route_handler.to_response(app=scope[\"app\"], data=response_data, request=request)\r\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/base.py\", line 469, in to_response\r\n    return await response_handler(app=app, data=data, request=request, return_dto=self.resolve_return_dto())  # type: ignore\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/_utils.py\", line 99, in handler\r\n    data = return_dto(ctx).data_to_encodable_type(data)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/abc.py\", line 103, in data_to_encodable_type\r\n    return backend.encode_data(data, self.connection_context)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/abc.py\", line 286, in encode_data\r\n    return transfer_data(\r\n           ^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/utils.py\", line 140, in transfer_data\r\n    return type(source_data)(\r\n           ^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/utils.py\", line 141, in <genexpr>\r\n    transfer_data(destination_type, item, field_definitions, dto_for)  # type:ignore[call-arg]\r\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/utils.py\", line 144, in transfer_data\r\n    return transfer_instance_data(destination_type, source_data, field_definitions, dto_for)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/utils.py\", line 196, in transfer_instance_data\r\n    unstructured_data[destination_name] = transfer_type_data(\r\n                                          ^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/utils.py\", line 240, in transfer_type_data\r\n    return transfer_type.parsed_type.origin(source_value)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nTypeError: 'NoneType' object is not iterable\r\n```\r\n\r\n\r\n### Litestar Version\r\n\r\n76696a2ae243ed05c4361e9f4dda3e06d0859e16\r\n\r\n### Platform\r\n\r\n- [X] Linux\r\n- [ ] Mac\r\n- [ ] Windows\r\n- [ ] Other (Please specify in the description above)",
                "comments": [
                    {
                        "body": "I couldn't do it in minimal way so i pushed a repo , based on  full-stack .\r\nAlso the error has been changed to  `TypeError: Sequence() takes no arguments`  after updating to latest commit \r\n\r\n\r\n```py\r\nTraceback (most recent call last):\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/middleware/exceptions/middleware.py\", line 150, in __call__\r\n    await self.app(scope, receive, send)\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 77, in handle\r\n    response = await self._get_response_for_request(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 129, in _get_response_for_request\r\n    response = await self._call_handler_function(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 162, in _call_handler_function\r\n    response: ASGIApp = await route_handler.to_response(app=scope[\"app\"], data=response_data, request=request)\r\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/base.py\", line 469, in to_response\r\n    return await response_handler(app=app, data=data, request=request, return_dto=self.resolve_return_dto())  # type: ignore\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/_utils.py\", line 99, in handler\r\n    data = return_dto(ctx).data_to_encodable_type(data)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/abc.py\", line 103, in data_to_encodable_type\r\n    return backend.encode_data(data, self.connection_context)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/abc.py\", line 300, in encode_data\r\n    return transfer_data(\r\n           ^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/utils.py\", line 148, in transfer_data\r\n    return origin(  # type:ignore[no-any-return]\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nTypeError: Sequence() takes no arguments\r\n```\r\n \r\n https://github.com/v3ss0n/litestar-fullstack-error-reproduce ",
                        "user": "v3ss0n",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-05-30T17:32:59Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1761#issuecomment-1568814594"
                    },
                    {
                        "body": "better MVCE added : https://github.com/v3ss0n/starlite-pg-redis-docker/tree/repro-dto-nontype",
                        "user": "v3ss0n",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-05-30T18:17:00Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1761#issuecomment-1568869259"
                    },
                    {
                        "body": "it comes from this line (which was totally fine before update)\r\n`async def filter(self, service: \"Service\", filters: list[\"FilterTypes\"] = validation_skip) -> Sequence[Model]:`\r\nafter changing `Sequence[Model]` to list[Model]` - problem solved\r\n\r\nBut `Sequence` is fine before the update.\r\n\r\nEDIT: MyPy don't like `list[Model]`\r\n```\r\nsrc/app/domain/projects/controllers.py:43: error: Incompatible return value type (got \"Sequence[Project]\", expected \"List[Project]\")  [return-value]\r\nsrc/app/domain/backlogs/controllers.py:42: error: Incompatible return value type (got \"Sequence[Backlog]\", expected \"List[Backlog]\")  [return-value]\r\nFound 2 errors in 2 files (checked 2 source files)\r\n```",
                        "user": "v3ss0n",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-05-30T18:44:50Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1761#issuecomment-1568905421"
                    },
                    {
                        "body": "> I couldn't do it in minimal way so i pushed a repo , based on  full-stack .\n> \n> Also the error has been changed to  `TypeError: Sequence() takes no arguments`  after updating to latest commit \n> \n> \n> \n> \n> \n> ```py\n> \n> Traceback (most recent call last):\n> \n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/middleware/exceptions/middleware.py\", line 150, in __call__\n> \n>     await self.app(scope, receive, send)\n> \n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 77, in handle\n> \n>     response = await self._get_response_for_request(\n> \n>                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n> \n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 129, in _get_response_for_request\n> \n>     response = await self._call_handler_function(\n> \n>                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n> \n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 162, in _call_handler_function\n> \n>     response: ASGIApp = await route_handler.to_response(app=scope[\"app\"], data=response_data, request=request)\n> \n>                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n> \n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/base.py\", line 469, in to_response\n> \n>     return await response_handler(app=app, data=data, request=request, return_dto=self.resolve_return_dto())  # type: ignore\n> \n>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n> \n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/_utils.py\", line 99, in handler\n> \n>     data = return_dto(ctx).data_to_encodable_type(data)\n> \n>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n> \n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/abc.py\", line 103, in data_to_encodable_type\n> \n>     return backend.encode_data(data, self.connection_context)\n> \n>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n> \n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/abc.py\", line 300, in encode_data\n> \n>     return transfer_data(\n> \n>            ^^^^^^^^^^^^^^\n> \n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/utils.py\", line 148, in transfer_data\n> \n>     return origin(  # type:ignore[no-any-return]\n> \n>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n> \n> TypeError: Sequence() takes no arguments\n> \n> ```\n> \n>  \n> \n>  https://github.com/v3ss0n/litestar-fullstack-error-reproduce \n\nThis isn't the same error as the OP though? Sure it is the same issue?",
                        "user": "peterschutt",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-05-30T19:31:02Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1761#issuecomment-1568970927"
                    },
                    {
                        "body": "> I couldn't do it in minimal way so i pushed a repo , based on full-stack . Also the error has been changed to `TypeError: Sequence() takes no arguments` after updating to latest commit\r\n> \r\n> ```python\r\n> Traceback (most recent call last):\r\n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/middleware/exceptions/middleware.py\", line 150, in __call__\r\n>     await self.app(scope, receive, send)\r\n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 77, in handle\r\n>     response = await self._get_response_for_request(\r\n>                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 129, in _get_response_for_request\r\n>     response = await self._call_handler_function(\r\n>                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 162, in _call_handler_function\r\n>     response: ASGIApp = await route_handler.to_response(app=scope[\"app\"], data=response_data, request=request)\r\n>                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/base.py\", line 469, in to_response\r\n>     return await response_handler(app=app, data=data, request=request, return_dto=self.resolve_return_dto())  # type: ignore\r\n>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/_utils.py\", line 99, in handler\r\n>     data = return_dto(ctx).data_to_encodable_type(data)\r\n>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/abc.py\", line 103, in data_to_encodable_type\r\n>     return backend.encode_data(data, self.connection_context)\r\n>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/abc.py\", line 300, in encode_data\r\n>     return transfer_data(\r\n>            ^^^^^^^^^^^^^^\r\n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/utils.py\", line 148, in transfer_data\r\n>     return origin(  # type:ignore[no-any-return]\r\n>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n> TypeError: Sequence() takes no arguments\r\n> ```\r\n> \r\n> https://github.com/v3ss0n/litestar-fullstack-error-reproduce\r\n\r\nI know what the issue is here and this is fixed easy enough - but I doubt this is the same as your OP.\r\n\r\nHowever, I think you should consider why the service object is annotated as if it returns generic sequences from the `list()` method, when it knows that it returns a concrete `list`, e.g. [this](https://github.com/cofin/litestar-fullstack/blob/046592ece2abe69c7dd66f6757cd9bd49c4f6e17/src/app/lib/service/sqlalchemy.py#L331-L341):\r\n\r\n```py\r\n    async def list(self, *filters: FilterTypes, **kwargs: Any) -> Sequence[ModelT]:\r\n        \"\"\"Wrap repository scalars operation.\r\n\r\n        Args:\r\n            *filters: Collection route filters.\r\n            **kwargs: Keyword arguments for attribute based filtering.\r\n\r\n        Returns:\r\n            The list of instances retrieved from the repository.\r\n        \"\"\"\r\n        return await self.repository.list(*filters, **kwargs)\r\n```\r\nIf this method is typed to return `list[ModelT]` - which is what the `repository.list()` method is annotated to return, then you don't need to type the return type of your handler as `Sequence[ModelT]` in the first place.\r\n\r\nGeneric collections are usually good to annotate function arguments with, as when you are authoring a function, you tend to know what you are doing with the argument value within the function, and so you know if you just need any old sequence, or if you are relying on particular methods of a concrete collection type.\r\n\r\nOn the other hand, using generic types for return annotations means that downstream users of that method need to inspect the object, or cast it to something else at runtime so that they know what they are actually dealing with. E.g.,:\r\n\r\n```py\r\ndef returns_list() -> Sequence[int]:\r\n    return [1, 2, 3]\r\n\r\nl = returns_list()\r\nl.append(4)  # mypy will complain because it thinks `l` is a generic sequence which has no `append()` method\r\n\r\n# so user needs to do this\r\nl = list(returns_list())\r\nl.append(4)\r\n```\r\nThis example is essentially what the service object is does in that repo. It knows that `self.repository.list()` returns a `list`, but annotates the return of its own `list()` method as `Sequence`, which loses info for downstream users.\r\n",
                        "user": "peterschutt",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-05-30T20:25:25Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1761#issuecomment-1569045935"
                    },
                    {
                        "body": "Created #1763 for the `Sequence` issue - I minimized most of the conversation around that in this issue as it not the same issue as OP.",
                        "user": "peterschutt",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-05-30T22:38:47Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1761#issuecomment-1569221059"
                    },
                    {
                        "body": "> This isn't the same error as the OP though? Sure it is the same issue?\r\n\r\nYeah , the first issue gone after i updated to ccc9b33831620ea20a4dffa0d0a76501f2a785bb   , I will try to reproduce the OP again.",
                        "user": "v3ss0n",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-05-31T02:42:15Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1761#issuecomment-1569414828"
                    },
                    {
                        "body": "I'll close this for now @v3ss0n - please reopen if you can reproduce.",
                        "user": "peterschutt",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-06-07T11:18:16Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1761#issuecomment-1580572290"
                    },
                    {
                        "body": "I haven't encourter the first issue yet.  so its safe to close so far. thanks a lot !",
                        "user": "v3ss0n",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-06-07T16:42:49Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1761#issuecomment-1581182422"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/1615",
                "title": "Bug: Using `websocket_listener` in controller causes `TypeError: .handler_fn() got multiple values for argument 'socket'`",
                "labels": [
                    "Bug :bug:",
                    "Great MCVE"
                ],
                "user": "xEricL",
                "issue_author_association": "NONE",
                "number": 1615,
                "id": 1694337319,
                "state": "closed",
                "project_created_at": "2023-05-03T15:44:09Z",
                "closed_at": "2023-05-07T16:07:49Z",
                "body": "### Description\r\n\r\nConfirmed by @provinzkraut in Discord\r\n\r\n\r\n\r\n### URL to code causing the issue\r\n\r\n_No response_\r\n\r\n### MCVE\r\n\r\n```python\r\nfrom litestar import Controller, WebSocket, websocket_listener\r\nfrom litestar.testing import create_test_client\r\n\r\n\r\nclass ClientController(Controller):\r\n    path: str = \"/client\"\r\n\r\n    @websocket_listener(\"/ws\")\r\n    async def websocket_handler(self, data: bytes, socket: WebSocket) -> bytes:\r\n        return data\r\n\r\n\r\nwith create_test_client(ClientController) as client, client.websocket_connect(\"/client/ws\") as ws:\r\n    data = ws.send_bytes(b\"foo\")\r\n    assert data == b\"foo\"\r\n```\r\n\r\n\r\n### Screenshots\r\n\r\n\"![Exception Log](https://user-images.githubusercontent.com/37921711/235967617-91018971-d13d-489f-b023-bf9fa807c3ae.png)\"\r\n\r\n\r\n### Logs\r\n\r\n_No response_\r\n\r\n### Litestar Version\r\n\r\n2.0.0alpha5\r\n\r\n### Platform\r\n\r\n- [X] Linux\r\n- [ ] Mac\r\n- [ ] Windows\r\n- [ ] Other (Please specify in the description above)\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n> [!NOTE]  \n> While we are open for sponsoring on [GitHub Sponsors](https://github.com/sponsors/litestar-org/) and \n> [OpenCollective](https://opencollective.com/litestar), we also utilize [Polar.sh](https://polar.sh/) to engage in pledge-based sponsorship.\n>\n> Check out all issues funded or available for funding [on our Polar.sh dashboard](https://polar.sh/litestar-org)\n> * If you would like to see an issue prioritized, make a pledge towards it!\n> * We receive the pledge once the issue is completed & verified\n> * This, along with engagement in the community, helps us know which features are a priority to our users.\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/1615\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/1615/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/1615/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/1371",
                "title": "Combining redirects and templated responses",
                "labels": [
                    "Documentation :books:",
                    "Enhancement",
                    "Great MCVE"
                ],
                "user": "zoni",
                "issue_author_association": "CONTRIBUTOR",
                "number": 1371,
                "id": 1636212394,
                "state": "closed",
                "project_created_at": "2023-03-22T17:30:38Z",
                "closed_at": "2023-03-30T11:08:24Z",
                "body": "## Context\r\n\r\nI'm working on a project with non-API/non-RESTful routes where, depending on the result of backend processing, either one of these two types of responses should be returned:\r\n\r\n1. A templated HTML response ([`Template`]); or\r\n2. A redirect to another (external) URL ([`Redirect`])\r\n\r\nI'm struggling on how to implement this and not sure whether I'm running into a documentation issue where it's just not clear, or an actual API design limitation of Starlite's response handling in general.\r\n\r\n## Environment info\r\n\r\n- `Linux l-057 6.1.18-200.fc37.x86_64 #1 SMP PREEMPT_DYNAMIC Sat Mar 11 16:09:14 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux`\r\n- `Python 3.11.2`\r\n- `starlite 1.51.7` ([full requirements.txt](https://gist.github.com/zoni/c3b0c2afc8f40c801f18ecc5b9f00d7b/8b1ec72b3895dddb0cd795c025ae90ac0e73cbbd#file-requirements-txt))\r\n\r\n## Partial solutions\r\n\r\nI've gotten quite close to a working solution that meets both goals, but it doesn't _quite_ get me where I want.\r\nFor clarity, I'll iterate over all possible approaches I've attempted so far.\r\n\r\n### Template response\r\n\r\nPoint (1) can be achieved with simple [`Template`] response, which looks as follows:\r\n\r\nhttps://gist.github.com/zoni/c3b0c2afc8f40c801f18ecc5b9f00d7b/000c36e412b093fc8ced1ab4e98d57d9f2aea119\r\n\r\n### Redirect response\r\n\r\nPoint (2) can be achieved with simple [`Redirect`] response, which looks as follows:\r\n\r\nhttps://gist.github.com/zoni/c3b0c2afc8f40c801f18ecc5b9f00d7b/c16f9c20f173eceea2be13181ff8fbb9b7649fc0\r\n\r\n### Combining Template + Redirect\r\n\r\nA naive attempt was to return a union of `Template` and `Redirect`: \r\n\r\nhttps://gist.github.com/zoni/c3b0c2afc8f40c801f18ecc5b9f00d7b/44e0e0e6e8ffe474b8ff75c1610720800fe5537d\r\n\r\nThis however fails with a `ValueError` on OpenAPI schema generation:\r\n\r\n<details>\r\n<summary>Traceback</summary>\r\n<pre>\r\nTraceback (most recent call last):\r\n  File \"/usr/lib64/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\r\n    self.run()\r\n  File \"/usr/lib64/python3.11/multiprocessing/process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/work/.cache/pypoetry/virtualenvs/starlite-issue-5tyW83TP-py3.11/lib/python3.11/site-packages/uvicorn/_subprocess.py\", line 76, in subprocess_started\r\n    target(sockets=sockets)\r\n  File \"/home/work/.cache/pypoetry/virtualenvs/starlite-issue-5tyW83TP-py3.11/lib/python3.11/site-packages/uvicorn/server.py\", line 59, in run\r\n    return asyncio.run(self.serve(sockets=sockets))\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/lib64/python3.11/asyncio/runners.py\", line 190, in run\r\n    return runner.run(main)\r\n           ^^^^^^^^^^^^^^^^\r\n  File \"/usr/lib64/python3.11/asyncio/runners.py\", line 118, in run\r\n    return self._loop.run_until_complete(task)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/lib64/python3.11/asyncio/base_events.py\", line 653, in run_until_complete\r\n    return future.result()\r\n           ^^^^^^^^^^^^^^^\r\n  File \"/home/work/.cache/pypoetry/virtualenvs/starlite-issue-5tyW83TP-py3.11/lib/python3.11/site-packages/uvicorn/server.py\", line 66, in serve\r\n    config.load()\r\n  File \"/home/work/.cache/pypoetry/virtualenvs/starlite-issue-5tyW83TP-py3.11/lib/python3.11/site-packages/uvicorn/config.py\", line 471, in load\r\n    self.loaded_app = import_from_string(self.app)\r\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/work/.cache/pypoetry/virtualenvs/starlite-issue-5tyW83TP-py3.11/lib/python3.11/site-packages/uvicorn/importer.py\", line 21, in import_from_string\r\n    module = importlib.import_module(module_str)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/lib64/python3.11/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<frozen importlib._bootstrap>\", line 1206, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1178, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1149, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"/home/work/starlite_issue/app.py\", line 16, in <module>\r\n    app = Starlite(\r\n          ^^^^^^^^^\r\n  File \"/home/work/.cache/pypoetry/virtualenvs/starlite-issue-5tyW83TP-py3.11/lib/python3.11/site-packages/starlite/app.py\", line 390, in __init__\r\n    self.update_openapi_schema()\r\n  File \"/home/work/.cache/pypoetry/virtualenvs/starlite-issue-5tyW83TP-py3.11/lib/python3.11/site-packages/starlite/app.py\", line 732, in update_openapi_schema\r\n    self.openapi_schema = construct_open_api_with_schema_class(\r\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/work/.cache/pypoetry/virtualenvs/starlite-issue-5tyW83TP-py3.11/lib/python3.11/site-packages/pydantic_openapi_schema/utils/utils.py\", line 53, in construct_open_api_with_schema_class\r\n    schema_definitions = schema(schema_classes, ref_prefix=REF_PREFIX, by_alias=by_alias)[\"definitions\"]\r\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"pydantic/schema.py\", line 146, in pydantic.schema.schema\r\n  File \"pydantic/schema.py\", line 581, in pydantic.schema.model_process_schema\r\n  File \"pydantic/schema.py\", line 622, in pydantic.schema.model_type_schema\r\n  File \"pydantic/schema.py\", line 255, in pydantic.schema.field_schema\r\n  File \"pydantic/schema.py\", line 527, in pydantic.schema.field_type_schema\r\n  File \"pydantic/schema.py\", line 850, in pydantic.schema.field_singleton_schema\r\n  File \"pydantic/schema.py\", line 745, in pydantic.schema.field_singleton_sub_fields_schema\r\n  File \"pydantic/schema.py\", line 527, in pydantic.schema.field_type_schema\r\n  File \"pydantic/schema.py\", line 949, in pydantic.schema.field_singleton_schema\r\nValueError: Value not declarable with JSON Schema, field: name='background_BackgroundTask' type=BackgroundTask required=True\r\n</pre>\r\n</details>\r\n\r\nI don't actually care about OpenAPI for these endpoints, so setting `include_in_schema=False` would be fine for me as well:\r\n\r\nhttps://gist.github.com/zoni/c3b0c2afc8f40c801f18ecc5b9f00d7b/5710d90b2a6de48e3b251e8820f9d0d0abbc8552\r\n\r\nThis removes the exception, but doesn't get us the intended behavior however. Instead, it results in a JSON rendering of the [`Template`] and [`Redirect`] objects:\r\n\r\n<details>\r\n<summary>Result of the template response</summary>\r\n<pre>\r\n[17:00:13] work in ~\r\n  http localhost:5000/world\r\nHTTP/1.1 307 Temporary Redirect\r\ncontent-length: 132\r\ncontent-type: application/json\r\ndate: Wed, 22 Mar 2023 16:00:16 GMT\r\nserver: uvicorn\r\n\r\n{\r\n    \"background\": null,\r\n    \"context\": {\r\n        \"name\": \"world\"\r\n    },\r\n    \"cookies\": [],\r\n    \"encoding\": \"utf-8\",\r\n    \"headers\": {},\r\n    \"media_type\": null,\r\n    \"name\": \"hello.html.j2\"\r\n}\r\n</pre>\r\n</details>\r\n\r\n<details>\r\n<summary>Result of the Redirect response</summary>\r\n<pre>\r\n[17:00:16] work in ~\r\n  http localhost:5000/foo\r\nHTTP/1.1 307 Temporary Redirect\r\ncontent-length: 114\r\ncontent-type: application/json\r\ndate: Wed, 22 Mar 2023 16:00:19 GMT\r\nserver: uvicorn\r\n\r\n{\r\n    \"background\": null,\r\n    \"cookies\": [],\r\n    \"encoding\": \"utf-8\",\r\n    \"headers\": {},\r\n    \"media_type\": null,\r\n    \"path\": \"http://example.com/foo\"\r\n}\r\n</pre>\r\n</details>\r\n\r\n### Using only `Response`\r\n\r\nThe closest to achieving this goal that I've come up with is to use a `Response`, but then I don't have access to a Template engine to return a ***templated*** response anymore:\r\n\r\nhttps://gist.github.com/zoni/c3b0c2afc8f40c801f18ecc5b9f00d7b/48d7b837f33a4b522657027d78bd006399b4f04e\r\n\r\nLack of templating aside, we can see this lets us mix a redirect with an arbitrary content response:\r\n\r\n<details>\r\n<summary>text/html content response</summary>\r\n<pre>\r\n[17:09:26] work in ~\r\n  http localhost:5000/world\r\nHTTP/1.1 200 OK\r\ncontent-length: 11\r\ncontent-type: text/html; charset=utf-8\r\ndate: Wed, 22 Mar 2023 16:09:30 GMT\r\nserver: uvicorn\r\n\r\nHello world\r\n</pre>\r\n</details>\r\n\r\n<details>\r\n<summary>redirect response (no content body)</summary>\r\n<pre>\r\n[17:09:30] work in ~\r\n  http localhost:5000/foo\r\nHTTP/1.1 307 Temporary Redirect\r\nTransfer-Encoding: chunked\r\ncontent-type: text/plain; charset=utf-8\r\ndate: Wed, 22 Mar 2023 16:09:38 GMT\r\nlocation: http://example.com/foo\r\nserver: uvicorn\r\n</pre>\r\n</details>\r\n\r\n(Also worth noting this requires setting `content=\"\", media_type=\"text/plain\"` on `Response()` otherwise it defaults to JSON with a `\"\"` body as well, so it's a bit less ergonomic)\r\n\r\n## Desired solution\r\n\r\nIdeally, I'd like to be able to combine [`Template`] + [`Redirect`]. That is, a function signature like `def hello(name: str = \"world\") -> Template | Redirect:`\r\n\r\n(Or for older Python versions, `def hello(name: str = \"world\") -> typing.Union[Template, Redirect]:`)\r\n\r\nI'm also quite happy just returning `Response`, but then I would like a way to get access to the templating engine myself, so that it's possible to do something along the lines of (pseudo-code):\r\n\r\n```python\r\n\r\n@get(\"/{name:str}\", include_in_schema=False)\r\ndef hello(name: str = \"world\", templater: TemplateEngine) -> Response:\r\n        response_content = templater.get_template(\"hello.html.j2\").render(context={\"name\": name})\r\n\r\n        return Response(\r\n            content=response_content,\r\n            media_type=\"text/html\",\r\n        )\r\n```\r\n\r\nThis _might_ already be possible and I just don't know how to get the TemplateEngine injected. If so, I'd love to be pointed at how this could be achieved, and I'll happily make a PR to at least document this better.\r\n\r\n## Miscellaneous notes\r\n\r\nWhile I'm talking only about Template and Redirect here as that is the use-case I'm trying to solve, I imagine the same issues likely exist around mixing in [`StreamingResponse`] and [`FileResponse`].\r\n\r\n[`Template`]: https://docs.starliteproject.dev/latest/reference/datastructures/response_containers.html#starlite.datastructures.response_containers.Template\r\n[`Redirect`]: https://docs.starliteproject.dev/latest/reference/datastructures/response_containers.html#starlite.datastructures.response_containers.Redirect\r\n[`StreamingResponse`]: https://docs.starliteproject.dev/latest/reference/response.html#starlite.response.StreamingResponse\r\n[`FileResponse`]: https://docs.starliteproject.dev/latest/reference/response.html#starlite.response.FileResponse\r\n",
                "comments": [
                    {
                        "body": "Thanks a lot for the very detailed write up!\r\n\r\nSo, this is actually possible, but not very ergonomic. \r\nTruth be told, templates haven't received a lot of attention but could certainly use some. Unfortunately I can't make any promises as to when that might happen.\r\n\r\nAnyway, here's (one) possible way of doing this:\r\n\r\n```python\r\nfrom pathlib import Path\r\n\r\nfrom starlite import (\r\n    Redirect,\r\n    Starlite,\r\n    Template,\r\n    TemplateConfig,\r\n    Request,\r\n    get,\r\n    Response,\r\n    ResponseContainer,\r\n)\r\nfrom starlite.contrib.jinja import JinjaTemplateEngine\r\nfrom starlite.status_codes import HTTP_307_TEMPORARY_REDIRECT\r\n\r\n\r\n@get(\"/{name:str}\", include_in_schema=False)\r\ndef hello(name: str, request: Request) -> ResponseContainer | Response:\r\n    if name == \"foo\":\r\n        return Redirect(path=f\"http://example.com/{name}\").to_response(\r\n            headers={},\r\n            status_code=HTTP_307_TEMPORARY_REDIRECT,\r\n            media_type=\"text/plain\",\r\n            request=request,\r\n            app=request.app,\r\n        )\r\n\r\n    return Template(name=\"hello.html.j2\", context={\"name\": name})\r\n\r\n\r\napp = Starlite(\r\n    route_handlers=[hello],\r\n    template_config=TemplateConfig(\r\n        directory=Path(\"templates\"),\r\n        engine=JinjaTemplateEngine,\r\n    ),\r\n)\r\n```\r\n\r\nor alternatively: \r\n\r\n```python\r\n@get(\"/{name:str}\", include_in_schema=False)\r\ndef hello(name: str) -> ResponseContainer | Response:\r\n    if name == \"foo\":\r\n        return Response(\r\n            content=b\"\",\r\n            headers={\"location\": f\"http://example.com/{name}\"},\r\n            status_code=HTTP_307_TEMPORARY_REDIRECT,\r\n        )\r\n\r\n    return Template(name=\"hello.html.j2\", context={\"name\": name})\r\n```\r\n\r\nBoth aren't that ergonomic, and there should definitely be a better way.\r\n\r\nThe actual issue though lies within the `Redirect` response container. Because it does not accept a `status_code`, you cannot simply return it. If this were the case, you could do:\r\n\r\n```python\r\n@get(\"/{name:str}\", include_in_schema=False)\r\ndef hello(name: str) -> ResponseContainer:\r\n    if name == \"foo\":\r\n        return Redirect(path=f\"http://example.com/{name}\", status_code=HTTP_307_TEMPORARY_REDIRECT)\r\n\r\n    return Template(name=\"hello.html.j2\", context={\"name\": name})\r\n```\r\n\r\nwhich is quite a lot nicer.\r\n\r\nI'll open an issue to support this, although it will most likely end up in 2.0.\r\n\r\n<hr> \r\n\r\nFrom a documentation perspective, we should definitely have a section about returning optional redirect like that.",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-03-22T19:01:28Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1371#issuecomment-1480108618"
                    },
                    {
                        "body": "@zoni I added a fix for this in #1412. \r\n\r\nWith this, it should work as expected:\r\n\r\n```python\r\n@get(\"/{name:str}\")\r\ndef hello(name: str = \"world\") -> Template | Redirect:\r\n    if name == \"foo\":\r\n        return Redirect(path=f\"http://example.com/{name}\", status_code=HTTP_307_TEMPORARY_REDIRECT)\r\n\r\n    return Template(name=\"hello.html.j2\", context={\"name\": name})\r\n```\r\n\r\nThis will only be available in `2.0` though, so you'll have to stick with one of the suggested workarounds for now unless you're working with the alpha releases.",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-03-30T11:10:21Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1371#issuecomment-1490115827"
                    },
                    {
                        "body": "You folks work fast @provinzkraut, thanks! I was already debating upgrading this codebase to the 2.0 alpha, so with this, now seems as good a time as any.\r\n\r\nWill upgrade and take it for a spin! In case I run into any issues I'll report back, but judging by the changes from #1412, I don't expect to encounter any difficulties :smile: ",
                        "user": "zoni",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-04-02T14:58:22Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1371#issuecomment-1493365321"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/1271",
                "title": "Bug: Using `from __future__ import annotations` breaks template support",
                "labels": [
                    "Bug :bug:",
                    "Great MCVE"
                ],
                "user": "Nadock",
                "issue_author_association": "CONTRIBUTOR",
                "number": 1271,
                "id": 1609650594,
                "state": "closed",
                "project_created_at": "2023-03-04T07:14:29Z",
                "closed_at": "2023-03-09T15:16:11Z",
                "body": "**Describe the bug**\r\nIf you include `from __future__ import annotations` in the same file as a route handler that returns a `starlite.Template` the template will not be rendered. Instead, the `starlite.Template` object is converted to JSON and that is returned instead.\r\n\r\n**To Reproduce**\r\nBelow is code that reproduces the error for me.\r\n\r\n```python\r\n# app.py\r\nfrom __future__ import annotations\r\n\r\nimport pathlib\r\n\r\nimport starlite\r\nfrom starlite.contrib import jinja\r\n\r\n\r\n@starlite.get(\"/\")\r\ndef index() -> starlite.Template:\r\n    return starlite.Template(name=\"repro.html\")\r\n\r\n\r\napp = starlite.Starlite(\r\n    route_handlers=[index],\r\n    template_config=starlite.TemplateConfig(\r\n        directory=pathlib.Path(\"./templates\"),\r\n        engine=jinja.JinjaTemplateEngine,\r\n    ),\r\n)\r\n```\r\n\r\n```html\r\n<!-- templates/repro.html -->\r\n<!DOCTYPE html>\r\n<html lang=\"en-au\">\r\n\r\n<head>\r\n    <meta content=\"text/html;charset=utf-8\" http-equiv=\"Content-Type\">\r\n    <meta content=\"utf-8\" http-equiv=\"encoding\">\r\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\r\n    <meta name=\"color-scheme\" content=\"dark light\">\r\n    <title>from __future__ import annotations</title>\r\n</head>\r\n\r\n<body>\r\n    <h1>Hello, world!</h1>\r\n</body>\r\n```\r\n\r\n\r\n**Additional context**\r\n**With** the `from __future__ import annotations` line:\r\n![Screenshot 2023-03-04 at 17 41 19](https://user-images.githubusercontent.com/1491530/222881622-8e8eebe7-52a4-4ba0-b59d-f3989f6ba9f0.png)\r\n\r\n**Without** the `from __future__ import annotations` line:\r\n\r\n![Screenshot 2023-03-04 at 17 46 14](https://user-images.githubusercontent.com/1491530/222881797-5e2d66a5-05b4-4a52-b0ea-0ba91c69aa2a.png)\r\n\r\n---\r\n\r\nI've only just started using **Starlite** so I'm not sure if there is something I missed in the documentation that says you shouldn't use `from __future__ import annotations`. But even if there is, maybe **Starlite** could raise an exception when you do this.\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n> [!NOTE]  \n> While we are open for sponsoring on [GitHub Sponsors](https://github.com/sponsors/litestar-org/) and \n> [OpenCollective](https://opencollective.com/litestar), we also utilize [Polar.sh](https://polar.sh/) to engage in pledge-based sponsorship.\n>\n> Check out all issues funded or available for funding [on our Polar.sh dashboard](https://polar.sh/litestar-org)\n> * If you would like to see an issue prioritized, make a pledge towards it!\n> * We receive the pledge once the issue is completed & verified\n> * This, along with engagement in the community, helps us know which features are a priority to our users.\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/1271\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/1271/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/1271/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [
                    {
                        "body": "Hi, what version have you tested? And can you check our main branch?",
                        "user": "Goldziher",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-03-04T11:05:59Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1271#issuecomment-1454701730"
                    },
                    {
                        "body": "This was tested on `1.51.6` and I've also been able to reproduce this when installing 06c50d7 from `main`, all using Python `3.11.1`.",
                        "user": "Nadock",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-03-04T14:06:45Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1271#issuecomment-1454751316"
                    },
                    {
                        "body": "I actually came across the cause of this today, and it will be fixed for 2.0.\r\n\r\nThe handler gets a reference to its signature here:\r\n\r\nhttps://github.com/starlite-api/starlite/blob/fbe51fb18bb685e579b66d0a42f1e0c3a4fae24f/starlite/handlers/http.py#L477\r\n\r\nHowever, support for resolving types in `inspect.Signature.from_callable()` is only available in 3.10+.\r\n\r\nWe go on to use an `isinstance()` check on the return annotation, but it is still a string here:\r\n\r\nhttps://github.com/starlite-api/starlite/blob/fbe51fb18bb685e579b66d0a42f1e0c3a4fae24f/starlite/handlers/http.py#L610\r\n\r\nThis will be fixed in 2.0 from this commit: https://github.com/starlite-api/starlite/pull/1160/commits/1ce9c5a84a0836139a2570317855b9a14d15d808 - and a few of the preceding commits on that branch.\r\n\r\nWe could do some `eval()` work to try to resolve the type of the return annotation in the 1.5x branch, but I'd suggest that you don't rely to heavily on `__future__.annotations` anywhere that there needs to be runtime introspection of types on the 1.x series.",
                        "user": "peterschutt",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-03-05T14:02:30Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1271#issuecomment-1455100905"
                    },
                    {
                        "body": "If there's a fix coming in `2.0` that's excellent  \r\n\r\n> We could do some eval() work to try to resolve the type of the return annotation in the 1.5x branch, but I'd suggest that you don't rely to heavily on __future__.annotations anywhere that there needs to be runtime introspection of types on the 1.x series.\r\n\r\nYeah that's fine honestly. This was my first foray into using Starlite so I the side effects of `__future__.annotations` weren't clear. Maybe worth a note in the documentation that `__future__.annotations` can cause issues, but it doesn't sound like back porting a fix is that worth it.",
                        "user": "Nadock",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-03-06T01:17:45Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1271#issuecomment-1455286181"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/1219",
                "title": "Bug: `JWTAuth.login` raises `SerializationException` despite `type_encoders` settings",
                "labels": [
                    "Bug :bug:",
                    "Triage Required :hospital:",
                    "Needs MCVE"
                ],
                "user": "LonelyVikingMichael",
                "issue_author_association": "CONTRIBUTOR",
                "number": 1219,
                "id": 1590806190,
                "state": "closed",
                "project_created_at": "2023-02-19T18:42:17Z",
                "closed_at": "2023-03-02T06:54:14Z",
                "body": "**Describe the bug**\r\n`JWTAuth.login` instantiates and returns a `starlite.Response` object that does not respect custom defined `type_encoders`. This will raise an exception if the response body custom types such as `asyncpg.pgproto.pgproto.UUID` etc.\r\n\r\n**To Reproduce**\r\nN/A\r\n\r\n**Additional context**\r\nThis wasn't a problem in older releases before `type_encoders` were introduced, as we'd override the Response class directly to customise serialization.\r\n",
                "comments": [
                    {
                        "body": "can you give me an MCVE? or a failing test? would be very helpful to have it. ",
                        "user": "Goldziher",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-02-27T17:25:43Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1219#issuecomment-1446740936"
                    },
                    {
                        "body": "My mistake, project was using an older Starlite version.",
                        "user": "LonelyVikingMichael",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-03-02T06:54:14Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1219#issuecomment-1451384006"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/854",
                "title": "Bug: Incorretly raised `ImproperlyConfiguredException` for sub-paths with a `path`-type parameter",
                "labels": [
                    "Bug :bug:",
                    "Great MCVE"
                ],
                "user": "provinzkraut",
                "issue_author_association": "MEMBER",
                "number": 854,
                "id": 1463132166,
                "state": "closed",
                "project_created_at": "2022-11-24T10:36:00Z",
                "closed_at": "2022-11-24T18:02:06Z",
                "body": "**Describe the bug**\r\nAs described by @rgajason in https://github.com/starlite-api/starlite/discussions/825#discussioncomment-4221738, when using the `path` type for a path parameter, an `ImproperlyConfiguredException` will be raised, where a `str` type parameter would be accepted.\r\n\r\n**To Reproduce**\r\n```python\r\nfrom pathlib import Path\r\n\r\nfrom starlite import Starlite, post, put\r\n\r\n\r\n@post(path=\"/{string:str}\")\r\ndef post_endpoint(string: str) -> None:\r\n    pass\r\n\r\n\r\n@put(path=\"/{string:str}/{path:path}\")\r\ndef put_endpoint(string: str, path: Path) -> None:\r\n    pass\r\n\r\n\r\napp = Starlite(route_handlers=[post_endpoint, put_endpoint])\r\n```\r\n\r\n**This works**\r\n```python\r\nfrom starlite import Starlite, post, put\r\n\r\n\r\n@post(path=\"/{string:str}\")\r\ndef post_endpoint(string: str) -> None:\r\n    pass\r\n\r\n\r\n@put(path=\"/{string:str}/{path:str}\")\r\ndef put_endpoint(string: str, path: str) -> None:\r\n    pass\r\n\r\n\r\napp = Starlite(route_handlers=[post_endpoint, put_endpoint])\r\n```\r\n",
                "comments": [
                    {
                        "body": "@Goldziher @peterschutt Probably one of you should take a look at this",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-24T10:36:30Z",
                        "url": "https://github.com/litestar-org/litestar/issues/854#issuecomment-1326263815"
                    },
                    {
                        "body": "Thanks for the quick fix.  I can confirm that this change allows the app to startup.",
                        "user": "rgajason",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-28T16:22:20Z",
                        "url": "https://github.com/litestar-org/litestar/issues/854#issuecomment-1329375581"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/849",
                "title": "Bug: POSTs Result In HTTP 500 When Logging Middleware Enabled",
                "labels": [
                    "Bug :bug:",
                    "Great MCVE"
                ],
                "user": "rgajason",
                "issue_author_association": "CONTRIBUTOR",
                "number": 849,
                "id": 1461932424,
                "state": "closed",
                "project_created_at": "2022-11-23T15:09:02Z",
                "closed_at": "2022-11-26T12:42:55Z",
                "body": "**Describe the bug**\r\nWith the logging middleware enabled, POSTs are returning an HTTP 500.\r\n\r\n**To Reproduce**\r\n```python\r\nfrom starlite import Starlite, LoggingConfig, post\r\nfrom starlite.middleware import LoggingMiddlewareConfig\r\nfrom pydantic import BaseModel\r\n\r\nlogging_middleware_config = LoggingMiddlewareConfig()\r\n\r\nclass Widget(BaseModel):\r\n    name: str\r\n    description: str | None = None\r\n    width_inches: float\r\n    height_inches: float\r\n\r\n\r\n@post(\"/\")\r\nasync def my_handler(data: Widget) -> Widget:\r\n    return data\r\n\r\n\r\napp = Starlite(\r\n    route_handlers=[my_handler],\r\n    logging_config=LoggingConfig(),\r\n    middleware=[logging_middleware_config.middleware],\r\n)\r\n```\r\n\r\nStart up the app, POST to it:\r\n\r\n```shell\r\ncurl --request POST --url http://localhost:8000/ --header 'Content-Type: application/json' --data '{\r\n  \"name\": \"foo\",\r\n  \"description\": \"bar\",\r\n  \"width_inches\": 1.23,\r\n  \"height_inches\": 4.56\r\n}'\r\n{\"status_code\":500,\"detail\":\"RuntimeError()\"}\r\n```\r\n\r\nIf I remove the `middleware` argument from the app and restart, POST works as expected.\r\n\r\n**Additional context**\r\nPython 3.10.8\r\n\r\n```\r\nanyio==3.6.2\r\nappdirs==1.4.4\r\nattrs==22.1.0\r\nbcrypt==4.0.1\r\nbeanie==1.15.4\r\nblack==22.10.0\r\ncasbin==1.17.4\r\ncasbin-pymongo-adapter==1.0.0\r\ncertifi==2022.9.24\r\ncffi==1.15.1\r\ncharset-normalizer==2.1.1\r\nclick==8.1.3\r\ncommonmark==0.9.1\r\ncoverage==6.5.0\r\ncryptography==38.0.3\r\ndistlib==0.3.6\r\ndnspython==2.2.1\r\nemail-validator==1.3.0\r\neradicate==2.1.0\r\nexceptiongroup==1.0.4\r\nFaker==15.3.2\r\nfilelock==3.8.0\r\nflake8==5.0.4\r\nflake8-black==0.3.4\r\nflake8-builtins==2.0.1\r\nflake8-comprehensions==3.10.1\r\nflake8-eradicate==1.4.0\r\nflake8-isort==5.0.0\r\nflake8-plugin-utils==1.3.2\r\nflake8-pytest-style==1.6.0\r\nggshield==1.14.1\r\ngraphql-core==3.2.3\r\nh11==0.14.0\r\nh2==4.1.0\r\nhpack==4.0.0\r\nhttpcore==0.16.1\r\nhttpx==0.23.1\r\nhyperframe==6.0.1\r\nidna==3.4\r\niniconfig==1.1.1\r\nisort==5.10.1\r\nJinja2==3.1.2\r\nldap3==2.9.1\r\nMarkupSafe==2.1.1\r\nmarshmallow==3.18.0\r\nmarshmallow-dataclass==8.5.10\r\nmccabe==0.7.0\r\nmongomock==4.1.2\r\nmongomock-motor==0.0.13\r\nmotor==3.1.1\r\nmultidict==6.0.2\r\nmypy-extensions==0.4.3\r\noauthlib==3.2.2\r\norjson==3.8.2\r\npackaging==21.3\r\npasslib==1.7.4\r\npathspec==0.10.2\r\npep8-naming==0.13.2\r\npicologging==0.9.1\r\nplatformdirs==2.5.4\r\npluggy==1.0.0\r\npyasn1==0.4.8\r\npycodestyle==2.9.1\r\npycparser==2.21\r\npydantic==1.10.2\r\npydantic-factories==1.15.0\r\npydantic-openapi-schema==1.3.0\r\npyflakes==2.5.0\r\npygitguardian==1.4.0\r\nPygments==2.13.0\r\npymongo==4.3.3\r\npyparsing==3.0.9\r\npytest==7.2.0\r\npytest-asyncio==0.20.2\r\npytest-cov==4.0.0\r\npython-dateutil==2.8.2\r\npython-dotenv==0.21.0\r\npython-multipart==0.0.5\r\nPyYAML==6.0\r\nrequests==2.28.1\r\nrfc3986==1.5.0\r\nrich==12.5.1\r\nsentinels==1.0.0\r\nsgqlc==16.0\r\nsimpleeval==0.9.12\r\nsix==1.16.0\r\nsniffio==1.3.0\r\nstarlite==1.40.1\r\nstarlite-multipart==1.2.0\r\ntoml==0.10.2\r\ntomli==2.0.1\r\ntyping-inspect==0.8.0\r\ntyping_extensions==4.4.0\r\nurllib3==1.26.12\r\nuvicorn==0.20.0\r\nvirtualenv==20.16.7\r\nyarl==1.8.1\r\n```",
                "comments": [
                    {
                        "body": "I can reproduce the problem. Will take a look into it tonight",
                        "user": "jtraub",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-23T15:14:54Z",
                        "url": "https://github.com/litestar-org/litestar/issues/849#issuecomment-1325233713"
                    },
                    {
                        "body": "@jtraub I hope you don't mind I went ahead with a fix in #860?\r\n\r\n@rgajason Merging this PR should fix your problem. Can you confirm?",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-26T12:06:12Z",
                        "url": "https://github.com/litestar-org/litestar/issues/849#issuecomment-1328034833"
                    },
                    {
                        "body": "@provinzkraut oops, I got buried with day job and forgot about the issue. Thanks for taking care of it.",
                        "user": "jtraub",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-26T12:26:31Z",
                        "url": "https://github.com/litestar-org/litestar/issues/849#issuecomment-1328037623"
                    },
                    {
                        "body": "@provinzkraut confirmed working! Thank you so much!",
                        "user": "rgajason",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-28T15:54:36Z",
                        "url": "https://github.com/litestar-org/litestar/issues/849#issuecomment-1329336479"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/816",
                "title": "Endpoints 404 when using path parameters in Controller path",
                "labels": [
                    "Bug :bug:",
                    "Great MCVE"
                ],
                "user": "sssssss340",
                "issue_author_association": "NONE",
                "number": 816,
                "id": 1454310947,
                "state": "closed",
                "project_created_at": "2022-11-18T01:59:08Z",
                "closed_at": "2022-11-18T05:12:01Z",
                "body": "**Describe the bug**\r\nWhen using a path parameter in the base path for a Controller, endpoints without further path parameters return 404. In the example provided, get_user functions as-is, while list_users only functions if get_user is deleted.\r\n\r\n**To Reproduce**\r\nMinimal example:\r\n\r\n```python\r\nfrom starlite import Controller, get\r\nfrom pydantic import BaseModel, UUID4, Field\r\nfrom uuid import uuid4\r\n\r\n\r\nclass User(BaseModel):\r\n    id: UUID4 = Field(default_factory=uuid4)\r\n\r\n\r\nclass UserController(Controller):\r\n    path = \"/{realm:str}/users\"\r\n\r\n    @get()\r\n    async def list_users(self, realm: str) -> list[User]:\r\n        return [User()]\r\n\r\n    @get(path=\"/{user_id:uuid}\")\r\n    async def get_user(self, realm: str, user_id: UUID4) -> User:\r\n        return User()\r\n```\r\n\r\n**Additional context**\r\nVersion info:\r\n```\r\n$ python3 --version\r\nPython 3.11.0\r\n\r\n$ pip freeze\r\nanyio==3.6.2\r\ncertifi==2022.9.24\r\nclick==8.1.3\r\ndnspython==2.2.1\r\nemail-validator==1.3.0\r\nFaker==15.3.2\r\nh11==0.12.0\r\nhttpcore==0.15.0\r\nhttpx==0.23.0\r\nidna==3.4\r\nmultidict==6.0.2\r\norjson==3.8.1\r\npydantic==1.10.2\r\npydantic-factories==1.15.0\r\npydantic-openapi-schema==1.3.0\r\npython-dateutil==2.8.2\r\nPyYAML==6.0\r\nrfc3986==1.5.0\r\nsix==1.16.0\r\nsniffio==1.3.0\r\nstarlite==1.39.0\r\nstarlite-multipart==1.2.0\r\ntyping_extensions==4.4.0\r\nuvicorn==0.19.0\r\n```\r\n",
                "comments": [
                    {
                        "body": "@all-contributors please add @sssssss340 for bug",
                        "user": "peterschutt",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-18T02:01:01Z",
                        "url": "https://github.com/litestar-org/litestar/issues/816#issuecomment-1319449846"
                    },
                    {
                        "body": "@peterschutt \n\nI've put up [a pull request](https://github.com/starlite-api/starlite/pull/817) to add @sssssss340! :tada:",
                        "user": "allcontributors[bot]",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-18T02:01:11Z",
                        "url": "https://github.com/litestar-org/litestar/issues/816#issuecomment-1319449977"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/803",
                "title": "All requests fail when `exclude_opt_key` or `exclude` param is passed to `AllowedHostsConfig` or `CompressionConfig`",
                "labels": [
                    "Bug :bug:",
                    "Great MCVE"
                ],
                "user": "jtraub",
                "issue_author_association": "CONTRIBUTOR",
                "number": 803,
                "id": 1447859936,
                "state": "closed",
                "project_created_at": "2022-11-14T11:12:20Z",
                "closed_at": "2022-11-18T04:29:22Z",
                "body": "**Describe the bug**\r\nWhen `exclude_opt_key` or `exclude` params are passed to `AllowedHostsConfig` or `CompressionConfig` all requests generate 500 error. \r\n\r\nThis happens because we apply both middlewares on app's asgi handler. Temp.solution would be moving its applicationto the `build_route_middleware_stack` function (the same way we did with CSRF middleware).\r\n\r\n**To Reproduce**\r\nRun this file and open http://127.0.0.1:8000/ in the browser.\r\nYou will see `{\"status_code\":500,\"detail\":\"KeyError('route_handler')\"}`\r\n\r\n```python\r\nimport uvicorn\r\nfrom starlite import Starlite, get, AllowedHostsConfig\r\n\r\n@get(\"/\")\r\ndef index() -> str:\r\n    return \"ok\"\r\n\r\napp = Starlite(\r\n    route_handlers=[index],\r\n    allowed_hosts=AllowedHostsConfig(\r\n        allowed_hosts=[\"localhost\"],\r\n        exclude_opt_key=\"skip_allowed_hosts\"\r\n    )\r\n)\r\n\r\nif __name__ == \"__main__\":\r\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\r\n\r\n```\r\n\r\nUPD: Will try to provide a temp fix soon.",
                "comments": [
                    {
                        "body": "Closed in #804 ",
                        "user": "peterschutt",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-18T04:29:22Z",
                        "url": "https://github.com/litestar-org/litestar/issues/803#issuecomment-1319529427"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/781",
                "title": "Bug: Rate Limiter Middleware: exclude path is ignored, static files throw 429 error",
                "labels": [
                    "Bug :bug:",
                    "Great MCVE"
                ],
                "user": "ThinksFast",
                "issue_author_association": "CONTRIBUTOR",
                "number": 781,
                "id": 1442905595,
                "state": "closed",
                "project_created_at": "2022-11-09T23:14:26Z",
                "closed_at": "2022-12-10T13:24:50Z",
                "body": "**Describe the bug**\r\nWhen using the RateLimiter middleware, the `exclude` path does not seem to be honored.  In the code example below, the app serves an HTML response to the root URL path.  In the HTML response, there is a reference to a static file which serves CSS.  With a rate limit of 1 request per second, the homepage will get served, but the CSS file throws a 429 error code.\r\n\r\n**To Reproduce**\r\n\r\nAPP:\r\n```python\r\nimport uvicorn\r\nfrom starlite import (\r\n    Request,\r\n    Starlite,\r\n    State,\r\n    StaticFilesConfig,\r\n    Template,\r\n    TemplateConfig,\r\n    get,\r\n)\r\nfrom starlite.middleware import RateLimitConfig\r\nfrom starlite.template.jinja import JinjaTemplateEngine\r\n\r\n\r\n@get(\"/\")\r\nasync def serveHomepage(request: Request, state: State) -> Template:\r\n\r\n    return Template(\r\n        name=\"index.html.j2\",\r\n        context={\"request\": request},\r\n    )\r\n\r\n\r\nrate_limit_config = RateLimitConfig(\r\n    rate_limit=(\"second\", 1),\r\n    exclude=[r\"^/src.*$\"],\r\n)\r\n\r\napp = Starlite(\r\n    route_handlers=[serveHomepage],\r\n    template_config=TemplateConfig(\r\n        directory=\"src/templates\", engine=JinjaTemplateEngine\r\n    ),\r\n    static_files_config=[\r\n        StaticFilesConfig(directories=[\"src/static\"], path=\"/src/static\"),\r\n        StaticFilesConfig(\r\n            directories=[\"src/templates\"], path=\"/src/templates\", html_mode=True\r\n        ),\r\n    ],\r\n    middleware=[rate_limit_config.middleware],\r\n)\r\n\r\nif __name__ == \"__main__\":\r\n    uvicorn.run(app, host=\"127.0.0.1\", port=8000)\r\n\r\n```\r\n\r\nHTML TEMPLATE:\r\n```html\r\n<html>\r\n\r\n<head>\r\n  <link href=\"/src/static/css/styles.css\" rel=\"stylesheet\" type=\"text/css\" />\r\n</head>\r\n\r\n<body>\r\n  <h1>Header</h1>\r\n</body>\r\n\r\n</html>\r\n```\r\n\r\nSTYLES.CSS... you can just make an empty file  \r\n\r\n**Additional context**\r\nOn my local, I'm running Starlite 1.38.0 on Python 3.11.  Maybe there's an issue with how I'm declaring the path, but I've tried numerous string formats for the excludes option, none seem to work:\r\n\r\n`exclude=[r\"^/src.*$\"]`\r\n`exclude=[r\"^src.*$\"]`\r\n`exclude=[\"/src/\"]`\r\n`exclude=[\"src/\"]`\r\n`exclude=[\"/src/static/css/styles.css\"]`\r\n",
                "comments": [
                    {
                        "body": "Somewhat easier to reproduce example:\r\n\r\n```python\r\nfrom starlite import Starlite, StaticFilesConfig, TestClient\r\nfrom starlite.middleware import RateLimitConfig\r\n\r\n\r\nrate_limit_config = RateLimitConfig(rate_limit=(\"second\", 1), exclude=[r\"^/static.*$\"])\r\n\r\napp = Starlite(\r\n    route_handlers=[],\r\n    static_files_config=[\r\n        StaticFilesConfig(directories=[\"static\"], path=\"static\"),\r\n    ],\r\n    middleware=[rate_limit_config.middleware],\r\n)\r\n\r\n\r\nwith TestClient(app=app) as client:\r\n    assert client.get(\"/static/starlite-hero.svg\").status_code == 200\r\n    assert client.get(\"/static/starlite-hero.svg\").status_code == 200\r\n```\r\n\r\nI already pinned down the problem somewhat. [`middleware.utils.should_bypass_middleware`](https://github.com/starlite-api/starlite/blob/main/starlite/middleware/utils.py#L31) does not receive the correct path. The path it receives does not include the `/static` prefix; This gets stripped away in [`asgi.routing_trie.traversal.parse_path_to_route`](https://github.com/starlite-api/starlite/blob/main/starlite/asgi/routing_trie/traversal.py#L94). I'm not sure how far this is intended/expected behaviour or what the best fix for this is. Before I take a deep dive here, @Goldziher maybe you want to take a look at it?",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-26T12:49:32Z",
                        "url": "https://github.com/litestar-org/litestar/issues/781#issuecomment-1328040704"
                    },
                    {
                        "body": "A possible solution would be to simply use `scope[\"raw_path\"]` in `should_bypass_middleware`. I think that might more closely match expected behaviour? Although I'd still like to hear your input @Goldziher about the expected behaviour for paths there.",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-26T12:56:43Z",
                        "url": "https://github.com/litestar-org/litestar/issues/781#issuecomment-1328041638"
                    },
                    {
                        "body": ">  I'm not sure how far this is intended/expected behaviour or what the best fix for this is\r\n\r\nI think we have discussed this in Discord. Also, it is documented in https://starlite-api.github.io/starlite/usage/1-routing/5-mounting-asgi-apps/ (see Info box there).\r\n\r\nStaticFiles is handled as a mounted ASGI app",
                        "user": "jtraub",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-26T13:06:08Z",
                        "url": "https://github.com/litestar-org/litestar/issues/781#issuecomment-1328043229"
                    },
                    {
                        "body": "> StaticFiles is handled as a mounted ASGI app\r\n\r\nHmm, I see. That makes handling of path-based exclusion a bit un-intuitive I think. WDYT of the solution to check against `scope[\"raw_path\"]`?\r\n\r\n",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-26T13:08:46Z",
                        "url": "https://github.com/litestar-org/litestar/issues/781#issuecomment-1328043711"
                    },
                    {
                        "body": "@provinzkraut  I would personally expect here a more advanced fix than looking into `raw_path`.\r\n\r\nFor example, when I apply RateLimitingMiddleware on an app and then I mount this app into another Starlite app I expect that RateLimitingMiddleware here would not take into account `raw_path` because I expect that the mounted app behaves the same way standalone app works.\r\n\r\nMaybe we can somehow expose is_mount flag to middlewares depending on their application point?",
                        "user": "jtraub",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-26T13:08:59Z",
                        "url": "https://github.com/litestar-org/litestar/issues/781#issuecomment-1328043762"
                    },
                    {
                        "body": "Just to be explicit about `StaticFiles`: [This line](https://github.com/starlite-api/starlite/blob/4daf431c7a86d713fd7c880c06395f92589147e9/starlite/handlers/asgi.py#L52) makes StaticFiles to be treated as a mounted app.",
                        "user": "jtraub",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-26T13:11:39Z",
                        "url": "https://github.com/litestar-org/litestar/issues/781#issuecomment-1328044213"
                    },
                    {
                        "body": "> WDYT of the solution to check against scope[\"raw_path\"]\r\n\r\nI think it should be a big PR that would propagate `is_mount` flag value to middlewares and route handlers. Looking into `path` or `raw_path` would depend on value of that flag.\r\nFastAPI seems to be doing something like this - I took a look at it on Monday (yes, I am strugging with a similar problem so I was exploring what others do).\r\n\r\nRelated issue here - #788 ",
                        "user": "jtraub",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-26T13:15:21Z",
                        "url": "https://github.com/litestar-org/litestar/issues/781#issuecomment-1328044776"
                    },
                    {
                        "body": "> Maybe we can somehow expose is_mount flag to middlewares depending on their application point?\r\n\r\nThat could work but would be messy. How about adding the relevant information to the scope? E.g. something like `scope[\"mount_path\"] = self.path` if something is mounted?\r\n",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-26T13:16:23Z",
                        "url": "https://github.com/litestar-org/litestar/issues/781#issuecomment-1328044933"
                    },
                    {
                        "body": "> How about adding the relevant information to the scope?\r\n\r\nThis would work but what is our policy on internal middlewares and asgi apps compatibility? Do we want to make them compatible so others can use them outside of Starlite?\r\n\r\nIf we do not care about this we can take your way for sure. ",
                        "user": "jtraub",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-26T13:19:01Z",
                        "url": "https://github.com/litestar-org/litestar/issues/781#issuecomment-1328045323"
                    },
                    {
                        "body": "We could do it in a compatible way as well. Passing `is_mount` around is also not really compatible. What we could do is simply check if such a key exists, if it does use it to re-construct the path from `scope[\"mount_path\"]` and `scope[\"path\"]`, if it doesn't exist, we just use the `scope[\"path\"]` as is.",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-26T13:21:34Z",
                        "url": "https://github.com/litestar-org/litestar/issues/781#issuecomment-1328045692"
                    },
                    {
                        "body": "Yeah, that makes sense. Lets do it the way your described.\r\n\r\n@provinzkraut I can do it this weekend + fix openapi generation for mounted starlite apps (and maybe #788) if you are busy with something else as it directly affects my employer apps :-)\r\nIf you want to fix it yourself - feel free to do it. I have a lot of problems with pydantic-factories at the moment so I will work on something else.",
                        "user": "jtraub",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-26T13:26:53Z",
                        "url": "https://github.com/litestar-org/litestar/issues/781#issuecomment-1328046484"
                    },
                    {
                        "body": "@jtraub I'm fine either way, if you wanna do it have at it, otherwise I'll take this on.",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-11-26T13:29:19Z",
                        "url": "https://github.com/litestar-org/litestar/issues/781#issuecomment-1328046825"
                    },
                    {
                        "body": "@provinzkraut ok, let me take this then as I would be able to test the fix extensively tomorrow.",
                        "user": "jtraub",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-26T13:34:02Z",
                        "url": "https://github.com/litestar-org/litestar/issues/781#issuecomment-1328047481"
                    },
                    {
                        "body": "so, any updates on this? ",
                        "user": "Goldziher",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-12-01T18:06:55Z",
                        "url": "https://github.com/litestar-org/litestar/issues/781#issuecomment-1334155299"
                    },
                    {
                        "body": "I got it working fine but got buried with trying to fix piccolo admin and make all middlewares work in a mounted starlite instance\r\n\r\nI am in the bed already so give me some time to make a PR tomorrow :-)",
                        "user": "jtraub",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-12-01T18:58:28Z",
                        "url": "https://github.com/litestar-org/litestar/issues/781#issuecomment-1334210607"
                    }
                ],
                "pull_request": null
            }
        ],
        "SecurityPolicy_reporting_mechanism": "advisory",
        "num_security_issues_after_policy": 24,
        "num_security_issue_and_pull": 29,
        "security_issues_created_after_policy": [
            {
                "url": "https://github.com/litestar-org/litestar/issues/3829",
                "title": "Enhancement: provide security middleware",
                "labels": [
                    "Enhancement",
                    "Middleware",
                    "Security"
                ],
                "user": "sobolevn",
                "issue_author_association": "MEMBER",
                "number": 3829,
                "id": 2596576465,
                "state": "open",
                "project_created_at": "2024-10-18T06:43:35Z",
                "closed_at": null,
                "body": "### Summary\n\nDjango has a middleware that should always be used: https://docs.djangoproject.com/en/3.0/ref/middleware/#module-django.middleware.security\r\n\r\nI think that Litestar should also have it out of the box. \r\n\r\nWhat it does? It provide security-related headers for the responses.\r\n- [`X-Content-Type-Options: nosniff`](https://docs.djangoproject.com/en/3.0/ref/middleware/#x-content-type-options)\r\n- Secure SSL settings: https://docs.djangoproject.com/en/3.0/ref/middleware/#http-strict-transport-security\r\n- `Referrer-Policy: no-referrer` header (also supports other values: https://docs.djangoproject.com/en/3.0/ref/middleware/#referrer-policy)\r\n\r\nThere are also 3rd party django libs that also work in the same field:\r\n- https://github.com/adamchainz/django-permissions-policy which sets `Permissions-Policy` header\r\n\r\nMaybe something else that I forgot about?\r\n\r\nAll things should be customizable and work the regular way Litestar middleware works.\r\n\r\nIf others agree, I can work on this :)\n\n### Basic Example\n\n_No response_\n\n### Drawbacks and Impact\n\n_No response_\n\n### Unresolved questions\n\n_No response_\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n> [!NOTE]  \n> While we are open for sponsoring on [GitHub Sponsors](https://github.com/sponsors/litestar-org/) and \n> [OpenCollective](https://opencollective.com/litestar), we also utilize [Polar.sh](https://polar.sh/) to engage in pledge-based sponsorship.\n>\n> Check out all issues funded or available for funding [on our Polar.sh dashboard](https://polar.sh/litestar-org)\n> * If you would like to see an issue prioritized, make a pledge towards it!\n> * We receive the pledge once the issue is completed & verified\n> * This, along with engagement in the community, helps us know which features are a priority to our users.\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/3829\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/3829/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/3829/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/pull/3824",
                "title": "chore(mypy): enable `truthy-bool` error code",
                "labels": [
                    "Triage Required :hospital:",
                    "pr/external",
                    "pr/internal",
                    "size: small",
                    "area/private-api",
                    "area/dependencies",
                    "area/security"
                ],
                "user": "sobolevn",
                "issue_author_association": "MEMBER",
                "number": 3824,
                "id": 2593953691,
                "state": "open",
                "project_created_at": "2024-10-17T08:01:52Z",
                "closed_at": null,
                "body": "Docs: https://mypy.readthedocs.io/en/stable/error_code_list2.html#check-that-expression-is-not-implicitly-true-in-boolean-context-truthy-bool\r\n\r\nI am using `# type: ignore[truthy-bool]` for `.components` check, because I see that it is treated specially for some reason (like `pragma: no cover`). Is this correct?\r\n\r\nI also removed configs that are part of the `--strict` flag from settings.",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/litestar-org/litestar/pull/3824?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=litestar-org) Report\nAll modified and coverable lines are covered by tests :white_check_mark:\n> Project coverage is 98.42%. Comparing base [(`ffcecb1`)](https://app.codecov.io/gh/litestar-org/litestar/commit/ffcecb127fcca372df3474c0f465db4a257a3e51?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=litestar-org) to head [(`eb26f81`)](https://app.codecov.io/gh/litestar-org/litestar/commit/eb26f812de481c47634cfc5eebdb1b346526d71b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=litestar-org).\n\n<details><summary>Additional details and impacted files</summary>\n\n\n```diff\n@@            Coverage Diff             @@\n##             main    #3824      +/-   ##\n==========================================\n+ Coverage   98.41%   98.42%   +0.01%     \n==========================================\n  Files         332      332              \n  Lines       15500    15498       -2     \n  Branches     1703     1702       -1     \n==========================================\n  Hits        15254    15254              \n+ Misses        113      112       -1     \n+ Partials      133      132       -1     \n```\n\n</details>\n\n[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/litestar-org/litestar/pull/3824?dropdown=coverage&src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=litestar-org).   \n:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=litestar-org).\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-10-17T08:07:02Z",
                        "url": "https://github.com/litestar-org/litestar/pull/3824#issuecomment-2418852604"
                    },
                    {
                        "body": "Please, take a look at these lines:\r\n<img width=\"1299\" alt=\"  2024-10-17  11 43 46\" src=\"https://github.com/user-attachments/assets/fe6a142d-6718-4796-be45-44a54b8674ba\">\r\n\r\nLooks like `else` is never actually reached. Should I remove this branch?",
                        "user": "sobolevn",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-10-17T08:44:34Z",
                        "url": "https://github.com/litestar-org/litestar/pull/3824#issuecomment-2418930857"
                    },
                    {
                        "body": "> Looks like `else` is never actually reached. Should I remove this branch?\r\n\r\nSeems to be a missing test case?\r\n",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-10-19T08:34:57Z",
                        "url": "https://github.com/litestar-org/litestar/pull/3824#issuecomment-2423694828"
                    },
                    {
                        "body": "> Seems to be a missing test case?\r\n\r\nI am not quite sure, to be honest :)\r\nHere's why. Here's the code in question: https://github.com/litestar-org/litestar/blob/f7b258f97592626934b4224e52c030983c9bf41b/litestar/security/base.py#L90-L95\r\n\r\nWhere `app_config.openapi_config.components` has a type of `Components | list[Components]` https://github.com/litestar-org/litestar/blob/f7b258f97592626934b4224e52c030983c9bf41b/litestar/openapi/config.py#L91 `Components` can never be false (it does not have `__bool__` or `__len__` defined).\r\n\r\nSo, mypy raises an error for this case. We either have:\r\n- Missing `None` annotation for `components` and a missing test case ?\r\n- Extra `else` branch in this `if` ?",
                        "user": "sobolevn",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-10-19T09:30:53Z",
                        "url": "https://github.com/litestar-org/litestar/pull/3824#issuecomment-2423719479"
                    },
                    {
                        "body": ">     * Extra `else` branch in this `if` ?\r\n\r\nIsn't it the `elif` branch that's extra then, and should be an `else` instead?\r\n",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-10-19T09:52:35Z",
                        "url": "https://github.com/litestar-org/litestar/pull/3824#issuecomment-2423730131"
                    },
                    {
                        "body": "## [![Quality Gate Passed](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/QualityGateBadge/qg-passed-20px.png 'Quality Gate Passed')](https://sonarcloud.io/dashboard?id=litestar-org_litestar&pullRequest=3824) **Quality Gate passed**  \nIssues  \n![](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/passed-16px.png '') [0 New issues](https://sonarcloud.io/project/issues?id=litestar-org_litestar&pullRequest=3824&issueStatuses=OPEN,CONFIRMED&sinceLeakPeriod=true)  \n![](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/accepted-16px.png '') [0 Accepted issues](https://sonarcloud.io/project/issues?id=litestar-org_litestar&pullRequest=3824&issueStatuses=ACCEPTED)\n\nMeasures  \n![](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/passed-16px.png '') [0 Security Hotspots](https://sonarcloud.io/project/security_hotspots?id=litestar-org_litestar&pullRequest=3824&issueStatuses=OPEN,CONFIRMED&sinceLeakPeriod=true)  \n![](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/passed-16px.png '') [0.0% Coverage on New Code](https://sonarcloud.io/component_measures?id=litestar-org_litestar&pullRequest=3824&metric=new_coverage&view=list)  \n![](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/passed-16px.png '') [0.0% Duplication on New Code](https://sonarcloud.io/component_measures?id=litestar-org_litestar&pullRequest=3824&metric=new_duplicated_lines_density&view=list)  \n  \n[See analysis details on SonarCloud](https://sonarcloud.io/dashboard?id=litestar-org_litestar&pullRequest=3824)\n\n",
                        "user": "sonarcloud[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-10-24T01:51:48Z",
                        "url": "https://github.com/litestar-org/litestar/pull/3824#issuecomment-2434061889"
                    },
                    {
                        "body": "Documentation preview will be available shortly at https://litestar-org.github.io/litestar-docs-preview/3824",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-10-24T01:53:23Z",
                        "url": "https://github.com/litestar-org/litestar/pull/3824#issuecomment-2434063475"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/litestar-org/litestar/pulls/3824",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/3451",
                "title": "Bug: Litestar instance or factory not found",
                "labels": [
                    "Bug :bug:",
                    "Needs MCVE"
                ],
                "user": "glickums",
                "issue_author_association": "NONE",
                "number": 3451,
                "id": 2269585407,
                "state": "closed",
                "project_created_at": "2024-04-29T17:34:09Z",
                "closed_at": "2024-07-30T05:11:52Z",
                "body": "Hi, every time I try to run litestar from vscode I get a \"Could not find Litestar instance or factory\"\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n> [!NOTE]  \n> While we are open for sponsoring on [GitHub Sponsors](https://github.com/sponsors/litestar-org/) and \n> [OpenCollective](https://opencollective.com/litestar), we also utilize [Polar.sh](https://polar.sh/) to engage in pledge-based sponsorship.\n>\n> Check out all issues funded or available for funding [on our Polar.sh dashboard](https://polar.sh/litestar-org)\n> * If you would like to see an issue prioritized, make a pledge towards it!\n> * We receive the pledge once the issue is completed & verified\n> * This, along with engagement in the community, helps us know which features are a priority to our users.\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/3451\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/3451/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/3451/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [
                    {
                        "body": "Can you provide an MCVE of your project structure? You can see *how* Litestar discovers things in https://docs.litestar.dev/latest/usage/cli.html#autodiscovery, and you error indicates those criteria are not met.\r\n\r\nIf it is not in your current directory, or discoverable otherwise as listed in the documentation, you have to provide the path via something like:\r\n```\r\nlitestar --app-dir \"/Users/jacob/Library/Application Support/JetBrains/PyCharm2023.3/scratches/\" run\r\n```\r\nor \r\n```\r\nlitestar --app module.path.to.examples.basic:app run\r\n```",
                        "user": "JacobCoffee",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-04-29T19:18:54Z",
                        "url": "https://github.com/litestar-org/litestar/issues/3451#issuecomment-2083487580"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/3397",
                "title": "Bug: Using asyncio.create_subprocess_shell / _exec in lifespan raises NotImplementedError",
                "labels": [
                    "Question",
                    "Compatibility",
                    "Needs MCVE",
                    "Needs Response :warning:"
                ],
                "user": "tim-hilt",
                "issue_author_association": "NONE",
                "number": 3397,
                "id": 2246860525,
                "state": "closed",
                "project_created_at": "2024-04-16T20:48:33Z",
                "closed_at": "2024-04-17T06:45:43Z",
                "body": "### Description\n\nNot a whole lot more to say. I want to have a long running process that updates some data periodically in the background. With FastAPI I could use the lifespan-function as presented below, but with Litestar the following exception is raised:\r\n\r\n```\r\n      | Traceback (most recent call last):\r\n      |   File \"C:\\<disguised>\\app.py\", line 112, in update_data\r\n      |     data = await exec_shell_command()\r\n      |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n      |   File \"C:\\<disguised>\\app.py\", line 17, in exec_shell_command\r\n      |     proc = await asyncio.create_subprocess_shell(\r\n      |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n      |   File \"C:\\Appl\\Python\\Lib\\asyncio\\subprocess.py\", line 208, in create_subprocess_shell\r\n      |     transport, protocol = await loop.subprocess_shell(\r\n      |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n      |   File \"C:\\Appl\\Python\\Lib\\asyncio\\base_events.py\", line 1661, in subprocess_shell\r\n      |     transport = await self._make_subprocess_transport(\r\n      |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n      |   File \"C:\\Appl\\Python\\Lib\\asyncio\\base_events.py\", line 502, in _make_subprocess_transport\r\n      |     raise NotImplementedError\r\n      | NotImplementedError\r\n      +------------------------------------\r\n```\r\n\r\nI think it has something to do with the event-loop being used, but I don't know enough to find out the cause fully on my own.\n\n### URL to code causing the issue\n\n_No response_\n\n### MCVE\n\n```python\nfrom contextlib import asynccontextmanager\r\nfrom typing import AsyncGenerator\r\n\r\nfrom litestar import Litestar, get\r\nimport anyio\r\n\r\nasync def update_data() -> None:\r\n    while True:\r\n        proc = await asyncio.create_subprocess_shell(\r\n            \"ls -l\",\r\n            stdout=asyncio.subprocess.PIPE,\r\n            stderr=asyncio.subprocess.PIPE,\r\n        )\r\n\r\n        stdout, _ = await proc.communicate()\r\n        asyncio.sleep(60)\r\n\r\n@asynccontextmanager\r\nasync def lifespan(_: Litestar) -> AsyncGenerator[None, None]:\r\n    async with anyio.create_task_group() as tg:\r\n        tg.start_soon(update_data)\r\n        yield\r\n        tg.cancel_scope.cancel()\r\n\r\n@get(\"/\")\r\nasync def root() -> dict[str, str]:\r\n    return {\"Hello\": \"World\"}\r\n\r\napp = Litestar(route_handlers=[root], lifespan=[lifespan])\n```\n\n\n### Steps to reproduce\n\n```bash\nJust run the code presented above\n```\n\n\n### Screenshots\n\n```bash\n\"![SCREENSHOT_DESCRIPTION](SCREENSHOT_LINK.png)\"\n```\n\n\n### Logs\n\n_No response_\n\n### Litestar Version\n\n2.8.2\n\n### Platform\n\n- [ ] Linux\n- [ ] Mac\n- [X] Windows\n- [ ] Other (Please specify in the description above)\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n> [!NOTE]  \n> While we are open for sponsoring on [GitHub Sponsors](https://github.com/sponsors/litestar-org/) and \n> [OpenCollective](https://opencollective.com/litestar), we also utilize [Polar.sh](https://polar.sh/) to engage in pledge-based sponsorship.\n>\n> Check out all issues funded or available for funding [on our Polar.sh dashboard](https://polar.sh/litestar-org)\n> * If you would like to see an issue prioritized, make a pledge towards it!\n> * We receive the pledge once the issue is completed & verified\n> * This, along with engagement in the community, helps us know which features are a priority to our users.\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/3397\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/3397/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/3397/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [
                    {
                        "body": "Can you please provide the exact command that you use to run the application, e.g., `litestar run ...` or `uvicorn ...` or something else? Do you have `--reload` enabled, or are you useing multiple workers?\r\n\r\nFrom [Subprocess Support on Windows](https://docs.python.org/3/library/asyncio-platforms.html#subprocess-support-on-windows):\r\n\r\n> On Windows, the default event loop [`ProactorEventLoop`](https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.ProactorEventLoop) supports subprocesses, whereas [`SelectorEventLoop`](https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.SelectorEventLoop) does not.\r\n\r\nUvicorn explicitly set the event loop to be `SelectorEventLoop` if reloading enabled, or multiple workers ([ref](https://github.com/encode/uvicorn/blob/0efd3835da6dcc713f74aadf7b52779d0d1fa17d/uvicorn/loops/asyncio.py#L8-L10)).\r\n\r\n> With FastAPI I could use the lifespan-function as presented below\r\n\r\nI can find the same issue mentioned in the fastapi repo:\r\n\r\n- https://github.com/tiangolo/fastapi/issues/4361\r\n- https://github.com/tiangolo/fastapi/issues/964\r\n\r\nSo there has to be some difference in the configuration at the server level that is causing the `SelectorEventLoop` to be enabled in this case, and not in the FastAPI case.",
                        "user": "peterschutt",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-17T00:14:33Z",
                        "url": "https://github.com/litestar-org/litestar/issues/3397#issuecomment-2060102617"
                    },
                    {
                        "body": "Indeed it seems to be connected to enabling multiple workers. I think I added the `workers=4` attribute to the `uvicorn.run` call when using FastAPI without even trying it out. Then I switched to Litestar and it crashed :D So: My bad. But still interesting to learn more about event-loops.",
                        "user": "tim-hilt",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-04-17T06:45:43Z",
                        "url": "https://github.com/litestar-org/litestar/issues/3397#issuecomment-2060496902"
                    },
                    {
                        "body": "the tl;dr would be imho to use linux :)\r\n\r\nnow from my poor memory, uvicorn aims at supporting both windows and linux and in doing so has to deal with 2 different default event loops. both of those loop default support subprocesses, but uvicorn overrides the default one to SelectorEventLoop.\r\nI think the override of the loop in windows is a way to let windows subprocess reload the app, with the iocp loop it wasn't working.\r\nso in essence on windows we force the loop to be the non-default one to suport the reload thing (better dx experience) at the cost of what you encounter : being unable to use subprocesses\r\n\r\nnow this may need a rethink on uvicorn's side I'm not too sure.",
                        "user": "euri10",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-17T07:58:51Z",
                        "url": "https://github.com/litestar-org/litestar/issues/3397#issuecomment-2060642041"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2992",
                "title": "Enhancement: Multiple TestClients / explicit test app running",
                "labels": [
                    "Enhancement",
                    "Needs MCVE"
                ],
                "user": "mtvx",
                "issue_author_association": "NONE",
                "number": 2992,
                "id": 2087001446,
                "state": "open",
                "project_created_at": "2024-01-17T21:20:25Z",
                "closed_at": null,
                "body": "### Summary\r\n\r\nSometimes, it would be nice to initialize multiple `Testclient`s, but only do the blocking portal magic once. The request routing magic lives in `TestClient(Transport)` so simply copying the `base_url` to a `httpx.Client` won't work (found out by trying).\r\n\r\nAn example where this could be needed is when testing the API from the perspective of 2 different users. Using just one client might not be feasible due to cookies that server could set (should be different for the two users) and in general it would be nice to have the two separated.\r\n\r\n```py\r\nclient = TestClient(app=app)\r\nclient.get(..., auth=user1_auth)  # requires also...\r\nclient.get(..., auth=user2_auth)  # ...this repetition\r\n```\r\n\r\n### Basic Example\r\n\r\nMaybe something like:\r\n\r\n```py\r\nwith create_portal(app) as portal:\r\n    user1 = TestClient(portal=portal, auth=...)\r\n    user2 = TestClient(portal=portal, auth=...)\r\n    user1.get(...)\r\n    user2.get(...)\r\n```\r\n\r\n### Drawbacks and Impact\r\n\r\n_No response_\r\n\r\n### Unresolved questions\r\n\r\n_No response_\r\n\r\n<!-- POLAR PLEDGE BADGE START -->\r\n---\r\n> [!NOTE]  \r\n> While we are open for sponsoring on [GitHub Sponsors](https://github.com/sponsors/litestar-org/) and \r\n> [OpenCollective](https://opencollective.com/litestar), we also utilize [Polar.sh](https://polar.sh/) to engage in pledge-based sponsorship.\r\n>\r\n> Check out all issues funded or available for funding [on our Polar.sh dashboard](https://polar.sh/litestar-org)\r\n> * If you would like to see an issue prioritized, make a pledge towards it!\r\n> * We receive the pledge once the issue is completed & verified\r\n> * This, along with engagement in the community, helps us know which features are a priority to our users.\r\n\r\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2992\">\r\n<picture>\r\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2992/pledge.svg?darkmode=1\">\r\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2992/pledge.svg\">\r\n</picture>\r\n</a>\r\n<!-- POLAR PLEDGE BADGE END -->\r\n",
                "comments": [
                    {
                        "body": "Can you provide an example use case where two client instances would be useful?",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-01-18T19:13:53Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2992#issuecomment-1899062380"
                    },
                    {
                        "body": "Hi, I did try to give an example up there - are you saying it doesn't make sense or is unclear?\r\n\r\nIt's just to reduce boilerplate - when you're testing an endpoint with two (or multiple) different users, it's helpful to create client per-user, and avoid having to pass `auth=...` and maybe something else each time.\r\n\r\nAlso technically/semantically I'd say it makes sense to separate the a) test app \"running\" from b) test client that calls it.",
                        "user": "mtvx",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-01-19T07:36:29Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2992#issuecomment-1899907359"
                    },
                    {
                        "body": "> Hi, I did try to give an example up there - are you saying it doesn't make sense or is unclear?\r\n\r\nI can't speak for @provinzkraut but it makes it a lot easier to consider the problem if there's a copy/paste example.\r\n",
                        "user": "peterschutt",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-30T05:06:52Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2992#issuecomment-2084390000"
                    },
                    {
                        "body": "I get that same issue a while back if I get OP correctly. Let me try to explain.\r\n\r\nyou have an app with buyers/sellers: depending on this role you can do different things, sellers can add products, edit, delete them etc, buyers can list then only, put then in a cart living in a session, etc...\r\n\r\nnow let's say you want to test the buyer putting product X on his cart, but before the order button is pressed the seller deleted the item : you'd need two TestClient and the portal will fuck you up iirc\r\n\r\n\r\n",
                        "user": "euri10",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-04-30T06:49:47Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2992#issuecomment-2084507792"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2902",
                "title": "Bug: DTO support empty payload",
                "labels": [
                    "Bug :bug:",
                    "Great MCVE",
                    "High Priority",
                    "DTOs"
                ],
                "user": "peterschutt",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2902,
                "id": 2042831823,
                "state": "closed",
                "project_created_at": "2023-12-15T03:32:39Z",
                "closed_at": "2023-12-15T23:52:27Z",
                "body": "### Description\n\nDTO supported data fails if no body is sent with the request, even if a default value is provided for the parameter.\n\n### URL to code causing the issue\n\n_No response_\n\n### MCVE\n\n```python\nfrom dataclasses import dataclass\r\nfrom typing import Optional\r\n\r\nfrom litestar import Litestar, post\r\nfrom litestar.contrib.pydantic import PydanticPlugin\r\nfrom litestar.dto import DataclassDTO\r\nfrom litestar.logging import LoggingConfig\r\n\r\n\r\n@dataclass\r\nclass Foo:\r\n    foo: str\r\n\r\n\r\n@post(path=\"/\", dto=DataclassDTO[Foo])\r\ndef test(data: Optional[Foo] = None) -> dict:\r\n    return {\"foo\": data}\r\n\r\n\r\napp = Litestar(\r\n    route_handlers=[test],\r\n    logging_config=LoggingConfig(),\r\n    middleware=[],\r\n    plugins=[PydanticPlugin(prefer_alias=True)],\r\n)\n```\n\n\n### Steps to reproduce\n\n```bash\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\n```\n\n\n### Screenshots\n\n```bash\n\"![SCREENSHOT_DESCRIPTION](SCREENSHOT_LINK.png)\"\n```\n\n\n### Logs\n\n```bash\nFO:     127.0.0.1:38110 - \"POST / HTTP/1.1\" 400 Bad Request\r\nERROR - 2023-12-15 02:27:22,851 - litestar - config - exception raised on http connection to route /\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/serialization/msgspec_hooks.py\", line 187, in decode_json\r\n    return msgspec.json.decode(\r\nmsgspec.DecodeError: Input data was truncated\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/routes/http.py\", line 177, in _get_response_data\r\n    kwargs[\"data\"] = await kwargs[\"data\"]\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/_kwargs/extractors.py\", line 450, in dto_extractor\r\n    return data_dto(connection).decode_bytes(body)\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/dto/base_dto.py\", line 97, in decode_bytes\r\n    return backend.populate_data_from_raw(value, self.asgi_connection)\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/dto/_backend.py\", line 301, in populate_data_from_raw\r\n    source_data=self.parse_raw(raw, asgi_connection),\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/dto/_backend.py\", line 208, in parse_raw\r\n    result = decode_json(value=raw, target_type=self.annotation, type_decoders=type_decoders)\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/serialization/msgspec_hooks.py\", line 191, in decode_json\r\n    raise SerializationException(str(msgspec_error)) from msgspec_error\r\nlitestar.exceptions.base_exceptions.SerializationException: Input data was truncated\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/middleware/exceptions/middleware.py\", line 191, in __call__\r\n    await self.app(scope, receive, send)\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/routes/http.py\", line 81, in handle\r\n    response = await self._get_response_for_request(\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/routes/http.py\", line 133, in _get_response_for_request\r\n    return await self._call_handler_function(\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/routes/http.py\", line 153, in _call_handler_function\r\n    response_data, cleanup_group = await self._get_response_data(\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/routes/http.py\", line 179, in _get_response_data\r\n    raise ClientException(str(e)) from e\r\nlitestar.exceptions.http_exceptions.ClientException: 400: Input data was truncated\r\nTraceback (most recent call last):\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/serialization/msgspec_hooks.py\", line 187, in decode_json\r\n    return msgspec.json.decode(\r\nmsgspec.DecodeError: Input data was truncated\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/routes/http.py\", line 177, in _get_response_data\r\n    kwargs[\"data\"] = await kwargs[\"data\"]\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/_kwargs/extractors.py\", line 450, in dto_extractor\r\n    return data_dto(connection).decode_bytes(body)\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/dto/base_dto.py\", line 97, in decode_bytes\r\n    return backend.populate_data_from_raw(value, self.asgi_connection)\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/dto/_backend.py\", line 301, in populate_data_from_raw\r\n    source_data=self.parse_raw(raw, asgi_connection),\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/dto/_backend.py\", line 208, in parse_raw\r\n    result = decode_json(value=raw, target_type=self.annotation, type_decoders=type_decoders)\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/serialization/msgspec_hooks.py\", line 191, in decode_json\r\n    raise SerializationException(str(msgspec_error)) from msgspec_error\r\nlitestar.exceptions.base_exceptions.SerializationException: Input data was truncated\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/middleware/exceptions/middleware.py\", line 191, in __call__\r\n    await self.app(scope, receive, send)\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/routes/http.py\", line 81, in handle\r\n    response = await self._get_response_for_request(\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/routes/http.py\", line 133, in _get_response_for_request\r\n    return await self._call_handler_function(\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/routes/http.py\", line 153, in _call_handler_function\r\n    response_data, cleanup_group = await self._get_response_data(\r\n  File \"/home/simon/miniconda3/envs/resonance/lib/python3.10/site-packages/litestar/routes/http.py\", line 179, in _get_response_data\r\n    raise ClientException(str(e)) from e\r\nlitestar.exceptions.http_exceptions.ClientException: 400: Input data was truncated\n```\n\n\n### Litestar Version\n\nmain\n\n### Platform\n\n- [X] Linux\n- [ ] Mac\n- [ ] Windows\n- [ ] Other (Please specify in the description above)\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n> [!NOTE]  \n> While we are open for sponsoring on [GitHub Sponsors](https://github.com/sponsors/litestar-org/) and \n> [OpenCollective](https://opencollective.com/litestar), we also utilize [Polar.sh](https://polar.sh/) to engage in pledge-based sponsorship.\n>\n> Check out all issues funded or available for funding [on our Polar.sh dashboard](https://polar.sh/litestar-org)\n> * If you would like to see an issue prioritized, make a pledge towards it!\n> * We receive the pledge once the issue is completed & verified\n> * This, along with engagement in the community, helps us know which features are a priority to our users.\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2902\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2902/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2902/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2721",
                "title": "Bug: Renaming in DTOs with nested fields will rename all occurrences.",
                "labels": [
                    "Bug :bug:",
                    "Great MCVE"
                ],
                "user": "simon-lund",
                "issue_author_association": "NONE",
                "number": 2721,
                "id": 2001748427,
                "state": "closed",
                "project_created_at": "2023-11-20T09:32:28Z",
                "closed_at": "2023-11-27T04:30:55Z",
                "body": "### Description\r\n\r\nIn the example below, we have two models: 'Chat' and 'Message', each with an 'id' field. We also define a ResponseDTO for the Chat model, using DTOConfig to rename its 'id' field to 'chat_id'. \r\n\r\nThe intention is to only rename the 'id' of the Chat model. However, this configuration unexpectedly renames the 'id' field in the nested Message objects as well. As a result, the response output is \r\n\r\n`{\"chat_id\":\"1\",\"messages\":[{\"chat_id\":\"1\",\"created_at\":\"1\",\"user_id\":\"1\"}]}`, \r\n\r\nwhere both Chat and Message 'id' fields are affected, contrary to the intended behavior.\r\n\r\n\r\n### URL to code causing the issue\r\n\r\n_No response_\r\n\r\n### MCVE\r\n\r\n```python\r\nfrom typing_extensions import List\r\nfrom litestar import get, Litestar\r\nfrom pydantic import BaseModel\r\nfrom litestar.dto import DTOConfig\r\nfrom litestar.contrib.pydantic import PydanticDTO\r\n\r\nclass Message(BaseModel):\r\n    id: str\r\n    created_at: str\r\n    user_id: str\r\n\r\nclass Chat(BaseModel):\r\n    id: str\r\n    messages: List[Message]\r\n\r\nclass ResponseDTO(PydanticDTO[Chat]):\r\n    config = DTOConfig(rename_fields={\"id\": \"chat_id\"})\r\n\r\n@get(return_dto=ResponseDTO)\r\nasync def get_chat() -> Chat:\r\n    return Chat(id=\"1\", messages=[Message(id=\"1\", created_at=\"1\", user_id=\"1\")])\r\n\r\napp = Litestar([get_chat])\r\n```\r\n\r\n\r\n### Steps to reproduce\r\n\r\n```bash\r\n1. Start Litestar\r\n2. Make API call `curl localhost:8000`\r\n3. Observe :bug:\r\n```\r\n\r\n\r\n### Screenshots\r\n\r\n_No response_\r\n\r\n### Logs\r\n\r\n_No response_\r\n\r\n### Litestar Version\r\n\r\n2.2.1\r\n\r\n### Platform\r\n\r\n- [X] Linux\r\n- [ ] Mac\r\n- [ ] Windows\r\n- [ ] Other (Please specify in the description above)\r\n\r\n<!-- POLAR PLEDGE BADGE START -->\r\n---\r\n> [!NOTE]  \r\n> While we are open for sponsoring on [GitHub Sponsors](https://github.com/sponsors/litestar-org/) and \r\n> [OpenCollective](https://opencollective.com/litestar), we also utilize [Polar.sh](https://polar.sh/) to engage in pledge-based sponsorship.\r\n>\r\n> Check out all issues funded or available for funding [on our Polar.sh Litestar dashboard](https://polar.sh/litestar-org)\r\n> * If you would like to see an issue prioritized, make a pledge towards it!\r\n> * We receive the pledge once the issue is completed & verified\r\n> * This, along with engagement in the community, helps us know which features are a priority to our users.\r\n\r\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2721\">\r\n<picture>\r\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2721/pledge.svg?darkmode=1\">\r\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2721/pledge.svg\">\r\n</picture>\r\n</a>\r\n<!-- POLAR PLEDGE BADGE END -->\r\n",
                "comments": [
                    {
                        "body": "@peterschutt Haven't really investigated yet, but it happens on both the regular and the codegen backend",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-26T13:01:32Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2721#issuecomment-1826778706"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2635",
                "title": "Bug: Schema generation partially broken since litestar version 2.3.0",
                "labels": [
                    "Bug :bug:",
                    "Great MCVE"
                ],
                "user": "euthuppan",
                "issue_author_association": "NONE",
                "number": 2635,
                "id": 1984601950,
                "state": "closed",
                "project_created_at": "2023-11-09T00:17:28Z",
                "closed_at": "2023-11-11T04:21:24Z",
                "body": "### Description\n\n2.2.1 is my last working version of litestar. \r\n\r\nBefore:\r\n<img width=\"467\" alt=\"image\" src=\"https://github.com/litestar-org/litestar/assets/85191795/dc9594b1-4b09-4607-9061-dcd65bf0a09f\">\r\n\r\nAfter:\r\nI first get this `internal server error` when i first try to go to my Swagger URL\r\n\r\n<img width=\"436\" alt=\"image\" src=\"https://github.com/litestar-org/litestar/assets/85191795/90112884-907e-4ee0-a14c-a92c338ef761\">\r\n\r\nAnd then when i refresh once more, it goes to my swagger page, but only 2/3 of it.\r\n\r\n\r\n\r\n<img width=\"217\" alt=\"image\" src=\"https://github.com/litestar-org/litestar/assets/85191795/74f16208-e80a-46de-b580-3dd566e0f14b\">\r\n\r\nWith no changes in my code, the problems just start at version 2.3.0 and beyond. Just wanted to bring attention to this, as I will now be sticking to litestar 2.2.1 until this is resolved.\n\n### URL to code causing the issue\n\n_No response_\n\n### MCVE\n\n```python\nHow my app code looks like when passing in my controllers:\r\n\r\napp = Litestar(\r\n    route_handlers=[\r\n        read_root,\r\n        refresh_templates,\r\n        LinuxPXEController,\r\n        WindowsPXEController,\r\n        ESXiPXEController\r\n    ],\r\n ...\n```\n\n\n### Steps to reproduce\n\n_No response_\n\n### Screenshots\n\n```bash\n\"![SCREENSHOT_DESCRIPTION](SCREENSHOT_LINK.png)\"\n```\n\n\n### Logs\n\n_No response_\n\n### Litestar Version\n\n2.3.0\n\n### Platform\n\n- [X] Linux\n- [X] Mac\n- [ ] Windows\n- [ ] Other (Please specify in the description above)\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n> [!NOTE]  \n> While we are open for sponsoring on [GitHub Sponsors](https://github.com/sponsors/litestar-org/) and \n> [OpenCollective](https://opencollective.com/litestar), we also utilize [Polar.sh](https://polar.sh/) to engage in pledge-based sponsorship.\n>\n> Check out all issues funded or available for funding [on our Polar.sh Litestar dashboard](https://polar.sh/litestar-org)\n> * If you would like to see an issue prioritized, make a pledge towards it!\n> * We receive the pledge once the issue is completed & verified\n> * This, along with engagement in the community, helps us know which features are a priority to our users.\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2635\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2635/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2635/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [
                    {
                        "body": "@euthuppan could you please enable `debug` mode on the application and let us know if that gives you additional output?\r\n\r\n```python\r\napp = Litestar(\r\n    debug=True,\r\n    route_handlers=[\r\n        read_root,\r\n        refresh_templates,\r\n        LinuxPXEController,\r\n        WindowsPXEController,\r\n        ESXiPXEController\r\n    ],\r\n    ```",
                        "user": "cofin",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-09T02:59:50Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2635#issuecomment-1803087926"
                    },
                    {
                        "body": "I've also started running into this issue with v2.3, find a screenshot of the error in debug mode below:\r\n![Screenshot 2023-11-09 at 11 39 54](https://github.com/litestar-org/litestar/assets/20231751/6eb6b953-781c-4f86-8d96-a947ff92128c)\r\n\r\n\r\nThis also happens for ReDoc and Elements, so it's consistent across all OpenAPI renderers.",
                        "user": "timwedde",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-11-09T10:43:29Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2635#issuecomment-1803588469"
                    },
                    {
                        "body": "@timwedde @euthuppan could one of you provide an MCVE that reproduces this?\r\n\r\nAlso, which Pydantic version are you using?",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-09T20:04:07Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2635#issuecomment-1804576606"
                    },
                    {
                        "body": "Took me a little while to track this down, but here you go:\r\n```py\r\n# pip install pydantic==2.4.2 litestar==2.3.2\r\n\r\nfrom litestar import Litestar, get\r\nfrom pydantic import BaseModel, Field\r\n\r\n\r\nclass Model(BaseModel):\r\n    id: int\r\n    fail: dict = {}  # fails\r\n    # fail: dict = Field(default={})  # fails\r\n    # fail: dict = Field(default_factory=dict)  # works\r\n\r\n\r\n@get(\"/\")\r\nasync def mcve() -> Model:\r\n    return Model(id=1)\r\n\r\n\r\napp = Litestar(\r\n    debug=True,\r\n    route_handlers=[mcve],\r\n)\r\n```\r\n\r\nSeems that this may now be semi-intended behavior since the `default_factory` approach is likely the objectively correct one anyway, but it does somewhat smell like a breaking change in a minor version update. For reference, this does work properly on Litestar versions before 2.3.x, with the same pydantic version.",
                        "user": "timwedde",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-11-10T11:57:11Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2635#issuecomment-1805608693"
                    },
                    {
                        "body": "So things seems to have broken on 46ea14bf045f1804e0a1623407ec525179acbfb4 (#2553) for the MCVE above (`fail: dict = {}`). Bisected all the way from a7fe0f306e541253351fb1ad373bf6ff590eef9a (v2.2.0) to 0c6a57f8454838572aa6eaffd89123c778d638df (current main)",
                        "user": "Alc-Alc",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-11-10T12:16:54Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2635#issuecomment-1805636304"
                    },
                    {
                        "body": "So change this https://github.com/litestar-org/litestar/blob/0c6a57f8454838572aa6eaffd89123c778d638df/litestar/contrib/pydantic/utils.py#L164-L165\r\n\r\n```py\r\ndef is_pydantic_undefined(value: Any) -> bool:\r\n    return any(v is value for v in PYDANTIC_UNDEFINED_SENTINELS)\r\n```\r\n\r\nso that it is the same as this (avoid the hash)?\r\n\r\nhttps://github.com/litestar-org/litestar/blob/0c6a57f8454838572aa6eaffd89123c778d638df/litestar/utils/predicates.py#L314-L323\r\n\r\n",
                        "user": "Alc-Alc",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-11-10T12:54:07Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2635#issuecomment-1805681312"
                    },
                    {
                        "body": "Thanks for the effort @Alc-Alc! The proposed change looks good to me, do you want to implement it (and add a test case to reproduce)?",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-10T17:49:54Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2635#issuecomment-1806165561"
                    },
                    {
                        "body": "Also thanks @timwedde for the great mcve! This is really helpful! :)",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-10T17:51:14Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2635#issuecomment-1806166972"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2503",
                "title": "Litestar consumes high amount of CPU",
                "labels": [
                    "Question",
                    "Needs MCVE"
                ],
                "user": "bpereto",
                "issue_author_association": "NONE",
                "number": 2503,
                "id": 1957867543,
                "state": "closed",
                "project_created_at": "2023-10-23T19:19:18Z",
                "closed_at": "2023-10-23T19:59:46Z",
                "body": "### Description\r\n\r\nRunning litestar `litestar app run` with uvicorn consumes in an idling state on my machines 40-45% CPU.\r\n\r\nIs this normal or is there a way to reduce the idling CPU consumption?\r\n\r\nAttached a picture of cProfile. `python -m cProfile -o litestar.pstats ./.venv/bin/litestar run`\r\n\r\n![litestar_profile](https://github.com/litestar-org/litestar/assets/1131885/ab23a525-f85e-479e-8a5d-981fe68c46e3)\r\n\r\n### URL to code causing the issue\r\n\r\n_No response_\r\n\r\n### MCVE\r\n\r\n```python\r\nUVICORN_LOOP=uvloop litestar run                            \r\nUsing Litestar app from env: 'app.asgi:create_app'\r\nStarting server process \r\n\r\n Litestar version              2.2.1                                                                                                        \r\n Debug mode                    Disabled                                                                                                     \r\n Python Debugger on exception  Disabled                                                                                                     \r\n CORS                          Enabled                                                                                                      \r\n CSRF                          Disabled                                                                                                     \r\n OpenAPI                       Enabled path=/schema                                                                                         \r\n Compression                   Disabled                                                                                                     \r\n Template engine               ViteTemplateEngine                                                                                           \r\n Static files                  path=/static dirs=.../src/app/domain/web/public html_mode=Enabled \r\n Middlewares                   JWTCookieAuthenticationMiddleware, SentryLitestarASGIMiddleware, middleware_factory                          \r\n\r\n2023-10-23T19:12:38.780745Z [info     ] Started server process [4257]  [uvicorn.error] \r\n2023-10-23T19:12:38.781923Z [info     ] Waiting for application startup. [uvicorn.error] \r\n2023-10-23T19:12:38.789916Z [info     ] Application startup complete.  [uvicorn.error] \r\n2023-10-23T19:12:38.792650Z [info     ] Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit) [uvicorn.error] \r\n^C2023-10-23T19:15:04.770399Z [info     ] Shutting down                  [uvicorn.error] \r\n^C2023-10-23T19:15:04.910332Z [info     ] Finished server process [4257] [uvicorn.error] \r\n^C2023-10-23T19:15:04.974529Z [info     ] ASGI 'lifespan' protocol appears unsupported. [uvicorn.error] \r\n```\r\n```\r\n\r\n\r\n### Steps to reproduce\r\n\r\n```bash\r\n- Run `litestar run`\r\n- Look process ressources\r\n```\r\n\r\n\r\n### Screenshots\r\n\r\n![litestar_profile](https://github.com/litestar-org/litestar/assets/1131885/ab23a525-f85e-479e-8a5d-981fe68c46e3)\r\r\n\r\n\r\n### Logs\r\n\r\n_No response_\r\n\r\n### Litestar Version\r\n\r\n2.2.1\r\npython3.11\r\n\r\n\r\n\r\n### Platform\r\n\r\n- [ ] Linux\r\n- [X] Mac\r\n- [ ] Windows\r\n- [ ] Other (Please specify in the description above)\r\n\r\n<!-- POLAR PLEDGE BADGE START -->\r\n---\r\n> [!NOTE]  \r\n> While we are open for sponsoring on [GitHub Sponsors](https://github.com/sponsors/litestar-org/) and \r\n> [OpenCollective](https://opencollective.com/litestar), we also utilize [Polar.sh](https://polar.sh/) to engage in pledge-based sponsorship.\r\n>\r\n> Check out all issues funded or available for funding [on our Polar.sh Litestar dashboard](https://polar.sh/litestar-org)\r\n> * If you would like to see an issue prioritized, make a pledge towards it!\r\n> * We receive the pledge once the issue is completed & verified\r\n> * This, along with engagement in the community, helps us know which features are a priority to our users.\r\n\r\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2503\">\r\n<picture>\r\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2503/pledge.svg?darkmode=1\">\r\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2503/pledge.svg\">\r\n</picture>\r\n</a>\r\n<!-- POLAR PLEDGE BADGE END -->\r\n",
                "comments": [
                    {
                        "body": "I cannot reproduce this with a basic application. Can you provide a reproducible example? Its really hard to debug this without actually know what your app looks like, but Im fairly certain that theres some kind of busy loop involved youre not aware of.",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-10-23T19:59:03Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2503#issuecomment-1775927550"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2461",
                "title": "Bug: `url_for` template callable doesn't work in Jinja macros",
                "labels": [
                    "Question",
                    "Great MCVE"
                ],
                "user": "geeshta",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2461,
                "id": 1945955396,
                "state": "closed",
                "project_created_at": "2023-10-16T19:37:49Z",
                "closed_at": "2023-10-16T20:00:10Z",
                "body": "### Description\n\nWhen using the `url_for`  template callable inside of a Jinja macro, an exception is thrown.  It seems that the `request` context variable is not injected, which is responsible for resolving URLs.\r\n\r\nSee MCVE:\r\n```\r\n<li>{{ item.name }} - <a href=\"{{ url_for('item_detail', id=item.id) }}\">Detail</a></li>\r\n```\r\nThis is inside of a Jinja macro which gets called inside of another template. This leads to an error. If you delete the `<a>` tag, the macro will work properly.\r\n```\r\n<a href=\"{{ url_for('item_list') }}\">Back to list</a>\r\n```\r\nThis is directly inside of a template string and doesn't raise an error.\r\n\n\n### URL to code causing the issue\n\n_No response_\n\n### MCVE\n\n```python\nfrom jinja2.environment import Environment\r\nfrom jinja2.loaders import DictLoader\r\nfrom litestar import Litestar, get\r\nfrom litestar.contrib.jinja import JinjaTemplateEngine\r\nfrom litestar.response import Template\r\nfrom litestar.template import TemplateConfig\r\n\r\nmacros = r\"\"\"\r\n{% macro list_items(items) %}\r\n  <ul>\r\n  {% for item in items %}\r\n    <li>{{ item.name }} - <a href=\"{{ url_for('item_detail', id=item.id) }}\">Detail</a></li>\r\n  {% endfor %}\r\n  </ul>\r\n{% endmacro %}\r\n\"\"\"\r\n\r\nitem_list_template = r\"\"\"\r\n{% import \"macros.html.j2\" as render %}\r\n<html>\r\n  <head></head>\r\n  <body>\r\n    {{ render.list_items(items) }}\r\n  </body>\r\n</html>\r\n\"\"\"\r\n\r\nitem_detail_template = r\"\"\"\r\n<html>\r\n  <head></head>\r\n  <body>\r\n    <div>\r\n      <strong>{{ item.id }}: </strong>{{ item.name }}\r\n    </div>\r\n    <div>\r\n      <a href=\"{{ url_for('item_list') }}\">Back to list</a>\r\n    </div>\r\n  </body>\r\n</html>\r\n\"\"\"\r\n\r\n\r\njinja_env = Environment(\r\n    loader=DictLoader(\r\n        {\r\n            \"macros.html.j2\": macros,\r\n            \"item_list.html.j2\": item_list_template,\r\n            \"item_detail.html.j2\": item_detail_template,\r\n        }\r\n    )\r\n)\r\ntemplate_config = TemplateConfig(engine=JinjaTemplateEngine.from_environment(jinja_env))\r\n\r\nitems = [\r\n    {\"id\": 1, \"name\": \"Alice\"},\r\n    {\"id\": 2, \"name\": \"Bob\"},\r\n    {\"id\": 3, \"name\": \"Charlie\"},\r\n]\r\n\r\n\r\n@get(\"/\", name=\"item_list\")\r\nasync def item_list() -> Template:\r\n    return Template(\"item_list.html.j2\", context={\"items\": items})\r\n\r\n\r\n@get(\"/{id:int}\", name=\"item_detail\")\r\nasync def item_detail(id: int) -> Template:\r\n    item = [item for item in items if item[\"id\"] == id][0]\r\n    return Template(\"item_detail.html.j2\", context={\"item\": item})\r\n\r\n\r\napp = Litestar(route_handlers=[item_list, item_detail], template_config=template_config)\n```\n\n\n### Steps to reproduce\n\n```bash\n1. Run the MCVE app\r\n2. Navigate to `/`\r\n3. An error is raised\r\n4. When navigating to `/1`, no error is raised\r\n5. If you delete the `<a>` tag inside of the macro and navigate to `/`, no error is raised\n```\n\n\n### Screenshots\n\n```bash\n\"![SCREENSHOT_DESCRIPTION](SCREENSHOT_LINK.png)\"\n```\n\n\n### Logs\n\n```bash\nERROR - 2023-10-16 21:31:07,972585630 - litestar - middleware - exception raised on http connection to route /\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/middleware/exceptions/middleware.py\", line 191, in __call__\r\n    await self.app(scope, receive, send)\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 79, in handle\r\n    response = await self._get_response_for_request(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 131, in _get_response_for_request\r\n    response = await self._call_handler_function(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 164, in _call_handler_function\r\n    response: ASGIApp = await route_handler.to_response(app=scope[\"app\"], data=response_data, request=request)\r\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/base.py\", line 494, in to_response\r\n    return await response_handler(app=app, data=data, request=request)  # type: ignore\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/_utils.py\", line 153, in handler\r\n    return response.to_asgi_response(  # type: ignore\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/response/template.py\", line 130, in to_asgi_response\r\n    body = template.render(**context).encode(self.encoding)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/jinja2/environment.py\", line 1301, in render\r\n    self.environment.handle_exception()\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/jinja2/environment.py\", line 936, in handle_exception\r\n    raise rewrite_traceback_stack(source=source)\r\n  File \"<template>\", line 6, in top-level template code\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/jinja2/runtime.py\", line 777, in _invoke\r\n    rv = self._func(*arguments)\r\n         ^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<template>\", line 5, in template\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/template/base.py\", line 42, in url_for\r\n    return context[\"request\"].app.route_reverse(route_name, **path_parameters)\r\n           ~~~~~~~^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/jinja2/runtime.py\", line 331, in __getitem__\r\n    raise KeyError(key)\r\nKeyError: 'request'\r\nTraceback (most recent call last):\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/middleware/exceptions/middleware.py\", line 191, in __call__\r\n    await self.app(scope, receive, send)\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 79, in handle\r\n    response = await self._get_response_for_request(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 131, in _get_response_for_request\r\n    response = await self._call_handler_function(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 164, in _call_handler_function\r\n    response: ASGIApp = await route_handler.to_response(app=scope[\"app\"], data=response_data, request=request)\r\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/base.py\", line 494, in to_response\r\n    return await response_handler(app=app, data=data, request=request)  # type: ignore\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/_utils.py\", line 153, in handler\r\n    return response.to_asgi_response(  # type: ignore\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/response/template.py\", line 130, in to_asgi_response\r\n    body = template.render(**context).encode(self.encoding)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/jinja2/environment.py\", line 1301, in render\r\n    self.environment.handle_exception()\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/jinja2/environment.py\", line 936, in handle_exception\r\n    raise rewrite_traceback_stack(source=source)\r\n  File \"<template>\", line 6, in top-level template code\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/jinja2/runtime.py\", line 777, in _invoke\r\n    rv = self._func(*arguments)\r\n         ^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<template>\", line 5, in template\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/litestar/template/base.py\", line 42, in url_for\r\n    return context[\"request\"].app.route_reverse(route_name, **path_parameters)\r\n           ~~~~~~~^^^^^^^^^^^\r\n  File \"/home/geeshta/prog/litestar/bugs/.venv/lib/python3.11/site-packages/jinja2/runtime.py\", line 331, in __getitem__\r\n    raise KeyError(key)\r\nKeyError: 'request'\n```\n\n\n### Litestar Version\n\n2.1.1\n\n### Platform\n\n- [X] Linux\n- [ ] Mac\n- [ ] Windows\n- [ ] Other (Please specify in the description above)\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n> [!NOTE]  \n> While we are open for sponsoring on [GitHub Sponsors](https://github.com/sponsors/litestar-org/) and \n> [OpenCollective](https://opencollective.com/litestar), we also utilize [Polar.sh](https://polar.sh/) to engage in pledge-based sponsorship.\n>\n> Check out all issues funded or available for funding [on our Polar.sh Litestar dashboard](https://polar.sh/litestar-org)\n> * If you would like to see an issue prioritized, make a pledge towards it!\n> * We receive the pledge once the issue is completed & verified\n> * This, along with engagement in the community, helps us know which features are a priority to our users.\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2461\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2461/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2461/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [
                    {
                        "body": "Have you tried importing the macro `with context`?\r\n\r\nSo `{% import \"macros.html.j2\" as render with context %}`",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-10-16T19:58:56Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2461#issuecomment-1765180305"
                    },
                    {
                        "body": "@provinzkraut I have not and when I did, it fixed the issue. Thanks!",
                        "user": "geeshta",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-10-16T20:00:10Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2461#issuecomment-1765181846"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2442",
                "title": "Enhancement: Auth0/Keycloak",
                "labels": [
                    "Enhancement",
                    "Security"
                ],
                "user": "Saphyel",
                "issue_author_association": "NONE",
                "number": 2442,
                "id": 1943292538,
                "state": "open",
                "project_created_at": "2023-10-14T14:25:21Z",
                "closed_at": null,
                "body": "### Summary\n\nWould be possible to include documentation for this services in the documentation ?\r\n\r\nThey are becoming more common to use them (and their competitors) so I think having a section for them it would be great\n\n### Basic Example\n\n_No response_\n\n### Drawbacks and Impact\n\n_No response_\n\n### Unresolved questions\n\n_No response_\n\n<!-- POLAR PLEDGE BADGE START -->\n> [!NOTE]  \n> Check out all issues funded or available for funding here: https://polar.sh/litestar-org\n> * If you would like to see an issue prioritized, make a pledge towards it!\n> * We receive the pledge once the issue is completed & verified\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2442\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2442/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2442/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [
                    {
                        "body": "I'm not familiar with Litestar, but there's an [MRE](https://en.wikipedia.org/wiki/Minimal_reproducible_example#:~:text=In%20computing%2C%20a%20minimal%20reproducible,to%20be%20demonstrated%20and%20reproduced.) for FastAPI here: [ilyesAj/keycloak-fastAPI-integration](https://github.com/ilyesAj/keycloak-fastAPI-integration/tree/main).",
                        "user": "codespearhead",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-03-12T13:14:06Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2442#issuecomment-1991625525"
                    },
                    {
                        "body": "Found another one, and this one uses Litestar for the backend: https://github.com/GhentCDH/nuxt-keycloak-jwt-auth .\r\n\r\nHowever, it's important to emphasize that without a well-maintained Python OAuth 2.x server implementation (covering both Authorization and Resource Servers) and a Python OpenID Connect 1.x (OIDC) client, it is impossible to securely and reliably integrate it into Litestar or into any other Python framework for that matter.\r\n\r\nThis issue is not unique to Python though: most ecosystems outside of Java and C# face the same challenge (see [Certified Relying Party Libraries and Certified OpenID Provider Libraries](https://openid.net/developers/certified-openid-connect-implementations/)).\r\n\r\nThe best approach would be to contribute to improving [Authlib](https://github.com/lepture/authlib).",
                        "user": "codespearhead",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-08-13T15:14:14Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2442#issuecomment-2286503119"
                    },
                    {
                        "body": "Re: authlib, we have an issue for tracking that impl.\r\n\r\nhttps://github.com/lepture/authlib/issues/601",
                        "user": "JacobCoffee",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-08-13T16:45:04Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2442#issuecomment-2286684215"
                    },
                    {
                        "body": "Any news on this? Migrating from FASTAPI where i use Auth0. But am stuck getting it to work in litestar.\r\n\r\n```python\r\n# app/auth/routes.py\r\n\r\nfrom urllib.parse import quote_plus, urlencode, urljoin\r\n\r\nfrom authlib.integrations.starlette_client import OAuth\r\nfrom fastapi import APIRouter, Request\r\nfrom fastapi.responses import RedirectResponse\r\n\r\nfrom app.config import settings\r\n\r\nrouter = APIRouter()\r\n\r\noauth = OAuth()\r\noauth.register(\r\n    \"auth0\",\r\n    client_id=settings.auth0_client_id,\r\n    client_secret=settings.auth0_client_secret,  # Ensure you import the secret\r\n    client_kwargs={\r\n        \"scope\": \"openid profile email\",\r\n    },\r\n    server_metadata_url=f\"https://{settings.auth0_domain}/.well-known/openid-configuration\",\r\n)\r\n\r\n\r\n@router.get(\"/callback\")\r\nasync def callback(request: Request):\r\n    token = await oauth.auth0.authorize_access_token(request)\r\n\r\n    request.session[\"user\"] = token\r\n    return RedirectResponse(url=\"/\")\r\n\r\n\r\n@router.get(\"/login\")\r\nasync def login(request: Request):\r\n    redirect_uri = request.url_for(\"callback\")\r\n    return await oauth.auth0.authorize_redirect(request, redirect_uri)\r\n\r\n\r\n@router.get(\"/logout\")\r\nasync def logout(request: Request):\r\n    request.session.clear()\r\n    return_to_url = urljoin(str(request.base_url), \"/\")\r\n    logout_url = f\"https://{settings.auth0_domain}/v2/logout?\" + urlencode(\r\n        {\r\n            \"returnTo\": return_to_url,\r\n            \"client_id\": settings.auth0_client_id,\r\n        },\r\n        quote_via=quote_plus,\r\n    )\r\n    return RedirectResponse(logout_url)\r\n```",
                        "user": "Yacobolo",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-08-24T21:18:34Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2442#issuecomment-2308541421"
                    },
                    {
                        "body": "> Any news on this? Migrating from FASTAPI where i use Auth0. But am stuck getting it to work in litestar.\r\n\r\nThe issue seems to be that you're using the `authlib` Starlette integration, so you should probably ask this question over at *authlib* regarding plans for a Litestar integration. There's not much we can do here.\r\n\r\nThat being said, Auth0 has an [SDK for Python](https://auth0-python.readthedocs.io/en/latest/), that you should be able to easily integrate into your Litestar application. You'd simply have to replace the authlib API shown in your example with the equivalent Auth0 SDK functionality :)\r\n",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-08-25T08:23:06Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2442#issuecomment-2308729442"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2368",
                "title": "Bug: using Any return type on before_request handler throws an error on schema",
                "labels": [
                    "Bug :bug:",
                    "Great MCVE"
                ],
                "user": "rseeley",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2368,
                "id": 1913978174,
                "state": "closed",
                "project_created_at": "2023-09-26T17:29:45Z",
                "closed_at": "2023-09-30T17:37:52Z",
                "body": "### Description\n\nUsing `Any` as a return type for a `before_request` handler throws an error when accessing the schema pages/openapi.json endpoints. Looking at the documentation, it should return some value or `None`, and using one or both of those as a return type is successful. The API itself runs just fine with an invalid return type, and this only seems to affect the schema routes.\r\n\r\nIt seems like maybe this is expected behavior so that you are forced to set a proper return type, but maybe a more extensive error message pointing to the location of the issue could be added? The current error I get is `litestar.exceptions.http_exceptions.ImproperlyConfiguredException: 500: Unable to serialize response content`, which took a while to figure out what caused it.\n\n### URL to code causing the issue\n\nhttps://github.com/rseeley/litestar-before-request-error-mvce/blob/main/app.py\n\n### MCVE\n\n_No response_\n\n### Steps to reproduce\n\n```bash\n1. Follow the steps in the README section titled \"Install litestar\"\r\n2. Access the schema at http://127.0.0.1:8000/schema or http://127.0.0.1:8000/schema/openapi.json\n```\n\n\n### Screenshots\n\n_No response_\n\n### Logs\n\n_No response_\n\n### Litestar Version\n\n2.1.1\n\n### Platform\n\n- [ ] Linux\n- [X] Mac\n- [ ] Windows\n- [ ] Other (Please specify in the description above)\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n\n## Funding\n* If you would like to see an issue prioritized, make a pledge towards it!\n* We receive the pledge once the issue is completed & verified\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2368\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2368/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2368/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [
                    {
                        "body": "Thanks for the great MCVE!\r\n\r\nWhat's happening here is Litestar alters the return type of the handler based on the return type of the hook if it's not `None` or ` | None`. Since the hook returns an `ASGIResponse` if you don't return anything, and we default to encode with JSON, Litestar will then attempt to encode the `ASGIResponse` as JSON.\r\n\r\nI'm not entirely sure *why* we alter the return type like this, @peterschutt do you have any insight there? I removed the code in question and it didn't seem to break anything, so I'm not even sure this is actually intentional.\r\n\r\nIn any case, I don't think we *should* be doing this, since it's extremely unexpected and I can't think of a good reason why this would be the desired behaviour. The return type of the handler should be the source of truth in any case, and it's the user's responsibility to return an appropriate type from any hooks that might be in the pipeline.",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-30T10:47:59Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2368#issuecomment-1741738740"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2314",
                "title": "Bug: Guards should not be executed for `OPTIONS` requests",
                "labels": [
                    "Bug :bug:",
                    "Security"
                ],
                "user": "v3ss0n",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2314,
                "id": 1900867425,
                "state": "closed",
                "project_created_at": "2023-09-18T12:49:57Z",
                "closed_at": "2024-03-29T16:44:50Z",
                "body": "### Description\r\n\r\nWhen guards are applied at Controller level , it is blocking the OPTIONS requests and causing error when accessing users on the guards.\r\n\r\n```py\r\n\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/connection/base.py\", line 228, in user\r\n    raise ImproperlyConfiguredException(\"'user' is not defined in scope, install an AuthMiddleware to set it\")\r\nlitestar.exceptions.http_exceptions.ImproperlyConfiguredException: 500: 'user' is not defined in scope, install an AuthMiddleware to set it\r\n\r\n```\r\n\r\n### URL to code causing the issue\r\n\r\nhttps://github.com/litestar-org/litestar-fullstack\r\n\r\n### MCVE\r\n\r\n```python\r\nTo be included\r\n```\r\n\r\n\r\n### Steps to reproduce\r\n\r\n```bash\r\ncurl 'http://0.0.0.0:9000/api/tags' \\    \r\n  -X 'OPTIONS' \\\r\n  -H 'Accept: */*' \\\r\n  -H 'Accept-Language: en-US,en;q=0.9' \\\r\n  -H 'Access-Control-Request-Headers: authorization,content-type' \\\r\n  -H 'Access-Control-Request-Method: POST' \\\r\n  -H 'Connection: keep-alive' \\\r\n  -H 'Origin: http://localhost:8000' \\\r\n  -H 'Referer: http://localhost:8000/' \\\r\n  -H 'Sec-Fetch-Mode: cors' \\\r\n```\r\n\r\n\r\n### Screenshots\r\n\r\n```bash\r\n\"![SCREENSHOT_DESCRIPTION](SCREENSHOT_LINK.png)\"\r\n```\r\n\r\n\r\n### Logs\r\n\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/middleware/exceptions/middleware.py\", line 191, in __call__\r\n    await self.app(scope, receive, send)\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 77, in handle\r\n    await route_handler.authorize_connection(connection=request)\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/handlers/base.py\", line 481, in authorize_connection\r\n    await guard(connection, copy(self))  # type: ignore\r\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/utils/sync.py\", line 65, in __call__\r\n    return await self.ref.value(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/utils/sync.py\", line 101, in wrapper\r\n    return await run_sync(applied_kwarg, *args)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\r\n    return await get_async_backend().run_sync_in_worker_thread(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2106, in run_sync_in_worker_thread\r\n    return await future\r\n           ^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 833, in run\r\n    result = context.run(func, *args)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/src/app/domain/accounts/guards.py\", line 27, in requires_active_user\r\n    if connection.user.is_active:\r\n       ^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/connection/base.py\", line 228, in user\r\n    raise ImproperlyConfiguredException(\"'user' is not defined in scope, install an AuthMiddleware to set it\")\r\nlitestar.exceptions.http_exceptions.ImproperlyConfiguredException: 500: 'user' is not defined in scope, install an AuthMiddleware to set it\r\n\r\n```\r\n\r\n\r\n### Litestar Version\r\n\r\n2.0.1\r\n\r\n### Platform\r\n\r\n- [X] Linux\r\n- [X] Mac\r\n- [X] Windows\r\n- [X] Other (Please specify in the description above)\r\n",
                "comments": [
                    {
                        "body": "@v3ss0n Does the updated title better reflect the issue?  From your error, it looks like the guard is executing when you send in an `OPTIONS` request and it should not?",
                        "user": "cofin",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-18T18:08:42Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1724126407"
                    },
                    {
                        "body": "Sorry for late reply , after raising this issue i got sick due to food poison . @guacs  already fixed it and i am marking it as closed. \r\n\r\nI am thinking if it is fit better with your title because it happens on Controller and APP level.  What if we apply directly to `options` decorator  ?  ( should not do that but for whatever reason , if someone want to do?) should this still execute?",
                        "user": "v3ss0n",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-26T11:29:58Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1735349069"
                    },
                    {
                        "body": "> Sorry for late reply , after raising this issue i got sick due to food poison . @guacs already fixed it and i am marking it as closed.\r\n> \r\n> I am thinking if it is fit better with your title because it happens on Controller and APP level. What if we apply directly to `options` decorator ? ( should not do that but for whatever reason , if someone want to do?) should this still execute?\r\n\r\nThe fix that was made in #2325 does **NOT** fix this issue by preventing guards from called for OPTIONS requests. It only prevents the middleware from being executed for OPTIONS requests by default. \r\n\r\nThere was already a mechanism for avoiding calling the middleware based on the HTTP method, but there is not an in-built mechanism for guards as of now. ",
                        "user": "guacs",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-26T13:18:36Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1735527776"
                    },
                    {
                        "body": "My workaround for now.\r\n\r\n```python\r\nasync def example_guard(connection: ASGIConnection, _: BaseRouteHandler) -> None:\r\n    if connection.scope.get(\"method\") == \"OPTIONS\":\r\n        return\r\n\r\n    # guard logic\r\n```",
                        "user": "bwalendz",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-27T16:01:55Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1737683131"
                    },
                    {
                        "body": "> My workaround for now.\r\n> \r\n> ```python\r\n> async def example_guard(connection: ASGIConnection, _: BaseRouteHandler) -> None:\r\n>     if connection.scope.get(\"method\") == \"OPTIONS\":\r\n>         return\r\n> \r\n>     # guard logic\r\n> ```\r\n\r\nis that for 2.1 ? I think 2.1 should  be fine for that now.",
                        "user": "v3ss0n",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-27T17:23:28Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1737801628"
                    },
                    {
                        "body": "> > My workaround for now.\r\n> > ```python\r\n> > async def example_guard(connection: ASGIConnection, _: BaseRouteHandler) -> None:\r\n> >     if connection.scope.get(\"method\") == \"OPTIONS\":\r\n> >         return\r\n> > \r\n> >     # guard logic\r\n> > ```\r\n> \r\n> is that for 2.1 ? I think 21 should be fine for that now.\r\n\r\nJust updated to 2.1.1final0 and still behaves the same, the preflight OPTIONS is still being passed to the guard. I think it's similar to what @guacs is describing.\r\n\r\n",
                        "user": "bwalendz",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-27T18:18:30Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1737871449"
                    },
                    {
                        "body": "> > > My workaround for now.\r\n> > > ```python\r\n> > > async def example_guard(connection: ASGIConnection, _: BaseRouteHandler) -> None:\r\n> > >     if connection.scope.get(\"method\") == \"OPTIONS\":\r\n> > >         return\r\n> > > \r\n> > >     # guard logic\r\n> > > ```\r\n> > \r\n> > \r\n> > is that for 2.1 ? I think 21 should be fine for that now.\r\n> \r\n> Just updated to 2.1.1final0 and still behaves the same, the preflight OPTIONS is still being passed to the guard. I think it's similar to what @guacs is describing.\r\n\r\nYeah, that behavior should still be there since it hasn't been fixed yet :P",
                        "user": "guacs",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-28T00:16:56Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1738269729"
                    },
                    {
                        "body": "This problem still exist  , i had tried with 2.3.1 . \r\nWhat should be the best way to fix this. ",
                        "user": "v3ss0n",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-11-06T09:44:40Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1794435764"
                    },
                    {
                        "body": "Just encountered this one today on the latest version 2.3.2",
                        "user": "Kumzy",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-11-26T13:21:18Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1826783313"
                    },
                    {
                        "body": "It would be easy enough to bypass calling guards for OPTIONS requests - my question is, should it only apply to the options handlers that we generate, or should it be a blanket rule for all OPTIONS method handlers, or be configurable in some manner?",
                        "user": "peterschutt",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-11-27T05:15:42Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1827138101"
                    },
                    {
                        "body": "> It would be easy enough to bypass calling guards for OPTIONS requests - my question is, should it only apply to the options handlers that we generate, or should it be a blanket rule for all OPTIONS method handlers, or be configurable in some manner?\r\n\r\nI think the ideal would be that the guard should only apply to what was defined in the controller/action. So the controller guard should only be applied to `GET /home` and `POST /profile`.\r\n\r\n```python\r\nclass Site(Controller):\r\n   guards = [permission_guard]\r\n\r\n   @get(path=\"/home\")\r\n   async def home(self) -> None:\r\n      pass\r\n\r\n   @post(path=\"/profile\")\r\n   async def profile(self) -> None:\r\n      pass\r\n```\r\n\r\nThe action guard should only apply to its respective action method handled, `GET` or `POST`.\r\n\r\n```python\r\nclass Site(Controller):\r\n   @get(\r\n      path=\"/home\",\r\n      guards=[permission_guard],\r\n   )\r\n   async def home(self) -> None:\r\n      pass\r\n\r\n   @post(\r\n      path=\"/profile\",\r\n      guards=[role_guard],\r\n   )\r\n   async def profile(self) -> None:\r\n      pass\r\n```\r\n\r\n",
                        "user": "bwalendz",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-01-24T22:08:52Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1908995865"
                    },
                    {
                        "body": "> > It would be easy enough to bypass calling guards for OPTIONS requests - my question is, should it only apply to the options handlers that we generate, or should it be a blanket rule for all OPTIONS method handlers, or be configurable in some manner?\r\n> \r\n> I think the ideal would be that the guard should only apply to what was defined in the controller/action. So the controller guard should only be applied to `GET /home` and `POST /profile`.\r\n\r\n\r\nShould we try to handle if an options handler is manually created?\r\n\r\n```py\r\nclass Site(Controller):\r\n   guards = [permission_guard]\r\n\r\n   @get(path=\"/home\")\r\n   async def home(self) -> None:\r\n      pass\r\n\r\n    @route(path=\"/home\", http_method=\"OPTIONS\")\r\n    async def home_options_handler(self) -> Response[str | None]:\r\n        ...\r\n```",
                        "user": "peterschutt",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-01-27T10:03:00Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1913102779"
                    },
                    {
                        "body": "My issue with excluding generated `OPTION` handlers by default is: What if you *want* to include guards for them? IMO all security related things should be strict by default and have an option to make it lax. Having a handler automagically generated circumvents your auth without any way to interfere or possibly even know that this is happening sounds like a potential security nightmare to me and not a good user experience.\r\n\r\nThe workaround presented in [this comment](https://github.com/litestar-org/litestar/issues/2314#issuecomment-1737683131) is the ideal way to handle this IMO; It requires you to explicitly exclude something from the authentication.\r\n",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-01-27T10:16:30Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1913106224"
                    },
                    {
                        "body": "> My issue with excluding generated `OPTION` handlers by default is: What if you _want_ to include guards for them? IMO all security related things should be strict by default and have an option to make it lax. Having a handler automagically generated circumvents your auth without any way to interfere or possibly even know that this is happening sounds like a potential security nightmare to me and not a good user experience.\r\n> \r\n> The workaround presented in [this comment](https://github.com/litestar-org/litestar/issues/2314#issuecomment-1737683131) is the ideal way to handle this IMO; It requires you to explicitly exclude something from the authentication.\r\n\r\nThe main point of my example is i am not explicitly handling OPTIONS requests but the guard is being applied. Preflight OPTIONS are a special case as well because they're forced by the browser for CORS.\r\n\r\nMost other frameworks, through middleware or whatever, will swallow the preflight OPTIONS requests so they don't even make it to your controller because this is the most common use case. So that is another approach instead of needing to workaround every guard that exists.",
                        "user": "bwalendz",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-01T21:40:56Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1922294993"
                    },
                    {
                        "body": "> > My issue with excluding generated `OPTION` handlers by default is: What if you _want_ to include guards for them? IMO all security related things should be strict by default and have an option to make it lax. Having a handler automagically generated circumvents your auth without any way to interfere or possibly even know that this is happening sounds like a potential security nightmare to me and not a good user experience.\r\n> > The workaround presented in [this comment](https://github.com/litestar-org/litestar/issues/2314#issuecomment-1737683131) is the ideal way to handle this IMO; It requires you to explicitly exclude something from the authentication.\r\n> \r\n> The main point of my example is i am not explicitly handling OPTIONS requests but the guard is being applied. Preflight OPTIONS are a special case as well because they're forced by the browser for CORS.\r\n> \r\n> Most other frameworks, through middleware or whatever, will swallow the preflight OPTIONS requests so they don't even make it to your controller because this is the most common use case. So that is another approach instead of needing to workaround every guard that exists.\r\n\r\nI agree with this as well. `OPTIONS` is a special case which means we should have special handling of `OPTIONS` requests as well. I think we should make it configurable somehow, though I'm not sure how easy that would be to implement. This way, the user should be able to specify whether to apply the guards for the automatically created `OPTIONS` handler as well as a way to specify the same for manually created `OPTIONS` handler as well.",
                        "user": "guacs",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-05T05:50:21Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-1926276952"
                    },
                    {
                        "body": "We have faced the exact same issue with guards. Took us couple of hours to troubleshoot. If we are not fixing it at least can we all agree to document it?",
                        "user": "HorusTheSonOfOsiris",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-03-19T20:15:16Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-2008051689"
                    },
                    {
                        "body": "@jayantraizada thanks for reminding me to document this! I've added this to the docs and linked to this issue in #3230.",
                        "user": "guacs",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-03-22T16:42:02Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-2015483976"
                    },
                    {
                        "body": "In any case, I don't think this is a bug, since the current behaviour works as intended, and is now also explicitly documented. Closing for now. We might revisit the autogenerated OPTIONS handler behaviour in the future.",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-03-29T16:44:50Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2314#issuecomment-2027472552"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2305",
                "title": "Docs: error in AbstractAuthenticationMiddleware example",
                "labels": [
                    "Documentation :books:",
                    "Security"
                ],
                "user": "rimai4",
                "issue_author_association": "NONE",
                "number": 2305,
                "id": 1898071330,
                "state": "open",
                "project_created_at": "2023-09-15T09:38:46Z",
                "closed_at": null,
                "body": "### Summary\n\nIn the JWTAuthenticationMiddleware example, the following line gives an error:\r\n\r\n`engine = cast(\"AsyncEngine\", connection.app.state.postgres_connection)`\r\n\r\ncalling keys() on `connection.app.state` gives the following result:\r\n`['db_engine', 'session_maker_class']`\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n\n## Funding\n* If you would like to see an issue prioritized, make a pledge towards it!\n* We receive the pledge once the issue is completed & verified\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2305\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2305/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2305/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [
                    {
                        "body": "I think this entire section needs rewriting. The examples are not even moved to the `examples/` dir.",
                        "user": "geeshta",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-15T12:26:04Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2305#issuecomment-1721192490"
                    },
                    {
                        "body": "> I think this entire section needs rewriting. The examples are not even moved to the `examples/` dir.\r\n\r\nAgreed. If any of you guys want to work on that let me know and I'll assign you (=",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-15T12:36:06Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2305#issuecomment-1721207487"
                    },
                    {
                        "body": "@provinzkraut I'll give it a shot.",
                        "user": "geeshta",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-15T12:44:10Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2305#issuecomment-1721218688"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2288",
                "title": "Bug: serializer not working with misleading message ",
                "labels": [
                    "Bug :bug:",
                    "Needs MCVE"
                ],
                "user": "0xSwego",
                "issue_author_association": "NONE",
                "number": 2288,
                "id": 1887590461,
                "state": "closed",
                "project_created_at": "2023-09-08T12:27:59Z",
                "closed_at": "2023-10-01T01:19:53Z",
                "body": "### Description\r\n\r\nI had some problems with a serializer not working, and displaying an error message I couldn't decipher.\r\n\r\nThe issue was a SQLAlchemy relationship that was defined using a string type instead of the type itself:\r\n`conditions: Mapped[list[\"AlertTemplateCondition\"]] = relationship(back_populates=\"alert_template\")`\r\n\r\nWhen I was trying to serialize this object and its children, this error was raised:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/0xSwego/projects/litestar-backend-template/.venv/lib/python3.10/site-packages/litestar/serialization/msgspec_hooks.py\", line 141, in encode_json\r\n    return msgspec.json.encode(value, enc_hook=serializer) if serializer else _msgspec_json_encoder.encode(value)\r\n  File \"/home/0xSwego/projects/litestar-backend-template/.venv/lib/python3.10/site-packages/litestar/serialization/msgspec_hooks.py\", line 88, in default_serializer\r\n    raise TypeError(f\"Unsupported type: {type(value)!r}\")\r\nTypeError: Unsupported type: <class 'app.domain.alerts.models.AlertTemplateCondition'>\r\n```\r\n\r\nRemoving the quotes from the type fixed the issue:\r\n`conditions: Mapped[list[AlertTemplateCondition]] = relationship(back_populates=\"alert_template\")`\r\n\r\nIt'd be great if the right serializer was found even if the type is written in quotes.\r\n\r\n### URL to code causing the issue\r\n\r\n_No response_\r\n\r\n### MCVE\r\n\r\nModels:\r\n\r\n```py\r\nclass AlertTemplate(orm.DatabaseModel):\r\n    __tablename__ = \"alert_templates\"  # type: ignore[assignment]\r\n    \r\n    conditions: Mapped[list[\"AlertTemplateCondition\"]] = relationship(back_populates=\"alert_template\")\r\n\r\nclass AlertTemplateCondition(orm.DatabaseModel, orm.AuditColumns):\r\n    __tablename__ = \"alert_template_conditions\"  # type: ignore[assignment]\r\n\r\n    alert_template_id: Mapped[UUID] = mapped_column(ForeignKey(\"alert_templates.id\"))\r\n    alert_template: Mapped[AlertTemplate] = relationship()\r\n```\r\n\r\nDTOs:\r\n```py\r\nclass AlertTemplateDTO(SQLAlchemyDTO[AlertTemplate]):\r\n    config = dto.config(max_nested_depth=1)\r\n\r\nclass AlertTemplateConditionDTO(SQLAlchemyDTO[AlertTemplateCondition]):\r\n    config = dto.config(max_nested_depth=0)\r\n```\r\n\r\nController:\r\n```py\r\nclass AlertTemplatesController(Controller):\r\n    \"\"\"Handles the interactions within the AlertTemplate objects.\"\"\"\r\n\r\n    dependencies = {\"alert_template_service\": provide_alert_template_service}\r\n    return_dto = AlertTemplateDTO\r\n\r\n    @get(\r\n        operation_id=\"ListAlertTemplates\",\r\n        name=\"alert_templates:list\",\r\n        summary=\"List Alert Templates\",\r\n        path=urls.ALERT_TEMPLATES_LIST,\r\n    )\r\n    async def list_alert_templates(\r\n        self,\r\n        alert_template_service: AlertTemplateService,\r\n    ) -> OffsetPagination[AlertTemplate]:\r\n        \"\"\"List all alert templates\"\"\"\r\n        results = await alert_template_service.list()\r\n        return alert_template_service.to_dto(results)\r\n```\r\n\r\n### Litestar Version\r\n\r\n2.0.1\r\n\r\n### Platform\r\n\r\n- [X] Linux\r\n- [ ] Mac\r\n- [X] Windows\r\n- [ ] Other (Please specify in the description above)\r\n\r\n<!-- POLAR PLEDGE BADGE START -->\r\n---\r\n\r\n## Funding\r\n* If you would like to see an issue prioritized, make a pledge towards it!\r\n* We receive the pledge once the issue is completed & verified\r\n\r\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2288\">\r\n<picture>\r\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2288/pledge.svg?darkmode=1\">\r\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2288/pledge.svg\">\r\n</picture>\r\n</a>\r\n<!-- POLAR PLEDGE BADGE END -->\r\n",
                "comments": [
                    {
                        "body": "Could you provide a minimal reproduction of the bug?",
                        "user": "guacs",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-08T13:11:18Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2288#issuecomment-1711649522"
                    },
                    {
                        "body": "@guacs sure! I have taken the litestar-fullstack repo and added the code that is causing the problem:\r\nhttps://github.com/0xSwego/litestar-fullstack/tree/master\r\n\r\nI've also added a test that fails due to the error. Running `pytest tests/integration/test_alerts.py` will trigger it",
                        "user": "0xSwego",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-08T13:55:47Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2288#issuecomment-1711714930"
                    },
                    {
                        "body": "@0xSwego I'm having some trouble reproducing this. Could you provide a minimal example with a minimal self-contained application (not the litestar-fullstack one)?",
                        "user": "guacs",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-11T15:13:21Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2288#issuecomment-1714091158"
                    },
                    {
                        "body": "@0xSwego any updates on this?",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-17T08:20:54Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2288#issuecomment-1722422762"
                    },
                    {
                        "body": "@guacs I wouldn't know where to start from and it would take me a huge amount of time. If the issue cannot be reproduced because you have troubles with the code, I can close it.",
                        "user": "0xSwego",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-18T11:43:18Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2288#issuecomment-1723239692"
                    },
                    {
                        "body": "> @guacs I wouldn't know where to start from and it would take me a huge amount of time. If the issue cannot be reproduced because you have troubles with the code, I can close it.\r\n\r\nLet me try once more to reproduce this. If I'm not able to, then we can close it.",
                        "user": "guacs",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-18T12:57:24Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2288#issuecomment-1723354286"
                    },
                    {
                        "body": "@guacs you should be able to set up the whole project with the `make install` command (Unix friendly, unfortunately. I am on Windows and use WSL)",
                        "user": "0xSwego",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-09-18T13:14:46Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2288#issuecomment-1723387085"
                    },
                    {
                        "body": "@guacs any updates?",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-09-30T10:55:22Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2288#issuecomment-1741739814"
                    },
                    {
                        "body": "I'm closing this since I haven't been able to create an MCVE for this. If anyone faces this issue and can provide an MCVE, please feel free to reopen the issue.",
                        "user": "guacs",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-10-01T01:19:53Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2288#issuecomment-1741913400"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2118",
                "title": "Enhancement: Revoke jwt token",
                "labels": [
                    "Enhancement",
                    "Help Wanted :sos:",
                    "Good First Issue",
                    "Security"
                ],
                "user": "julio-34727",
                "issue_author_association": "NONE",
                "number": 2118,
                "id": 1836425637,
                "state": "open",
                "project_created_at": "2023-08-04T09:48:10Z",
                "closed_at": null,
                "body": "### Summary\n\nProvide a mechanism to revoke a jwt token on /logout similar to `flask-jwt-extended` (https://flask-jwt-extended.readthedocs.io/en/stable/blocklist_and_token_revoking.html).\n\n### Basic Example\n\n_No response_\n\n### Drawbacks and Impact\n\n_No response_\n\n### Unresolved questions\n\n_No response_\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n\n## Funding\n* If you would like to see an issue prioritized, make a pledge towards it!\n* We receive the pledge once the issue is completed & verified\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2118\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2118/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2118/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [
                    {
                        "body": "I would like to work on this but i'm not sure whats being asked. it doesn't seem like the example specified in the url: (https://flask-jwt-extended.readthedocs.io/en/stable/blocklist_and_token_revoking.html) does anything in particular to revoke the token for you. ",
                        "user": "andrewdoh",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-12-22T05:52:05Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2118#issuecomment-1867271755"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2071",
                "title": "Enhancement: integration with external OAuth2 provider.",
                "labels": [
                    "Enhancement",
                    "Help Wanted :sos:",
                    "polar",
                    "Security"
                ],
                "user": "cofin",
                "issue_author_association": "MEMBER",
                "number": 2071,
                "id": 1822979798,
                "state": "open",
                "project_created_at": "2023-07-26T18:55:30Z",
                "closed_at": null,
                "body": "### Summary\n\nIt would be great to have an integration with a third party library or have built in support for authenticating with OAuth2 providers such as Google or Github.\r\n\n\n### Basic Example\n\n_No response_\n\n### Drawbacks and Impact\n\n_No response_\n\n### Unresolved questions\n\n_No response_\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n\n## Funding\n* If you would like to see an issue prioritized, make a pledge towards it!\n* We receive the pledge once the issue is completed & verified\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2071\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2071/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2071/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [
                    {
                        "body": "This could/would be accomplished by developing an internal plugin via https://docs.litestar.dev/latest/usage/plugins.html#plugins.\r\n\r\nSome examples of others: \r\n- https://github.com/litestar-org/litestar/pull/3145#issuecomment-1966921258\r\n- https://github.com/cofin/litestar-granian\r\n- https://github.com/guacs/litestar-svcs",
                        "user": "JacobCoffee",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-28T00:42:56Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2071#issuecomment-1967977746"
                    },
                    {
                        "body": "I think we could develop a plugin for this, but imo it should be maintained as a seperate library (officially maintained by Litestar). Most likely we want to use something like [authlib](https://github.com/lepture/authlib/) to implement this and if this is kept separate, then users would only have to install it if they need it.",
                        "user": "guacs",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-28T00:48:08Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2071#issuecomment-1967982803"
                    },
                    {
                        "body": "By \"external OAuth2 provider\", do you mean a Python library or a separate OAuth2 provider? Because [Keycloak](https://github.com/keycloak/keycloak) is a no-brainer despite being written in Java.\r\n\r\nThere's also [python-social-auth](https://github.com/python-social-auth/social-core/blob/master/social_core/backends/github.py), which is used by [Zulip](https://github.com/zulip/zulip/blob/22bd8048b118f93758d2b0afd76acfc89eeeb3d9/zproject/backends.py#L2072) and [Sentry](https://github.com/getsentry/sentry/blob/f30cabd30a08718e26bee96a25e75e2b4ecc8b23/src/social_auth/backends/github.py#L35).\r\n\r\nHowever, it's worth noting that both projects seem to have integrated that library's source code into their own repository. Hence, their \"forks\" are maintained independently, which impacts [the library's health and integrity](https://github.com/python-social-auth/social-core/issues/445).\r\n\r\n",
                        "user": "codespearhead",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-03-13T02:01:57Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2071#issuecomment-1993107365"
                    },
                    {
                        "body": "I think at this stage, we have \"native\" support in the library and all we need to do OAuth2 connections as a client to any server.\r\n\r\nI'm not sure what we want here, but maybe some nice abstraction with some built-in common providers as a plugin that users can opt-in to?\r\n\r\n@litestar-org/maintainers ?",
                        "user": "JacobCoffee",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-03-13T03:14:06Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2071#issuecomment-1993285825"
                    },
                    {
                        "body": "Makes sense, because keeping the OAuth client and the OAuth provider in the same package is risky imo, given how much of a burden maintaining the latter actually is.\n\nFor reference: [Laravel Socialite](https://github.com/laravel/socialite) is an OAuth client with a few official adapters, whereas other adapters are [maintained by the community](https://github.com/SocialiteProviders/Providers/tree/master/src).",
                        "user": "codespearhead",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-03-13T03:22:16Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2071#issuecomment-1993305418"
                    },
                    {
                        "body": "In the Django world there is the kind of de-facto standard https://github.com/pennersr/django-allauth. Could be interesting to have a look at its implementation. Enabling authentication using regular accounts (user name + email + password or one time code) in addition to social accounts (GitHub, ) would be great. This would require to provide email service provider integration https://github.com/litestar-org/litestar/issues/3520 to enable email transmission based workflows for regular accounts (email verification email, password change email, ).",
                        "user": "fkromer",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-05-24T22:58:20Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2071#issuecomment-2130487187"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/2020",
                "title": "Bug: TypeError: parse_url_encoded_dict() got some positional-only arguments passed as keyword arguments: 'qs' and 'parse_numbers'",
                "labels": [
                    "Bug :bug:",
                    "Upstream",
                    "Great MCVE"
                ],
                "user": "euri10",
                "issue_author_association": "CONTRIBUTOR",
                "number": 2020,
                "id": 1813835813,
                "state": "closed",
                "project_created_at": "2023-07-20T12:00:46Z",
                "closed_at": "2023-07-20T13:34:48Z",
                "body": "### Description\r\n\r\nNew litestar install\r\n```\r\n poetry add git+https://github.com/litestar-org/litestar.git\r\n\r\nUpdating dependencies\r\nResolving dependencies... (1.2s)\r\n\r\nPackage operations: 7 installs, 0 updates, 0 removals\r\n\r\n   Installing python-dateutil (2.8.2)\r\n   Installing faker (19.1.0)\r\n   Installing fast-query-parsers (1.0.1)\r\n   Installing msgspec (0.17.0)\r\n   Installing multidict (6.0.4)\r\n   Installing polyfactory (2.6.2)\r\n   Installing litestar (2.0.0beta2 dc8790e)\r\n```\r\nleads to this error filling the form below:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/middleware/exceptions/middleware.py\", line 157, in __call__\r\n    await self.app(scope, receive, send)\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/routes/http.py\", line 77, in handle\r\n    response = await self._get_response_for_request(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/routes/http.py\", line 129, in _get_response_for_request\r\n    response = await self._call_handler_function(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/routes/http.py\", line 158, in _call_handler_function\r\n    response_data, cleanup_group = await self._get_response_data(\r\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/routes/http.py\", line 182, in _get_response_data\r\n    kwargs[\"data\"] = await kwargs[\"data\"]\r\n                     ^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/_kwargs/extractors.py\", line 363, in extract_url_encoded_extractor\r\n    else parse_url_encoded_form_data(await connection.body())\r\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/_parsers.py\", line 24, in parse_url_encoded_form_data\r\n    return parse_url_encoded_dict(qs=encoded_data, parse_numbers=False)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nTypeError: parse_url_encoded_dict() got some positional-only arguments passed as keyword arguments: 'qs' and 'parse_numbers'\r\nTraceback (most recent call last):\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/middleware/exceptions/middleware.py\", line 157, in __call__\r\n    await self.app(scope, receive, send)\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/routes/http.py\", line 77, in handle\r\n    response = await self._get_response_for_request(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/routes/http.py\", line 129, in _get_response_for_request\r\n    response = await self._call_handler_function(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/routes/http.py\", line 158, in _call_handler_function\r\n    response_data, cleanup_group = await self._get_response_data(\r\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/routes/http.py\", line 182, in _get_response_data\r\n    kwargs[\"data\"] = await kwargs[\"data\"]\r\n                     ^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/_kwargs/extractors.py\", line 363, in extract_url_encoded_extractor\r\n    else parse_url_encoded_form_data(await connection.body())\r\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/lotso/.cache/pypoetry/virtualenvs/abdul-5gvWwsxX-py3.11/lib/python3.11/site-packages/litestar/_parsers.py\", line 24, in parse_url_encoded_form_data\r\n    return parse_url_encoded_dict(qs=encoded_data, parse_numbers=False)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nTypeError: parse_url_encoded_dict() got some positional-only arguments passed as keyword arguments: 'qs' and 'parse_numbers'\r\nINFO:     127.0.0.1:51104 - \"POST /auth/login HTTP/1.1\" 500 Internal Server Error\r\n```\r\n\r\n### URL to code causing the issue\r\n\r\n_No response_\r\n\r\n### MCVE\r\n\r\n```python\r\n@dataclass\r\nclass LoginFormData:\r\n    username: str\r\n    password: str\r\n    captcha: str\r\n\r\n\r\n@post(\"/login\", name=\"login_post\")\r\nasync def login_post(\r\n    request: Request,\r\n    conn: BuildPgConnection,\r\n    app_settings: AppSettings,\r\n    data: Annotated[LoginFormData, Body(media_type=RequestEncodingType.URL_ENCODED)],\r\n) -> Template:\r\n    try:\r\n```\r\n\r\n\r\n### Steps to reproduce\r\n\r\n```bash\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n```\r\n\r\n\r\n### Screenshots\r\n\r\n```bash\r\n\"![SCREENSHOT_DESCRIPTION](SCREENSHOT_LINK.png)\"\r\n```\r\n\r\n\r\n### Logs\r\n\r\n_No response_\r\n\r\n### Litestar Version\r\n\r\n   Installing litestar (2.0.0beta2 dc8790e)\r\n\r\n\r\n### Platform\r\n\r\n- [X] Linux\r\n- [ ] Mac\r\n- [ ] Windows\r\n- [ ] Other (Please specify in the description above)\r\n\r\n<!-- POLAR PLEDGE BADGE START -->\r\n## Funding\r\n* If you would like to see an issue prioritized, make a pledge towards it!\r\n* We receive the pledge once the issue is completed & verified\r\n\r\n<a href=\"https://polar.sh/litestar-org/litestar/issues/2020\">\r\n<picture>\r\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/2020/pledge.svg?darkmode=1\">\r\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/2020/pledge.svg\">\r\n</picture>\r\n</a>\r\n<!-- POLAR PLEDGE BADGE END -->\r\n",
                "comments": [
                    {
                        "body": "I believe this is related to a recent change in `fast-query-parsers`. @Goldziher?\r\n\r\nNot sure why this hasn't been caught in our tests though.",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-07-20T12:07:36Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2020#issuecomment-1643808008"
                    },
                    {
                        "body": "Hmm yes, seems that maturin is positional only. \n\nCan you remove `parse_numbers=` and keep the args?",
                        "user": "Goldziher",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-07-20T12:17:12Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2020#issuecomment-1643820882"
                    },
                    {
                        "body": "> Hmm yes, seems that maturin is positional only.\r\n\r\nIt does support it. I have a fix read to go for `fast-query-parsers`. PR incoming.",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-07-20T12:18:29Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2020#issuecomment-1643822709"
                    },
                    {
                        "body": "> I believe this is related to a recent change in `fast-query-parsers`. @Goldziher?\r\n> \r\n> Not sure why this hasn't been caught in our tests though.\r\n\r\nI dont know the code well enough but it seems to me that test_kwargs only uses https://github.com/litestar-org/litestar/blob/dc8790e63f0e90f1650042558a9be620bf4b1eae/tests/unit/test_kwargs/__init__.py#L4-L8 so there are no tests on other possible attrs, dataclass forms etc, might be wrong on this again I dont know the source well enough",
                        "user": "euri10",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-07-20T12:31:11Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2020#issuecomment-1643841022"
                    },
                    {
                        "body": "This should resolve it: https://github.com/litestar-org/fast-query-parsers/pull/18 by allowing positional as well as keyword arguments.",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-07-20T12:31:53Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2020#issuecomment-1643842032"
                    },
                    {
                        "body": "> so there are no tests on other possible attrs, dataclass forms etc, might be wrong on this again I dont know the source well enough\r\n\r\nThe issue is at the calling site of `parse_url_encoded_form_data`, which we definitely run during tests. We'll have to investigate that one.\r\n\r\nhttps://github.com/litestar-org/litestar/blob/dc8790e63f0e90f1650042558a9be620bf4b1eae/litestar/_parsers.py#L24",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-07-20T12:34:06Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2020#issuecomment-1643845151"
                    },
                    {
                        "body": "yep, sorry I was referring to https://github.com/litestar-org/litestar/issues/2019 and https://github.com/litestar-org/litestar/issues/1997, wrong topic",
                        "user": "euri10",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-07-20T12:36:59Z",
                        "url": "https://github.com/litestar-org/litestar/issues/2020#issuecomment-1643849242"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/1837",
                "title": "KeyError when configuring DTO",
                "labels": [
                    "Bug :bug:",
                    "Triage Required :hospital:",
                    "Needs MCVE"
                ],
                "user": "jhert0",
                "issue_author_association": "NONE",
                "number": 1837,
                "id": 1761819429,
                "state": "closed",
                "project_created_at": "2023-06-17T12:47:59Z",
                "closed_at": "2023-06-18T02:09:39Z",
                "body": "### Description\r\n\r\nI'm getting a KeyError on startup that seems to be coming from my DTO I create with SQLAlchemyDTO. The property that is being called out in the exception is a relationship. If I try to exclude it from the DTO I still get the error.\r\n\r\n### URL to code causing the issue\r\n\r\n_No response_\r\n\r\n### MCVE\r\n\r\n_No response_\r\n\r\n### Steps to reproduce\r\n\r\n```\r\n1. Create a model for SQLAlchemy that includes a relationship to another model.\r\n2. Create a DTO for the one that has the relationship.\r\n3. Start the app.\r\n```\r\n\r\n\r\n### Screenshots\r\n\r\n_No response_\r\n\r\n### Logs\r\n\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/bin/litestar\", line 8, in <module>\r\n    sys.exit(run_cli())\r\n             ^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/__main__.py\", line 6, in run_cli\r\n    litestar_group()\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/click/core.py\", line 1130, in __call__\r\n    return self.main(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/click/core.py\", line 1055, in main\r\n    rv = self.invoke(ctx)\r\n         ^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/click/core.py\", line 1657, in invoke\r\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/click/core.py\", line 1404, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/click/core.py\", line 760, in invoke\r\n    return __callback(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/click/decorators.py\", line 26, in new_func\r\n    return f(get_current_context(), *args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/cli/_utils.py\", line 231, in wrapped\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/cli/commands/core.py\", line 113, in run_command\r\n    env = cast(LitestarEnv, ctx.obj())\r\n                            ^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/cli/main.py\", line 51, in <lambda>\r\n    ctx.obj = lambda: LitestarEnv.from_env(app_path)\r\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/cli/_utils.py\", line 113, in from_env\r\n    loaded_app = _load_app_from_path(app_path)\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/cli/_utils.py\", line 254, in _load_app_from_path\r\n    module = importlib.import_module(module_path)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<frozen importlib._bootstrap>\", line 1206, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1178, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1149, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"/home/jhert/src/bankroller/services/vault/vault/main.py\", line 24, in <module>\r\n    app = Litestar(\r\n          ^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/app.py\", line 432, in __init__\r\n    self.register(route_handler)\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/app.py\", line 570, in register\r\n    route_handler.on_registration(self)\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/handlers/http_handlers/base.py\", line 482, in on_registration\r\n    super().on_registration(app)\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/handlers/base.py\", line 393, in on_registration\r\n    self._init_handler_dtos()\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/handlers/base.py\", line 372, in _init_handler_dtos\r\n    return_dto.on_registration(HandlerContext(\"return\", str(self), self.parsed_fn_signature.return_type))\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/dto/factory/abc.py\", line 171, in on_registration\r\n    backend = cls._type_backend_map.setdefault(key, backend_type(backend_context))\r\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/dto/factory/_backends/abc.py\", line 124, in __init__\r\n    self.parsed_field_definitions = self.parse_model(context.model_type, context.config.exclude)\r\n                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/dto/factory/_backends/abc.py\", line 162, in parse_model\r\n    for field_definition in self.context.field_definition_generator(model_type):\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/contrib/sqlalchemy/dto.py\", line 195, in generate_field_definitions\r\n    yield from cls.handle_orm_descriptor(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/lib/python3.11/functools.py\", line 946, in _method\r\n    return method.__get__(obj, cls)(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/jhert/.cache/pypoetry/virtualenvs/vault-ePQ6d2du-py3.11/lib/python3.11/site-packages/litestar/contrib/sqlalchemy/dto.py\", line 86, in _\r\n    if (parsed_type := model_type_hints[key]).origin is Mapped:\r\n                       ~~~~~~~~~~~~~~~~^^^^^\r\nKeyError: 'prices'\r\n```\r\n\r\n\r\n### Litestar Version\r\n\r\n2.0.0b1\r\n\r\n### Platform\r\n\r\n- [X] Linux\r\n- [ ] Mac\r\n- [ ] Windows\r\n- [ ] Other (Please specify in the description above)",
                "comments": [
                    {
                        "body": "Hey @jhert0 thanks for reporting this. Can you provide a reproducible example for the behaviour you're describing?",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-06-17T12:56:43Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1837#issuecomment-1595741551"
                    },
                    {
                        "body": "As @provinzkraut suggested, an example that properly reproduces the issue is going to be a big help. Not only for identifying the source of the issue, but also for assessing whether there is some pattern of usage that we need to consider more thoroughly.\r\n\r\nThe `SQLAlchemyDTO` is tested against relationships in these tests:\r\n\r\n- https://github.com/litestar-org/litestar/blob/a1842a000f2f3639bc9d1b0875ae31da050689cd/tests/contrib/sqlalchemy/test_dto.py#L229\r\n- https://github.com/litestar-org/litestar/blob/a1842a000f2f3639bc9d1b0875ae31da050689cd/tests/contrib/sqlalchemy/test_dto.py#L270\r\n- https://github.com/litestar-org/litestar/blob/a1842a000f2f3639bc9d1b0875ae31da050689cd/tests/contrib/sqlalchemy/test_dto.py#L374\r\n- https://github.com/litestar-org/litestar/blob/a1842a000f2f3639bc9d1b0875ae31da050689cd/tests/contrib/sqlalchemy/test_dto.py#L412\r\n- https://github.com/litestar-org/litestar/blob/a1842a000f2f3639bc9d1b0875ae31da050689cd/tests/contrib/sqlalchemy/test_dto.py#L449\r\n\r\nSo perhaps you can look at those as an example of how to build an MCVE for the DTO and help us to determine what is different in your case.\r\n\r\nGiven that the exception originates as a key error from the type hints extracted from the model in this line:\r\n\r\n```\r\n    if (parsed_type := model_type_hints[key]).origin is Mapped:\r\n```\r\n\r\nI'm speculating that the relationship might be declared on the model without a type annotation. E.g.,:\r\n\r\n```py\r\nclass Market(Base):\r\n    prices = relationship(\"Price\")\r\n```\r\n\r\nInstead of something like:\r\n\r\n```py\r\nclass Market(Base):\r\n    prices: Mapped[list[Price]] = relationship()\r\n```\r\n\r\nSpeculation on my part though, so I'll wait to hear from you before going any further.\r\n\r\nCheers.",
                        "user": "peterschutt",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-06-17T22:46:34Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1837#issuecomment-1595878693"
                    },
                    {
                        "body": "Yes that was it, I was missing the type hint. Thank you.",
                        "user": "jhert0",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-06-18T02:09:39Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1837#issuecomment-1595926138"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/1761",
                "title": "DTO : TypeError: 'NoneType' object is not iterable",
                "labels": [
                    "Triage Required :hospital:",
                    "Needs MCVE"
                ],
                "user": "v3ss0n",
                "issue_author_association": "CONTRIBUTOR",
                "number": 1761,
                "id": 1731953007,
                "state": "closed",
                "project_created_at": "2023-05-30T10:14:43Z",
                "closed_at": "2023-06-07T11:18:16Z",
                "body": "### Description\r\n\r\nAfter updating to 76696a2ae243ed05c4361e9f4dda3e06d0859e16 \r\nDTOs i have , having this error .\r\n\r\n```py\r\nTypeError: 'NoneType' object is not iterable\r\n```\r\n\r\n\r\n### URL to code causing the issue\r\n\r\n_No response_\r\n\r\n### MCVE\r\nhttps://github.com/v3ss0n/starlite-pg-redis-docker/tree/repro-dto-nontype\r\n\r\n\r\n### Steps to reproduce\r\n\r\n1. Make a request to Projects API\r\n```bash\r\ncurl -X 'GET' \\\r\n  'http://localhost:8000/v1/api/projects?page=1&page-size=100' \\\r\n  -H 'accept: application/json'\r\n```\r\n2. See error\r\n\r\n\r\n### Screenshots\r\n\r\n```bash\r\n\"![SCREENSHOT_DESCRIPTION](SCREENSHOT_LINK.png)\"\r\n```\r\n\r\n\r\n### Logs\r\n\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/middleware/exceptions/middleware.py\", line 150, in __call__\r\n    await self.app(scope, receive, send)\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 77, in handle\r\n    response = await self._get_response_for_request(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 129, in _get_response_for_request\r\n    response = await self._call_handler_function(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 162, in _call_handler_function\r\n    response: ASGIApp = await route_handler.to_response(app=scope[\"app\"], data=response_data, request=request)\r\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/base.py\", line 469, in to_response\r\n    return await response_handler(app=app, data=data, request=request, return_dto=self.resolve_return_dto())  # type: ignore\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/_utils.py\", line 99, in handler\r\n    data = return_dto(ctx).data_to_encodable_type(data)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/abc.py\", line 103, in data_to_encodable_type\r\n    return backend.encode_data(data, self.connection_context)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/abc.py\", line 286, in encode_data\r\n    return transfer_data(\r\n           ^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/utils.py\", line 140, in transfer_data\r\n    return type(source_data)(\r\n           ^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/utils.py\", line 141, in <genexpr>\r\n    transfer_data(destination_type, item, field_definitions, dto_for)  # type:ignore[call-arg]\r\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/utils.py\", line 144, in transfer_data\r\n    return transfer_instance_data(destination_type, source_data, field_definitions, dto_for)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/utils.py\", line 196, in transfer_instance_data\r\n    unstructured_data[destination_name] = transfer_type_data(\r\n                                          ^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/utils.py\", line 240, in transfer_type_data\r\n    return transfer_type.parsed_type.origin(source_value)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nTypeError: 'NoneType' object is not iterable\r\n```\r\n\r\n\r\n### Litestar Version\r\n\r\n76696a2ae243ed05c4361e9f4dda3e06d0859e16\r\n\r\n### Platform\r\n\r\n- [X] Linux\r\n- [ ] Mac\r\n- [ ] Windows\r\n- [ ] Other (Please specify in the description above)",
                "comments": [
                    {
                        "body": "I couldn't do it in minimal way so i pushed a repo , based on  full-stack .\r\nAlso the error has been changed to  `TypeError: Sequence() takes no arguments`  after updating to latest commit \r\n\r\n\r\n```py\r\nTraceback (most recent call last):\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/middleware/exceptions/middleware.py\", line 150, in __call__\r\n    await self.app(scope, receive, send)\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 77, in handle\r\n    response = await self._get_response_for_request(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 129, in _get_response_for_request\r\n    response = await self._call_handler_function(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 162, in _call_handler_function\r\n    response: ASGIApp = await route_handler.to_response(app=scope[\"app\"], data=response_data, request=request)\r\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/base.py\", line 469, in to_response\r\n    return await response_handler(app=app, data=data, request=request, return_dto=self.resolve_return_dto())  # type: ignore\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/_utils.py\", line 99, in handler\r\n    data = return_dto(ctx).data_to_encodable_type(data)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/abc.py\", line 103, in data_to_encodable_type\r\n    return backend.encode_data(data, self.connection_context)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/abc.py\", line 300, in encode_data\r\n    return transfer_data(\r\n           ^^^^^^^^^^^^^^\r\n  File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/utils.py\", line 148, in transfer_data\r\n    return origin(  # type:ignore[no-any-return]\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nTypeError: Sequence() takes no arguments\r\n```\r\n \r\n https://github.com/v3ss0n/litestar-fullstack-error-reproduce ",
                        "user": "v3ss0n",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-05-30T17:32:59Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1761#issuecomment-1568814594"
                    },
                    {
                        "body": "better MVCE added : https://github.com/v3ss0n/starlite-pg-redis-docker/tree/repro-dto-nontype",
                        "user": "v3ss0n",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-05-30T18:17:00Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1761#issuecomment-1568869259"
                    },
                    {
                        "body": "it comes from this line (which was totally fine before update)\r\n`async def filter(self, service: \"Service\", filters: list[\"FilterTypes\"] = validation_skip) -> Sequence[Model]:`\r\nafter changing `Sequence[Model]` to list[Model]` - problem solved\r\n\r\nBut `Sequence` is fine before the update.\r\n\r\nEDIT: MyPy don't like `list[Model]`\r\n```\r\nsrc/app/domain/projects/controllers.py:43: error: Incompatible return value type (got \"Sequence[Project]\", expected \"List[Project]\")  [return-value]\r\nsrc/app/domain/backlogs/controllers.py:42: error: Incompatible return value type (got \"Sequence[Backlog]\", expected \"List[Backlog]\")  [return-value]\r\nFound 2 errors in 2 files (checked 2 source files)\r\n```",
                        "user": "v3ss0n",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-05-30T18:44:50Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1761#issuecomment-1568905421"
                    },
                    {
                        "body": "> I couldn't do it in minimal way so i pushed a repo , based on  full-stack .\n> \n> Also the error has been changed to  `TypeError: Sequence() takes no arguments`  after updating to latest commit \n> \n> \n> \n> \n> \n> ```py\n> \n> Traceback (most recent call last):\n> \n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/middleware/exceptions/middleware.py\", line 150, in __call__\n> \n>     await self.app(scope, receive, send)\n> \n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 77, in handle\n> \n>     response = await self._get_response_for_request(\n> \n>                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n> \n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 129, in _get_response_for_request\n> \n>     response = await self._call_handler_function(\n> \n>                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n> \n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 162, in _call_handler_function\n> \n>     response: ASGIApp = await route_handler.to_response(app=scope[\"app\"], data=response_data, request=request)\n> \n>                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n> \n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/base.py\", line 469, in to_response\n> \n>     return await response_handler(app=app, data=data, request=request, return_dto=self.resolve_return_dto())  # type: ignore\n> \n>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n> \n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/_utils.py\", line 99, in handler\n> \n>     data = return_dto(ctx).data_to_encodable_type(data)\n> \n>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n> \n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/abc.py\", line 103, in data_to_encodable_type\n> \n>     return backend.encode_data(data, self.connection_context)\n> \n>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n> \n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/abc.py\", line 300, in encode_data\n> \n>     return transfer_data(\n> \n>            ^^^^^^^^^^^^^^\n> \n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/utils.py\", line 148, in transfer_data\n> \n>     return origin(  # type:ignore[no-any-return]\n> \n>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n> \n> TypeError: Sequence() takes no arguments\n> \n> ```\n> \n>  \n> \n>  https://github.com/v3ss0n/litestar-fullstack-error-reproduce \n\nThis isn't the same error as the OP though? Sure it is the same issue?",
                        "user": "peterschutt",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-05-30T19:31:02Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1761#issuecomment-1568970927"
                    },
                    {
                        "body": "> I couldn't do it in minimal way so i pushed a repo , based on full-stack . Also the error has been changed to `TypeError: Sequence() takes no arguments` after updating to latest commit\r\n> \r\n> ```python\r\n> Traceback (most recent call last):\r\n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/middleware/exceptions/middleware.py\", line 150, in __call__\r\n>     await self.app(scope, receive, send)\r\n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 77, in handle\r\n>     response = await self._get_response_for_request(\r\n>                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 129, in _get_response_for_request\r\n>     response = await self._call_handler_function(\r\n>                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/routes/http.py\", line 162, in _call_handler_function\r\n>     response: ASGIApp = await route_handler.to_response(app=scope[\"app\"], data=response_data, request=request)\r\n>                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/base.py\", line 469, in to_response\r\n>     return await response_handler(app=app, data=data, request=request, return_dto=self.resolve_return_dto())  # type: ignore\r\n>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/handlers/http_handlers/_utils.py\", line 99, in handler\r\n>     data = return_dto(ctx).data_to_encodable_type(data)\r\n>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/abc.py\", line 103, in data_to_encodable_type\r\n>     return backend.encode_data(data, self.connection_context)\r\n>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/abc.py\", line 300, in encode_data\r\n>     return transfer_data(\r\n>            ^^^^^^^^^^^^^^\r\n>   File \"/workspace/app/.venv/lib/python3.11/site-packages/litestar/dto/factory/_backends/utils.py\", line 148, in transfer_data\r\n>     return origin(  # type:ignore[no-any-return]\r\n>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n> TypeError: Sequence() takes no arguments\r\n> ```\r\n> \r\n> https://github.com/v3ss0n/litestar-fullstack-error-reproduce\r\n\r\nI know what the issue is here and this is fixed easy enough - but I doubt this is the same as your OP.\r\n\r\nHowever, I think you should consider why the service object is annotated as if it returns generic sequences from the `list()` method, when it knows that it returns a concrete `list`, e.g. [this](https://github.com/cofin/litestar-fullstack/blob/046592ece2abe69c7dd66f6757cd9bd49c4f6e17/src/app/lib/service/sqlalchemy.py#L331-L341):\r\n\r\n```py\r\n    async def list(self, *filters: FilterTypes, **kwargs: Any) -> Sequence[ModelT]:\r\n        \"\"\"Wrap repository scalars operation.\r\n\r\n        Args:\r\n            *filters: Collection route filters.\r\n            **kwargs: Keyword arguments for attribute based filtering.\r\n\r\n        Returns:\r\n            The list of instances retrieved from the repository.\r\n        \"\"\"\r\n        return await self.repository.list(*filters, **kwargs)\r\n```\r\nIf this method is typed to return `list[ModelT]` - which is what the `repository.list()` method is annotated to return, then you don't need to type the return type of your handler as `Sequence[ModelT]` in the first place.\r\n\r\nGeneric collections are usually good to annotate function arguments with, as when you are authoring a function, you tend to know what you are doing with the argument value within the function, and so you know if you just need any old sequence, or if you are relying on particular methods of a concrete collection type.\r\n\r\nOn the other hand, using generic types for return annotations means that downstream users of that method need to inspect the object, or cast it to something else at runtime so that they know what they are actually dealing with. E.g.,:\r\n\r\n```py\r\ndef returns_list() -> Sequence[int]:\r\n    return [1, 2, 3]\r\n\r\nl = returns_list()\r\nl.append(4)  # mypy will complain because it thinks `l` is a generic sequence which has no `append()` method\r\n\r\n# so user needs to do this\r\nl = list(returns_list())\r\nl.append(4)\r\n```\r\nThis example is essentially what the service object is does in that repo. It knows that `self.repository.list()` returns a `list`, but annotates the return of its own `list()` method as `Sequence`, which loses info for downstream users.\r\n",
                        "user": "peterschutt",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-05-30T20:25:25Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1761#issuecomment-1569045935"
                    },
                    {
                        "body": "Created #1763 for the `Sequence` issue - I minimized most of the conversation around that in this issue as it not the same issue as OP.",
                        "user": "peterschutt",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-05-30T22:38:47Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1761#issuecomment-1569221059"
                    },
                    {
                        "body": "> This isn't the same error as the OP though? Sure it is the same issue?\r\n\r\nYeah , the first issue gone after i updated to ccc9b33831620ea20a4dffa0d0a76501f2a785bb   , I will try to reproduce the OP again.",
                        "user": "v3ss0n",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-05-31T02:42:15Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1761#issuecomment-1569414828"
                    },
                    {
                        "body": "I'll close this for now @v3ss0n - please reopen if you can reproduce.",
                        "user": "peterschutt",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-06-07T11:18:16Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1761#issuecomment-1580572290"
                    },
                    {
                        "body": "I haven't encourter the first issue yet.  so its safe to close so far. thanks a lot !",
                        "user": "v3ss0n",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-06-07T16:42:49Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1761#issuecomment-1581182422"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/1615",
                "title": "Bug: Using `websocket_listener` in controller causes `TypeError: .handler_fn() got multiple values for argument 'socket'`",
                "labels": [
                    "Bug :bug:",
                    "Great MCVE"
                ],
                "user": "xEricL",
                "issue_author_association": "NONE",
                "number": 1615,
                "id": 1694337319,
                "state": "closed",
                "project_created_at": "2023-05-03T15:44:09Z",
                "closed_at": "2023-05-07T16:07:49Z",
                "body": "### Description\r\n\r\nConfirmed by @provinzkraut in Discord\r\n\r\n\r\n\r\n### URL to code causing the issue\r\n\r\n_No response_\r\n\r\n### MCVE\r\n\r\n```python\r\nfrom litestar import Controller, WebSocket, websocket_listener\r\nfrom litestar.testing import create_test_client\r\n\r\n\r\nclass ClientController(Controller):\r\n    path: str = \"/client\"\r\n\r\n    @websocket_listener(\"/ws\")\r\n    async def websocket_handler(self, data: bytes, socket: WebSocket) -> bytes:\r\n        return data\r\n\r\n\r\nwith create_test_client(ClientController) as client, client.websocket_connect(\"/client/ws\") as ws:\r\n    data = ws.send_bytes(b\"foo\")\r\n    assert data == b\"foo\"\r\n```\r\n\r\n\r\n### Screenshots\r\n\r\n\"![Exception Log](https://user-images.githubusercontent.com/37921711/235967617-91018971-d13d-489f-b023-bf9fa807c3ae.png)\"\r\n\r\n\r\n### Logs\r\n\r\n_No response_\r\n\r\n### Litestar Version\r\n\r\n2.0.0alpha5\r\n\r\n### Platform\r\n\r\n- [X] Linux\r\n- [ ] Mac\r\n- [ ] Windows\r\n- [ ] Other (Please specify in the description above)\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n> [!NOTE]  \n> While we are open for sponsoring on [GitHub Sponsors](https://github.com/sponsors/litestar-org/) and \n> [OpenCollective](https://opencollective.com/litestar), we also utilize [Polar.sh](https://polar.sh/) to engage in pledge-based sponsorship.\n>\n> Check out all issues funded or available for funding [on our Polar.sh dashboard](https://polar.sh/litestar-org)\n> * If you would like to see an issue prioritized, make a pledge towards it!\n> * We receive the pledge once the issue is completed & verified\n> * This, along with engagement in the community, helps us know which features are a priority to our users.\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/1615\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/1615/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/1615/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/1371",
                "title": "Combining redirects and templated responses",
                "labels": [
                    "Documentation :books:",
                    "Enhancement",
                    "Great MCVE"
                ],
                "user": "zoni",
                "issue_author_association": "CONTRIBUTOR",
                "number": 1371,
                "id": 1636212394,
                "state": "closed",
                "project_created_at": "2023-03-22T17:30:38Z",
                "closed_at": "2023-03-30T11:08:24Z",
                "body": "## Context\r\n\r\nI'm working on a project with non-API/non-RESTful routes where, depending on the result of backend processing, either one of these two types of responses should be returned:\r\n\r\n1. A templated HTML response ([`Template`]); or\r\n2. A redirect to another (external) URL ([`Redirect`])\r\n\r\nI'm struggling on how to implement this and not sure whether I'm running into a documentation issue where it's just not clear, or an actual API design limitation of Starlite's response handling in general.\r\n\r\n## Environment info\r\n\r\n- `Linux l-057 6.1.18-200.fc37.x86_64 #1 SMP PREEMPT_DYNAMIC Sat Mar 11 16:09:14 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux`\r\n- `Python 3.11.2`\r\n- `starlite 1.51.7` ([full requirements.txt](https://gist.github.com/zoni/c3b0c2afc8f40c801f18ecc5b9f00d7b/8b1ec72b3895dddb0cd795c025ae90ac0e73cbbd#file-requirements-txt))\r\n\r\n## Partial solutions\r\n\r\nI've gotten quite close to a working solution that meets both goals, but it doesn't _quite_ get me where I want.\r\nFor clarity, I'll iterate over all possible approaches I've attempted so far.\r\n\r\n### Template response\r\n\r\nPoint (1) can be achieved with simple [`Template`] response, which looks as follows:\r\n\r\nhttps://gist.github.com/zoni/c3b0c2afc8f40c801f18ecc5b9f00d7b/000c36e412b093fc8ced1ab4e98d57d9f2aea119\r\n\r\n### Redirect response\r\n\r\nPoint (2) can be achieved with simple [`Redirect`] response, which looks as follows:\r\n\r\nhttps://gist.github.com/zoni/c3b0c2afc8f40c801f18ecc5b9f00d7b/c16f9c20f173eceea2be13181ff8fbb9b7649fc0\r\n\r\n### Combining Template + Redirect\r\n\r\nA naive attempt was to return a union of `Template` and `Redirect`: \r\n\r\nhttps://gist.github.com/zoni/c3b0c2afc8f40c801f18ecc5b9f00d7b/44e0e0e6e8ffe474b8ff75c1610720800fe5537d\r\n\r\nThis however fails with a `ValueError` on OpenAPI schema generation:\r\n\r\n<details>\r\n<summary>Traceback</summary>\r\n<pre>\r\nTraceback (most recent call last):\r\n  File \"/usr/lib64/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\r\n    self.run()\r\n  File \"/usr/lib64/python3.11/multiprocessing/process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/home/work/.cache/pypoetry/virtualenvs/starlite-issue-5tyW83TP-py3.11/lib/python3.11/site-packages/uvicorn/_subprocess.py\", line 76, in subprocess_started\r\n    target(sockets=sockets)\r\n  File \"/home/work/.cache/pypoetry/virtualenvs/starlite-issue-5tyW83TP-py3.11/lib/python3.11/site-packages/uvicorn/server.py\", line 59, in run\r\n    return asyncio.run(self.serve(sockets=sockets))\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/lib64/python3.11/asyncio/runners.py\", line 190, in run\r\n    return runner.run(main)\r\n           ^^^^^^^^^^^^^^^^\r\n  File \"/usr/lib64/python3.11/asyncio/runners.py\", line 118, in run\r\n    return self._loop.run_until_complete(task)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/lib64/python3.11/asyncio/base_events.py\", line 653, in run_until_complete\r\n    return future.result()\r\n           ^^^^^^^^^^^^^^^\r\n  File \"/home/work/.cache/pypoetry/virtualenvs/starlite-issue-5tyW83TP-py3.11/lib/python3.11/site-packages/uvicorn/server.py\", line 66, in serve\r\n    config.load()\r\n  File \"/home/work/.cache/pypoetry/virtualenvs/starlite-issue-5tyW83TP-py3.11/lib/python3.11/site-packages/uvicorn/config.py\", line 471, in load\r\n    self.loaded_app = import_from_string(self.app)\r\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/work/.cache/pypoetry/virtualenvs/starlite-issue-5tyW83TP-py3.11/lib/python3.11/site-packages/uvicorn/importer.py\", line 21, in import_from_string\r\n    module = importlib.import_module(module_str)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/lib64/python3.11/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<frozen importlib._bootstrap>\", line 1206, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1178, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1149, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"/home/work/starlite_issue/app.py\", line 16, in <module>\r\n    app = Starlite(\r\n          ^^^^^^^^^\r\n  File \"/home/work/.cache/pypoetry/virtualenvs/starlite-issue-5tyW83TP-py3.11/lib/python3.11/site-packages/starlite/app.py\", line 390, in __init__\r\n    self.update_openapi_schema()\r\n  File \"/home/work/.cache/pypoetry/virtualenvs/starlite-issue-5tyW83TP-py3.11/lib/python3.11/site-packages/starlite/app.py\", line 732, in update_openapi_schema\r\n    self.openapi_schema = construct_open_api_with_schema_class(\r\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/work/.cache/pypoetry/virtualenvs/starlite-issue-5tyW83TP-py3.11/lib/python3.11/site-packages/pydantic_openapi_schema/utils/utils.py\", line 53, in construct_open_api_with_schema_class\r\n    schema_definitions = schema(schema_classes, ref_prefix=REF_PREFIX, by_alias=by_alias)[\"definitions\"]\r\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"pydantic/schema.py\", line 146, in pydantic.schema.schema\r\n  File \"pydantic/schema.py\", line 581, in pydantic.schema.model_process_schema\r\n  File \"pydantic/schema.py\", line 622, in pydantic.schema.model_type_schema\r\n  File \"pydantic/schema.py\", line 255, in pydantic.schema.field_schema\r\n  File \"pydantic/schema.py\", line 527, in pydantic.schema.field_type_schema\r\n  File \"pydantic/schema.py\", line 850, in pydantic.schema.field_singleton_schema\r\n  File \"pydantic/schema.py\", line 745, in pydantic.schema.field_singleton_sub_fields_schema\r\n  File \"pydantic/schema.py\", line 527, in pydantic.schema.field_type_schema\r\n  File \"pydantic/schema.py\", line 949, in pydantic.schema.field_singleton_schema\r\nValueError: Value not declarable with JSON Schema, field: name='background_BackgroundTask' type=BackgroundTask required=True\r\n</pre>\r\n</details>\r\n\r\nI don't actually care about OpenAPI for these endpoints, so setting `include_in_schema=False` would be fine for me as well:\r\n\r\nhttps://gist.github.com/zoni/c3b0c2afc8f40c801f18ecc5b9f00d7b/5710d90b2a6de48e3b251e8820f9d0d0abbc8552\r\n\r\nThis removes the exception, but doesn't get us the intended behavior however. Instead, it results in a JSON rendering of the [`Template`] and [`Redirect`] objects:\r\n\r\n<details>\r\n<summary>Result of the template response</summary>\r\n<pre>\r\n[17:00:13] work in ~\r\n  http localhost:5000/world\r\nHTTP/1.1 307 Temporary Redirect\r\ncontent-length: 132\r\ncontent-type: application/json\r\ndate: Wed, 22 Mar 2023 16:00:16 GMT\r\nserver: uvicorn\r\n\r\n{\r\n    \"background\": null,\r\n    \"context\": {\r\n        \"name\": \"world\"\r\n    },\r\n    \"cookies\": [],\r\n    \"encoding\": \"utf-8\",\r\n    \"headers\": {},\r\n    \"media_type\": null,\r\n    \"name\": \"hello.html.j2\"\r\n}\r\n</pre>\r\n</details>\r\n\r\n<details>\r\n<summary>Result of the Redirect response</summary>\r\n<pre>\r\n[17:00:16] work in ~\r\n  http localhost:5000/foo\r\nHTTP/1.1 307 Temporary Redirect\r\ncontent-length: 114\r\ncontent-type: application/json\r\ndate: Wed, 22 Mar 2023 16:00:19 GMT\r\nserver: uvicorn\r\n\r\n{\r\n    \"background\": null,\r\n    \"cookies\": [],\r\n    \"encoding\": \"utf-8\",\r\n    \"headers\": {},\r\n    \"media_type\": null,\r\n    \"path\": \"http://example.com/foo\"\r\n}\r\n</pre>\r\n</details>\r\n\r\n### Using only `Response`\r\n\r\nThe closest to achieving this goal that I've come up with is to use a `Response`, but then I don't have access to a Template engine to return a ***templated*** response anymore:\r\n\r\nhttps://gist.github.com/zoni/c3b0c2afc8f40c801f18ecc5b9f00d7b/48d7b837f33a4b522657027d78bd006399b4f04e\r\n\r\nLack of templating aside, we can see this lets us mix a redirect with an arbitrary content response:\r\n\r\n<details>\r\n<summary>text/html content response</summary>\r\n<pre>\r\n[17:09:26] work in ~\r\n  http localhost:5000/world\r\nHTTP/1.1 200 OK\r\ncontent-length: 11\r\ncontent-type: text/html; charset=utf-8\r\ndate: Wed, 22 Mar 2023 16:09:30 GMT\r\nserver: uvicorn\r\n\r\nHello world\r\n</pre>\r\n</details>\r\n\r\n<details>\r\n<summary>redirect response (no content body)</summary>\r\n<pre>\r\n[17:09:30] work in ~\r\n  http localhost:5000/foo\r\nHTTP/1.1 307 Temporary Redirect\r\nTransfer-Encoding: chunked\r\ncontent-type: text/plain; charset=utf-8\r\ndate: Wed, 22 Mar 2023 16:09:38 GMT\r\nlocation: http://example.com/foo\r\nserver: uvicorn\r\n</pre>\r\n</details>\r\n\r\n(Also worth noting this requires setting `content=\"\", media_type=\"text/plain\"` on `Response()` otherwise it defaults to JSON with a `\"\"` body as well, so it's a bit less ergonomic)\r\n\r\n## Desired solution\r\n\r\nIdeally, I'd like to be able to combine [`Template`] + [`Redirect`]. That is, a function signature like `def hello(name: str = \"world\") -> Template | Redirect:`\r\n\r\n(Or for older Python versions, `def hello(name: str = \"world\") -> typing.Union[Template, Redirect]:`)\r\n\r\nI'm also quite happy just returning `Response`, but then I would like a way to get access to the templating engine myself, so that it's possible to do something along the lines of (pseudo-code):\r\n\r\n```python\r\n\r\n@get(\"/{name:str}\", include_in_schema=False)\r\ndef hello(name: str = \"world\", templater: TemplateEngine) -> Response:\r\n        response_content = templater.get_template(\"hello.html.j2\").render(context={\"name\": name})\r\n\r\n        return Response(\r\n            content=response_content,\r\n            media_type=\"text/html\",\r\n        )\r\n```\r\n\r\nThis _might_ already be possible and I just don't know how to get the TemplateEngine injected. If so, I'd love to be pointed at how this could be achieved, and I'll happily make a PR to at least document this better.\r\n\r\n## Miscellaneous notes\r\n\r\nWhile I'm talking only about Template and Redirect here as that is the use-case I'm trying to solve, I imagine the same issues likely exist around mixing in [`StreamingResponse`] and [`FileResponse`].\r\n\r\n[`Template`]: https://docs.starliteproject.dev/latest/reference/datastructures/response_containers.html#starlite.datastructures.response_containers.Template\r\n[`Redirect`]: https://docs.starliteproject.dev/latest/reference/datastructures/response_containers.html#starlite.datastructures.response_containers.Redirect\r\n[`StreamingResponse`]: https://docs.starliteproject.dev/latest/reference/response.html#starlite.response.StreamingResponse\r\n[`FileResponse`]: https://docs.starliteproject.dev/latest/reference/response.html#starlite.response.FileResponse\r\n",
                "comments": [
                    {
                        "body": "Thanks a lot for the very detailed write up!\r\n\r\nSo, this is actually possible, but not very ergonomic. \r\nTruth be told, templates haven't received a lot of attention but could certainly use some. Unfortunately I can't make any promises as to when that might happen.\r\n\r\nAnyway, here's (one) possible way of doing this:\r\n\r\n```python\r\nfrom pathlib import Path\r\n\r\nfrom starlite import (\r\n    Redirect,\r\n    Starlite,\r\n    Template,\r\n    TemplateConfig,\r\n    Request,\r\n    get,\r\n    Response,\r\n    ResponseContainer,\r\n)\r\nfrom starlite.contrib.jinja import JinjaTemplateEngine\r\nfrom starlite.status_codes import HTTP_307_TEMPORARY_REDIRECT\r\n\r\n\r\n@get(\"/{name:str}\", include_in_schema=False)\r\ndef hello(name: str, request: Request) -> ResponseContainer | Response:\r\n    if name == \"foo\":\r\n        return Redirect(path=f\"http://example.com/{name}\").to_response(\r\n            headers={},\r\n            status_code=HTTP_307_TEMPORARY_REDIRECT,\r\n            media_type=\"text/plain\",\r\n            request=request,\r\n            app=request.app,\r\n        )\r\n\r\n    return Template(name=\"hello.html.j2\", context={\"name\": name})\r\n\r\n\r\napp = Starlite(\r\n    route_handlers=[hello],\r\n    template_config=TemplateConfig(\r\n        directory=Path(\"templates\"),\r\n        engine=JinjaTemplateEngine,\r\n    ),\r\n)\r\n```\r\n\r\nor alternatively: \r\n\r\n```python\r\n@get(\"/{name:str}\", include_in_schema=False)\r\ndef hello(name: str) -> ResponseContainer | Response:\r\n    if name == \"foo\":\r\n        return Response(\r\n            content=b\"\",\r\n            headers={\"location\": f\"http://example.com/{name}\"},\r\n            status_code=HTTP_307_TEMPORARY_REDIRECT,\r\n        )\r\n\r\n    return Template(name=\"hello.html.j2\", context={\"name\": name})\r\n```\r\n\r\nBoth aren't that ergonomic, and there should definitely be a better way.\r\n\r\nThe actual issue though lies within the `Redirect` response container. Because it does not accept a `status_code`, you cannot simply return it. If this were the case, you could do:\r\n\r\n```python\r\n@get(\"/{name:str}\", include_in_schema=False)\r\ndef hello(name: str) -> ResponseContainer:\r\n    if name == \"foo\":\r\n        return Redirect(path=f\"http://example.com/{name}\", status_code=HTTP_307_TEMPORARY_REDIRECT)\r\n\r\n    return Template(name=\"hello.html.j2\", context={\"name\": name})\r\n```\r\n\r\nwhich is quite a lot nicer.\r\n\r\nI'll open an issue to support this, although it will most likely end up in 2.0.\r\n\r\n<hr> \r\n\r\nFrom a documentation perspective, we should definitely have a section about returning optional redirect like that.",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-03-22T19:01:28Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1371#issuecomment-1480108618"
                    },
                    {
                        "body": "@zoni I added a fix for this in #1412. \r\n\r\nWith this, it should work as expected:\r\n\r\n```python\r\n@get(\"/{name:str}\")\r\ndef hello(name: str = \"world\") -> Template | Redirect:\r\n    if name == \"foo\":\r\n        return Redirect(path=f\"http://example.com/{name}\", status_code=HTTP_307_TEMPORARY_REDIRECT)\r\n\r\n    return Template(name=\"hello.html.j2\", context={\"name\": name})\r\n```\r\n\r\nThis will only be available in `2.0` though, so you'll have to stick with one of the suggested workarounds for now unless you're working with the alpha releases.",
                        "user": "provinzkraut",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-03-30T11:10:21Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1371#issuecomment-1490115827"
                    },
                    {
                        "body": "You folks work fast @provinzkraut, thanks! I was already debating upgrading this codebase to the 2.0 alpha, so with this, now seems as good a time as any.\r\n\r\nWill upgrade and take it for a spin! In case I run into any issues I'll report back, but judging by the changes from #1412, I don't expect to encounter any difficulties :smile: ",
                        "user": "zoni",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-04-02T14:58:22Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1371#issuecomment-1493365321"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/1271",
                "title": "Bug: Using `from __future__ import annotations` breaks template support",
                "labels": [
                    "Bug :bug:",
                    "Great MCVE"
                ],
                "user": "Nadock",
                "issue_author_association": "CONTRIBUTOR",
                "number": 1271,
                "id": 1609650594,
                "state": "closed",
                "project_created_at": "2023-03-04T07:14:29Z",
                "closed_at": "2023-03-09T15:16:11Z",
                "body": "**Describe the bug**\r\nIf you include `from __future__ import annotations` in the same file as a route handler that returns a `starlite.Template` the template will not be rendered. Instead, the `starlite.Template` object is converted to JSON and that is returned instead.\r\n\r\n**To Reproduce**\r\nBelow is code that reproduces the error for me.\r\n\r\n```python\r\n# app.py\r\nfrom __future__ import annotations\r\n\r\nimport pathlib\r\n\r\nimport starlite\r\nfrom starlite.contrib import jinja\r\n\r\n\r\n@starlite.get(\"/\")\r\ndef index() -> starlite.Template:\r\n    return starlite.Template(name=\"repro.html\")\r\n\r\n\r\napp = starlite.Starlite(\r\n    route_handlers=[index],\r\n    template_config=starlite.TemplateConfig(\r\n        directory=pathlib.Path(\"./templates\"),\r\n        engine=jinja.JinjaTemplateEngine,\r\n    ),\r\n)\r\n```\r\n\r\n```html\r\n<!-- templates/repro.html -->\r\n<!DOCTYPE html>\r\n<html lang=\"en-au\">\r\n\r\n<head>\r\n    <meta content=\"text/html;charset=utf-8\" http-equiv=\"Content-Type\">\r\n    <meta content=\"utf-8\" http-equiv=\"encoding\">\r\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\r\n    <meta name=\"color-scheme\" content=\"dark light\">\r\n    <title>from __future__ import annotations</title>\r\n</head>\r\n\r\n<body>\r\n    <h1>Hello, world!</h1>\r\n</body>\r\n```\r\n\r\n\r\n**Additional context**\r\n**With** the `from __future__ import annotations` line:\r\n![Screenshot 2023-03-04 at 17 41 19](https://user-images.githubusercontent.com/1491530/222881622-8e8eebe7-52a4-4ba0-b59d-f3989f6ba9f0.png)\r\n\r\n**Without** the `from __future__ import annotations` line:\r\n\r\n![Screenshot 2023-03-04 at 17 46 14](https://user-images.githubusercontent.com/1491530/222881797-5e2d66a5-05b4-4a52-b0ea-0ba91c69aa2a.png)\r\n\r\n---\r\n\r\nI've only just started using **Starlite** so I'm not sure if there is something I missed in the documentation that says you shouldn't use `from __future__ import annotations`. But even if there is, maybe **Starlite** could raise an exception when you do this.\n\n<!-- POLAR PLEDGE BADGE START -->\n---\n> [!NOTE]  \n> While we are open for sponsoring on [GitHub Sponsors](https://github.com/sponsors/litestar-org/) and \n> [OpenCollective](https://opencollective.com/litestar), we also utilize [Polar.sh](https://polar.sh/) to engage in pledge-based sponsorship.\n>\n> Check out all issues funded or available for funding [on our Polar.sh dashboard](https://polar.sh/litestar-org)\n> * If you would like to see an issue prioritized, make a pledge towards it!\n> * We receive the pledge once the issue is completed & verified\n> * This, along with engagement in the community, helps us know which features are a priority to our users.\n\n<a href=\"https://polar.sh/litestar-org/litestar/issues/1271\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://polar.sh/api/github/litestar-org/litestar/issues/1271/pledge.svg?darkmode=1\">\n  <img alt=\"Fund with Polar\" src=\"https://polar.sh/api/github/litestar-org/litestar/issues/1271/pledge.svg\">\n</picture>\n</a>\n<!-- POLAR PLEDGE BADGE END -->\n",
                "comments": [
                    {
                        "body": "Hi, what version have you tested? And can you check our main branch?",
                        "user": "Goldziher",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-03-04T11:05:59Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1271#issuecomment-1454701730"
                    },
                    {
                        "body": "This was tested on `1.51.6` and I've also been able to reproduce this when installing 06c50d7 from `main`, all using Python `3.11.1`.",
                        "user": "Nadock",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-03-04T14:06:45Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1271#issuecomment-1454751316"
                    },
                    {
                        "body": "I actually came across the cause of this today, and it will be fixed for 2.0.\r\n\r\nThe handler gets a reference to its signature here:\r\n\r\nhttps://github.com/starlite-api/starlite/blob/fbe51fb18bb685e579b66d0a42f1e0c3a4fae24f/starlite/handlers/http.py#L477\r\n\r\nHowever, support for resolving types in `inspect.Signature.from_callable()` is only available in 3.10+.\r\n\r\nWe go on to use an `isinstance()` check on the return annotation, but it is still a string here:\r\n\r\nhttps://github.com/starlite-api/starlite/blob/fbe51fb18bb685e579b66d0a42f1e0c3a4fae24f/starlite/handlers/http.py#L610\r\n\r\nThis will be fixed in 2.0 from this commit: https://github.com/starlite-api/starlite/pull/1160/commits/1ce9c5a84a0836139a2570317855b9a14d15d808 - and a few of the preceding commits on that branch.\r\n\r\nWe could do some `eval()` work to try to resolve the type of the return annotation in the 1.5x branch, but I'd suggest that you don't rely to heavily on `__future__.annotations` anywhere that there needs to be runtime introspection of types on the 1.x series.",
                        "user": "peterschutt",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-03-05T14:02:30Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1271#issuecomment-1455100905"
                    },
                    {
                        "body": "If there's a fix coming in `2.0` that's excellent  \r\n\r\n> We could do some eval() work to try to resolve the type of the return annotation in the 1.5x branch, but I'd suggest that you don't rely to heavily on __future__.annotations anywhere that there needs to be runtime introspection of types on the 1.x series.\r\n\r\nYeah that's fine honestly. This was my first foray into using Starlite so I the side effects of `__future__.annotations` weren't clear. Maybe worth a note in the documentation that `__future__.annotations` can cause issues, but it doesn't sound like back porting a fix is that worth it.",
                        "user": "Nadock",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-03-06T01:17:45Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1271#issuecomment-1455286181"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/litestar-org/litestar/issues/1219",
                "title": "Bug: `JWTAuth.login` raises `SerializationException` despite `type_encoders` settings",
                "labels": [
                    "Bug :bug:",
                    "Triage Required :hospital:",
                    "Needs MCVE"
                ],
                "user": "LonelyVikingMichael",
                "issue_author_association": "CONTRIBUTOR",
                "number": 1219,
                "id": 1590806190,
                "state": "closed",
                "project_created_at": "2023-02-19T18:42:17Z",
                "closed_at": "2023-03-02T06:54:14Z",
                "body": "**Describe the bug**\r\n`JWTAuth.login` instantiates and returns a `starlite.Response` object that does not respect custom defined `type_encoders`. This will raise an exception if the response body custom types such as `asyncpg.pgproto.pgproto.UUID` etc.\r\n\r\n**To Reproduce**\r\nN/A\r\n\r\n**Additional context**\r\nThis wasn't a problem in older releases before `type_encoders` were introduced, as we'd override the Response class directly to customise serialization.\r\n",
                "comments": [
                    {
                        "body": "can you give me an MCVE? or a failing test? would be very helpful to have it. ",
                        "user": "Goldziher",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-02-27T17:25:43Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1219#issuecomment-1446740936"
                    },
                    {
                        "body": "My mistake, project was using an older Starlite version.",
                        "user": "LonelyVikingMichael",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-03-02T06:54:14Z",
                        "url": "https://github.com/litestar-org/litestar/issues/1219#issuecomment-1451384006"
                    }
                ],
                "pull_request": null
            }
        ],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Generic policy",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 23,
        "num_noncompliant_security_pull": 1,
        "has_generic_policy": true
    },
    {
        "project_name": "cure53/dompurify",
        "project_url": "https://github.com/cure53/dompurify",
        "SSF": {
            "date": "2024-10-30T01:15:33+07:00",
            "repo": {
                "name": "github.com/cure53/dompurify",
                "commit": "211ffb5bb94c24b6482b91021b6334295b1152e4"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.5,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'main'",
                        "Warn: branch protection not enabled for branch '3.x'",
                        "Warn: branch protection not enabled for branch '2.x'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "10 out of 10 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 5,
                    "reason": "Found 5/9 approved changesets -- score normalized to 5",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: google contributor org/company found, hasadna contributor org/company found, pry contributor org/company found, WuLiFang contributor org/company found, jmapio contributor org/company found, NateGameTeam contributor org/company found, bgzt contributor org/company found, Maps4HTML contributor org/company found, zed-industries contributor org/company found, googlers contributor org/company found, OpenBudget contributor org/company found, blues-lab contributor org/company found, w3c contributor org/company found, elephantfigstudios contributor org/company found, wulifang contributor org/company found, Miscreants contributor org/company found, oracle contributor org/company found, opfo contributor org/company found, webhintio contributor org/company found, octokey contributor org/company found, freelancer contributor org/company found, Leaflet contributor org/company found, jsdom contributor org/company found, qunitjs contributor org/company found, agoric contributor org/company found, commercetools gmbh contributor org/company found, danger contributor org/company found, microsoft contributor org/company found, jquery contributor org/company found, Agoric contributor org/company found, finepenetrationtests forfinewebsites contributor org/company found, SEP007 contributor org/company found, fastmail contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 33 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "28 commit(s) and 11 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build-and-test.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/cure53/DOMPurify/build-and-test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build-and-test.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/cure53/DOMPurify/build-and-test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/build-and-test.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/cure53/DOMPurify/build-and-test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/cure53/DOMPurify/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/cure53/DOMPurify/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:48: update your workflow using https://app.stepsecurity.io/secureworkflow/cure53/DOMPurify/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:62: update your workflow using https://app.stepsecurity.io/secureworkflow/cure53/DOMPurify/codeql-analysis.yml/main?enable=pin",
                        "Info:   0 out of   6 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   1 out of   1 npmCommand dependencies pinned"
                    ],
                    "score": 3,
                    "reason": "dependency not pinned by hash detected -- score normalized to 3",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: all commits (28) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/build-and-test.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/codeql-analysis.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-grv7-fg5c-xmjg",
                        "Warn: Project is vulnerable to: GHSA-952p-6rrq-rcjv",
                        "Warn: Project is vulnerable to: GHSA-c2qf-rxjj-qqgw"
                    ],
                    "score": 7,
                    "reason": "3 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/cure53/dompurify/contents/SECURITY.md",
        "SecurityPolicy_content": "## Supported Versions\n\nAlways the latest release.\n\n## Reporting a Vulnerability\n\nFirst of all, please immediately contact us via [email](mailto:mario@cure53.de) so we can work on a fix. [PGP key](https://keyserver.ubuntu.com/pks/lookup?op=vindex&search=0xC26C858090F70ADA)\n\nAlso, you probably qualify for a bug bounty! The fine folks over at [Fastmail](https://www.fastmail.com/) use DOMPurify for their services and added our library to their bug bounty scope. So, if you find a way to bypass or weaken DOMPurify, please also have a look at their website and the [bug bounty info](https://www.fastmail.com/about/bugbounty/).\n",
        "project_all_labels": [
            "bug",
            "dependencies",
            "duplicate",
            "enhancement",
            "github_actions",
            "invalid",
            "javascript",
            "question",
            "wontfix"
        ],
        "README_content": "# DOMPurify\n\n[![npm version](https://badge.fury.io/js/dompurify.svg)](http://badge.fury.io/js/dompurify) ![Build and Test](https://github.com/cure53/DOMPurify/workflows/Build%20and%20Test/badge.svg?branch=main) [![Downloads](https://img.shields.io/npm/dm/dompurify.svg)](https://www.npmjs.com/package/dompurify) ![npm package minimized gzipped size (select exports)](https://img.shields.io/bundlejs/size/dompurify?color=%233C1&label=minified) ![GitHub code size in bytes](https://img.shields.io/github/languages/code-size/cure53/dompurify?color=%233C1) [![dependents](https://badgen.net/github/dependents-repo/cure53/dompurify?color=green&label=dependents)](https://github.com/cure53/DOMPurify/network/dependents)\n\n[![NPM](https://nodei.co/npm/dompurify.png)](https://nodei.co/npm/dompurify/)\n\nDOMPurify is a DOM-only, super-fast, uber-tolerant XSS sanitizer for HTML, MathML and SVG.\n\nIt's also very simple to use and get started with. DOMPurify was [started in February 2014](https://github.com/cure53/DOMPurify/commit/a630922616927373485e0e787ab19e73e3691b2b) and, meanwhile, has reached version **v3.1.7**.\n\nDOMPurify is written in JavaScript and works in all modern browsers (Safari (10+), Opera (15+), Edge, Firefox and Chrome - as well as almost anything else using Blink, Gecko or WebKit). It doesn't break on MSIE or other legacy browsers. It simply does nothing.\n\n**Note that [DOMPurify v2.5.7](https://github.com/cure53/DOMPurify/releases/tag/2.5.7) is the latest version supporting MSIE. For important security updates compatible with MSIE, please use the [2.x branch](https://github.com/cure53/DOMPurify/tree/2.x).**\n\nOur automated tests cover [19 different browsers](https://github.com/cure53/DOMPurify/blob/main/test/karma.custom-launchers.config.js#L5) right now, more to come. We also cover Node.js v16.x, v17.x, v18.x and v19.x, running DOMPurify on [jsdom](https://github.com/jsdom/jsdom). Older Node versions are known to work as well, but hey... no guarantees.\n\nDOMPurify is written by security people who have vast background in web attacks and XSS. Fear not. For more details please also read about our [Security Goals & Threat Model](https://github.com/cure53/DOMPurify/wiki/Security-Goals-&-Threat-Model). Please, read it. Like, really.\n\n## What does it do?\n\nDOMPurify sanitizes HTML and prevents XSS attacks. You can feed DOMPurify with string full of dirty HTML and it will return a string (unless configured otherwise) with clean HTML. DOMPurify will strip out everything that contains dangerous HTML and thereby prevent XSS attacks and other nastiness. It's also damn bloody fast. We use the technologies the browser provides and turn them into an XSS filter. The faster your browser, the faster DOMPurify will be.\n\n## How do I use it?\n\nIt's easy. Just include DOMPurify on your website.\n\n### Using the unminified development version\n\n```html\n<script type=\"text/javascript\" src=\"src/purify.js\"></script>\n```\n\n### Using the minified and tested production version (source-map available)\n\n```html\n<script type=\"text/javascript\" src=\"dist/purify.min.js\"></script>\n```\n\nAfterwards you can sanitize strings by executing the following code:\n\n```js\nconst clean = DOMPurify.sanitize(dirty);\n```\n\nOr maybe this, if you love working with Angular or alike:\n\n```js\nimport DOMPurify from 'dompurify';\n\nconst clean = DOMPurify.sanitize('<b>hello there</b>');\n```\n\nThe resulting HTML can be written into a DOM element using `innerHTML` or the DOM using `document.write()`. That is fully up to you.\nNote that by default, we permit HTML, SVG **and** MathML. If you only need HTML, which might be a very common use-case, you can easily set that up as well:\n\n```js\nconst clean = DOMPurify.sanitize(dirty, { USE_PROFILES: { html: true } });\n```\n\n### Is there any foot-gun potential?\n\nWell, please note, if you _first_ sanitize HTML and then modify it _afterwards_, you might easily **void the effects of sanitization**. If you feed the sanitized markup to another library _after_ sanitization, please be certain that the library doesn't mess around with the HTML on its own.\n\n### Okay, makes sense, let's move on\n\nAfter sanitizing your markup, you can also have a look at the property `DOMPurify.removed` and find out, what elements and attributes were thrown out. Please **do not use** this property for making any security critical decisions. This is just a little helper for curious minds.\n\n### Running DOMPurify on the server\n\nDOMPurify technically also works server-side with Node.js. Our support strives to follow the [Node.js release cycle](https://nodejs.org/en/about/releases/).\n\nRunning DOMPurify on the server requires a DOM to be present, which is probably no surprise. Usually, [jsdom](https://github.com/jsdom/jsdom) is the tool of choice and we **strongly recommend** to use the latest version of _jsdom_.\n\nWhy? Because older versions of _jsdom_ are known to be buggy in ways that result in XSS _even if_ DOMPurify does everything 100% correctly. There are **known attack vectors** in, e.g. _jsdom v19.0.0_ that are fixed in _jsdom v20.0.0_ - and we really recommend to keep _jsdom_ up to date because of that.\n\nPlease also be aware that tools like [happy-dom](https://github.com/capricorn86/happy-dom) exist but **are not considered safe** at this point. Combining DOMPurify with _happy-dom_ is currently not recommended and will likely lead to XSS.\n\nOther than that, you are fine to use DOMPurify on the server. Probably. This really depends on _jsdom_ or whatever DOM you utilize server-side. If you can live with that, this is how you get it to work:\n\n```bash\nnpm install dompurify\nnpm install jsdom\n```\n\nFor _jsdom_ (please use an up-to-date version), this should do the trick:\n\n```js\nconst createDOMPurify = require('dompurify');\nconst { JSDOM } = require('jsdom');\n\nconst window = new JSDOM('').window;\nconst DOMPurify = createDOMPurify(window);\nconst clean = DOMPurify.sanitize('<b>hello there</b>');\n```\n\nOr even this, if you prefer working with imports:\n\n```js\nimport { JSDOM } from 'jsdom';\nimport DOMPurify from 'dompurify';\n\nconst window = new JSDOM('').window;\nconst purify = DOMPurify(window);\nconst clean = purify.sanitize('<b>hello there</b>');\n```\n\nIf you have problems making it work in your specific setup, consider looking at the amazing [isomorphic-dompurify](https://github.com/kkomelin/isomorphic-dompurify) project which solves lots of problems people might run into.\n\n```bash\nnpm install isomorphic-dompurify\n```\n\n```js\nimport DOMPurify from 'isomorphic-dompurify';\n\nconst clean = DOMPurify.sanitize('<s>hello</s>');\n```\n\n## Is there a demo?\n\nOf course there is a demo! [Play with DOMPurify](https://cure53.de/purify)\n\n## What if I find a _security_ bug?\n\nFirst of all, please immediately contact us via [email](mailto:mario@cure53.de) so we can work on a fix. [PGP key](https://keyserver.ubuntu.com/pks/lookup?op=vindex&search=0xC26C858090F70ADA)\n\nAlso, you probably qualify for a bug bounty! The fine folks over at [Fastmail](https://www.fastmail.com/) use DOMPurify for their services and added our library to their bug bounty scope. So, if you find a way to bypass or weaken DOMPurify, please also have a look at their website and the [bug bounty info](https://www.fastmail.com/about/bugbounty/).\n\n## Some purification samples please?\n\nHow does purified markup look like? Well, [the demo](https://cure53.de/purify) shows it for a big bunch of nasty elements. But let's also show some smaller examples!\n\n```js\nDOMPurify.sanitize('<img src=x onerror=alert(1)//>'); // becomes <img src=\"x\">\nDOMPurify.sanitize('<svg><g/onload=alert(2)//<p>'); // becomes <svg><g></g></svg>\nDOMPurify.sanitize('<p>abc<iframe//src=jAva&Tab;script:alert(3)>def</p>'); // becomes <p>abc</p>\nDOMPurify.sanitize('<math><mi//xlink:href=\"data:x,<script>alert(4)</script>\">'); // becomes <math><mi></mi></math>\nDOMPurify.sanitize('<TABLE><tr><td>HELLO</tr></TABL>'); // becomes <table><tbody><tr><td>HELLO</td></tr></tbody></table>\nDOMPurify.sanitize('<UL><li><A HREF=//google.com>click</UL>'); // becomes <ul><li><a href=\"//google.com\">click</a></li></ul>\n```\n\n## What is supported?\n\nDOMPurify currently supports HTML5, SVG and MathML. DOMPurify per default allows CSS, HTML custom data attributes. DOMPurify also supports the Shadow DOM - and sanitizes DOM templates recursively. DOMPurify also allows you to sanitize HTML for being used with the jQuery `$()` and `elm.html()` API without any known problems.\n\n## What about legacy browsers like Internet Explorer?\n\nDOMPurify does nothing at all. It simply returns exactly the string that you fed it. DOMPurify exposes a property called `isSupported`, which tells you whether it will be able to do its job, so you can come up with your own backup plan.\n\n## What about DOMPurify and Trusted Types?\n\nIn version 1.0.9, support for [Trusted Types API](https://github.com/w3c/webappsec-trusted-types) was added to DOMPurify.\nIn version 2.0.0, a config flag was added to control DOMPurify's behavior regarding this.\n\nWhen `DOMPurify.sanitize` is used in an environment where the Trusted Types API is available and `RETURN_TRUSTED_TYPE` is set to `true`, it tries to return a `TrustedHTML` value instead of a string (the behavior for `RETURN_DOM` and `RETURN_DOM_FRAGMENT` config options does not change).\n\nNote that in order to create a policy in `trustedTypes` using DOMPurify, `RETURN_TRUSTED_TYPE: false` is required, as `createHTML` expects a normal string, not `TrustedHTML`. The example below shows this.\n\n```js\nwindow.trustedTypes!.createPolicy('default', {\n  createHTML: (to_escape) =>\n    DOMPurify.sanitize(to_escape, { RETURN_TRUSTED_TYPE: false }),\n});\n```\n\n## Can I configure DOMPurify?\n\nYes. The included default configuration values are pretty good already - but you can of course override them. Check out the [`/demos`](https://github.com/cure53/DOMPurify/tree/main/demos) folder to see a bunch of examples on how you can [customize DOMPurify](https://github.com/cure53/DOMPurify/tree/main/demos#what-is-this).\n\n### General settings\n```js\n// strip {{ ... }}, ${ ... } and <% ... %> to make output safe for template systems\n// be careful please, this mode is not recommended for production usage.\n// allowing template parsing in user-controlled HTML is not advised at all.\n// only use this mode if there is really no alternative.\nconst clean = DOMPurify.sanitize(dirty, {SAFE_FOR_TEMPLATES: true});\n\n\n// change how e.g. comments containing risky HTML characters are treated.\n// be very careful, this setting should only be set to `false` if you really only handle \n// HTML and nothing else, no SVG, MathML or the like. \n// Otherwise, changing from `true` to `false` will lead to XSS in this or some other way.\nconst clean = DOMPurify.sanitize(dirty, {SAFE_FOR_XML: false});\n```\n\n### Control our allow-lists and block-lists\n```js\n// allow only <b> elements, very strict\nconst clean = DOMPurify.sanitize(dirty, {ALLOWED_TAGS: ['b']});\n\n// allow only <b> and <q> with style attributes\nconst clean = DOMPurify.sanitize(dirty, {ALLOWED_TAGS: ['b', 'q'], ALLOWED_ATTR: ['style']});\n\n// allow all safe HTML elements but neither SVG nor MathML\n// note that the USE_PROFILES setting will override the ALLOWED_TAGS setting\n// so don't use them together\nconst clean = DOMPurify.sanitize(dirty, {USE_PROFILES: {html: true}});\n\n// allow all safe SVG elements and SVG Filters, no HTML or MathML\nconst clean = DOMPurify.sanitize(dirty, {USE_PROFILES: {svg: true, svgFilters: true}});\n\n// allow all safe MathML elements and SVG, but no SVG Filters\nconst clean = DOMPurify.sanitize(dirty, {USE_PROFILES: {mathMl: true, svg: true}});\n\n// change the default namespace from HTML to something different\nconst clean = DOMPurify.sanitize(dirty, {NAMESPACE: 'http://www.w3.org/2000/svg'});\n\n// leave all safe HTML as it is and add <style> elements to block-list\nconst clean = DOMPurify.sanitize(dirty, {FORBID_TAGS: ['style']});\n\n// leave all safe HTML as it is and add style attributes to block-list\nconst clean = DOMPurify.sanitize(dirty, {FORBID_ATTR: ['style']});\n\n// extend the existing array of allowed tags and add <my-tag> to allow-list\nconst clean = DOMPurify.sanitize(dirty, {ADD_TAGS: ['my-tag']});\n\n// extend the existing array of allowed attributes and add my-attr to allow-list\nconst clean = DOMPurify.sanitize(dirty, {ADD_ATTR: ['my-attr']});\n\n// prohibit ARIA attributes, leave other safe HTML as is (default is true)\nconst clean = DOMPurify.sanitize(dirty, {ALLOW_ARIA_ATTR: false});\n\n// prohibit HTML5 data attributes, leave other safe HTML as is (default is true)\nconst clean = DOMPurify.sanitize(dirty, {ALLOW_DATA_ATTR: false});\n```\n\n### Control behavior relating to Custom Elements\n```js\n// DOMPurify allows to define rules for Custom Elements. When using the CUSTOM_ELEMENT_HANDLING\n// literal, it is possible to define exactly what elements you wish to allow (by default, none are allowed).\n//\n// The same goes for their attributes. By default, the built-in or configured allow.list is used.\n//\n// You can use a RegExp literal to specify what is allowed or a predicate, examples for both can be seen below.\n// The default values are very restrictive to prevent accidental XSS bypasses. Handle with great care!\n\nconst clean = DOMPurify.sanitize(\n    '<foo-bar baz=\"foobar\" forbidden=\"true\"></foo-bar><div is=\"foo-baz\"></div>',\n    {\n        CUSTOM_ELEMENT_HANDLING: {\n            tagNameCheck: null, // no custom elements are allowed\n            attributeNameCheck: null, // default / standard attribute allow-list is used\n            allowCustomizedBuiltInElements: false, // no customized built-ins allowed\n        },\n    }\n); // <div is=\"\"></div>\n\nconst clean = DOMPurify.sanitize(\n    '<foo-bar baz=\"foobar\" forbidden=\"true\"></foo-bar><div is=\"foo-baz\"></div>',\n    {\n        CUSTOM_ELEMENT_HANDLING: {\n            tagNameCheck: /^foo-/, // allow all tags starting with \"foo-\"\n            attributeNameCheck: /baz/, // allow all attributes containing \"baz\"\n            allowCustomizedBuiltInElements: true, // customized built-ins are allowed\n        },\n    }\n); // <foo-bar baz=\"foobar\"></foo-bar><div is=\"foo-baz\"></div>\n\nconst clean = DOMPurify.sanitize(\n    '<foo-bar baz=\"foobar\" forbidden=\"true\"></foo-bar><div is=\"foo-baz\"></div>',\n    {\n        CUSTOM_ELEMENT_HANDLING: {\n            tagNameCheck: (tagName) => tagName.match(/^foo-/), // allow all tags starting with \"foo-\"\n            attributeNameCheck: (attr) => attr.match(/baz/), // allow all containing \"baz\"\n            allowCustomizedBuiltInElements: true, // allow customized built-ins\n        },\n    }\n); // <foo-bar baz=\"foobar\"></foo-bar><div is=\"foo-baz\"></div>\n```\n### Control behavior relating to URI values\n```js\n// extend the existing array of elements that can use Data URIs\nconst clean = DOMPurify.sanitize(dirty, {ADD_DATA_URI_TAGS: ['a', 'area']});\n\n// extend the existing array of elements that are safe for URI-like values (be careful, XSS risk)\nconst clean = DOMPurify.sanitize(dirty, {ADD_URI_SAFE_ATTR: ['my-attr']});\n\n```\n### Control permitted attribute values\n```js\n// allow external protocol handlers in URL attributes (default is false, be careful, XSS risk)\n// by default only http, https, ftp, ftps, tel, mailto, callto, sms, cid and xmpp are allowed.\nconst clean = DOMPurify.sanitize(dirty, {ALLOW_UNKNOWN_PROTOCOLS: true});\n\n// allow specific protocols handlers in URL attributes via regex (default is false, be careful, XSS risk)\n// by default only http, https, ftp, ftps, tel, mailto, callto, sms, cid and xmpp are allowed.\n// Default RegExp: /^(?:(?:(?:f|ht)tps?|mailto|tel|callto|sms|cid|xmpp):|[^a-z]|[a-z+.\\-]+(?:[^a-z+.\\-:]|$))/i;\nconst clean = DOMPurify.sanitize(dirty, {ALLOWED_URI_REGEXP: /^(?:(?:(?:f|ht)tps?|mailto|tel|callto|sms|cid|xmpp|xxx):|[^a-z]|[a-z+.\\-]+(?:[^a-z+.\\-:]|$))/i});\n\n```\n### Influence the return-type\n```js\n// return a DOM HTMLBodyElement instead of an HTML string (default is false)\nconst clean = DOMPurify.sanitize(dirty, {RETURN_DOM: true});\n\n// return a DOM DocumentFragment instead of an HTML string (default is false)\nconst clean = DOMPurify.sanitize(dirty, {RETURN_DOM_FRAGMENT: true});\n\n// use the RETURN_TRUSTED_TYPE flag to turn on Trusted Types support if available\nconst clean = DOMPurify.sanitize(dirty, {RETURN_TRUSTED_TYPE: true}); // will return a TrustedHTML object instead of a string if possible\n\n// use a provided Trusted Types policy\nconst clean = DOMPurify.sanitize(dirty, {\n    // supplied policy must define createHTML and createScriptURL\n    TRUSTED_TYPES_POLICY: trustedTypes.createPolicy({\n        createHTML(s) { return s},\n        createScriptURL(s) { return s},\n    }\n});\n```\n### Influence how we sanitize\n```js\n// return entire document including <html> tags (default is false)\nconst clean = DOMPurify.sanitize(dirty, {WHOLE_DOCUMENT: true});\n\n// disable DOM Clobbering protection on output (default is true, handle with care, minor XSS risks here)\nconst clean = DOMPurify.sanitize(dirty, {SANITIZE_DOM: false});\n\n// enforce strict DOM Clobbering protection via namespace isolation (default is false)\n// when enabled, isolates the namespace of named properties (i.e., `id` and `name` attributes)\n// from JS variables by prefixing them with the string `user-content-`\nconst clean = DOMPurify.sanitize(dirty, {SANITIZE_NAMED_PROPS: true});\n\n// keep an element's content when the element is removed (default is true)\nconst clean = DOMPurify.sanitize(dirty, {KEEP_CONTENT: false});\n\n// glue elements like style, script or others to document.body and prevent unintuitive browser behavior in several edge-cases (default is false)\nconst clean = DOMPurify.sanitize(dirty, {FORCE_BODY: true});\n\n// remove all <a> elements under <p> elements that are removed\nconst clean = DOMPurify.sanitize(dirty, {FORBID_CONTENTS: ['a'], FORBID_TAGS: ['p']});\n\n// change the parser type so sanitized data is treated as XML and not as HTML, which is the default\nconst clean = DOMPurify.sanitize(dirty, {PARSER_MEDIA_TYPE: 'application/xhtml+xml'});\n```\n### Influence where we sanitize\n```js\n// use the IN_PLACE mode to sanitize a node \"in place\", which is much faster depending on how you use DOMPurify\nconst dirty = document.createElement('a');\ndirty.setAttribute('href', 'javascript:alert(1)');\n\nconst clean = DOMPurify.sanitize(dirty, {IN_PLACE: true}); // see https://github.com/cure53/DOMPurify/issues/288 for more info\n```\n\nThere is even [more examples here](https://github.com/cure53/DOMPurify/tree/main/demos#what-is-this), showing how you can run, customize and configure DOMPurify to fit your needs.\n\n## Persistent Configuration\n\nInstead of repeatedly passing the same configuration to `DOMPurify.sanitize`, you can use the `DOMPurify.setConfig` method. Your configuration will persist until your next call to `DOMPurify.setConfig`, or until you invoke `DOMPurify.clearConfig` to reset it. Remember that there is only one active configuration, which means once it is set, all extra configuration parameters passed to `DOMPurify.sanitize` are ignored.\n\n## Hooks\n\nDOMPurify allows you to augment its functionality by attaching one or more functions with the `DOMPurify.addHook` method to one of the following hooks:\n\n- `beforeSanitizeElements`\n- `uponSanitizeElement` (No 's' - called for every element)\n- `afterSanitizeElements`\n- `beforeSanitizeAttributes`\n- `uponSanitizeAttribute`\n- `afterSanitizeAttributes`\n- `beforeSanitizeShadowDOM`\n- `uponSanitizeShadowNode`\n- `afterSanitizeShadowDOM`\n\nIt passes the currently processed DOM node, when needed a literal with verified node and attribute data and the DOMPurify configuration to the callback. Check out the [MentalJS hook demo](https://github.com/cure53/DOMPurify/blob/main/demos/hooks-mentaljs-demo.html) to see how the API can be used nicely.\n\n_Example_:\n\n```js\nDOMPurify.addHook(\n  'uponSanitizeAttribute',\n  function (currentNode, hookEvent, config) {\n    // Do something with the current node\n    // You can also mutate hookEvent for current node (i.e. set hookEvent.forceKeepAttr = true)\n    // For other than 'uponSanitizeAttribute' hook types hookEvent equals to null\n  }\n);\n```\n\n## Removed Configuration\n\n| Option          | Since | Note                     |\n|-----------------|-------|--------------------------|\n| SAFE_FOR_JQUERY | 2.1.0 | No replacement required. |\n\n## Continuous Integration\n\nWe are currently using Github Actions in combination with BrowserStack. This gives us the possibility to confirm for each and every commit that all is going according to plan in all supported browsers. Check out the build logs here: https://github.com/cure53/DOMPurify/actions\n\nYou can further run local tests by executing `npm test`. The tests work fine with Node.js v0.6.2 and jsdom@8.5.0.\n\nAll relevant commits will be signed with the key `0x24BB6BF4` for additional security (since 8th of April 2016).\n\n### Development and contributing\n\n#### Installation (`npm i`)\n\nWe support `npm` officially. GitHub Actions workflow is configured to install dependencies using `npm`. When using deprecated version of `npm` we can not fully ensure the versions of installed dependencies which might lead to unanticipated problems.\n\n#### Scripts\n\nWe rely on npm run-scripts for integrating with our tooling infrastructure. We use ESLint as a pre-commit hook to ensure code consistency. Moreover, to ease formatting we use [prettier](https://github.com/prettier/prettier) while building the `/dist` assets happens through `rollup`.\n\nThese are our npm scripts:\n\n- `npm run dev` to start building while watching sources for changes\n- `npm run test` to run our test suite via jsdom and karma\n  - `test:jsdom` to only run tests through jsdom\n  - `test:karma` to only run tests through karma\n- `npm run lint` to lint the sources using ESLint (via xo)\n- `npm run format` to format our sources using prettier to ease to pass ESLint\n- `npm run build` to build our distribution assets minified and unminified as a UMD module\n  - `npm run build:umd` to only build an unminified UMD module\n  - `npm run build:umd:min` to only build a minified UMD module\n\nNote: all run scripts triggered via `npm run <script>`.\n\nThere are more npm scripts but they are mainly to integrate with CI or are meant to be \"private\" for instance to amend build distribution files with every commit.\n\n## Security Mailing List\n\nWe maintain a mailing list that notifies whenever a security-critical release of DOMPurify was published. This means, if someone found a bypass and we fixed it with a release (which always happens when a bypass was found) a mail will go out to that list. This usually happens within minutes or few hours after learning about a bypass. The list can be subscribed to here:\n\n[https://lists.ruhr-uni-bochum.de/mailman/listinfo/dompurify-security](https://lists.ruhr-uni-bochum.de/mailman/listinfo/dompurify-security)\n\nFeature releases will not be announced to this list.\n\n## Who contributed?\n\nMany people helped and help DOMPurify become what it is and need to be acknowledged here!\n\n[hash_kitten ](https://twitter.com/hash_kitten), [kevin_mizu ](https://twitter.com/kevin_mizu), [icesfont ](https://github.com/icesfont) [dcramer ](https://github.com/dcramer), [JGraph ](https://github.com/jgraph), [baekilda ](https://github.com/baekilda), [Healthchecks ](https://github.com/healthchecks), [Sentry ](https://github.com/getsentry), [jarrodldavis ](https://github.com/jarrodldavis), [CynegeticIO](https://github.com/CynegeticIO), [ssi02014 ](https://github.com/ssi02014), [GrantGryczan](https://github.com/GrantGryczan), [Lowdefy](https://twitter.com/lowdefy), [granlem](https://twitter.com/MaximeVeit), [oreoshake](https://github.com/oreoshake), [tdeekens ](https://github.com/tdeekens), [peernohell ](https://github.com/peernohell), [is2ei](https://github.com/is2ei), [SoheilKhodayari](https://github.com/SoheilKhodayari), [franktopel](https://github.com/franktopel), [NateScarlet](https://github.com/NateScarlet), [neilj](https://github.com/neilj), [fhemberger](https://github.com/fhemberger), [Joris-van-der-Wel](https://github.com/Joris-van-der-Wel), [ydaniv](https://github.com/ydaniv), [terjanq](https://twitter.com/terjanq), [filedescriptor](https://github.com/filedescriptor), [ConradIrwin](https://github.com/ConradIrwin), [gibson042](https://github.com/gibson042), [choumx](https://github.com/choumx), [0xSobky](https://github.com/0xSobky), [styfle](https://github.com/styfle), [koto](https://github.com/koto), [tlau88](https://github.com/tlau88), [strugee](https://github.com/strugee), [oparoz](https://github.com/oparoz), [mathiasbynens](https://github.com/mathiasbynens), [edg2s](https://github.com/edg2s), [dnkolegov](https://github.com/dnkolegov), [dhardtke](https://github.com/dhardtke), [wirehead](https://github.com/wirehead), [thorn0](https://github.com/thorn0), [styu](https://github.com/styu), [mozfreddyb](https://github.com/mozfreddyb), [mikesamuel](https://github.com/mikesamuel), [jorangreef](https://github.com/jorangreef), [jimmyhchan](https://github.com/jimmyhchan), [jameydeorio](https://github.com/jameydeorio), [jameskraus](https://github.com/jameskraus), [hyderali](https://github.com/hyderali), [hansottowirtz](https://github.com/hansottowirtz), [hackvertor](https://github.com/hackvertor), [freddyb](https://github.com/freddyb), [flavorjones](https://github.com/flavorjones), [djfarrelly](https://github.com/djfarrelly), [devd](https://github.com/devd), [camerondunford](https://github.com/camerondunford), [buu700](https://github.com/buu700), [buildog](https://github.com/buildog), [alabiaga](https://github.com/alabiaga), [Vector919](https://github.com/Vector919), [Robbert](https://github.com/Robbert), [GreLI](https://github.com/GreLI), [FuzzySockets](https://github.com/FuzzySockets), [ArtemBernatskyy](https://github.com/ArtemBernatskyy), [@garethheyes](https://twitter.com/garethheyes), [@shafigullin](https://twitter.com/shafigullin), [@mmrupp](https://twitter.com/mmrupp), [@irsdl](https://twitter.com/irsdl),[ShikariSenpai](https://github.com/ShikariSenpai), [ansjdnakjdnajkd](https://github.com/ansjdnakjdnajkd), [@asutherland](https://twitter.com/asutherland), [@mathias](https://twitter.com/mathias), [@cgvwzq](https://twitter.com/cgvwzq), [@robbertatwork](https://twitter.com/robbertatwork), [@giutro](https://twitter.com/giutro), [@CmdEngineer\\_](https://twitter.com/CmdEngineer_), [@avr4mit](https://twitter.com/avr4mit) and especially [@securitymb ](https://twitter.com/securitymb) & [@masatokinugawa ](https://twitter.com/masatokinugawa)\n\n## Testing powered by\n\n<a target=\"_blank\" href=\"https://www.browserstack.com/\"><img width=\"200\" src=\"https://github.com/cure53/DOMPurify/assets/6709482/f70be7eb-8fc4-41ea-9653-9d359235328f\"></a><br>\n\nAnd last but not least, thanks to [BrowserStack Open-Source Program](https://www.browserstack.com/open-source) for supporting this project with their services for free and delivering excellent, dedicated and very professional support on top of that.\n",
        "num_commits": 2030,
        "project_age_days": 3907,
        "project_created_at": "2014-02-17",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-23",
        "num_contributors": 99,
        "num_pull": 413,
        "num_issues": 999,
        "num_opening_issue": 2,
        "project_size(kB)": 10215,
        "num_stargazers": 13907,
        "num_watchers": 13907,
        "num_forks": 717,
        "num_subscribers": 153,
        "SecurityPolicy_created_at": "2019-10-10 17:06:46",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "2f1a97d06336816e69ca44e311c70ab0456efe6f",
                "url": "https://github.com/cure53/DOMPurify/commit/2f1a97d06336816e69ca44e311c70ab0456efe6f",
                "date": "2022-04-24 16:00:24"
            },
            {
                "commit_id": "e34ea757b5b7f28dbdbd001f4d402620e21276fb",
                "url": "https://github.com/cure53/DOMPurify/commit/e34ea757b5b7f28dbdbd001f4d402620e21276fb",
                "date": "2020-08-14 13:25:48"
            },
            {
                "commit_id": "73b5d46b1260b206949329a03511ff5adbc99bf0",
                "url": "https://github.com/cure53/DOMPurify/commit/73b5d46b1260b206949329a03511ff5adbc99bf0",
                "date": "2019-10-15 22:03:39"
            },
            {
                "commit_id": "78401705222c4e60d3fe41bf9c3fdd55f791e370",
                "url": "https://github.com/cure53/DOMPurify/commit/78401705222c4e60d3fe41bf9c3fdd55f791e370",
                "date": "2019-10-10 17:06:46"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email_external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "eventlet/eventlet",
        "project_url": "https://github.com/eventlet/eventlet",
        "SSF": {
            "date": "2024-10-29T19:25:52+07:00",
            "repo": {
                "name": "github.com/eventlet/eventlet",
                "commit": "8637820f468268ffb0b8504561ea4772de23fcdb"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.2,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Info: status check found to merge onto on branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 8,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 out of 30 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: massfidelity contributor org/company found, BirdseyeSoftware contributor org/company found, psf contributor org/company found, projg2 contributor org/company found, historymesh contributor org/company found, gr0und-s3ct0r contributor org/company found, openuado contributor org/company found, lambda labs contributor org/company found, red hat contributor org/company found, gentoo-mirror contributor org/company found, django contributor org/company found, jointakahe contributor org/company found, gevent contributor org/company found, deltachat contributor org/company found, Spacelog contributor org/company found, eventlet contributor org/company found, python contributor org/company found, redhatofficial contributor org/company found, nameko contributor org/company found, epio contributor org/company found, Moritz-Systems contributor org/company found, httplib2 contributor org/company found, red hat - openstack core developer contributor org/company found, van-clj contributor org/company found, http://twitter.com/tavisrudd/ contributor org/company found, intel contributor org/company found, gentoo contributor org/company found, NetBSD contributor org/company found, llvm contributor org/company found, conda-forge contributor org/company found, OpenGenus contributor org/company found, beaglecli contributor org/company found, pytest-dev contributor org/company found, async-email contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 34 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 6,
                    "reason": "1 commit(s) and 7 issue activity found in the last 90 days -- score normalized to 6",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/publish.yaml:17"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yaml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/docs.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yaml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/docs.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yaml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/publish.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yaml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/publish.yaml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish.yaml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/publish.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/style.yaml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/style.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/style.yaml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/style.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/style.yaml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/style.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/style.yaml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/style.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yaml:59: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/test.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yaml:61: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/test.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yaml:69: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/test.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yaml:78: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/test.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yaml:107: update your workflow using https://app.stepsecurity.io/secureworkflow/eventlet/eventlet/test.yaml/master?enable=pin",
                        "Warn: goCommand not pinned by hash: bin/bench-compare:73",
                        "Warn: pipCommand not pinned by hash: .github/workflows/docs.yaml:21",
                        "Warn: pipCommand not pinned by hash: .github/workflows/docs.yaml:22",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish.yaml:29",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish.yaml:30",
                        "Warn: pipCommand not pinned by hash: .github/workflows/style.yaml:39",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yaml:83",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yaml:110",
                        "Info:   0 out of  13 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   1 goCommand dependencies pinned",
                        "Info:   0 out of   7 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/style.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/test.yaml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/eventlet/eventlet/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nmaster branch and latest release get priority support. You should expect all known problems fixed in master.\n\nAll other released versions receive security updates per request.\nIf you use some old version and can not upgrade for any or no reason, ask for security update release, most likely you will get it.\n\n## Reporting a Vulnerability\n\nContact current maintainers. At 2021-03: temotor@gmail.com or https://t.me/temotor\nIf that doesn't work, open Github issue just asking for private communication channel.\n\nThis is volunteer maintained project, all issues are processed on best effort basis, no deadlines promised. Of course, security vulnerabilities get priority over regular issues.\n\nYou can expect fame in history or maybe you prefer anonymity - say what you prefer.\n\nThank you for responsible handling of security problems. Your attention and effort are appreciated.\n",
        "project_all_labels": [
            "asyncio",
            "bug",
            "changelog",
            "deprecation",
            "design",
            "doc",
            "feature",
            "feature-dns",
            "feature-psycopg",
            "feature-tls",
            "feature-websocket",
            "feature-wsgi",
            "feature-zmq",
            "governance",
            "greenthreads",
            "importance-bug",
            "importance-enhancement",
            "important",
            "infra",
            "invalid",
            "need-contributor",
            "need-feedback",
            "need-test",
            "platform-bsd",
            "platform-osx",
            "platform-python2",
            "platform-python3",
            "platform-python3.10+",
            "platform-windows",
            "Python3.12_compat",
            "Python3.13_compat",
            "release",
            "resolution-duplicate",
            "resolution-question",
            "resolution-wontfix",
            "security",
            "tests",
            "tracing",
            "urgent"
        ],
        "README_content": "Warning\n=======\n\n**New usages of eventlet are now heavily discouraged! Please read the\nfollowing.**\n\nEventlet was created almost 18 years ago, at a time where async\nfeatures were absent from the CPython stdlib. With time eventlet evolved and\nCPython too, but since several years the maintenance activity of eventlet\ndecreased leading to a growing gap between eventlet and the CPython\nimplementation.\n\nThis gap is now too high and can lead you to unexpected side effects and bugs\nin your applications.\n\nEventlet now follows a new maintenance policy. **Only maintenance for\nstability and bug fixing** will be provided. **No new features will be\naccepted**, except those related to the asyncio migration. **Usages in new\nprojects are discouraged**. **Our goal is to plan the retirement of eventlet**\nand to give you ways to move away from eventlet.\n\nIf you are looking for a library to manage async network programming,\nand if you do not yet use eventlet, then, we encourage you to use `asyncio`_,\nwhich is the official async library of the CPython stdlib.\n\nIf you already use eventlet, we hope to enable migration to asyncio for some use\ncases; see `Migrating off of Eventlet`_. Only new features related to the migration\nsolution will be accepted.\n\nIf you have questions concerning maintenance goals or concerning\nthe migration do not hesitate to `open a new issue`_, we will be happy to\nanswer them.\n\n.. _asyncio: https://docs.python.org/3/library/asyncio.html\n.. _open a new issue: https://github.com/eventlet/eventlet/issues/new\n.. _Migrating off of Eventlet: https://eventlet.readthedocs.io/en/latest/asyncio/migration.html#migration-guide\n\nEventlet\n========\n\n.. image:: https://img.shields.io/pypi/v/eventlet\n    :target: https://pypi.org/project/eventlet/\n\n.. image:: https://img.shields.io/github/actions/workflow/status/eventlet/eventlet/test.yaml?branch=master\n    :target: https://github.com/eventlet/eventlet/actions?query=workflow%3Atest+branch%3Amaster\n\n.. image:: https://codecov.io/gh/eventlet/eventlet/branch/master/graph/badge.svg\n    :target: https://codecov.io/gh/eventlet/eventlet\n\n\nEventlet is a concurrent networking library for Python that allows you to change how you run your code, not how you write it.\n\nIt uses epoll or libevent for highly scalable non-blocking I/O.  Coroutines ensure that the developer uses a blocking style of programming that is similar to threading, but provide the benefits of non-blocking I/O.  The event dispatch is implicit, which means you can easily use Eventlet from the Python interpreter, or as a small part of a larger application.\n\nIt's easy to get started using Eventlet, and easy to convert existing\napplications to use it.  Start off by looking at the `examples`_,\n`common design patterns`_, and the list of `basic API primitives`_.\n\n.. _examples: https://eventlet.readthedocs.io/en/latest/examples.html\n.. _common design patterns: https://eventlet.readthedocs.io/en/latest/design_patterns.html\n.. _basic API primitives: https://eventlet.readthedocs.io/en/latest/basic_usage.html\n\n\nGetting Eventlet\n================\n\nThe easiest way to get Eventlet is to use pip::\n\n  pip install -U eventlet\n\nTo install latest development version once::\n\n  pip install -U https://github.com/eventlet/eventlet/archive/master.zip\n\n\nBuilding the Docs Locally\n=========================\n\nTo build a complete set of HTML documentation::\n\n  tox -e docs\n\nThe built html files can be found in doc/build/html afterward.\n\nSupported Python versions\n=========================\n\nPython 3.7-3.12 are currently supported.\n",
        "num_commits": 2547,
        "project_age_days": 4340,
        "project_created_at": "2012-12-11",
        "latest_updated_at": "2024-10-26",
        "latest_pushed_at": "2024-09-12",
        "num_contributors": 140,
        "num_pull": 437,
        "num_issues": 982,
        "num_opening_issue": 222,
        "project_size(kB)": 9238,
        "num_stargazers": 1245,
        "num_watchers": 1245,
        "num_forks": 324,
        "num_subscribers": 63,
        "SecurityPolicy_created_at": "2021-03-31 20:44:04",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "71b76bfc5166050dc333c72ead6b51a8933061e7",
                "url": "https://github.com/eventlet/eventlet/commit/71b76bfc5166050dc333c72ead6b51a8933061e7",
                "date": "2021-03-31 20:44:04"
            }
        ],
        "project_security_labels": [
            "security"
        ],
        "security_issues": [
            {
                "url": "https://github.com/eventlet/eventlet/pull/916",
                "title": "for eventlet issue 913 - Dnspython 2.6.0rc1 dns.query.udp() API chang",
                "labels": [
                    "security"
                ],
                "user": "kelvin-j-li",
                "issue_author_association": "CONTRIBUTOR",
                "number": 916,
                "id": 2134296152,
                "state": "closed",
                "project_created_at": "2024-02-14T12:56:50Z",
                "closed_at": "2024-02-19T13:42:27Z",
                "body": "e heads-up #913",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) Report\nAttention: `12 lines` in your changes are missing coverage. Please review.\n> Comparison is base [(`b6f6e7c`)](https://app.codecov.io/gh/eventlet/eventlet/commit/b6f6e7c3a81853c2bf380f48bc0da7b894a3a903?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) 56% compared to head [(`e21efb1`)](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) 56%.\n\n| [Files](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | Patch % | Lines |\n|---|---|---|\n| [eventlet/support/greendns.py](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet#diff-ZXZlbnRsZXQvc3VwcG9ydC9ncmVlbmRucy5weQ==) | 33% | [10 Missing and 2 partials :warning: ](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) |\n\n<details><summary>Additional details and impacted files</summary>\n\n\n```diff\n@@          Coverage Diff          @@\n##           master   #916   +/-   ##\n=====================================\n- Coverage      56%    56%   -1%     \n=====================================\n  Files          89     89           \n  Lines        9718   9728   +10     \n  Branches     1809   1812    +3     \n=====================================\n  Hits         5461   5461           \n- Misses       3883   3892    +9     \n- Partials      374    375    +1     \n```\n\n| [Flag](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flags&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | Coverage  | |\n|---|---|---|\n| [ipv6](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `23% <22%> (-1%)` | :arrow_down: |\n| [py310asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py310epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py310poll](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py310selects](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py311asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py311epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py312asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `50% <22%> (-1%)` | :arrow_down: |\n| [py312epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <22%> (-1%)` | :arrow_down: |\n| [py37asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `50% <22%> (-1%)` | :arrow_down: |\n| [py37epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <22%> (-1%)` | :arrow_down: |\n| [py38asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <22%> (-1%)` | :arrow_down: |\n| [py38epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py38openssl](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <22%> (-1%)` | :arrow_down: |\n| [py38poll](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py38selects](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py39asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <22%> (-1%)` | :arrow_down: |\n| [py39dnspython1](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <22%> (-1%)` | :arrow_down: |\n| [py39epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py39poll](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py39selects](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n\nFlags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet#carryforward-flags-in-the-pull-request-comment) to find out more.\n\n\n</details>\n\n[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet).   \n:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet).\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-14T15:54:57Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1944116544"
                    },
                    {
                        "body": "@kelvin-j-li do you plan to propose related unit test (see my previous suggestion), or can I merge this patch?",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-16T10:32:25Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1948128668"
                    },
                    {
                        "body": "This fix is not enough, and the change at line 837 is a regression without the updated receive code.  The main fix for the CVE are [the changes to receive_udp in this commit](https://github.com/rthalley/dnspython/commit/f66e25b5f549acf66d1fb6ead13eb3cff7d09af3)\r\n\r\nI don't have a good unit test for these as they involve receiving various invalid things and ignoring them.",
                        "user": "rthalley",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-16T13:04:35Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1948353751"
                    },
                    {
                        "body": "I think eventlet changes should look a lot [like this branch](https://github.com/rthalley/eventlet/tree/tudoor)\r\n\r\nAlso, I added some unit tests to dnspython, see class [IgnoreErrors](https://github.com/rthalley/dnspython/blob/master/tests/test_query.py) if you want to adapt them.",
                        "user": "rthalley",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-16T15:30:15Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1948624734"
                    },
                    {
                        "body": "@rthalley: Thanks for details \r\n@kelvin-j-li: I let you acknowledge Bob's suggestions.",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-16T16:50:53Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1948870731"
                    },
                    {
                        "body": "> @rthalley: Thanks for details @kelvin-j-li: I let you acknowledge Bob's suggestions.\r\n\r\nhi Herv / Bob:\r\nyes, I agree with @rthalley. \r\n\r\nDo you prefer me to copy the code from https://github.com/rthalley/eventlet/tree/tudoor to this PR? I am ok with close this PR and use Bob's change/PR instead from https://github.com/rthalley/eventlet/tree/tudoor\r\n\r\nMany thanks!\r\n\r\n",
                        "user": "kelvin-j-li",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-19T01:36:32Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1951548007"
                    },
                    {
                        "body": "Hi @kelvin-j-li \r\n\r\nWe have to use the latest version of the Bob's branch with the `Truncated` changes included. AFAIK Bob designed a fix but do not proposed a pull request. If Bob is ok with copying his changes, you could copy his branch and then co-author the fix, else Bob could simply propose a pull request. \r\n\r\n@rthalley do you have any preference?\r\n  ",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-19T10:02:51Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1952099761"
                    },
                    {
                        "body": "I didn't do a PR in part because I don't have time to write the tests; I mostly wanted to show the sort of thing that is needed to keep the CVE fix.   I'm ok with just copying from my branch.",
                        "user": "rthalley",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-19T12:57:24Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1952398437"
                    },
                    {
                        "body": "hi @4383 / @rthalley,\r\nI had copy Bob fix into this PR:\r\n\r\ncfe9b7b - (HEAD -> master, origin/master, origin/HEAD) Copied the complete fix for (CVE-2023-29483) and handling of truncated exceptions in greendns.py provided by Bob Halley from https://github.com/rthalley/eventlet/tree/tudoor\r\n\r\nthanks! ",
                        "user": "kelvin-j-li",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-19T13:18:55Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1952435152"
                    },
                    {
                        "body": "Thanks guys (@kelvin-j-li, @rthalley) for the collaboration.\r\n\r\nThis patch LGTM, I'm going to merge it.",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-19T13:37:39Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1952472285"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/eventlet/eventlet/pulls/916",
                    "merged_at": "2024-02-19T13:42:27Z"
                }
            },
            {
                "url": "https://github.com/eventlet/eventlet/pull/826",
                "title": "Fix security issue related to RFC 9112",
                "labels": [
                    "important",
                    "urgent",
                    "security"
                ],
                "user": "4383",
                "issue_author_association": "MEMBER",
                "number": 826,
                "id": 2037889523,
                "state": "closed",
                "project_created_at": "2023-12-12T14:36:56Z",
                "closed_at": "2024-01-11T15:05:25Z",
                "body": "Reject requests which contains headers `content-length` and `transfer-encoding` at the same time.\r\n\r\nThat's not allowed by RFC 9112 and that could lead to potential security attacks.\r\n\r\nhttps://www.rfc-editor.org/rfc/rfc9112#section-6.1-15\r\n\r\nThis is an extract of the RFC:\r\n\r\n> A server MAY reject a request that contains both Content-Length and\r\n> Transfer-Encoding or process such a request in accordance with the\r\n> Transfer-Encoding alone. Regardless, the server MUST close the\r\n> connection after responding to such a request to avoid the potential\r\n> attacks.\r\n\r\n> A server or client that receives an HTTP/1.0 message containing\r\n> a Transfer-Encoding header field MUST treat the message as if the\r\n> framing is faulty, even if a Content-Length is present, and close the\r\n> connection after processing the message. The message sender might have\r\n> retained a portion of the message, in buffer, that could be\r\n> misinterpreted by further use of the connection.\r\n\r\nThe following request would lead to this scenario:\r\n\r\n```\r\nPOST / HTTP/1.1\r\nHost: a.com\r\nTransfer-Encoding: chunked\r\nContent-Length: 0\r\nContent-Type: application/x-\"##-form-urlencoded\r\n14\r\nid=1'or sleep(1);###\r\n0\r\n```\r\n\r\nWith these changes, when this kind of request is received the connection is closed and an error 400 is returned.\r\n\r\nThis scenario can be tested by using the following process:\r\n\r\n1. run a wsgi server either: \r\n- by using the wsgi sample in official examples (http://eventlet.net/doc/examples.html#wsgi-server) \r\n- or by using my previous patch (https://github.com/eventlet/eventlet/pull/825) that allow you to run wsgi server from the command line (`$ eventlet_wsgi_example`)\r\n2. send the following HTTP request to the running server:\r\n```\r\ncurl -d \"param1=value1&param2=value2\" -X POST -H 'Transfer-Encoding:\r\nchunked' -H 'Content-Length: 0' --http1.1 http://0.0.0.0:8090 -i\r\n```\r\n\r\nThe previous curl command display returned headers and status code. You can observe that now, with these changes, bad requests are rejected.\r\n\r\n These changes also remove `content-lenght` from the `chunk` tests to avoid reflecting something that's not a bad practice.\r\n\r\nThis security issue was originally discovered by Keran Mu (mkr22@mails.tsinghua.edu.cn) and Jianjun Chen\r\n(jianjun@tsinghua.edu.cn), from Tsinghua University and Zhongguancun Laboratory\r\n\r\nThanks to them for raising our attention about this security problem.",
                "comments": [
                    {
                        "body": "> From the RFC:\r\n> \r\n> > Early implementations of Transfer-Encoding would occasionally send both a chunked transfer coding for message framing and an estimated Content-Length header field for use by progress bars. This is why Transfer-Encoding is defined as overriding Content-Length, as opposed to them being mutually incompatible.\r\n> \r\n> Given that, should we maybe make this in some way configurable, but defaulting to the more-secure behavior? That would allow us an escape hatch for working with old clients that cannot be updated (for example, because their source code may have been lost), particularly if the operator and/or application developer know that the service will not be forwarding any messages.\r\n\r\nTotally agree with the \"configurable but defaulting to the more secure behavior\" path. I'll rework my patch to introduce an option.\r\n \r\n> \r\n> I'd also like to note that since we're relying on stdlib's HTTP parsing, there are still cases where a client may send both headers but we don't 400. See also: [python/cpython#81274](https://github.com/python/cpython/issues/81274) and #574 (which unfortunately I never properly followed up on).\r\n\r\nThanks for the heads up.\r\n\r\n> \r\n> That said, I agree, [the danger is certainly real](https://bugs.launchpad.net/swift/+bug/1840507).\r\n\r\n",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-12-14T10:00:11Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1855538257"
                    },
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) Report\nAttention: `6 lines` in your changes are missing coverage. Please review.\n> Comparison is base [(`dbb411d`)](https://app.codecov.io/gh/eventlet/eventlet/commit/dbb411d6a8531c52bf9507297e8d844f52d1d8ef?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) 54% compared to head [(`457e760`)](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) 54%.\n\n| [Files](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | Patch % | Lines |\n|---|---|---|\n| [eventlet/wsgi.py](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet#diff-ZXZlbnRsZXQvd3NnaS5weQ==) | 33% | [5 Missing and 1 partial :warning: ](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) |\n\n<details><summary>Additional details and impacted files</summary>\n\n\n```diff\n@@          Coverage Diff          @@\n##           master   #826   +/-   ##\n=====================================\n- Coverage      54%    54%   -1%     \n=====================================\n  Files          88     88           \n  Lines        9744   9752    +8     \n  Branches     1814   1816    +2     \n=====================================\n- Hits         5296   5295    -1     \n- Misses       4082   4089    +7     \n- Partials      366    368    +2     \n```\n\n| [Flag](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flags&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | Coverage  | |\n|---|---|---|\n| [ipv6](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `22% <11%> (-1%)` | :arrow_down: |\n| [py310epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <33%> (-1%)` | :arrow_down: |\n| [py310poll](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <33%> (-1%)` | :arrow_down: |\n| [py310selects](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py311epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <33%> (-1%)` | :arrow_down: |\n| [py312epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `50% <33%> (-1%)` | :arrow_down: |\n| [py37epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `50% <33%> (-1%)` | :arrow_down: |\n| [py38epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py38openssl](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <33%> (-1%)` | :arrow_down: |\n| [py38poll](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py38selects](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py39dnspython1](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <33%> (-1%)` | :arrow_down: |\n| [py39epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py39poll](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py39selects](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n\nFlags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet#carryforward-flags-in-the-pull-request-comment) to find out more.\n\n\n</details>\n\n[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet).   \n:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet).\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-12-14T11:13:46Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1855654256"
                    },
                    {
                        "body": "codecov is a bit flaky...",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-12-18T16:40:03Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1860998056"
                    },
                    {
                        "body": "@tipabu is the latest version is ok for you?",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-01-08T10:55:23Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1880777407"
                    },
                    {
                        "body": "If no answer in a few days should probably just proceed, given it's a security issue.",
                        "user": "itamarst",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-01-09T16:55:12Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1883424382"
                    },
                    {
                        "body": "> If no answer in a few days should probably just proceed, given it's a security issue.\r\n\r\nyes",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-01-10T15:22:21Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1885054329"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/eventlet/eventlet/pulls/826",
                    "merged_at": "2024-01-11T15:05:25Z"
                }
            }
        ],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 2,
        "num_security_issue_and_pull": 2,
        "security_issues_created_after_policy": [
            {
                "url": "https://github.com/eventlet/eventlet/pull/916",
                "title": "for eventlet issue 913 - Dnspython 2.6.0rc1 dns.query.udp() API chang",
                "labels": [
                    "security"
                ],
                "user": "kelvin-j-li",
                "issue_author_association": "CONTRIBUTOR",
                "number": 916,
                "id": 2134296152,
                "state": "closed",
                "project_created_at": "2024-02-14T12:56:50Z",
                "closed_at": "2024-02-19T13:42:27Z",
                "body": "e heads-up #913",
                "comments": [
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) Report\nAttention: `12 lines` in your changes are missing coverage. Please review.\n> Comparison is base [(`b6f6e7c`)](https://app.codecov.io/gh/eventlet/eventlet/commit/b6f6e7c3a81853c2bf380f48bc0da7b894a3a903?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) 56% compared to head [(`e21efb1`)](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) 56%.\n\n| [Files](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | Patch % | Lines |\n|---|---|---|\n| [eventlet/support/greendns.py](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet#diff-ZXZlbnRsZXQvc3VwcG9ydC9ncmVlbmRucy5weQ==) | 33% | [10 Missing and 2 partials :warning: ](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) |\n\n<details><summary>Additional details and impacted files</summary>\n\n\n```diff\n@@          Coverage Diff          @@\n##           master   #916   +/-   ##\n=====================================\n- Coverage      56%    56%   -1%     \n=====================================\n  Files          89     89           \n  Lines        9718   9728   +10     \n  Branches     1809   1812    +3     \n=====================================\n  Hits         5461   5461           \n- Misses       3883   3892    +9     \n- Partials      374    375    +1     \n```\n\n| [Flag](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flags&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | Coverage  | |\n|---|---|---|\n| [ipv6](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `23% <22%> (-1%)` | :arrow_down: |\n| [py310asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py310epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py310poll](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py310selects](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py311asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py311epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py312asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `50% <22%> (-1%)` | :arrow_down: |\n| [py312epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <22%> (-1%)` | :arrow_down: |\n| [py37asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `50% <22%> (-1%)` | :arrow_down: |\n| [py37epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <22%> (-1%)` | :arrow_down: |\n| [py38asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <22%> (-1%)` | :arrow_down: |\n| [py38epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py38openssl](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <22%> (-1%)` | :arrow_down: |\n| [py38poll](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py38selects](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py39asyncio](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <22%> (-1%)` | :arrow_down: |\n| [py39dnspython1](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <22%> (-1%)` | :arrow_down: |\n| [py39epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py39poll](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n| [py39selects](https://app.codecov.io/gh/eventlet/eventlet/pull/916/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <22%> (-1%)` | :arrow_down: |\n\nFlags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet#carryforward-flags-in-the-pull-request-comment) to find out more.\n\n\n</details>\n\n[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/eventlet/eventlet/pull/916?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet).   \n:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet).\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-14T15:54:57Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1944116544"
                    },
                    {
                        "body": "@kelvin-j-li do you plan to propose related unit test (see my previous suggestion), or can I merge this patch?",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-16T10:32:25Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1948128668"
                    },
                    {
                        "body": "This fix is not enough, and the change at line 837 is a regression without the updated receive code.  The main fix for the CVE are [the changes to receive_udp in this commit](https://github.com/rthalley/dnspython/commit/f66e25b5f549acf66d1fb6ead13eb3cff7d09af3)\r\n\r\nI don't have a good unit test for these as they involve receiving various invalid things and ignoring them.",
                        "user": "rthalley",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-16T13:04:35Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1948353751"
                    },
                    {
                        "body": "I think eventlet changes should look a lot [like this branch](https://github.com/rthalley/eventlet/tree/tudoor)\r\n\r\nAlso, I added some unit tests to dnspython, see class [IgnoreErrors](https://github.com/rthalley/dnspython/blob/master/tests/test_query.py) if you want to adapt them.",
                        "user": "rthalley",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-16T15:30:15Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1948624734"
                    },
                    {
                        "body": "@rthalley: Thanks for details \r\n@kelvin-j-li: I let you acknowledge Bob's suggestions.",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-16T16:50:53Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1948870731"
                    },
                    {
                        "body": "> @rthalley: Thanks for details @kelvin-j-li: I let you acknowledge Bob's suggestions.\r\n\r\nhi Herv / Bob:\r\nyes, I agree with @rthalley. \r\n\r\nDo you prefer me to copy the code from https://github.com/rthalley/eventlet/tree/tudoor to this PR? I am ok with close this PR and use Bob's change/PR instead from https://github.com/rthalley/eventlet/tree/tudoor\r\n\r\nMany thanks!\r\n\r\n",
                        "user": "kelvin-j-li",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-19T01:36:32Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1951548007"
                    },
                    {
                        "body": "Hi @kelvin-j-li \r\n\r\nWe have to use the latest version of the Bob's branch with the `Truncated` changes included. AFAIK Bob designed a fix but do not proposed a pull request. If Bob is ok with copying his changes, you could copy his branch and then co-author the fix, else Bob could simply propose a pull request. \r\n\r\n@rthalley do you have any preference?\r\n  ",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-19T10:02:51Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1952099761"
                    },
                    {
                        "body": "I didn't do a PR in part because I don't have time to write the tests; I mostly wanted to show the sort of thing that is needed to keep the CVE fix.   I'm ok with just copying from my branch.",
                        "user": "rthalley",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-19T12:57:24Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1952398437"
                    },
                    {
                        "body": "hi @4383 / @rthalley,\r\nI had copy Bob fix into this PR:\r\n\r\ncfe9b7b - (HEAD -> master, origin/master, origin/HEAD) Copied the complete fix for (CVE-2023-29483) and handling of truncated exceptions in greendns.py provided by Bob Halley from https://github.com/rthalley/eventlet/tree/tudoor\r\n\r\nthanks! ",
                        "user": "kelvin-j-li",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-19T13:18:55Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1952435152"
                    },
                    {
                        "body": "Thanks guys (@kelvin-j-li, @rthalley) for the collaboration.\r\n\r\nThis patch LGTM, I'm going to merge it.",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-19T13:37:39Z",
                        "url": "https://github.com/eventlet/eventlet/pull/916#issuecomment-1952472285"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/eventlet/eventlet/pulls/916",
                    "merged_at": "2024-02-19T13:42:27Z"
                }
            },
            {
                "url": "https://github.com/eventlet/eventlet/pull/826",
                "title": "Fix security issue related to RFC 9112",
                "labels": [
                    "important",
                    "urgent",
                    "security"
                ],
                "user": "4383",
                "issue_author_association": "MEMBER",
                "number": 826,
                "id": 2037889523,
                "state": "closed",
                "project_created_at": "2023-12-12T14:36:56Z",
                "closed_at": "2024-01-11T15:05:25Z",
                "body": "Reject requests which contains headers `content-length` and `transfer-encoding` at the same time.\r\n\r\nThat's not allowed by RFC 9112 and that could lead to potential security attacks.\r\n\r\nhttps://www.rfc-editor.org/rfc/rfc9112#section-6.1-15\r\n\r\nThis is an extract of the RFC:\r\n\r\n> A server MAY reject a request that contains both Content-Length and\r\n> Transfer-Encoding or process such a request in accordance with the\r\n> Transfer-Encoding alone. Regardless, the server MUST close the\r\n> connection after responding to such a request to avoid the potential\r\n> attacks.\r\n\r\n> A server or client that receives an HTTP/1.0 message containing\r\n> a Transfer-Encoding header field MUST treat the message as if the\r\n> framing is faulty, even if a Content-Length is present, and close the\r\n> connection after processing the message. The message sender might have\r\n> retained a portion of the message, in buffer, that could be\r\n> misinterpreted by further use of the connection.\r\n\r\nThe following request would lead to this scenario:\r\n\r\n```\r\nPOST / HTTP/1.1\r\nHost: a.com\r\nTransfer-Encoding: chunked\r\nContent-Length: 0\r\nContent-Type: application/x-\"##-form-urlencoded\r\n14\r\nid=1'or sleep(1);###\r\n0\r\n```\r\n\r\nWith these changes, when this kind of request is received the connection is closed and an error 400 is returned.\r\n\r\nThis scenario can be tested by using the following process:\r\n\r\n1. run a wsgi server either: \r\n- by using the wsgi sample in official examples (http://eventlet.net/doc/examples.html#wsgi-server) \r\n- or by using my previous patch (https://github.com/eventlet/eventlet/pull/825) that allow you to run wsgi server from the command line (`$ eventlet_wsgi_example`)\r\n2. send the following HTTP request to the running server:\r\n```\r\ncurl -d \"param1=value1&param2=value2\" -X POST -H 'Transfer-Encoding:\r\nchunked' -H 'Content-Length: 0' --http1.1 http://0.0.0.0:8090 -i\r\n```\r\n\r\nThe previous curl command display returned headers and status code. You can observe that now, with these changes, bad requests are rejected.\r\n\r\n These changes also remove `content-lenght` from the `chunk` tests to avoid reflecting something that's not a bad practice.\r\n\r\nThis security issue was originally discovered by Keran Mu (mkr22@mails.tsinghua.edu.cn) and Jianjun Chen\r\n(jianjun@tsinghua.edu.cn), from Tsinghua University and Zhongguancun Laboratory\r\n\r\nThanks to them for raising our attention about this security problem.",
                "comments": [
                    {
                        "body": "> From the RFC:\r\n> \r\n> > Early implementations of Transfer-Encoding would occasionally send both a chunked transfer coding for message framing and an estimated Content-Length header field for use by progress bars. This is why Transfer-Encoding is defined as overriding Content-Length, as opposed to them being mutually incompatible.\r\n> \r\n> Given that, should we maybe make this in some way configurable, but defaulting to the more-secure behavior? That would allow us an escape hatch for working with old clients that cannot be updated (for example, because their source code may have been lost), particularly if the operator and/or application developer know that the service will not be forwarding any messages.\r\n\r\nTotally agree with the \"configurable but defaulting to the more secure behavior\" path. I'll rework my patch to introduce an option.\r\n \r\n> \r\n> I'd also like to note that since we're relying on stdlib's HTTP parsing, there are still cases where a client may send both headers but we don't 400. See also: [python/cpython#81274](https://github.com/python/cpython/issues/81274) and #574 (which unfortunately I never properly followed up on).\r\n\r\nThanks for the heads up.\r\n\r\n> \r\n> That said, I agree, [the danger is certainly real](https://bugs.launchpad.net/swift/+bug/1840507).\r\n\r\n",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-12-14T10:00:11Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1855538257"
                    },
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) Report\nAttention: `6 lines` in your changes are missing coverage. Please review.\n> Comparison is base [(`dbb411d`)](https://app.codecov.io/gh/eventlet/eventlet/commit/dbb411d6a8531c52bf9507297e8d844f52d1d8ef?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) 54% compared to head [(`457e760`)](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) 54%.\n\n| [Files](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | Patch % | Lines |\n|---|---|---|\n| [eventlet/wsgi.py](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet#diff-ZXZlbnRsZXQvd3NnaS5weQ==) | 33% | [5 Missing and 1 partial :warning: ](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) |\n\n<details><summary>Additional details and impacted files</summary>\n\n\n```diff\n@@          Coverage Diff          @@\n##           master   #826   +/-   ##\n=====================================\n- Coverage      54%    54%   -1%     \n=====================================\n  Files          88     88           \n  Lines        9744   9752    +8     \n  Branches     1814   1816    +2     \n=====================================\n- Hits         5296   5295    -1     \n- Misses       4082   4089    +7     \n- Partials      366    368    +2     \n```\n\n| [Flag](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flags&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | Coverage  | |\n|---|---|---|\n| [ipv6](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `22% <11%> (-1%)` | :arrow_down: |\n| [py310epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <33%> (-1%)` | :arrow_down: |\n| [py310poll](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <33%> (-1%)` | :arrow_down: |\n| [py310selects](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py311epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `53% <33%> (-1%)` | :arrow_down: |\n| [py312epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `50% <33%> (-1%)` | :arrow_down: |\n| [py37epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `50% <33%> (-1%)` | :arrow_down: |\n| [py38epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py38openssl](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <33%> (-1%)` | :arrow_down: |\n| [py38poll](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py38selects](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py39dnspython1](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `51% <33%> (-1%)` | :arrow_down: |\n| [py39epolls](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py39poll](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n| [py39selects](https://app.codecov.io/gh/eventlet/eventlet/pull/826/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet) | `52% <33%> (-1%)` | :arrow_down: |\n\nFlags with carried forward coverage won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet#carryforward-flags-in-the-pull-request-comment) to find out more.\n\n\n</details>\n\n[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/eventlet/eventlet/pull/826?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet).   \n:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=eventlet).\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-12-14T11:13:46Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1855654256"
                    },
                    {
                        "body": "codecov is a bit flaky...",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-12-18T16:40:03Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1860998056"
                    },
                    {
                        "body": "@tipabu is the latest version is ok for you?",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-01-08T10:55:23Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1880777407"
                    },
                    {
                        "body": "If no answer in a few days should probably just proceed, given it's a security issue.",
                        "user": "itamarst",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-01-09T16:55:12Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1883424382"
                    },
                    {
                        "body": "> If no answer in a few days should probably just proceed, given it's a security issue.\r\n\r\nyes",
                        "user": "4383",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-01-10T15:22:21Z",
                        "url": "https://github.com/eventlet/eventlet/pull/826#issuecomment-1885054329"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/eventlet/eventlet/pulls/826",
                    "merged_at": "2024-01-11T15:05:25Z"
                }
            }
        ],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 2,
        "has_generic_policy": true
    },
    {
        "project_name": "appwrite/sdk-for-cli",
        "project_url": "https://github.com/appwrite/sdk-for-cli",
        "SSF": {
            "date": "2024-10-29T21:26:31+07:00",
            "repo": {
                "name": "github.com/appwrite/sdk-for-cli",
                "commit": "7773439c6ea2691ec93e147b15a0f339b99840a5"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.4,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch '1.6.x'",
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Warn: no status checks found to merge onto branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 1,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 4,
                    "reason": "2 out of 5 merged PRs checked by a CI test -- score normalized to 4",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: emirates contributor org/company found, lohanitech contributor org/company found, popupbits contributor org/company found, utopia-php contributor org/company found, fossasia contributor org/company found, acmbpdc contributor org/company found, EddieHubCommunity contributor org/company found, appwrite popupbits contributor org/company found, appwrite contributor org/company found, appwrite-labs contributor org/company found, open-runtimes contributor org/company found, collective contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 12 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.md:0",
                        "Info: FSF or OSI recognized license: BSD 3-Clause \"New\" or \"Revised\" License: LICENSE.md:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "17 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/npm-publish.yml:6"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/npm-publish.yml:9: update your workflow using https://app.stepsecurity.io/secureworkflow/appwrite/sdk-for-cli/npm-publish.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/npm-publish.yml:10: update your workflow using https://app.stepsecurity.io/secureworkflow/appwrite/sdk-for-cli/npm-publish.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/npm-publish.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/appwrite/sdk-for-cli/npm-publish.yml/master?enable=pin",
                        "Warn: npmCommand not pinned by hash: .github/workflows/npm-publish.yml:27",
                        "Info:   0 out of   2 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   1 npmCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/appwrite/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/appwrite/.github/SECURITY.md:1",
                        "Warn: One or no descriptive hints of disclosure, vulnerability, and/or timelines in security policy",
                        "Info: Found text in security policy: github.com/appwrite/.github/SECURITY.md:1"
                    ],
                    "score": 9,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact 6.1.0 not signed: https://api.github.com/repos/appwrite/sdk-for-cli/releases/179863541",
                        "Warn: release artifact 6.0.0 not signed: https://api.github.com/repos/appwrite/sdk-for-cli/releases/172155073",
                        "Warn: release artifact 6.0.0-rc.9 not signed: https://api.github.com/repos/appwrite/sdk-for-cli/releases/171657088",
                        "Warn: release artifact 6.1.0 does not have provenance: https://api.github.com/repos/appwrite/sdk-for-cli/releases/179863541",
                        "Warn: release artifact 6.0.0 does not have provenance: https://api.github.com/repos/appwrite/sdk-for-cli/releases/172155073",
                        "Warn: release artifact 6.0.0-rc.9 does not have provenance: https://api.github.com/repos/appwrite/sdk-for-cli/releases/171657088"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/autoclose.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/npm-publish.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/appwrite/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Reporting a Vulnerability\n\nFor security issues, kindly email us at security@appwrite.io instead of posting a public issue in GitHub.\n",
        "project_all_labels": [
            "bug",
            "documentation",
            "duplicate",
            "enhancement",
            "good first issue",
            "hacktoberfest",
            "hacktoberfest-accepted",
            "help wanted",
            "invalid",
            "question",
            "wontfix"
        ],
        "README_content": "# Appwrite Command Line SDK\n\n![License](https://img.shields.io/github/license/appwrite/sdk-for-cli.svg?style=flat-square)\n![Version](https://img.shields.io/badge/api%20version-1.6.0-blue.svg?style=flat-square)\n[![Build Status](https://img.shields.io/travis/com/appwrite/sdk-generator?style=flat-square)](https://travis-ci.com/appwrite/sdk-generator)\n[![Twitter Account](https://img.shields.io/twitter/follow/appwrite?color=00acee&label=twitter&style=flat-square)](https://twitter.com/appwrite)\n[![Discord](https://img.shields.io/discord/564160730845151244?label=discord&style=flat-square)](https://appwrite.io/discord)\n\n**This SDK is compatible with Appwrite server version 1.6.x. For older versions, please check [previous releases](https://github.com/appwrite/sdk-for-cli/releases).**\n\nAppwrite is an open-source backend as a service server that abstract and simplify complex and repetitive development tasks behind a very simple to use REST API. Appwrite aims to help you develop your apps faster and in a more secure way. Use the Command Line SDK to integrate your app with the Appwrite server to easily start interacting with all of Appwrite backend APIs and tools. For full API documentation and tutorials go to [https://appwrite.io/docs](https://appwrite.io/docs)\n\n![Appwrite](https://github.com/appwrite/appwrite/raw/main/public/images/github.png)\n\n## Installation\n\nThe Appwrite CLI is a Node based command line tool to help you interact with the Appwrite API. The CLI is distributed both as an [`npm package`](https://www.npmjs.com/package/appwrite-cli) as well as [pre built binaries](https://github.com/appwrite/sdk-for-cli/releases/latest) for specific operating systems and architectures.\n\n### Install using NPM\n---\n\nIf you have `npm` installed, it's as easy as running\n\n```sh\n$ npm install -g appwrite-cli\n```\n\nOnce the installation is complete, you can verify the install using\n\n```sh\n$ appwrite -v\n6.1.0\n```\n\n### Install using prebuilt binaries\n---\n\nIf you do not have `npm` installed, you can always install the prebuilt binaries for your architecture and OS using our convenient installation scripts.\n\n### Linux / MacOS Terminal\n```bash\n$ wget -q https://appwrite.io/cli/install.sh  -O - | /bin/bash\n```\n\n### MacOS via [Homebrew](https://brew.sh)\n```bash\n$ brew install appwrite \n```\n\n### Windows\nVia Powershell\n```powershell\n$ iwr -useb https://appwrite.io/cli/install.ps1 | iex\n```\nVia [Scoop](https://scoop.sh)\n```powershell\n$ scoop install https://raw.githubusercontent.com/appwrite/sdk-for-cli/master/scoop/appwrite.json\n```\n\nOnce the installation completes, you can verify your install using\n```\n$ appwrite -v\n6.1.0\n```\n\n## Getting Started \n\nBefore you can use the CLI, you need to login to your Appwrite account. \n\n```sh\n$ appwrite login\n\n? Enter your email test@test.com\n? Enter your password ********\n Success \n```\nThis will also prompt you to enter your Appwrite endpoint ( default: http://localhost/v1 ) \n\n* ### Initialising your project\nOnce logged in, the CLI needs to be initialised before you can use it with your Appwrite project. You can do this with the `appwrite init project` command. \n\n```sh\n$ appwrite init project\n```\n\nThe following prompt will guide you through the setup process. The `init` command also creates an `appwrite.json` file representing your Appwrite project.\n\nThe `appwrite.json` file does a lot of things. \n* Provides context to the CLI\n* Keeps track of all your cloud functions\n* Keeps track of all your project's collections\n* Helps you deploy your Appwrite project to production and more..\n\nYou can also fetch all the collections in your current project using\n```sh\nappwrite init collection\n```\n\n* ### Creating and deploying cloud functions\n\nThe CLI makes it extremely easy to create and deploy Appwrite's cloud functions. Initialise your new function using\n\n```\n$ appwrite init function\n? What would you like to name your function? My Awesome Function\n? What runtime would you like to use? Node.js (node-15.5)\n Success \n```\n\nThis will create a new function `My Awesome Function` in your current Appwrite project and also create a template function for you to get started.\n\n```sh\n$ tree My\\ Awesome\\ Function \n\nMy Awesome Function\n README.md\n index.js\n package-lock.json\n package.json\n\n0 directories, 4 files\n```\n\nYou can now deploy this function using \n\n```sh\n$ appwrite deploy function\n\n? Which functions would you like to deploy? My Awesome Function (61d1a4c81dfcd95bc834)\n Info Deploying function My Awesome Function ( 61d1a4c81dfcd95bc834 )\n Success Deployed My Awesome Function ( 61d1a4c81dfcd95bc834 )\n```\n\nYour function has now been deployed on your Appwrite server! As soon as the build process is finished, you can start executing the function.\n\n* ### Deploying Collections\n\nSimilarly, you can deploy all your collections to your Appwrite server using \n\n```sh\nappwrite deploy collections\n```\n\n> ### Note\n> By default, requests to domains with self signed SSL certificates (or no certificates) are disabled. If you trust the domain, you can bypass the certificate validation using\n```sh\n$ appwrite client --selfSigned true\n```\n\n## Usage \n\nThe Appwrite CLI follows the following general syntax.\n```sh\n$ appwrite [COMMAND] --[OPTIONS]\n```\n\nA few sample commands to get you started \n\n```sh\n$ appwrite users create --userId \"unique()\" --email hello@appwrite.io --password very_strong_password\n$ appwrite users list \n```\n\nTo create a document you can use the following command \n```sh\n$ appwrite database createDocument --collectionId <ID> --documentId 'unique()' --data '{ \"Name\": \"Iron Man\" }' --permissions 'read(\"any\")' 'read(\"team:abc\")'\n```\n\n### Some Gotchas\n- `data` must be a valid JSON string where each key and value are enclosed in double quotes `\"` like the example above.\n- Some arguments like the `read` and `write` permissions are expected to be arrays. In the Appwrite CLI, array values are passed in using space as a separator like in the example above.\n\n\nTo get information about the different services available, you can use \n```sh\n$ appwrite -h\n```\n\nTo get information about a particular service and the commands available in a service you can use \n```sh\n$ appwrite users // or\n$ appwrite users --help // or\n$ appwrite users help // or\n$ appwrite accounts\n```\n\nTo get information about a particular command and the parameters it accepts, you can use\n\n```sh\n$ appwrite users list --help\n$ appwrite account get --help \n```\n\nAt any point, you can view or reset the CLI configuration using the `client` service.\n\n```\n$ appwrite client --debug\n// This will display your endpoint, projectID, API key and so on.\n$ appwrite client --reset\n```\n\n## CI mode\n\nThe Appwrite CLI can also work in a CI environment. The initialisation of the CLI works a bit differently in CI. In CI, you set your `endpoint`, `projectId` and `API Key` using \n\n```sh\nappwrite client --endpoint http://localhost/v1 --projectId <PROJECT_ID> --key <API KEY>\n```\n\n## Contribution\n\nThis library is auto-generated by Appwrite custom [SDK Generator](https://github.com/appwrite/sdk-generator). To learn more about how you can help us improve this SDK, please check the [contribution guide](https://github.com/appwrite/sdk-generator/blob/master/CONTRIBUTING.md) before sending a pull-request.\n\nTo build and test the CLI for development, follow these steps \n\n1. Clone the SDK Generator repository and cd into the directory\n```sh\n$ git clone https://github.com/appwrite/sdk-generator\n$ cd sdk-generator\n```\n\n2. Ensure Docker is running locally and then install the composer dependencies using\n```sh \n$ docker run --rm --interactive --tty --volume \"$(pwd)\":/app composer install --ignore-platform-reqs --optimize-autoloader --no-plugins --no-scripts --prefer-dist\n\n# Generate the SDKs\n$ docker run --rm -v $(pwd):/app -w /app php:8.1-cli php example.php\n```\n\n3. Head over to the generated SDK and install the dependencies.\n```sh\n$ cd examples/cli\n$ npm install \n```\n\n4. Install the CLI using \n```sh\n$ npm install -g .\n```\n\n5. You can now use the CLI \n```sh\n$ appwrite -v\n```\n## License\n\nPlease see the [BSD-3-Clause license](https://raw.githubusercontent.com/appwrite/appwrite/master/LICENSE) file for more information.\n",
        "num_commits": 177,
        "project_age_days": 1498,
        "project_created_at": "2020-09-22",
        "latest_updated_at": "2024-10-15",
        "latest_pushed_at": "2024-10-14",
        "num_contributors": 12,
        "num_pull": 58,
        "num_issues": 146,
        "num_opening_issue": 21,
        "project_size(kB)": 851,
        "num_stargazers": 91,
        "num_watchers": 91,
        "num_forks": 27,
        "num_subscribers": 17,
        "SecurityPolicy_created_at": "2022-11-08 16:23:04",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "b4859dd2c01d136b4a21b473131997c2254df09b",
                "url": "https://github.com/appwrite/.github/commit/b4859dd2c01d136b4a21b473131997c2254df09b",
                "date": "2022-11-08 16:23:04"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "zopefoundation/restrictedpython",
        "project_url": "https://github.com/zopefoundation/restrictedpython",
        "SSF": {
            "date": "2024-10-29T22:27:35+07:00",
            "repo": {
                "name": "github.com/zopefoundation/restrictedpython",
                "commit": "642202897b419a74b1cb1756315936b45fb75e78"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.2,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Info: status check found to merge onto on branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 8,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "7 out of 7 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 2,
                    "reason": "Found 7/30 approved changesets -- score normalized to 2",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: axiros contributor org/company found, willowrise contributor org/company found, pytest-dev contributor org/company found, agendaless consulting contributor org/company found, zopyx contributor org/company found, jazkarta contributor org/company found, kitconcept contributor org/company found, PloneEdu contributor org/company found, PyLadies-Munich contributor org/company found, Pylons contributor org/company found, repoze contributor org/company found, pwman3 contributor org/company found, sphinx-contrib contributor org/company found, minddistrict contributor org/company found, gocept contributor org/company found, zodb contributor org/company found, plone contributor org/company found, collective contributor org/company found, ECC-Pilot contributor org/company found, lmu mnchen contributor org/company found, minddistrict gmbh contributor org/company found, freelancer contributor org/company found, plone-security contributor org/company found, zopefoundation contributor org/company found, lmu contributor org/company found, fanstatic contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 26 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.txt:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "18 commit(s) and 1 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pre-commit.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/zopefoundation/RestrictedPython/pre-commit.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pre-commit.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/zopefoundation/RestrictedPython/pre-commit.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pre-commit.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/zopefoundation/RestrictedPython/pre-commit.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pre-commit.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/zopefoundation/RestrictedPython/pre-commit.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:43: update your workflow using https://app.stepsecurity.io/secureworkflow/zopefoundation/RestrictedPython/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/zopefoundation/RestrictedPython/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:50: update your workflow using https://app.stepsecurity.io/secureworkflow/zopefoundation/RestrictedPython/tests.yml/master?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:59",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:60",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:70",
                        "Info:   0 out of   5 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   2 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   3 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: all commits (7) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/zopefoundation/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/zopefoundation/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/zopefoundation/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/zopefoundation/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/pre-commit.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/tests.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/zopefoundation/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\nThe Zope developer community uses the same security policy as the Plone developer community. The most up to date information about Plone security is on https://plone.org/security\n\n## Supported Versions\nFor supported versions, see the [Zope development roadmap](https://www.zope.dev/developer/roadmap.html).\n\n## Reporting a Vulnerability\nPlease do **NOT** create a public bug report if you think this may be a security issue.\nInstead, please contact the Plone and Zope Security Team via email: security@plone.org. See also https://plone.org/security/report\n\nOnly bug reports submitted directly to the security team email will be treated as responsible disclosure. Any offered for sale to third parties or submitted to public bug bounty programmes will be treated as irresponsible public disclosure. We will not confirm any submissions on third party platforms such as \"huntr\" or \"hackerone\" and do not give permission for those systems to accept reports on our behalf or to represent themselves as a conduit for vulnerability reports.\n",
        "project_all_labels": [
            "bug",
            "do not merge",
            "documentation",
            "duplicate",
            "enhancement",
            "invalid",
            "question",
            "RELEASE BLOCKER",
            "wontfix"
        ],
        "README_content": ".. image:: https://github.com/zopefoundation/RestrictedPython/actions/workflows/tests.yml/badge.svg\n    :target: https://github.com/zopefoundation/RestrictedPython/actions/workflows/tests.yml\n\n.. image:: https://coveralls.io/repos/github/zopefoundation/RestrictedPython/badge.svg?branch=master\n    :target: https://coveralls.io/github/zopefoundation/RestrictedPython?branch=master\n\n.. image:: https://readthedocs.org/projects/restrictedpython/badge/\n    :target: https://restrictedpython.readthedocs.org/\n    :alt: Documentation Status\n\n.. image:: https://img.shields.io/pypi/v/RestrictedPython.svg\n    :target: https://pypi.org/project/RestrictedPython/\n    :alt: Current version on PyPI\n\n.. image:: https://img.shields.io/pypi/pyversions/RestrictedPython.svg\n    :target: https://pypi.org/project/RestrictedPython/\n    :alt: Supported Python versions\n\n.. image:: https://github.com/zopefoundation/RestrictedPython/raw/master/docs/logo.jpg\n\n================\nRestrictedPython\n================\n\nRestrictedPython is a tool that helps to define a subset of the Python language which allows to provide a program input into a trusted environment.\nRestrictedPython is not a sandbox system or a secured environment, but it helps to define a trusted environment and execute untrusted code inside of it.\n\n.. warning::\n\n   RestrictedPython only supports CPython. It does _not_ support PyPy and other Python implementations as it cannot provide its restrictions there.\n\nFor full documentation please see http://restrictedpython.readthedocs.io/.\n\nExample\n=======\n\nTo give a basic understanding what RestrictedPython does here two examples:\n\nAn unproblematic code example\n-----------------------------\n\nPython allows you to execute a large set of commands.\nThis would not harm any system.\n\n.. code-block:: pycon\n\n    >>> from RestrictedPython import compile_restricted\n    >>> from RestrictedPython import safe_globals\n    >>>\n    >>> source_code = \"\"\"\n    ... def example():\n    ...     return 'Hello World!'\n    ... \"\"\"\n    >>>\n    >>> loc = {}\n    >>> byte_code = compile_restricted(source_code, '<inline>', 'exec')\n    >>> exec(byte_code, safe_globals, loc)\n    >>>\n    >>> loc['example']()\n    'Hello World!'\n\nProblematic code example\n------------------------\n\nThis example directly executed in Python could harm your system.\n\n.. code-block:: pycon\n\n    >>> from RestrictedPython import compile_restricted\n    >>> from RestrictedPython import safe_globals\n    >>>\n    >>> source_code = \"\"\"\n    ... import os\n    ...\n    ... os.listdir('/')\n    ... \"\"\"\n    >>> byte_code = compile_restricted(source_code, '<inline>', 'exec')\n    >>> exec(byte_code, safe_globals, {})\n    Traceback (most recent call last):\n    ImportError: __import__ not found\n\nContributing to RestrictedPython\n--------------------------------\n\nIf you want to help maintain RestrictedPython and contribute, please refer to\nthe documentation `Contributing page\n<https://restrictedpython.readthedocs.io/en/latest/contributing/index.html>`_.\n",
        "num_commits": 747,
        "project_age_days": 4261,
        "project_created_at": "2013-02-28",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-09",
        "num_contributors": 39,
        "num_pull": 189,
        "num_issues": 288,
        "num_opening_issue": 21,
        "project_size(kB)": 1793,
        "num_stargazers": 467,
        "num_watchers": 467,
        "num_forks": 38,
        "num_subscribers": 78,
        "SecurityPolicy_created_at": "2020-10-01 12:54:56",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "73354a406601b5b932ed67429b32587d8a57cfa6",
                "url": "https://github.com/zopefoundation/.github/commit/73354a406601b5b932ed67429b32587d8a57cfa6",
                "date": "2022-02-02 06:58:30"
            },
            {
                "commit_id": "230a2bb9798705353da2e1a5178b4dfab52fc7f5",
                "url": "https://github.com/zopefoundation/.github/commit/230a2bb9798705353da2e1a5178b4dfab52fc7f5",
                "date": "2021-09-12 08:56:34"
            },
            {
                "commit_id": "7d9f3c84030087ca403d403727d1eaa801dd2fa5",
                "url": "https://github.com/zopefoundation/.github/commit/7d9f3c84030087ca403d403727d1eaa801dd2fa5",
                "date": "2020-10-02 06:43:48"
            },
            {
                "commit_id": "6404e075a3395a32fc186d66934e2677d3a4179e",
                "url": "https://github.com/zopefoundation/.github/commit/6404e075a3395a32fc186d66934e2677d3a4179e",
                "date": "2020-10-01 12:54:56"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "cog-creators/red-discordbot",
        "project_url": "https://github.com/cog-creators/red-discordbot",
        "SSF": {
            "date": "2024-10-29T20:02:55+07:00",
            "repo": {
                "name": "github.com/cog-creators/red-discordbot",
                "commit": "4e27059209473118142a5a220b002353dc82d3e4"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.3,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'V3/develop'",
                        "Info: 'force pushes' disabled on branch 'V3/develop'",
                        "Warn: 'branch protection settings apply to administrators' is disable on branch 'V3/develop'",
                        "Warn: required approving review count is 1 on branch 'V3/develop'",
                        "Warn: codeowners review is not required on branch 'V3/develop'",
                        "Info: status check found to merge onto on branch 'V3/develop'",
                        "Info: PRs are required in order to make changes on branch 'V3/develop'"
                    ],
                    "score": 8,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "26 out of 26 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 7,
                    "reason": "Found 17/22 approved changesets -- score normalized to 7",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: canva contributor org/company found, PyLav contributor org/company found, MikuAPI contributor org/company found, Tiny-Discord contributor org/company found, Goularte-Dev contributor org/company found, Ballsdex-Team contributor org/company found, Pikachu-DiscordBot contributor org/company found, mastercard contributor org/company found,  contributor org/company found, unified-moderation-network contributor org/company found, cog-creators contributor org/company found, MartineBot contributor org/company found, nekos-best contributor org/company found, redbrick contributor org/company found, Cog-Creators contributor org/company found, sagaz-dev contributor org/company found, tutturution contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 17 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: GNU General Public License v3.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 8 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/publish_release.yml:110"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/auto_labeler_issues.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/auto_labeler_issues.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/auto_labeler_pr.yml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/auto_labeler_pr.yml/V3/develop?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/auto_labeler_pr.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/auto_labeler_pr.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/check_label_pattern_exhaustiveness.yaml:12: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/check_label_pattern_exhaustiveness.yaml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/check_label_pattern_exhaustiveness.yaml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/check_label_pattern_exhaustiveness.yaml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/codeql-analysis.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:23: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/codeql-analysis.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/codeql-analysis.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:58: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/codeql-analysis.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/crowdin_upload_strings.yml:12: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/crowdin_upload_strings.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/crowdin_upload_strings.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/crowdin_upload_strings.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint_python.yaml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/lint_python.yaml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint_python.yaml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/lint_python.yaml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/prepare_release.yml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/prepare_release.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/prepare_release.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/prepare_release.yml/V3/develop?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/prepare_release.yml:44: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/prepare_release.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/prepare_release.yml:58: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/prepare_release.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/prepare_release.yml:76: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/prepare_release.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/prepare_release.yml:78: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/prepare_release.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/prepare_release.yml:94: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/prepare_release.yml/V3/develop?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/prepare_release.yml:106: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/prepare_release.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/prepare_release.yml:120: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/prepare_release.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_release.yml:87: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/publish_release.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_release.yml:90: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/publish_release.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_release.yml:105: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/publish_release.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_release.yml:123: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/publish_release.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_release.yml:129: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/publish_release.yml/V3/develop?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish_release.yml:141: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/publish_release.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_release.yml:163: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/publish_release.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_release.yml:167: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/publish_release.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_release.yml:183: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/publish_release.yml/V3/develop?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish_release.yml:195: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/publish_release.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_release.yml:210: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/publish_release.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_release.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/publish_release.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_release.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/publish_release.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_release.yml:60: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/publish_release.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_release.yml:63: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/publish_release.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_release.yml:78: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/publish_release.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/run_pip_compile.yaml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/run_pip_compile.yaml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/run_pip_compile.yaml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/run_pip_compile.yaml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/run_pip_compile.yaml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/run_pip_compile.yaml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/run_pip_compile.yaml:62: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/run_pip_compile.yaml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/run_pip_compile.yaml:65: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/run_pip_compile.yaml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/run_pip_compile.yaml:74: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/run_pip_compile.yaml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/run_pip_compile.yaml:79: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/run_pip_compile.yaml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/run_pip_compile.yaml:84: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/run_pip_compile.yaml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/run_pip_compile.yaml:94: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/run_pip_compile.yaml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:42: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/tests.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/tests.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:79: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/tests.yml/V3/develop?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:83: update your workflow using https://app.stepsecurity.io/secureworkflow/Cog-Creators/Red-DiscordBot/tests.yml/V3/develop?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/check_label_pattern_exhaustiveness.yaml:19",
                        "Warn: pipCommand not pinned by hash: .github/workflows/check_label_pattern_exhaustiveness.yaml:20",
                        "Warn: pipCommand not pinned by hash: .github/workflows/codeql-analysis.yml:29",
                        "Warn: pipCommand not pinned by hash: .github/workflows/codeql-analysis.yml:30",
                        "Warn: pipCommand not pinned by hash: .github/workflows/crowdin_upload_strings.yml:23",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint_python.yaml:24",
                        "Warn: pipCommand not pinned by hash: .github/workflows/prepare_release.yml:30",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish_release.yml:69",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish_release.yml:70",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish_release.yml:96",
                        "Warn: pipCommand not pinned by hash: .github/workflows/run_pip_compile.yaml:71",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:51",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:52",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:88",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:89",
                        "Info:   0 out of  46 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   5 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of  15 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: all commits (26) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact 3.5.13 not signed: https://api.github.com/repos/Cog-Creators/Red-DiscordBot/releases/172041404",
                        "Warn: release artifact 3.5.12 not signed: https://api.github.com/repos/Cog-Creators/Red-DiscordBot/releases/169232599",
                        "Warn: release artifact 3.5.11 not signed: https://api.github.com/repos/Cog-Creators/Red-DiscordBot/releases/168621432",
                        "Warn: release artifact 3.5.10 not signed: https://api.github.com/repos/Cog-Creators/Red-DiscordBot/releases/164896971",
                        "Warn: release artifact 3.5.13 does not have provenance: https://api.github.com/repos/Cog-Creators/Red-DiscordBot/releases/172041404",
                        "Warn: release artifact 3.5.12 does not have provenance: https://api.github.com/repos/Cog-Creators/Red-DiscordBot/releases/169232599",
                        "Warn: release artifact 3.5.11 does not have provenance: https://api.github.com/repos/Cog-Creators/Red-DiscordBot/releases/168621432",
                        "Warn: release artifact 3.5.10 does not have provenance: https://api.github.com/repos/Cog-Creators/Red-DiscordBot/releases/164896971"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql-analysis.yml:16",
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/publish_release.yml:119",
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/publish_release.yml:151",
                        "Warn: no topLevel permission defined: .github/workflows/check_label_pattern_exhaustiveness.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/codeql-analysis.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/crowdin_upload_strings.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/lint_python.yaml:1",
                        "Warn: topLevel 'contents' permission set to 'write': .github/workflows/prepare_release.yml:11",
                        "Warn: no topLevel permission defined: .github/workflows/publish_release.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/run_pip_compile.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/tests.yml:1"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/cog-creators/red-discordbot/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nThe table below explains the current state of our versions. Currently, only version\n3.5 and higher are supported and receive security updates. Versions lower than 3.5\nare considered End of Life and will not receive any security updates.\n\n| Version       | Branch     | Security Updates   | End of Life        |\n|---------------|------------|--------------------|--------------------|\n| < 2.0         | master     | :x:                | :white_check_mark: |\n| >= 2.0, < 3.0 | develop    | :x:                | :white_check_mark: |\n| >= 3.0, < 3.5 | V3/develop | :x:                | :white_check_mark: |\n| >= 3.5        | V3/develop | :white_check_mark: | :x:                |\n\n\n## Reporting a Vulnerability\n\nFor reporting vulnerabilities within Red-DiscordBot we make use of GitHub's\nprivate vulnerability reporting feature (More information can be found\n[here](https://docs.github.com/en/code-security/security-advisories/guidance-on-reporting-and-writing/privately-reporting-a-security-vulnerability)).\nThis ensures that all maintainers and key members have access to the reported\nvulnerability.\n\n### Opening a Vulnerability Report\n\nTo open a vulnerability report please fill out [this form](https://github.com/Cog-Creators/Red-DiscordBot/security/advisories/new)\n\nYou will be asked to provide a summary, details and proof of concept for your vulnerability report.\nWe ask that you fill out this form to the best of your ability, with as many details as possible.\nFurthermore, you'll be asked to provide affected products and severity.\nThese fields are optional and will be filled appropriately by the maintainers if not provided.\n\n### Timeline\n\nWe will try to answer your report within 7 days. If you haven't received an answer by then, we suggest you reach\nout to us privately. This can best be done via our [Discord server](https://discord.gg/red), and contacting\na member who has the Staff role.\n",
        "project_all_labels": [
            "Automated PR",
            "Blocked",
            "Blocked By: Damage Control",
            "Blocked By: Dependency",
            "Blocked By: Other PR",
            "Breaking Change",
            "Category: CI",
            "Category: Cogs - Admin",
            "Category: Cogs - Alias",
            "Category: Cogs - Audio",
            "Category: Cogs - Bank",
            "Category: Cogs - Cleanup",
            "Category: Cogs - CustomCommands",
            "Category: Cogs - Dev",
            "Category: Cogs - Downloader",
            "Category: Cogs - Economy",
            "Category: Cogs - Filter",
            "Category: Cogs - General",
            "Category: Cogs - Image",
            "Category: Cogs - Mod",
            "Category: Cogs - Modlog",
            "Category: Cogs - Mutes",
            "Category: Cogs - Permissions",
            "Category: Cogs - Reports",
            "Category: Cogs - Streams",
            "Category: Cogs - Trivia",
            "Category: Cogs - Trivia - Lists",
            "Category: Cogs - Warnings",
            "Category: Core - API - App Commands Package",
            "Category: Core - API - Audio",
            "Category: Core - API - Bank",
            "Category: Core - API - Commands Package",
            "Category: Core - API - Config",
            "Category: Core - API - Other",
            "Category: Core - API - Utils Package",
            "Category: Core - Bot Class",
            "Category: Core - Bot Commands",
            "Category: Core - Command-line Interfaces",
            "Category: Core - Help",
            "Category: Core - i18n",
            "Category: Core - Modlog",
            "Category: Core - Other Internals",
            "Category: Core - RPC/ZMQ",
            "Category: Docker",
            "Category: Docs - Changelogs",
            "Category: Docs - For Developers",
            "Category: Docs - Install Guides",
            "Category: Docs - Other",
            "Category: Docs - User Guides",
            "Category: Meta",
            "Category: RPC/ZMQ methods",
            "Category: Vendored Packages",
            "Changelog Entry: Added",
            "Changelog Entry: Pending",
            "Changelog Entry: Skipped",
            "Closed: Duplicate",
            "Closed: External",
            "Closed: Invalid",
            "Closed: User Error",
            "Closed: Won't Fix",
            "Complex Issue",
            "Docs-only",
            "Feature Branch",
            "Good First Issue",
            "Hacktoberfest",
            "hacktoberfest-accepted",
            "Help Wanted",
            "High Priority",
            "Needs Backport To stable-docs",
            "No Activity",
            "No Repro",
            "QA: Bypassed",
            "QA: Changes Requested",
            "QA: Passed",
            "Release Blocker",
            "Status: Accepted",
            "Status: Frozen",
            "Status: In Progress",
            "Status: Needs Discussion",
            "Status: Needs Info",
            "Status: Needs Triage",
            "Status: PRs Welcome",
            "Type: Bug",
            "Type: Dependency Update",
            "Type: Deprecation",
            "Type: Enhancement",
            "Type: Feature",
            "Type: Informational",
            "Type: Merge",
            "Type: Optimisation",
            "Type: Question",
            "Type: Removal"
        ],
        "README_content": "# Red - A multifunction Discord bot\n#### *Fun bringer, admin helper and music bot*  \n[<img align=\"right\" title=\"Art by Supergiant Games\" src=\"https://www.supergiantgames.com/static/images/transistor/cartoon_red.png\">](https://www.supergiantgames.com/games/transistor/)\n\n[<img src=\"https://img.shields.io/badge/Support-me!-orange.svg\">](https://www.patreon.com/Twentysix26) [<img src=\"https://img.shields.io/badge/Official-Server-green.svg\">](https://discord.gg/0k4npTwMvTpv9wrh) **< Announcements & Help!**  \n##**[ [This version is obsolete and no longer being supported. Use the current one] ](https://github.com/Twentysix26/Red-DiscordBot/)**  \n### Cool title, but what does it do exactly?\nA bit of everything. Seriously though:  \nIt has the [most common features](#general-commands) of many chatbots (!flip, !8, stopwatch, etc.), **custom commands** (inspired by Twitch's [Nightbot](https://www.nightbot.tv/)), memes.  \nIt features some games such as **Trivia**, rock paper scissors, [users can earn and play with credits](#economy-commands) in the slot machine.  \n[The audio part is quite fleshed out](#audio-commands). Users can **stream youtube videos**, create **playlists** that everyone will be able to play and control (previous/next song, pause/resume, shuffle...).  \n**MP3 and flac files can also be streamed** (see [FAQ](#faq) for details on local playlists)  \n**Twitch's online notifications**: Red will notify the channels you want whenever you favorite Twitch streamers are online.  \nAs for the moderation tools, it includes a **powerful message filter with regular expression capabilities** and **mass messages cleanup**.  \n[I'm planning to expand all this much more](#todo-list).  \nSee the [command list](#general-commands) for an even better idea of what this bot can do.\n\n### I don't even know what I'm looking at. How do I install this?\nDo not panic. [Enter the wiki and follow the tutorials](https://github.com/Twentysix26/Red-DiscordBot/wiki)!  \nIf you have any issue, consult the [troubleshooting](https://github.com/Twentysix26/Red-DiscordBot/wiki/Troubleshooting) page, and if you're still stuck, [join the official server](https://discord.gg/0k4npTwMvTpv9wrh) so you can get some help.\nOnce you're done, take a look at the command list and have fun.\n\n### General commands\n\n| Command                                       | Description                                |\n|-----------------------------------------------|--------------------------------------------|\n| !flip                                         | Flip a coin                                |\n| !rps [rock/paper/scissors]                    | Play  RPS                                  |\n| !proverb                                      | Random proverb                             |\n| !choose [option1 or option2 or option3 (...)] | Random choice. Supports multiple words     |\n| !8 [question?]                                | Ask 8 ball a question                      |\n| !sw                                           | Start/stop the stopwatch                   |\n| !trivia                                       | Trivia help and lists                      |\n| !trivia [list]                                | Start a trivia session                     |\n| !trivia stop                                  | Stop a trivia session                      |\n| !twitch [stream]                              | Check if stream is online                  |\n| !twitchalert [stream]                         | Red sends an alert in the channel when the stream is online (admin only)|\n| !stoptwitchalert [stream]                     | Stop stream alerts (admin only)      |\n| !roll [number]                                | Random number between 0 and chosen number. |\n| !gif [text]                                   | GIF search                                 |\n| !imdb [movie/etc]                             | Retrieve information from IMDB             |\n| !meme [id;text1;text2]                        | Create a meme                              |\n| !poll [question;answer1;answer2 (...)]        | Start poll in the current channel          |\n| !endpoll                                      | Stop poll                                  |\n| !addcom [command] [text]                      | Add a custom command                       |\n| !editcom [command] [text]                     | Edit a custom command                      |\n| !delcom [command]                             | Delete a custom command                    |\n| !customcommands                               | Custom commands' list                      |\n| !help                                         | Command list                               |\n| !audio help                                   | Audio command list and playlist explanation.|\n| !economy                                      | Explanation of the economy module          |\n| !admin help                                   | Admin commands list                        |\n| !meme help                                    | Explanation of !meme                       |\n\n### Audio commands\n\n| Command                    | Description                                                         |\n|----------------------------|---------------------------------------------------------------------|\n| !youtube [link]            | Play a youtube video in a voice channel                             |\n| !sing                      | Make Red sing                                                       |\n| !stop                      | Stop any voice channel activity                                     |\n| !play [playlist_name]      | Play chosen playlist                                                |\n| !playlists                 | Playlist's list                                                     |\n| !next or !skip             | Next song                                                           |\n| !prev                      | Previous song                                                       |\n| !pause                     | Pause song                                                          |\n| !resume                    | Resume song                                                         |\n| !replay or !repeat         | Replay current song                                                 |\n| !title or !song            | Current song's title + link                                         |\n| !shuffle                   | Mix current playlist                                                |\n| !volume [0-1]              | Sets Red's output volume                                            |\n| !addplaylist [name] [link] | Add a youtube playlist                                              |\n| !delplaylist [name]        | Delete a youtube playlist. Limited to author and admins             |\n| !getplaylist               | Get the current playlist through DM. This also works with favorites |\n| !addfavorite               | Add song to your favorites                                          |\n| !delfavorite               | Remove song from your favorites                                     |\n| !playfavorites             | Play your favorites                                                 |\n| !local [playlist_name]     | Play chosen local playlist                                          |\n| !local or !locallist       | Local playlists' list                                               |\n| !downloadmode              | Enables or disables download mode. (admin only)                     |\n\n### Admin commands\n\n| Command                                                   | Description                                       |\n|-----------------------------------------------------------|---------------------------------------------------|\n| !addwords [word1 word2 (...)] [phrase/with/many/words]    | Add words to message filter                       |\n| !removewords [word1 word2 (...)] [phrase/with/many/words] | Remove words from message filter                  |\n| !addregex [regex]                                         | Add regular expression to message filter          |\n| !removeregex [regex]                                      | Remove regular expression from message filter     |\n| !shutdown                                                 | Close the bot                                     |\n| !join [invite]                                            | Join another server                               |\n| !leaveserver                                              | Leave server                                      |\n| !shush                                                    | Ignore the current channel                        |\n| !talk                                                     | Stop ignoring the current channel                 |\n| !reload                                                   | Reload most files. Useful in case of manual edits |\n| !name [name]                                              | Change the bot's name                             |\n| !cleanup [number]                                         | Delete the last [number] messages                 |\n| !cleanup [name/mention] [number]                          | Delete the last [number] of messages by [name]    |\n| !blacklist [name/mention]                                 | Add user to blacklist. Red will ignore that user  |\n| !forgive [name/mention]                                   | Remove user from blacklist                        |\n| !setting [setting] [value]                                | Modify setting                                    |\n\n\n### Economy commands\n\n| Command     | Description                          |\n|-------------|--------------------------------------|\n| !register   | Register a new account               |\n| !balance    | Check your balance                   |\n| !slot [bid] | Play the slot machine                |\n| !slot help  | Slot machine explanation and payouts |\n| !payday     | Receive credits                      |\n\n### FAQ\n>I've done everything the README asked me to and it still doesn't work! Were you drunk when you coded this?  \n\nYou're probably missing something.  \nFeel free to join [my server](https://discord.gg/0k4npTwMvTpv9wrh) and head to #support to get some help! Oh, and my drinking habits are none of your business.  \n\n>Does this bot work on multiple servers?  \n\nSure it does. Should you do it? Maybe. The permissions system is not that great at the moment but if you trust the people running the server it's ok. It's not advisable to send the bot in random servers at the moment.   \nCustom commands only work in the server they were created in. Same for the message filter. This is by design. Also, remember that the bot can only be in one voice channel at once.\n\n>Will you implement [feature]?  \n\nSuggestions are always very welcome.\n\n>How do local playlists work?\n\nMake as many folders as you want inside the localtracks folder. Names must be without spaces. Every folder counts as a different playlist. Every playlist can contain mp3 and flac files. Users can stream them by doing !local [playlist_name] and see the full list\nwith !local or !locallist. They can also add tracks to their favorites.\n\n>What's download mode?\n\nEverytime you play the audio of a youtube video with download mode on the audio will be first downloaded and stored into the \"cache\" folder. It is recommended that you use this mode to avoid streaming problems. This is the default mode, you can switch between modes with !downloadmode.\n\n>Why is this bot called Red and the admin role \"Transistor\"? What's the meaning of !sing?\n\nThey're all references to [Transistor](https://www.supergiantgames.com/games/transistor/), a videogame by Supergiant Games.\n\n### TODO List\n- [x] [Start rewriting Red](https://github.com/Twentysix26/Red-DiscordBot/tree/develop)\n- [ ]  ~~Bundle some malware and slowly build up a botnet for world domination~~\n",
        "num_commits": 2871,
        "project_age_days": 3223,
        "project_created_at": "2016-01-02",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 169,
        "num_pull": 4122,
        "num_issues": 6230,
        "num_opening_issue": 286,
        "project_size(kB)": 82712,
        "num_stargazers": 4803,
        "num_watchers": 4803,
        "num_forks": 2305,
        "num_subscribers": 213,
        "SecurityPolicy_created_at": "2022-12-25 14:40:35",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "1248927fb6b54edc85c97c4a88f6cdb079e95afd",
                "url": "https://github.com/Cog-Creators/Red-DiscordBot/commit/1248927fb6b54edc85c97c4a88f6cdb079e95afd",
                "date": "2023-08-06 17:29:51"
            },
            {
                "commit_id": "0e58897bfcc67a245fa421549900fae2cd9d1b55",
                "url": "https://github.com/Cog-Creators/Red-DiscordBot/commit/0e58897bfcc67a245fa421549900fae2cd9d1b55",
                "date": "2022-12-25 14:40:35"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "advisory",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism",
            "Reporting mechanism",
            "Projects practice"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "pretix/pretix",
        "project_url": "https://github.com/pretix/pretix",
        "SSF": {
            "date": "2024-10-29T20:58:32+07:00",
            "repo": {
                "name": "github.com/pretix/pretix",
                "commit": "3f99e0bece90c3ee34e371d07c4f3bf72c0d63f4"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.3,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: branch 'master' does not require approvers",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Warn: no status checks found to merge onto branch 'master'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "19 out of 19 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 4,
                    "reason": "Found 9/22 approved changesets -- score normalized to 4",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: ad evolutio lda contributor org/company found, adyen contributor org/company found, microsoft contributor org/company found, djangocon contributor org/company found, metarheinmain contributor org/company found, nnev contributor org/company found, venueless contributor org/company found, muccc contributor org/company found, ramphastidae contributor org/company found, pretix | tu darmstadt contributor org/company found, ARCUM1991 contributor org/company found, pretix contributor org/company found, c3cashdesk contributor org/company found, pretalx contributor org/company found, svsticky contributor org/company found, cccs contributor org/company found, Suedost-Chaos-Organisation contributor org/company found, channable contributor org/company found, eindhoven university of technology (student) contributor org/company found, relishiq contributor org/company found, pretix-unofficial contributor org/company found, high can fly contributor org/company found, VSEScala contributor org/company found, abiapp contributor org/company found, gaflmu contributor org/company found, chaossocial contributor org/company found, ephios-dev contributor org/company found, pyconpt contributor org/company found, byro contributor org/company found, noscito-network contributor org/company found, itk development contributor org/company found, opacapp contributor org/company found, c3nav contributor org/company found, rami.io gmbh contributor org/company found, 3DEXCITE contributor org/company found, Weller-IT contributor org/company found, webappconcept contributor org/company found, hapibees-pei contributor org/company found, raumzeitlabor contributor org/company found, rttag contributor org/company found, pretalx.com contributor org/company found, freifunk-darmstadt contributor org/company found, d120 contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 43 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 19 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/build.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/build.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/build.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/docs.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/docs.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/docs.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/strings.yml:26: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/strings.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/strings.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/strings.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/strings.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/strings.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/strings.yml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/strings.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/strings.yml:53: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/strings.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/strings.yml:56: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/strings.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/style.yml:26: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/style.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/style.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/style.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/style.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/style.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/style.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/style.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/style.yml:48: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/style.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/style.yml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/style.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/style.yml:66: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/style.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/style.yml:68: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/style.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:47: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:49: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:52: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/tests.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yml:79: update your workflow using https://app.stepsecurity.io/secureworkflow/pretix/pretix/tests.yml/master?enable=pin",
                        "Warn: containerImage not pinned by hash: Dockerfile:1: pin your Docker image by updating python:3.11-bookworm to python:3.11-bookworm@sha256:70f1eb2927a8ef72840254b17024d3a8aa8c3c9715a625d426a2861b5899bc62",
                        "Warn: pipCommand not pinned by hash: Dockerfile:53-61",
                        "Warn: pipCommand not pinned by hash: Dockerfile:53-61",
                        "Warn: pipCommand not pinned by hash: .github/workflows/build.yml:44",
                        "Warn: pipCommand not pinned by hash: .github/workflows/docs.yml:43",
                        "Warn: pipCommand not pinned by hash: .github/workflows/strings.yml:41",
                        "Warn: pipCommand not pinned by hash: .github/workflows/strings.yml:66",
                        "Warn: pipCommand not pinned by hash: .github/workflows/style.yml:39",
                        "Warn: pipCommand not pinned by hash: .github/workflows/style.yml:59",
                        "Warn: pipCommand not pinned by hash: .github/workflows/style.yml:73",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:62",
                        "Info:   0 out of  23 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   1 containerImage dependencies pinned",
                        "Info:   0 out of  10 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 23 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/build.yml:16",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/docs.yml:18",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/strings.yml:16",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/style.yml:16",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/tests.yml:15",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 10,
                    "reason": "GitHub workflow tokens follow principle of least privilege",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-9c47-m6qq-7p4h",
                        "Warn: Project is vulnerable to: GHSA-76p3-8jx3-jpfq",
                        "Warn: Project is vulnerable to: GHSA-f8q6-p94x-37v3",
                        "Warn: Project is vulnerable to: GHSA-566m-qj78-rww5",
                        "Warn: Project is vulnerable to: GHSA-7fh5-64p2-3v2j",
                        "Warn: Project is vulnerable to: GHSA-hwj9-h5mp-3pm3",
                        "Warn: Project is vulnerable to: GHSA-gcx4-mw62-g8wm",
                        "Warn: Project is vulnerable to: GHSA-5j4c-8p2g-v4jx",
                        "Warn: Project is vulnerable to: GHSA-g3ch-rx76-35fx"
                    ],
                    "score": 1,
                    "reason": "9 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/pretix/pretix/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security policy\n\n## Reporting a vulnerability\n\nIf you discover a vulnerability with our software or server systems, please report it to us in private. Do not to attempt to harm our users, customer's data or our system's availability when looking for vulneratbilities.\n\nPlease contact us at security@pretix.eu with full details and steps to reproduce and allow reasonable time for us to resolve the issue before publishing your findings. If you wish to encrypt your email, you can find our GPG key [here](https://pretix.eu/.well-known/security@pretix.eu.asc).\n\nWe're not large enough to run a formal bug bounty program, but if you find a serious vulnerability in our service, we will find a way to show our gratitude. \n\n## Version support\n\nSecurity support is provided for the current stable release as well as the two previous stable releases.\nBe sure to keep your pretix installation up to date.\n\nNew releases and security issues will be announced on our [blog](https://pretix.eu/about/en/blog/). If you\nsubscribe to our [newsletter](https://pretix.eu/about/en/blog/) in the \"News about self-hosting pretix\"\ncategory, we will also send you an email on security issues. \n\nPast security issues are listed [on our website](https://pretix.eu/about/en/security).\n",
        "project_all_labels": [
            "assigned",
            "bug",
            "cla-signed",
            "dependencies",
            "docs",
            "duplicate",
            "easy",
            "enhancement",
            "help wanted",
            "internal:release-checklist",
            "invalid",
            "javascript",
            "plugin idea",
            "pr status: needs improvement",
            "pr status: needs review",
            "pretix.api",
            "pretix.base",
            "pretix.control",
            "pretix.plugins",
            "pretix.presale",
            "python",
            "question",
            "test case",
            "ui/ux",
            "wontfix"
        ],
        "README_content": "pretix\n======\n\n.. image:: https://img.shields.io/pypi/v/pretix.svg\n   :target: https://pypi.python.org/pypi/pretix\n\n.. image:: https://github.com/pretix/pretix/workflows/Documentation/badge.svg\n   :target: https://docs.pretix.eu/en/latest/\n\n.. image:: https://github.com/pretix/pretix/workflows/Tests/badge.svg\n\n.. image:: https://codecov.io/gh/pretix/pretix/branch/master/graph/badge.svg\n   :target: https://codecov.io/gh/pretix/pretix\n\n\n\nReinventing ticket presales, one ticket at a time.\n\nProject status & release cycle\n------------------------------\n\nWhile there is always a lot to do and improve on, pretix by now has been in use for thousands of events\nconferences that sold millions of tickets combined. We therefore think of pretix as being stable and ready to use.\n\nIf you want to use or extend pretix, we strongly recommend to follow our `blog`_. We will announce all\nreleases there. You can always find the latest stable version on PyPI or in the ``release/X.Y`` branch of\nthis repository. The ``master`` branch contains a development version that we also try to keep stable in\nthe sense that it does not break your data,  but its APIs might change without prior notice.\n\nTo get started using pretix on your own server, look at the `installation guide`_ in our documentation.\n\nSupport\n-------\n\nThis project is 100 percent free and open source software. You are welcome to ask questions in the GitHub\nrepository. Private support via email or phone is only offered to customers of our pretix Hosted or pretix\nEnterprise offerings. If you are interested in commercial support, hosting services or supporting this project\nfinancially, please go to `pretix.eu`_ or contact us at support@pretix.eu.\n\nContributing\n------------\nIf you want to contribute to pretix, please read the `developer documentation`_\nin our documentation. If you have any further questions, please do not hesitate to ask!\n\n.. image:: https://translate.pretix.eu/widgets/pretix/-/pretix/multi-blue.svg\n   :target: https://translate.pretix.eu/engage/pretix/\n\nCode of Conduct\n---------------\nWe have a `Code of Conduct`_ in place that applies to all project contributions,\nincluding issues, pull requests, etc.\n\nLicense\n-------\n\nThe code in this repository is covered by different licenses. Most of it is available to everyone under the terms of\nthe GNU AGPL license v3 with additional terms. See the LICENSE file for the complete license details.\n\n.. _installation guide: https://docs.pretix.eu/en/latest/admin/installation/index.html\n.. _developer documentation: https://docs.pretix.eu/en/latest/development/index.html\n.. _Code of Conduct: https://docs.pretix.eu/en/latest/development/contribution/codeofconduct.html\n.. _pretix.eu: https://pretix.eu\n.. _blog: https://pretix.eu/about/en/blog/\n",
        "num_commits": 12159,
        "project_age_days": 3704,
        "project_created_at": "2014-09-08",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 321,
        "num_pull": 2827,
        "num_issues": 4070,
        "num_opening_issue": 155,
        "project_size(kB)": 560794,
        "num_stargazers": 1866,
        "num_watchers": 1866,
        "num_forks": 470,
        "num_subscribers": 49,
        "SecurityPolicy_created_at": "2022-09-16 11:43:51",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "36b3968667f264df5165bcb192d317491559f5d0",
                "url": "https://github.com/pretix/pretix/commit/36b3968667f264df5165bcb192d317491559f5d0",
                "date": "2022-09-16 11:43:51"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism",
            "Scope of practice"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "elastic/apm-agent-python",
        "project_url": "https://github.com/elastic/apm-agent-python",
        "SSF": {
            "date": "2024-10-29T20:15:29+07:00",
            "repo": {
                "name": "github.com/elastic/apm-agent-python",
                "commit": "f570e8c2b68a8714628acac815aebcc3518b44c7"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 7.2,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: 'branch protection settings apply to administrators' is disable on branch 'main'",
                        "Warn: 'stale review dismissal' is disable on branch 'main'",
                        "Warn: required approving review count is 1 on branch 'main'",
                        "Warn: codeowners review is required - but no codeowners file found in repo",
                        "Warn: 'last push approval' is disable on branch 'main'",
                        "Info: status check found to merge onto on branch 'main'",
                        "Info: PRs are required in order to make changes on branch 'main'"
                    ],
                    "score": 5,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 out of 30 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: django-denmark contributor org/company found, cybernauterne contributor org/company found, pinojs contributor org/company found, standard contributor org/company found, dsrp contributor org/company found, jenkinsci contributor org/company found, elastic contributor org/company found, fenerum contributor org/company found, opbeat contributor org/company found, webtorrent contributor org/company found, callowayproject contributor org/company found, thunderpush contributor org/company found, ipfs-search contributor org/company found, jazzband contributor org/company found, sentry contributor org/company found, Ghini contributor org/company found, nodeschool contributor org/company found, nodejs contributor org/company found, visualspace contributor org/company found, MacSysadmin contributor org/company found, adobe contributor org/company found, billogram contributor org/company found, uppsaladatavetare contributor org/company found, getsentry contributor org/company found, hubot-archive contributor org/company found, LibraryOfCongress contributor org/company found, government contributor org/company found, cphex contributor org/company found, wealthsimple contributor org/company found, open-telemetry contributor org/company found, justquick  & gnarwhal studios contributor org/company found, dryad-networks contributor org/company found, netflix contributor org/company found, ghini.thesoftware (aka bauble.classic) contributor org/company found, adventure-js contributor org/company found, PolyPasswordHasher contributor org/company found, django-district contributor org/company found, libraryofcongress as cadams@loc.gov; personal projects as chris@improbable.org contributor org/company found, co-founder @ bucket.so contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 39 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1",
                        "Info: detected update tool: RenovateBot: renovate.json:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: BSD 3-Clause \"New\" or \"Revised\" License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 9 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/release.yml:34"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/labeler.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/labeler.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/labeler.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/labeler.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/labeler.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/labeler.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/matrix-command.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/matrix-command.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/microbenchmark.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/microbenchmark.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/packages.yml:23: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/packages.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pre-commit.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/pre-commit.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pre-commit.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/pre-commit.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pre-commit.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/pre-commit.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:43: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:44: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:66: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:81: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:82: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release.yml:86: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:97: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:119: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:131: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:175: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release.yml:176: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release.yml:199: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/release.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release.yml:203: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/release.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/run-matrix.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/run-matrix.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/run-matrix.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/run-matrix.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/run-matrix.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/run-matrix.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test-docs.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/test-docs.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test-reporter.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/test-reporter.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:134: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:137: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:148: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:155: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:55: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:174: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:179: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:191: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:195: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:202: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:219: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/updatecli.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/updatecli.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/updatecli.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/updatecli.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/updatecli.yml:44: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/updatecli.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/updatecli.yml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/elastic/apm-agent-python/updatecli.yml/main?enable=pin",
                        "Warn: containerImage not pinned by hash: tests/Dockerfile:2",
                        "Warn: pipCommand not pinned by hash: tests/Dockerfile:41",
                        "Warn: pipCommand not pinned by hash: tests/Dockerfile:41",
                        "Warn: pipCommand not pinned by hash: dev-utils/make-distribution.sh:42",
                        "Warn: pipCommand not pinned by hash: dev-utils/make-packages.sh:7",
                        "Warn: pipCommand not pinned by hash: scripts/run-benchmarks.sh:19",
                        "Warn: downloadThenRun not pinned by hash: tests/scripts/docker/run_tests.sh:9",
                        "Warn: pipCommand not pinned by hash: tests/scripts/run_tests.sh:6",
                        "Warn: pipCommand not pinned by hash: tests/scripts/run_tests.sh:7",
                        "Info:   3 out of  33 GitHub-owned GitHubAction dependencies pinned",
                        "Info:  10 out of  25 third-party GitHubAction dependencies pinned",
                        "Info:   2 out of   3 containerImage dependencies pinned",
                        "Info:   0 out of   7 pipCommand dependencies pinned",
                        "Info:   0 out of   1 downloadThenRun dependencies pinned"
                    ],
                    "score": 2,
                    "reason": "dependency not pinned by hash detected -- score normalized to 2",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/release.yml:24",
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/release.yml:63",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/release.yml:75",
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/release.yml:111",
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/release.yml:169",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/updatecli.yml:15",
                        "Info: jobLevel 'packages' permission set to 'read': .github/workflows/updatecli.yml:16",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/labeler.yml:10",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/matrix-command.yml:13",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/microbenchmark.yml:14",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/packages.yml:17",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/pre-commit.yml:9",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/release.yml:11",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/run-matrix.yml:12",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/test-docs.yml:14",
                        "Warn: no topLevel permission defined: .github/workflows/test-release.yml:1",
                        "Info: topLevel 'actions' permission set to 'read': .github/workflows/test-reporter.yml:13",
                        "Warn: topLevel 'checks' permission set to 'write': .github/workflows/test-reporter.yml:14",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/test-reporter.yml:12",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/test.yml:34",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/updatecli.yml:9"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/elastic/apm-agent-python/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\nThanks for your interest in the security of our products.\nOur security policy can be found at [https://www.elastic.co/community/security](https://www.elastic.co/community/security).\n\n## Reporting a Vulnerability\nPlease send security vulnerability reports to security@elastic.co.\n",
        "project_all_labels": [
            "7.14-candidate",
            "7.15-candidate",
            "7.16-candidate",
            "7.17-candidate",
            "8.0-candidate",
            "8.1-candidate",
            "8.10-candidate",
            "8.11-candidate",
            "8.12-candidate",
            "8.2-candidate",
            "8.3-candidate",
            "8.4-candidate",
            "8.5-candidate",
            "8.6-candidate",
            "8.7-candidate",
            "8.8-candidate",
            "8.9-candidate",
            "agent-python",
            "automation",
            "aws--extension",
            "backlog",
            "blocked",
            "breaking change",
            "bug",
            "build-failures",
            "chore",
            "ci",
            "ci-reported",
            "community",
            "conflicts",
            "cross APM agents",
            "dependencies",
            "discuss",
            "docs",
            "duplicate",
            "elastic-7.4",
            "elastic-7.5",
            "elastic-7.6",
            "enhancement",
            "estimation:Day",
            "estimation:Month",
            "estimation:Week",
            "feature",
            "flaky-test",
            "focus",
            "github_actions",
            "good first issue",
            "hacktoberfest-accepted",
            "help wanted",
            "impact:critical",
            "impact:high",
            "impact:low",
            "in progress",
            "instrumentation",
            "invalid",
            "meta",
            "needs investigation",
            "python",
            "QA:Needs Validation",
            "QA:Validated",
            "question",
            "r&d",
            "regression",
            "review",
            "stretch",
            "Team:Automation",
            "Team:Cloud-Monitoring",
            "Team:Cloudnative-Monitoring",
            "Team:Docs",
            "Team:Ecosystem",
            "Team:Elastic-Agent",
            "Team:Elastic-Agent-Control-Plane",
            "Team:Elastic-Agent-Data-Plane",
            "Team:Fleet",
            "Team:Infra Monitoring UI",
            "Team:Ingest Management",
            "Team:Integrations",
            "Team:Obs-DC",
            "Team:Obs-InfraObs",
            "Team:Platforms",
            "Team:Security-External Integrations",
            "Team:Service-Integrations",
            "Team:Services",
            "Team:Uptime",
            "technical debt",
            "triage",
            "upstream",
            "v7.11.0",
            "v7.12.0",
            "v7.13.0",
            "v7.14.0",
            "v7.15.0",
            "v7.16.0",
            "v7.17.0",
            "v8.0.0",
            "v8.1.0",
            "v8.10.0",
            "v8.11.0",
            "v8.12.0",
            "v8.2.0",
            "v8.3.0",
            "v8.4.0",
            "v8.5.0",
            "v8.6.0",
            "v8.7.0",
            "v8.8.0",
            "v8.9.0",
            "wontfix"
        ],
        "README_content": "elastic-apm -- Elastic APM agent for Python\n===========================================\n\n.. image:: https://github.com/elastic/apm-agent-python/actions/workflows/test.yml/badge.svg?branch=main\n    :target: https://github.com/elastic/apm-agent-python/actions/workflows/test.yml\n    :alt: Build Status\n\n.. image:: https://img.shields.io/pypi/v/elastic-apm.svg?style=flat\n    :target: https://pypi.python.org/pypi/elastic-apm/\n    :alt: Latest Version\n\n.. image:: https://img.shields.io/pypi/pyversions/elastic-apm.svg?style=flat\n    :target: https://pypi.python.org/pypi/elastic-apm/\n    :alt: Supported Python versions\n\n\nThis is the official Python module for Elastic APM.\n\nIt provides full out-of-the-box support for many of the popular frameworks,\nincluding Django, and Flask. Elastic APM is also easy to adapt for most\nWSGI-compatible web applications via `custom integrations`_.\n\nYour application doesn't live on the web? No problem! Elastic APM is easy to use in\nany Python application.\n\nRead the documentation_, including instructions on `running the tests locally`_.\n\nIf you're interested in contributing, `start here!`_\n\n.. _documentation: https://www.elastic.co/guide/en/apm/agent/python/current/index.html\n.. _`custom integrations`: https://www.elastic.co/blog/creating-custom-framework-integrations-with-the-elastic-apm-python-agent\n.. _`running the tests locally`: https://www.elastic.co/guide/en/apm/agent/python/current/run-tests-locally.html\n.. _`start here!`: https://github.com/elastic/apm-agent-python/blob/main/CONTRIBUTING.md\n\nLicense\n-------\n\nBSD-3-Clause\n\n\nMade with  and  by Elastic and our community.\n",
        "num_commits": 3697,
        "project_age_days": 2665,
        "project_created_at": "2017-07-13",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 196,
        "num_pull": 1416,
        "num_issues": 2145,
        "num_opening_issue": 119,
        "project_size(kB)": 8548,
        "num_stargazers": 412,
        "num_watchers": 412,
        "num_forks": 219,
        "num_subscribers": 236,
        "SecurityPolicy_created_at": "2021-06-28 10:44:52",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "f64994d0a72be9d54ddec76afb65842dc8bcabed",
                "url": "https://github.com/elastic/apm-agent-python/commit/f64994d0a72be9d54ddec76afb65842dc8bcabed",
                "date": "2021-06-28 10:44:52"
            }
        ],
        "project_security_labels": [
            "Team:Security-External Integrations"
        ],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "ipython/ipython",
        "project_url": "https://github.com/ipython/ipython",
        "SSF": {
            "date": "2024-10-29T19:53:07+07:00",
            "repo": {
                "name": "github.com/ipython/ipython",
                "commit": "b65cf89c05b4edb4a32b72e0c0e1b888020ee70f"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.5,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'allow deletion' disabled on branch '7.x'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch '7.x'",
                        "Warn: branch 'main' does not require approvers",
                        "Warn: branch '7.x' does not require approvers",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Warn: codeowners review is not required on branch '7.x'",
                        "Warn: no status checks found to merge onto branch 'main'",
                        "Warn: no status checks found to merge onto branch '7.x'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "9 out of 9 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 2,
                    "reason": "badge detected: InProgress",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 7,
                    "reason": "Found 8/11 approved changesets -- score normalized to 7",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: nebari-dev contributor org/company found, binder-examples contributor org/company found, cocotools contributor org/company found, Basware contributor org/company found, soda-inria contributor org/company found, RobCoIndustries contributor org/company found, SOCI contributor org/company found, sagemath contributor org/company found, NYUCCL contributor org/company found, NeuroVault contributor org/company found, livinglogic ag contributor org/company found, conda-forge contributor org/company found, pydata contributor org/company found, panosc-eu contributor org/company found, Jupyter-contrib contributor org/company found, OxfordNuffieldWRH contributor org/company found, quansight contributor org/company found, BeerTheorySociety contributor org/company found, enthought contributor org/company found, pygame contributor org/company found, pybind contributor org/company found, opensourcedesign contributor org/company found, zed-industries contributor org/company found, amazon web services contributor org/company found, databricks contributor org/company found, scikit-learn contributor org/company found, OpenDreamKit contributor org/company found, runtimed contributor org/company found, h5py contributor org/company found, skrub-data contributor org/company found, JuliaInterop contributor org/company found, LivingLogic contributor org/company found, rpy2 contributor org/company found, MeeseeksBox contributor org/company found, labyrinth-team contributor org/company found, jupytercalpoly contributor org/company found, JunoLab contributor org/company found, quantstack contributor org/company found, jupyterhealth contributor org/company found, nteract contributor org/company found, jovyan contributor org/company found, bqplot contributor org/company found, JuliaConcurrent contributor org/company found, EpicGames contributor org/company found, ovation.io contributor org/company found, RDFLib contributor org/company found, scipy-conference contributor org/company found, mamba-org contributor org/company found, emacs-jp contributor org/company found, binder-project contributor org/company found, numpy contributor org/company found, zeromq contributor org/company found, jupyter-resources contributor org/company found, joblib contributor org/company found, jupyter-robotics contributor org/company found, Maritime-Robotics-Student-Society contributor org/company found, NFAcademy contributor org/company found, jupyter contributor org/company found, WRSC contributor org/company found, berkeley-cocosci contributor org/company found, erdc contributor org/company found, sipb contributor org/company found, jupyter-xeus contributor org/company found, idiap contributor org/company found, quansight-labs contributor org/company found, computationalmodelling contributor org/company found, ICESAT-2HackWeek contributor org/company found, phosphorjs contributor org/company found, pyxg contributor org/company found, scikit-learn-contrib contributor org/company found, JuliaObjects contributor org/company found, apple contributor org/company found, jupyter-incubator contributor org/company found, machine-shop contributor org/company found, python-modernize contributor org/company found, dirty-cat contributor org/company found, jupyter-native contributor org/company found, simula research laboratory contributor org/company found, european xfel contributor org/company found, jupyterlab contributor org/company found, voila-dashboards contributor org/company found, JuliaFolds contributor org/company found, JuliaTesting contributor org/company found, JuliaLang contributor org/company found, getnikola contributor org/company found, cogmaster-stats contributor org/company found, JuliaLabs contributor org/company found, jupytercad contributor org/company found, jupytergis contributor org/company found, redux-observable contributor org/company found, jupyterday-atlanta-2016 contributor org/company found, jupyterhub contributor org/company found, vaultjs contributor org/company found, sympy contributor org/company found, networkx contributor org/company found, cloudpipe contributor org/company found, independent consultant up for hire contributor org/company found, xonsh contributor org/company found, nipy contributor org/company found, highorder contributor org/company found, jupyterlite contributor org/company found, kn-bibs contributor org/company found, pexpect contributor org/company found, matplotlib contributor org/company found, qmlpython contributor org/company found, anaconda contributor org/company found, howtowhale contributor org/company found, voila-gallery contributor org/company found, atom-community contributor org/company found, nokia contributor org/company found, theScienceHub contributor org/company found, pypa contributor org/company found, numfocus contributor org/company found, nilearn contributor org/company found, JuliaArrays contributor org/company found, pylab contributor org/company found, basware contributor org/company found, harmslab contributor org/company found, scipy-lectures contributor org/company found, cytoscape contributor org/company found, pickleshare contributor org/company found, python3statement contributor org/company found, jupyter-widgets contributor org/company found, scipy contributor org/company found, ipython contributor org/company found, qsnake contributor org/company found, xtensor-stack contributor org/company found, jupyter-lsp contributor org/company found, scientific-python contributor org/company found, jupyter-server contributor org/company found, ipython-contrib contributor org/company found, southampton-python contributor org/company found, jupyter-attic contributor org/company found, university of california berkeley. contributor org/company found, compmodels contributor org/company found, scipy-latinamerica contributor org/company found, JuliaPy contributor org/company found, heatlamp contributor org/company found, BIDS contributor org/company found, IRkernel contributor org/company found, joommf contributor org/company found, libRocket contributor org/company found, QuantStack contributor org/company found, JuliaFunctional contributor org/company found, reimandlab contributor org/company found, ucmerced contributor org/company found, European-XFEL contributor org/company found, individual-brain-charting contributor org/company found, spyder-ide contributor org/company found, JuliaPreludes contributor org/company found, CodeJockey contributor org/company found, physion contributor org/company found, thehackerwithin contributor org/company found, google contributor org/company found, jupytercon contributor org/company found, Parietal-INRIA contributor org/company found, plasmabio contributor org/company found, deconst contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 158 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Info: OSSFuzz integration found"
                    ],
                    "score": 10,
                    "reason": "project is fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: BSD 3-Clause \"New\" or \"Revised\" License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/ipython/ipython/docs.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/ipython/ipython/docs.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docs.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/ipython/ipython/docs.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/downstream.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/ipython/ipython/downstream.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/downstream.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/ipython/ipython/downstream.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/mypy.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/ipython/ipython/mypy.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/mypy.yml:23: update your workflow using https://app.stepsecurity.io/secureworkflow/ipython/ipython/mypy.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/nightly-wheel-build.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/ipython/ipython/nightly-wheel-build.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/nightly-wheel-build.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/ipython/ipython/nightly-wheel-build.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/nightly-wheel-build.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/ipython/ipython/nightly-wheel-build.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-package.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/ipython/ipython/python-package.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-package.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/ipython/ipython/python-package.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:59: update your workflow using https://app.stepsecurity.io/secureworkflow/ipython/ipython/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:61: update your workflow using https://app.stepsecurity.io/secureworkflow/ipython/ipython/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:106: update your workflow using https://app.stepsecurity.io/secureworkflow/ipython/ipython/test.yml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/docs.yml:24",
                        "Warn: pipCommand not pinned by hash: .github/workflows/docs.yml:25",
                        "Warn: pipCommand not pinned by hash: .github/workflows/downstream.yml:35",
                        "Warn: pipCommand not pinned by hash: .github/workflows/downstream.yml:41",
                        "Warn: pipCommand not pinned by hash: .github/workflows/downstream.yml:45",
                        "Warn: pipCommand not pinned by hash: .github/workflows/downstream.yml:47",
                        "Warn: pipCommand not pinned by hash: .github/workflows/mypy.yml:28",
                        "Warn: pipCommand not pinned by hash: .github/workflows/mypy.yml:29",
                        "Warn: pipCommand not pinned by hash: .github/workflows/nightly-wheel-build.yml:27",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python-package.yml:30",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python-package.yml:32",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:73",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:74",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:75",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:79",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:80",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:81",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:97",
                        "Info:   0 out of  12 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   3 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of  18 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 28 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Warn: One or no descriptive hints of disclosure, vulnerability, and/or timelines in security policy",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 9,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact 7.9.0 not signed: https://api.github.com/repos/ipython/ipython/releases/20987761",
                        "Warn: release artifact 7.8.0 not signed: https://api.github.com/repos/ipython/ipython/releases/19659644",
                        "Warn: release artifact 7.7.0 not signed: https://api.github.com/repos/ipython/ipython/releases/18900890",
                        "Warn: release artifact 7.6.1 not signed: https://api.github.com/repos/ipython/ipython/releases/18393742",
                        "Warn: release artifact 7.9.0 does not have provenance: https://api.github.com/repos/ipython/ipython/releases/20987761",
                        "Warn: release artifact 7.8.0 does not have provenance: https://api.github.com/repos/ipython/ipython/releases/19659644",
                        "Warn: release artifact 7.7.0 does not have provenance: https://api.github.com/repos/ipython/ipython/releases/18900890",
                        "Warn: release artifact 7.6.1 does not have provenance: https://api.github.com/repos/ipython/ipython/releases/18393742"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/docs.yml:6",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/downstream.yml:12",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/mypy.yml:10",
                        "Warn: no topLevel permission defined: .github/workflows/nightly-wheel-build.yml:1",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/python-package.yml:7",
                        "Warn: no topLevel permission defined: .github/workflows/test.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/ipython/ipython/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Reporting a Vulnerability\n\nAll IPython and Jupyter security are handled via security@ipython.org. \nYou can find more information on the Jupyter website. https://jupyter.org/security\n\n## Tidelift\n\nYou can report security concerns for IPython via the [Tidelift platform](https://tidelift.com/security). \n",
        "project_all_labels": [
            "8.0 what's new",
            "api-review",
            "arch-review",
            "async/await",
            "autosuggestions",
            "backported",
            "bug",
            "closed-pr",
            "core",
            "debugger",
            "dependencies",
            "deprecation/removal",
            "design-review",
            "Docathon",
            "documentation",
            "external-software-interaction",
            "good first issue",
            "Hacktoberfest",
            "hacktoberfest-accepted",
            "help wanted",
            "important",
            "ipep",
            "kernel",
            "magics",
            "matplotlib",
            "msg-spec",
            "nbconvert",
            "needs-decision",
            "needs-info",
            "notebook",
            "Numfocus SDG 2021",
            "osx",
            "parallel",
            "qtconsole",
            "R",
            "regression",
            "security",
            "spam",
            "Still Needs Manual Backport",
            "tab-completion",
            "testing",
            "UI",
            "unicode",
            "widgets",
            "windows",
            "zmq-console"
        ],
        "README_content": ".. image:: https://codecov.io/github/ipython/ipython/coverage.svg?branch=main\n    :target: https://codecov.io/github/ipython/ipython?branch=main\n\n.. image:: https://img.shields.io/pypi/v/IPython.svg\n    :target: https://pypi.python.org/pypi/ipython\n\n.. image:: https://github.com/ipython/ipython/actions/workflows/test.yml/badge.svg\n    :target: https://github.com/ipython/ipython/actions/workflows/test.yml\n\n.. image:: https://www.codetriage.com/ipython/ipython/badges/users.svg\n    :target: https://www.codetriage.com/ipython/ipython/\n\n.. image:: https://raster.shields.io/badge/Follows-SPEC--0000-brightgreen.png\n    :target: https://scientific-python.org/specs/spec-0000/\n\n.. image:: https://tidelift.com/badges/package/pypi/ipython?style=flat\n    :target: https://tidelift.com/subscription/pkg/pypi-ipython\n\n\n===========================================\n IPython: Productive Interactive Computing\n===========================================\n\nOverview\n========\n\nWelcome to IPython.  Our full documentation is available on `ipython.readthedocs.io\n<https://ipython.readthedocs.io/en/stable/>`_ and contains information on how to install, use, and\ncontribute to the project.\nIPython (Interactive Python) is a command shell for interactive computing in multiple programming languages, originally developed for the Python programming language, that offers introspection, rich media, shell syntax, tab completion, and history.\n\n**IPython versions and Python Support**\n\nStarting after IPython 8.16, we will progressively transition to `Spec-0000 <https://scientific-python.org/specs/spec-0000/>`_.\n\nStarting with IPython 7.10, IPython follows `NEP 29 <https://numpy.org/neps/nep-0029-deprecation_policy.html>`_\n\n**IPython 7.17+** requires Python version 3.7 and above.\n\n**IPython 7.10+** requires Python version 3.6 and above.\n\n**IPython 7.0** requires Python version 3.5 and above.\n\n**IPython 6.x** requires Python version 3.3 and above.\n\n**IPython 5.x LTS** is the compatible release for Python 2.7.\nIf you require Python 2 support, you **must** use IPython 5.x LTS. Please\nupdate your project configurations and requirements as necessary.\n\n\nThe Notebook, Qt console and a number of other pieces are now parts of *Jupyter*.\nSee the `Jupyter installation docs <https://jupyter.readthedocs.io/en/latest/install.html>`__\nif you want to use these.\n\nMain features of IPython\n========================\nComprehensive object introspection.\n\nInput history, persistent across sessions.\n\nCaching of output results during a session with automatically generated references.\n\nExtensible tab completion, with support by default for completion of python variables and keywords, filenames and function keywords.\n\nExtensible system of magic commands for controlling the environment and performing many tasks related to IPython or the operating system.\n\nA rich configuration system with easy switching between different setups (simpler than changing $PYTHONSTARTUP environment variables every time).\n\nSession logging and reloading.\n\nExtensible syntax processing for special purpose situations.\n\nAccess to the system shell with user-extensible alias system.\n\nEasily embeddable in other Python programs and GUIs.\n\nIntegrated access to the pdb debugger and the Python profiler.\n\n\nDevelopment and Instant running\n===============================\n\nYou can find the latest version of the development documentation on `readthedocs\n<https://ipython.readthedocs.io/en/latest/>`_.\n\nYou can run IPython from this directory without even installing it system-wide\nby typing at the terminal::\n\n   $ python -m IPython\n\nOr see the `development installation docs\n<https://ipython.readthedocs.io/en/latest/install/install.html#installing-the-development-version>`_\nfor the latest revision on read the docs.\n\nDocumentation and installation instructions for older version of IPython can be\nfound on the `IPython website <https://ipython.org/documentation.html>`_\n\n\nAlternatives to IPython\n=======================\n\nIPython may not be to your taste; if that's the case there might be similar\nproject that you might want to use:\n\n- The classic Python REPL.\n- `bpython <https://bpython-interpreter.org/>`_\n- `mypython <https://www.asmeurer.com/mypython/>`_\n- `ptpython and ptipython <https://pypi.org/project/ptpython/>`_\n- `Xonsh <https://xon.sh/>`_\n\nIgnoring commits with git blame.ignoreRevsFile\n==============================================\n\nAs of git 2.23, it is possible to make formatting changes without breaking\n``git blame``. See the `git documentation\n<https://git-scm.com/docs/git-config#Documentation/git-config.txt-blameignoreRevsFile>`_\nfor more details.\n\nTo use this feature you must:\n\n- Install git >= 2.23\n- Configure your local git repo by running:\n   - POSIX: ``tools\\configure-git-blame-ignore-revs.sh``\n   - Windows:  ``tools\\configure-git-blame-ignore-revs.bat``\n",
        "num_commits": 27181,
        "project_age_days": 5286,
        "project_created_at": "2010-05-10",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 421,
        "num_pull": 7131,
        "num_issues": 14495,
        "num_opening_issue": 1538,
        "project_size(kB)": 78941,
        "num_stargazers": 16303,
        "num_watchers": 16303,
        "num_forks": 4443,
        "num_subscribers": 742,
        "SecurityPolicy_created_at": "2022-01-17 14:28:28",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "3e5275d3a7ad2ee6efc916d5019626e77e516501",
                "url": "https://github.com/ipython/ipython/commit/3e5275d3a7ad2ee6efc916d5019626e77e516501",
                "date": "2022-09-08 16:22:20"
            },
            {
                "commit_id": "9eecab41318397815082d29814cce75b2cd34e45",
                "url": "https://github.com/ipython/ipython/commit/9eecab41318397815082d29814cce75b2cd34e45",
                "date": "2022-09-08 09:48:03"
            },
            {
                "commit_id": "b2f71a87af023177d38196dcf8c9c1a725b8cf59",
                "url": "https://github.com/ipython/ipython/commit/b2f71a87af023177d38196dcf8c9c1a725b8cf59",
                "date": "2022-02-09 18:59:30"
            },
            {
                "commit_id": "11f94ae18c8d2399d0e6e5260c9de322f4af7a31",
                "url": "https://github.com/ipython/ipython/commit/11f94ae18c8d2399d0e6e5260c9de322f4af7a31",
                "date": "2022-01-17 14:28:28"
            }
        ],
        "project_security_labels": [
            "security"
        ],
        "security_issues": [
            {
                "url": "https://github.com/ipython/ipython/issues/12023",
                "title": "Command injection in IPython",
                "labels": [
                    "security"
                ],
                "user": "mschwager",
                "issue_author_association": "NONE",
                "number": 12023,
                "id": 535410859,
                "state": "open",
                "project_created_at": "2019-12-10T00:06:34Z",
                "closed_at": null,
                "body": "Hi IPython,\r\n\r\nFirst off, I'd like to say how much I enjoy using IPython - I use it every day. Recently I've begun work on a [static analysis tool](https://github.com/dlint-py/dlint) for Python code. I ran a subset of its rules against the IPython code base and received some interesting results. In particular, Dlint's checks for `shell=True` subprocess calls:\r\n\r\n```\r\n$ python3 -m flake8 --select=DUO116 ipython/IPython/\r\nipython/IPython/core/interactiveshell.py:2482:22: DUO116 use of \"shell=True\" is insecure in \"subprocess\" module\r\nipython/IPython/core/hooks.py:80:12: DUO116 use of \"shell=True\" is insecure in \"subprocess\" module\r\nipython/IPython/core/page.py:214:24: DUO116 use of \"shell=True\" is insecure in \"subprocess\" module\r\nipython/IPython/lib/editorhooks.py:55:16: DUO116 use of \"shell=True\" is insecure in \"subprocess\" module\r\nipython/IPython/utils/_process_common.py:79:9: DUO116 use of \"shell=True\" is insecure in \"subprocess\" module\r\nipython/IPython/utils/sysinfo.py:58:12: DUO116 use of \"shell=True\" is insecure in \"subprocess\" module\r\n```\r\n\r\nI manually investigated each finding with the following results:\r\n\r\n* `interactiveshell.py`: Unclear if vulnerable, unclear if `shell=True` is necessary\r\n* `hooks.py`: Vulnerable via `$EDITOR, shell=True` unnecessary\r\n* `page.py`: Vulnerable via `$PAGER`, `shell=True` unnecessary\r\n* `editorhooks.py`: Unclear if vulnerable, unclear if shell=True is necessary\r\n* `_process_commend.py`: Unclear if vulnerable, seems shell=True is necessary\r\n* `sysinfo.py`: Not vulnerable, `shell=True` unnecessary\r\n\r\nThe following demonstrates the vulnerabilities in hooks and page:\r\n\r\n```\r\n$ PAGER='echo \"pager\" > /tmp/pager' ipython -c \"open??\"\r\n$ cat /tmp/pager\r\npager\r\n```\r\n```\r\n$ EDITOR='echo \"editor\" > /tmp/editor' ipython -c \"%edit\"\r\n$ cat /tmp/editor\r\neditor\r\n```\r\n\r\nThis issue is highlighted in the Python subprocess docs: [Subprocess Security Considerations](https://docs.python.org/3/library/subprocess.html#security-considerations). This issue falls under CWE-77: [Improper Neutralization of Special Elements used in a Command ('Command Injection')](https://cwe.mitre.org/data/definitions/77.html). I would recommend avoiding `shell=True` whenever possible and investigating the other findings and ensuring they do not have the same issue. It appears that most of the calls do not need shell functionality anyway.\r\n\r\nLet me know if you need any additional information!",
                "comments": [
                    {
                        "body": "Note: This conversation already happen on the security mailing list and is posted in public for transparency. \r\n\r\n--- \r\n\r\n@Carreau replied\r\n\r\nHi Matt,\r\n\r\nMany thanks for the kind words, and thanks for the report, and for\r\npointing us to dlint..\r\n\r\nA few questions and discussion though.\r\nAs far as I understand,  \"Command injection\" usually refer to\r\napplication that are not meant to run arbitrary command. But do so\r\nunder adversarial user input.\r\n\r\n1) The goal of IPython **is** to run arbitrary commands; If you run\r\ncan run IPython, or enter commands into it you don't need to modify\r\n$PAGER or $EDITOR to execute arbitrary commands. I'm also unsure how\r\nan attacker would modify those env variable or provide adversarial\r\ninput.\r\n2) I believe the `shell=True` is necessary (at least ini `$EDITOR`) in\r\nboth the case you outline we do want to explicitly run arbitrary\r\ncommands. For example $EDITOR='atom -w' to have a blocking GUI editor\r\nafter calling `%edit`. `Shell=False` will say `no such command 'atom\r\n-w'`  I guess those can be handled by `shlex.split()`, but other like\r\nipython -c '%sx echo \"onpurpose\" > /tmp/onpurpose' really must use\r\nshell (sx stands for shell execute).\r\n\r\nSo I'd like to better understand what your threat model is, or would\r\nbe for such attacks.\r\nDoes \"Command injection\" really make sens when the goal of the project\r\nis arbitrary code  execution, or if I misunderstood some of the issues\r\nbehind command injections.\r\n\r\nI understand that some of the above would be cleaner w/o shell=True,\r\nat least to show good practice.\r\n\r\nLet us know what you think, and wether there is a need to keep this\r\nprivate; in which case i'm open to have this public on the IPython\r\nrepo and/or do a security advisory.\r\n\r\n---- \r\n\r\n@takluyver replied\r\n\r\n$PAGER can also include options, e.g. \"less -R\". So we can't easily switch away from shell=True there.\r\n\r\nThe threat model here would have to be an attacker that can set environment variables for a context where IPython will be used, but not give IPython commands directly or write anywhere on the filesystem (because if you can do that, you can point one of these environment variables to a script you've written, which gets run even with 'shell=False'). I imagine you can come up with some scenario like that, but given how IPython is designed to be used, I suspect those scenarios are pretty unlikely. If you figure out potential improvements in that area, I'd discuss them in the open rather than through the private security channels.\r\n\r\n--- \r\n\r\n@mschwager replied\r\n\r\nHi,\r\n\r\nThanks for the clarifications. Based on your inputs it seems that there isn't much that can be done. Though I'd say avoiding shell=True is still a good practice :)\r\n\r\nSince IPython is mostly a CLI/development-focused tool, it's unlikely that it's used in such a way where these concerns are exploitable. However, there are probably places where it's being used in an unusual, hard to envision scenario. Further, the attacker would have to be somewhat constrained. As already mentioned, the attacker would have to be able to set env variables but not files on the filesystem. But even in this situation, defensive programming (such as shlex or no shell) wouldn't stop something like: EDITOR='python -c \"<arbitrary code>\"' ipython ...\r\n\r\nIf we consider some of the previously mentioned concerns:\r\nRequiring arguments to script, e.g. 'atom -w': we could avoid shell=True here by using shlex.split. Although this still falls into trouble with the arbitrary code example above.\r\nHandling shell execute functionality, e.g. '%sx': there's not much to be done here, this is the intended behavior :)\r\nThinking about shell=True a bit more... I believe this is most dangerous when user input is being concatenated with an existing string. For example, consider the following:\r\n\r\ncmd = 'ls -l {}'\r\ncmd = cmd.format(cmd, user_input_directory)\r\nsubprocess.Popen(cmd, shell=True)\r\n\r\nThe dangerous part here is that user input could be 'foo; rm -rf /'. Adding shell=True enables multiple commands with ';'. Although the IPython codebase doesn't contain this behavior (or at least doesn't where code execution isn't intended).\r\n\r\nAll in all I'd say that there's no security issues here. Although I would say shlex instead of shell=True would generally be better practice.\r\n\r\nI appreciate all your feedback here and quick responses. I can use this to improve Dlint's analysis capabilities.\r\n\r\n",
                        "user": "Carreau",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2019-12-10T13:55:46Z",
                        "url": "https://github.com/ipython/ipython/issues/12023#issuecomment-564043159"
                    },
                    {
                        "body": "I've done #12024 to remove the one obvious with a static string. \r\nI think we can try `page.py` and `hook.py` with the `shlex.split()` independently.",
                        "user": "Carreau",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2019-12-10T14:01:41Z",
                        "url": "https://github.com/ipython/ipython/issues/12023#issuecomment-564045598"
                    },
                    {
                        "body": "We should remember to check anything we want to change on Windows, unless it's something that would never run on Windows. I vaguely recall some cases where things mysteriously failed on Windows and setting `shell=True` was the fix (/workaround).",
                        "user": "takluyver",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2019-12-10T16:24:40Z",
                        "url": "https://github.com/ipython/ipython/issues/12023#issuecomment-564113398"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/ipython/ipython/issues/7486",
                "title": "Protect modal body from untrusted HTML",
                "labels": [
                    "important",
                    "security"
                ],
                "user": "Carreau",
                "issue_author_association": "MEMBER",
                "number": 7486,
                "id": 54607725,
                "state": "closed",
                "project_created_at": "2015-01-16T18:23:58Z",
                "closed_at": "2015-01-20T22:40:21Z",
                "body": "`IPython.dialog.modal({'body':\"<script>alert('bar')</script>\"})` does what you expect. \n\nWhich is annoying as `load_notebook_error` get the message from the rejected promise, whose `error.message` might be remote from some weird unexpected things. \n\nproposal: \n\nin our dialog implementation, use a `unsafe_body` key when we know the body come from a trusted source and contain html. Use it if necessary,  and sanitize/escape otherwise. \n",
                "comments": [
                    {
                        "body": "I agree that we should escape html from untrusted sources, but I disagree that we should use an 'unsafe_body' key, since we would always set it to true, which defeats its purpose. We should just be wary of html from untrusted sources. The load_notebook_error message does come from a trusted source, so it's not an example of a problem.\n",
                        "user": "minrk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2015-01-17T01:21:00Z",
                        "url": "https://github.com/ipython/ipython/issues/7486#issuecomment-70347952"
                    },
                    {
                        "body": "> The load_notebook_error message does come from a trusted source, so it's not an example of a problem\n\nOn jupyterdrive I am not completely certain it comes from a trusted source. (Agreed this is paranoia)\n\nI think I miss expressed myself with unsafe_body:\n\nImho :\n`modal({ body: '<script>alert('foo')</script>'})` should show `<script>alert('foo')</script>` and `modal({ unsafe_body: '<script>alert('foo')</script>'})` should execute the js, or whatever name we give it. \n\nunsafe usage  of modal should be explicit, safety should be default. \n",
                        "user": "Carreau",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2015-01-17T14:41:09Z",
                        "url": "https://github.com/ipython/ipython/issues/7486#issuecomment-70369304"
                    },
                    {
                        "body": "Every single case we have right now would use unsafe_body, so I'm not sure how that helps.\n",
                        "user": "minrk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2015-01-17T20:00:06Z",
                        "url": "https://github.com/ipython/ipython/issues/7486#issuecomment-70381959"
                    },
                    {
                        "body": "I think it's completely fine for this helper function to accept HTML.  I think wherever you're uncertain if the content is safe or not (you mention jupyterdrive) you should sanitize it before passing it into the dialog method.\n",
                        "user": "jdfreder",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2015-01-19T21:07:08Z",
                        "url": "https://github.com/ipython/ipython/issues/7486#issuecomment-70560827"
                    },
                    {
                        "body": "Absolutely. There's no way dialog should stop accepting HTML. I've retitled the issue, since I don't think @Carreau is proposing that.\n",
                        "user": "minrk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2015-01-19T21:22:28Z",
                        "url": "https://github.com/ipython/ipython/issues/7486#issuecomment-70563207"
                    },
                    {
                        "body": "Sorry for confusing title. \nI ment that if the function receive text it should not be considered trusted and turned into html. \n",
                        "user": "Carreau",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2015-01-19T21:24:53Z",
                        "url": "https://github.com/ipython/ipython/issues/7486#issuecomment-70563582"
                    },
                    {
                        "body": "This was addressed by #7493.\n",
                        "user": "takluyver",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2015-01-20T22:40:21Z",
                        "url": "https://github.com/ipython/ipython/issues/7486#issuecomment-70749482"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/ipython/ipython/issues/7044",
                "title": "IPython testsuite is insecure",
                "labels": [
                    "security"
                ],
                "user": "jdemeyer",
                "issue_author_association": "CONTRIBUTOR",
                "number": 7044,
                "id": 50298995,
                "state": "closed",
                "project_created_at": "2014-11-27T14:52:42Z",
                "closed_at": "2014-12-08T08:15:21Z",
                "body": "(this is about IPython 2.3.0, I am currently unable to check the IPython development version)\n\nWhen a user X runs the IPython testsuite on a shared system, then any user on that system can easily execute arbitrary code as user X.\n\nThe reason is that some tests from `IPython.utils.tests.test_process` involve creating a file `/tmp/tmpxxx.py` containing a `from __future__ import` statement. Python adds the script directory (`/tmp` in this case) to `sys.path` and tries to load `/tmp/__future__.py`. Any user can create a file `/tmp/__future__.py` which will then be executed by the IPython testsuite.\n\nUpstream issue: http://bugs.python.org/issue16202\nFixed downstream in Sage: http://trac.sagemath.org/ticket/13579\n",
                "comments": [
                    {
                        "body": "Thanks, we'll take care of that. \n\nUsually you can send an email at security@ipython.org if you want this to stay confidential.\n",
                        "user": "Carreau",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-11-27T17:12:25Z",
                        "url": "https://github.com/ipython/ipython/issues/7044#issuecomment-64814456"
                    },
                    {
                        "body": "Given http://bugs.python.org/issue16202, it can never be really confidential anyway...\n",
                        "user": "jdemeyer",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2014-11-27T17:21:26Z",
                        "url": "https://github.com/ipython/ipython/issues/7044#issuecomment-64815235"
                    },
                    {
                        "body": "Yeah, but in any case someone came upon this and wonder how to report a security issue :-) \n",
                        "user": "Carreau",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-11-27T17:23:17Z",
                        "url": "https://github.com/ipython/ipython/issues/7044#issuecomment-64815395"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/ipython/ipython/pull/7016",
                "title": "Use Content Security Policies instead of X-Frame-Options",
                "labels": [
                    "security"
                ],
                "user": "rgbkrk",
                "issue_author_association": "MEMBER",
                "number": 7016,
                "id": 49801033,
                "state": "closed",
                "project_created_at": "2014-11-22T18:50:07Z",
                "closed_at": "2014-12-02T23:56:20Z",
                "body": "Content Security Policies are supported by all major browsers while not all of X-Frame-Options is supported. For example, Chrome flat out ignores `ALLOW FROM` and just lets any site embed an iframe of the notebook (#6918).\n\nThis implements #6862, setting a default Content Security Policy and allowing for overrides in the same way that #6120 originally did for `X-Frame-Options`.\n",
                "comments": [
                    {
                        "body": "Solid read on [introducing a Content-Security-Policy and what they cover](http://www.html5rocks.com/en/tutorials/security/content-security-policy/).\n",
                        "user": "rgbkrk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-11-22T19:16:28Z",
                        "url": "https://github.com/ipython/ipython/pull/7016#issuecomment-64091767"
                    },
                    {
                        "body": "If you've ever loved problems with caching, you're going to LOVE this. It seems like Chrome caches the Content-Security-Policy for all open tabs. If you change the policy while you still have a tab open, _even if you open it incognito_, it will use the previous policy. Close all the tabs though and then you're fine.\n",
                        "user": "rgbkrk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-11-23T05:01:31Z",
                        "url": "https://github.com/ipython/ipython/pull/7016#issuecomment-64106930"
                    },
                    {
                        "body": "Originally this PR was including a report mode that would log everything in violation with a stringent policy. Since this fills up the JavaScript console, I took it out. If I could wrap it in checking for our `--debug` flag, I'd love to do that.\n\n```\nif \"Content-Security-Policy-Report-Only\" not in headers:\n    reporter_policy = (\"default-src 'self'; \" +\n                       \"report-uri \" + url_path_join(self.base_url, csp_report_uri) + \n                       \";\"\n    )\n    headers[\"Content-Security-Policy-Report-Only\"] = reporter_policy\n```\n\nWe can use the reporting mode for evaluating more stringent policies, in pieces over time.\n",
                        "user": "rgbkrk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-11-23T05:08:35Z",
                        "url": "https://github.com/ipython/ipython/pull/7016#issuecomment-64107066"
                    },
                    {
                        "body": "Included in this PR is an `/api/security/csp-report` endpoint that the user's browser will report CSP violations to (dependent on the `report-uri`). This is provided as a simple way for admins to get feedback about violations, since they can be more restrictive than we are here.\n\n![screen shot 2014-11-22 at 11 19 47 pm](https://cloud.githubusercontent.com/assets/836375/5156678/26388a52-729e-11e4-8199-1db606091fde.png)\n\nServer side logging:\n\n```\n[W 23:18:03.980 NotebookApp] {u'csp-report': {u'violated-directive': u\"frame-ancestors 'self'\", u'referrer': u'http://lambdaops.com/', u'blocked-uri': u'http://127.0.0.1:8888/tree', u'original-policy': u\"frame-ancestors 'self'; report-uri /api/security/csp-report;\", u'document-uri': u'http://127.0.0.1:8888/tree', u'status-code': 200}}\n```\n\nClient side console error:\n\n![screen shot 2014-11-22 at 11 10 45 pm](https://cloud.githubusercontent.com/assets/836375/5156676/ee8b2b46-729d-11e4-82d1-69d9ca414eff.png)\n",
                        "user": "rgbkrk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-11-23T05:19:28Z",
                        "url": "https://github.com/ipython/ipython/pull/7016#issuecomment-64107241"
                    },
                    {
                        "body": "No longer a WIP. At the very least, this PR does exactly what the `X-Frame-Options` code was supposed to do (and already doing): to only allow from same origin. What this does now though is allowing for alternate domains and really a lot more flexibility around controls.\n",
                        "user": "rgbkrk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-11-23T05:27:29Z",
                        "url": "https://github.com/ipython/ipython/pull/7016#issuecomment-64107355"
                    },
                    {
                        "body": "Rebased.\n",
                        "user": "rgbkrk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-11-28T18:20:56Z",
                        "url": "https://github.com/ipython/ipython/pull/7016#issuecomment-64919140"
                    },
                    {
                        "body": "Ping @ellisonbg about new URL path `/api/security/`.\n",
                        "user": "rgbkrk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-11-28T18:21:32Z",
                        "url": "https://github.com/ipython/ipython/pull/7016#issuecomment-64919178"
                    },
                    {
                        "body": "I have added this to the hackpad agenda...\n",
                        "user": "ellisonbg",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-11-30T02:38:17Z",
                        "url": "https://github.com/ipython/ipython/pull/7016#issuecomment-64973285"
                    },
                    {
                        "body": "Clarifications from the dev meeting:\n\nThe `/api/security/csp-report` endpoint is provided for the browser to report violations of a content security policy back to the server. This has to be reported to the same requesting domain, so it has to be included in the notebook server (or handled with a separate path by nginx, etc.) as a convenience.\n\nThis currently does no extra handling of the csp-report, which has a defined JSON spec. It just spits the JSON out to the log.\n",
                        "user": "rgbkrk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-12-02T18:49:30Z",
                        "url": "https://github.com/ipython/ipython/pull/7016#issuecomment-65282425"
                    },
                    {
                        "body": "Just made a couple of comments regarding log statements, but other than that it's good to go.\n",
                        "user": "minrk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-12-02T20:07:15Z",
                        "url": "https://github.com/ipython/ipython/pull/7016#issuecomment-65295450"
                    },
                    {
                        "body": "Updated the log statement.\n\n![screenshot 2014-12-02 14 51 32](https://cloud.githubusercontent.com/assets/836375/5270679/eb8fb5dc-7a32-11e4-8a89-91ecaaf8c5c8.png)\n\nView of embedded iframe on Firefox:\n\n![screenshot 2014-12-02 14 52 35](https://cloud.githubusercontent.com/assets/836375/5270688/f6e83314-7a32-11e4-970e-0a768d9e395a.png)\n",
                        "user": "rgbkrk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-12-02T20:53:27Z",
                        "url": "https://github.com/ipython/ipython/pull/7016#issuecomment-65302429"
                    },
                    {
                        "body": "When a page is in violation of the iframe embedding on the latest version of Chrome, it currently crashes the tab. This was not so just 10 days ago.\n\n/cc @kestertong ;)\n",
                        "user": "rgbkrk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-12-02T20:58:17Z",
                        "url": "https://github.com/ipython/ipython/pull/7016#issuecomment-65303191"
                    },
                    {
                        "body": "I rebased against `master` just in case. Not that it mattered though.\n",
                        "user": "rgbkrk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-12-02T21:27:29Z",
                        "url": "https://github.com/ipython/ipython/pull/7016#issuecomment-65307760"
                    },
                    {
                        "body": "Just for fun, I wrote some Node that will crash your Chrome tab:\n\n``` node\nvar http = require('http');\n\nhttp.createServer(function (req, res) {\n  res.writeHead(200, {'Content-Security-Policy': 'frame-ancestors \\'self\\'; report-uri /test'});\n  res.end(';)');\n}).listen(9999);\n\nhttp.createServer(function (req, res) {\n  res.end('<iframe src=\"http://127.0.0.1:9999\" width=\"100%\" height=\"100%\"></iframe>');\n}).listen(8000);\n```\n",
                        "user": "rgbkrk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-12-02T21:27:56Z",
                        "url": "https://github.com/ipython/ipython/pull/7016#issuecomment-65307832"
                    },
                    {
                        "body": "Reported the bug to Chrome. Doesn't affect the proper use case, just the invalid use case.\n",
                        "user": "rgbkrk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-12-02T21:47:11Z",
                        "url": "https://github.com/ipython/ipython/pull/7016#issuecomment-65310985"
                    },
                    {
                        "body": "Turns out that was just _my_ chrome. I couldn't crash anyone else's.\n",
                        "user": "rgbkrk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-12-03T00:11:18Z",
                        "url": "https://github.com/ipython/ipython/pull/7016#issuecomment-65330315"
                    },
                    {
                        "body": "> Turns out that was just my chrome. I couldn't crash anyone else's.\n\nThe troll under the bridge (as seen below) probably was to blame.\n:bridge_at_night: \n:trollface: \n",
                        "user": "jdfreder",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-12-03T21:59:53Z",
                        "url": "https://github.com/ipython/ipython/pull/7016#issuecomment-65498875"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/ipython/ipython/pulls/7016",
                    "merged_at": "2014-12-02T23:56:20Z"
                }
            },
            {
                "url": "https://github.com/ipython/ipython/issues/6862",
                "title": "X-Frame-Options is deprecated, use CSP instead",
                "labels": [
                    "notebook",
                    "security"
                ],
                "user": "rgbkrk",
                "issue_author_association": "MEMBER",
                "number": 6862,
                "id": 47822984,
                "state": "closed",
                "project_created_at": "2014-11-05T10:53:37Z",
                "closed_at": "2015-01-12T02:22:37Z",
                "body": "[Stack Overflow post](http://stackoverflow.com/questions/10205192/x-frame-options-allow-from-multiple-domains)\n[CSP Policy directives](https://developer.mozilla.org/en-US/docs/Web/Security/CSP/CSP_policy_directives)\n",
                "comments": [
                    {
                        "body": "Can we close this issue?\n",
                        "user": "ellisonbg",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2015-01-12T00:08:17Z",
                        "url": "https://github.com/ipython/ipython/issues/6862#issuecomment-69518959"
                    },
                    {
                        "body": "Ah, yes, fixed in #7016.\n",
                        "user": "rgbkrk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2015-01-12T02:22:37Z",
                        "url": "https://github.com/ipython/ipython/issues/6862#issuecomment-69524170"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/ipython/ipython/issues/4262",
                "title": "Support for custom authentication in Tornado handlers",
                "labels": [
                    "notebook",
                    "security"
                ],
                "user": "sychan",
                "issue_author_association": "CONTRIBUTOR",
                "number": 4262,
                "id": 19947985,
                "state": "closed",
                "project_created_at": "2013-09-23T23:27:16Z",
                "closed_at": "2015-01-11T04:13:54Z",
                "body": "   I'm working on adding authentication support to IPython and after looking at the code, it looks like it is easy enough to do if you are willing to either:\n   1) Fork the code\n   2) Monkeypatch the request handlers\n\n   Neither of these are very appealing (though I would much rather monkeypatch then fork). Are there any other options that could be implemented? I'm sure that other people are interested in this as well especially now that Docker is a viable means provisioning per user notebooks.\n\n   What I am trying to do specifically is to add an HTTP Authorization header to each request that contains an authentication token, and have the handlers verify the validity of the token before servicing the request. Its easy to do and a common approach. I actually need access to the token for backend web service requests. I can override the front end HTML templates and have already modified the javascript to add the headers to the ajax requests, but I am blocked on the backend.\n\n   An alternative might be to setup configurable handlers for /login and /logout and have the front end register the authentication token with the login handler and receive a secure session cookie that references the . Code on the backend such as notebook handlers would have to have access to the session object to authenticate the user for access to data.\n\n   What do people think?\n   Steve\n",
                "comments": [
                    {
                        "body": "Multi user is definitively on the list, and having a plugable authentifiaction  probably also. \nI just don't think we are ready yet, as auth might need several level of things (read, write, execute). \n\nWe are not even sure this will be done at current server level, and there is also the question as of which user is the server running and same question for the kernel. \n\nWe are wondering wether or not a proxy/client architecture might be good, where the proxy would actually handle launchin 1 ipython-server per user, and proxy to it. Then the proxy would handle auth.\n\nAnyway, if you think specifically at one way to do that, I suggest for you to draft a proposal and/or submit a pull request.\n\nI would also suggest looking at `DottedObjectName` configurable, that can allow to use custom class for some object in IPython.\n\nYou can probably have a look at [bookstore](https://github.com/rgbkrk/bookstore) a python package that allow to use rackspace as a storage backend. \n\nIt is a good example of how to use that with a 4 config line (extract from above link) : \n\n```\n# Setup IPython Notebook to write notebooks to CloudFiles\nc.NotebookApp.notebook_manager_class = 'bookstore.cloudfiles.CloudFilesNotebookManager'\n\n# Set your user name and API Key\nc.CloudFilesNotebookManager.account_name = USER_NAME\nc.CloudFilesNotebookManager.account_key = API_KEY\n\n# Container on CloudFiles\nc.CloudFilesNotebookManager.container_name = u'notebooks'\n```\n",
                        "user": "Carreau",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-09-25T16:30:38Z",
                        "url": "https://github.com/ipython/ipython/issues/4262#issuecomment-25102845"
                    },
                    {
                        "body": "Hi Matthias,\n    I agree that handling authentication can be complicated. However if you look at how pluggable authentication is handled in other web platforms, you'll probably see that what I suggested is a fairly conventional approach to dealing with a reasonable number of use cases. I would rather not fork the IPython core and send a PR without a reasonable belief that it would be acceptable to the IPython core devs - so some reasonable guidance about what would be acceptable/unacceptable in terms of design decisions would be helpful.\n\nAs far as having a front end proxy that instantiates new per user notebook instances, as you're no doubt aware, there's a bunch of people working on docker based solutions. We implemented a proof of concept with an nginx proxy + jiffylab, but I can't work on further it for a few weeks. I promised Paul Ivanov that I would upload the current duct tape and bailing wire prototype but haven't been able to scrape together the time for that yet. In the long term, my plan is to move most of the current jiffylab functionality into Nginx and enforce some level of authentication in the Nginx handlers - however that is a couple of months away, and will likely be using the Nginx embedded lua interpreter instead of python. It also doesn't solve the problem of making the authentication token available to a backend services like the notebook manager.\n\nThe example you posted uses a static username and password, so it doesn't support permissions based on user authentication. Thats really the problem, there needs to be a way to pass an authentication token from the web client through to the notebook manager and similar notebook server services, as well as a way to pass it through to the kernel - I implemented a monkeypatching solution for now on the notebook server and a parallel solution with frontend javascript calling into the kernel, but those are just hacks to get around the lack of support. I'll write up a strawman proposal to initiate discussion as you suggested, but it may take a couple of weeks until I'm past the current delivery crunch.\n\n   Steve\n",
                        "user": "sychan",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2013-09-25T18:27:01Z",
                        "url": "https://github.com/ipython/ipython/issues/4262#issuecomment-25112307"
                    },
                    {
                        "body": "@minrk this is an older issue on notebook auth. Is it still relevant?\n",
                        "user": "ellisonbg",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2015-01-11T02:31:06Z",
                        "url": "https://github.com/ipython/ipython/issues/4262#issuecomment-69481070"
                    },
                    {
                        "body": "@ellisonbg this should be addressed now\n",
                        "user": "minrk",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2015-01-11T04:14:05Z",
                        "url": "https://github.com/ipython/ipython/issues/4262#issuecomment-69483039"
                    }
                ],
                "pull_request": null
            }
        ],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 6,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "nsupdate-info/nsupdate.info",
        "project_url": "https://github.com/nsupdate-info/nsupdate.info",
        "SSF": {
            "date": "2024-10-30T00:26:17+07:00",
            "repo": {
                "name": "github.com/nsupdate-info/nsupdate.info",
                "commit": "3cf472aff713047df3c396c613c8211897560eef"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 4.5,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: branch 'master' does not require approvers",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Warn: no status checks found to merge onto branch 'master'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 1,
                    "reason": "2 out of 14 merged PRs checked by a CI test -- score normalized to 1",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 0/4 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: shackspace contributor org/company found, borgbackup contributor org/company found, discorporate contributor org/company found, nerdpol contributor org/company found, Selfnet contributor org/company found, opendata-stuttgart contributor org/company found, freelancer self-employed contributor org/company found, nsupdate-info contributor org/company found, moinwiki contributor org/company found, bepasty contributor org/company found, anatidae contributor org/company found, hft-swp contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 12 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: :0"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "19 commit(s) and 1 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:73: update your workflow using https://app.stepsecurity.io/secureworkflow/nsupdate-info/nsupdate.info/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:78: update your workflow using https://app.stepsecurity.io/secureworkflow/nsupdate-info/nsupdate.info/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:82: update your workflow using https://app.stepsecurity.io/secureworkflow/nsupdate-info/nsupdate.info/ci.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yml:100: update your workflow using https://app.stepsecurity.io/secureworkflow/nsupdate-info/nsupdate.info/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:32: update your workflow using https://app.stepsecurity.io/secureworkflow/nsupdate-info/nsupdate.info/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/nsupdate-info/nsupdate.info/ci.yml/master?enable=pin",
                        "Warn: containerImage not pinned by hash: scripts/docker/Dockerfile:1: pin your Docker image by updating python:3.11-alpine to python:3.11-alpine@sha256:f089154eb2546de825151b9340a60d39e2ba986ab17aaffca14301b0b961a11c",
                        "Warn: pipCommand not pinned by hash: scripts/docker/test.sh:8",
                        "Warn: pipCommand not pinned by hash: scripts/docker/test.sh:9",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:39",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:95",
                        "Info:   0 out of   5 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   1 containerImage dependencies pinned",
                        "Info:   0 out of   4 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 29 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: docs/security.rst:1",
                        "Warn: no linked content found",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: docs/security.rst:1",
                        "Info: Found text in security policy: docs/security.rst:1"
                    ],
                    "score": 4,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/ci.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-248v-346w-9cwc",
                        "Warn: Project is vulnerable to: GHSA-5hgc-2vfp-mqvc / PYSEC-2024-102",
                        "Warn: Project is vulnerable to: GHSA-795c-9xpc-xw6g / PYSEC-2024-68",
                        "Warn: Project is vulnerable to: GHSA-7h4p-27mh-hmrw / PYSEC-2023-225",
                        "Warn: Project is vulnerable to: GHSA-9jmf-237g-qf46 / PYSEC-2024-58",
                        "Warn: Project is vulnerable to: GHSA-f6f8-9mx6-9mx2 / PYSEC-2024-59",
                        "Warn: Project is vulnerable to: GHSA-h8gc-pgj2-vjm3 / PYSEC-2023-226",
                        "Warn: Project is vulnerable to: GHSA-jh75-99hh-qvx9 / PYSEC-2024-67",
                        "Warn: Project is vulnerable to: GHSA-pv4p-cwwg-4rph / PYSEC-2024-70",
                        "Warn: Project is vulnerable to: GHSA-qg2p-9jwr-mmqf / PYSEC-2024-56",
                        "Warn: Project is vulnerable to: GHSA-qmf9-6jqf-j8fq / PYSEC-2023-222",
                        "Warn: Project is vulnerable to: GHSA-r836-hh6v-rg5g / PYSEC-2024-69",
                        "Warn: Project is vulnerable to: GHSA-rrqc-c2jx-6jgv",
                        "Warn: Project is vulnerable to: GHSA-vm8q-m57g-pff3 / PYSEC-2024-47",
                        "Warn: Project is vulnerable to: GHSA-x7q2-wr7g-xqmf / PYSEC-2024-57",
                        "Warn: Project is vulnerable to: GHSA-xxj9-f6rv-m3x4 / PYSEC-2024-28",
                        "Warn: Project is vulnerable to: GHSA-jjg7-2v4v-x38h / PYSEC-2024-60",
                        "Warn: Project is vulnerable to: GHSA-9wx4-h78v-vm56",
                        "Warn: Project is vulnerable to: GHSA-2m57-hf25-phgg",
                        "Warn: Project is vulnerable to: GHSA-34jh-p97f-mpxf",
                        "Warn: Project is vulnerable to: GHSA-g4mx-q9vg-27p4 / PYSEC-2023-212",
                        "Warn: Project is vulnerable to: GHSA-v845-jxx5-vc9f / PYSEC-2023-192",
                        "Warn: Project is vulnerable to: GHSA-jh3w-4vvf-mjgr / PYSEC-2023-100",
                        "Warn: Project is vulnerable to: GHSA-r3xc-prgr-mg9p / PYSEC-2023-61"
                    ],
                    "score": 0,
                    "reason": "24 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/nsupdate-info/nsupdate.info/contents/docs/security.rst",
        "SecurityPolicy_content": "=======================\nSecurity considerations\n=======================\n\nTransmission security\n=====================\n\nUse https for the web interface as well as for the update client (if possible).\n\nOtherwise, your username / password (FQDN / update secret) will be transmitted\nin clear text (unencrypted).\n\nThe web interface will warn you if you use it via http. If WE_HAVE_TLS is\nset to True, it will suggest you better use the https site and link there.\n\nAdditionally, the service administrator can implement a redirect from the\nhttp to the https site within the webserver configuration for the WWW_HOST.\nThe redirect should **not** be implemented for WWW_IPV4_HOST and WWW_IPV6_HOST\nas it is unknown whether all update clients can deal with a redirect (and\nsupport TLS).\n\nFor the router / update client configuration examples we show when creating a\nupdate secret, we use update URLs with https: (and we also tell why it might\nnot work).\n\nOn the hosts overview page, we show whether we received the last update via TLS.\n\nPlease note that if you like security, you also need to use https (with\ncertificate verification) if you use the web-based method to query your IP\naddress. If you use http, a powerful attacker could MITM your request and\ntell you a wrong IP, which your updater then would happily write into DNS.\n\n\nLogin with remote vs. local Account\n===================================\n\nIf you use a already existing remote account to log in into our service, you\ndon't need to create a local profile (with username, E-Mail and password).\n\nThat way, we need to store less information about you - especially no password\nhash (and you also don't need to create a new password just for our service).\nSo, this is a little more safe if you just consider our service.\n\nBUT: If you use some external service to log in, you of course need to trust\nthem for this purpose as *they* are telling \"yes, this is really you\".\n\nAlso, if you cancel the account on that external service and you don't have\na local profile (login, E-Mail, password) with us, you will be unable to log\nin afterwards or recover access to your hosts/domains.\n\nSo maybe the best way is to first create a local profile (username, E-Mail,\npassword), then log in and associate your other remote accounts with that\nlocal profile.\n\n\nPasswords / Secrets / Keys\n==========================\n\nInteractive login password\n--------------------------\n\nWe recommend that you use a rather strong and not guessable password for this.\nDo not re-use passwords, use a password system or a password manager.\n\nThe interactive login password for the web site is stored using Django's\ndefault hasher mechanism, which is currently pbkdf2 (a very strong and\nintentionally slow password hash). Brute-Force attacks against such hashes are\nvery slow, much slower than against simple hashes like (s)sha1/sha256 etc.\n\nIt is NOT stored in clear text by nsupdate.info.\n\nIf you lose the password, you'll have to do a password reset via e-mail.\n\n\nAutomated update secret\n-----------------------\n\nThe automated update secret for routers or other update clients is a\nrandom and automatically generated secret. We store it using the sha1 hasher\nof Django (which in fact is salted-sha1, a not very strong, but fast-to-compute\nhash).\n\nConsidering that a lot of routers or update clients store this secret in clear\ntext in their configuration and often transmit it using unencrypted http (and\nnot https), this secret is not too safe anyway. We also wanted to save some cpu\ncycles here and rather not use pbkdf2 for this regularly and automatically used\nsecret.\n\nIt is not stored in clear text by nsupdate.info.\n\nIf you lose the secret, you'll have to generate a new one and change it in your\nupdate client also.\n\nWe use a random and automatically generated update secret to avoid that users\nenter a bad password here (like reusing a password they use somewhere else,\nchoosing a too simple password) and to avoid disclosure of such user-chosen\npasswords in case the hashes ever get stolen and brute forced.\n\n\nNameserver Update Secret (backend, RFC 2136)\n--------------------------------------------\n\nWe currently store this secret (which is basically a base64 encoded shared secret,\none per dynamic zone) \"as is\" into the database (\"Domain\" records there).\n\nThis is somehow critical, but also hard to do better - encryption would only\nhelp very little here as we would need to decrypt the update secret before using it,\nso we would need the unlocked decryption key on the same machine.\n\nMake sure no unauthorized person gets that secret or he/she will be able to update\nANY record in the respective zone / nameserver directly (without going over\nnsupdate.info software / service).\n\nWe support creating a random update secret, so you don't need an extra tool for this.\n\n\nOther Services Update Secret (dyndns2 client)\n---------------------------------------------\n\nWe need to store this secret \"as is\" into the database for the same reasons as\noutlined above.\n\nBut: we tell you in the services overview whether we'll use TLS to transmit the\nupdate, so at least if TLS is enabled, it won't go unencrypted over the wire.\n\n\nCSRF protection\n===============\n\nWe use Django's CSRF protection middleware.\n\n\nClickjacking protection\n=======================\n\nWe use Django's clickjacking protection middleware.\n\n\nXSS protection\n==============\n\nDjango's templating engine html-escapes inputs by default.\n\n\nCookies\n=======\n\nThe software (\"as is\") uses these cookies:\n\n* \"csrftoken\" (host-only, for CSRF protection)\n* \"sessionid\" (host-only, to keep the session when you have logged-in to the\n  web interface)\n\nIf you have set WE_HAVE_TLS to True (because you run the software on a https\nsite), you should also set *_COOKIE_SECURE to True to avoid the cookies getting\ntransmitted via http.\n\nWe use a session cookie by default (gets cleared when you close the browser).\nIf you check the \"Keep me logged in\" checkbox on the login screen, then we'll\nset a permanent cookie with a lifetime as configured by the site admin\n(SESSION_COOKIE_AGE, default: 14 days).\n\nBe careful with domain cookies\n------------------------------\n\nThe software (\"as is\") does not use any domain cookies.\n\nIn case you modify the software, please be extremely cautious with domain\ncookies and in case of doubt, do rather not use them.\n\nIf you use domain cookies (like for \".yourservice.net\", the leading dot\nmakes it a domain cookie), all hosts in that domain would be able to read\nand write these cookies. Your site (at e.g. www.yourservice.net), but also\nusers' sites (like attacker.yourservice.net).\n\nObviously, this might lead to security issues with stealing, modifying and\nfaking domain cookies.\n\n\nDjango's SECRET_KEY\n===================\n\nDjango's SECRET_KEY needs to be a long, random and secret string (it is\nusually set up by the administrator of the site).\n\nThe builtin default settings will try to read SECRET_KEY from an environment\nvariable of same name. If there is no such environment variable, the SECRET_KEY\nwill be undefined.\n\nYou can also define the SECRET_KEY in your local_settings.py.\n\nIf you do not define a SECRET_KEY by one of these methods, the application\nwill refuse to start and give you an error, that a SECRET_KEY is required.\n",
        "project_all_labels": [
            "BountySource",
            "bug",
            "dependencies",
            "duplicate",
            "easy",
            "enhancement",
            "invalid",
            "needs help",
            "scalability",
            "security",
            "task",
            "urgent",
            "wontfix"
        ],
        "README_content": "About nsupdate.info\n===================\n\nhttps://nsupdate.info is a free dynamic DNS service.\n\nnsupdate.info is also the name of the software used to implement it.\nIf you like, you can use it to host the service on your own server.\n\nDocumentation: https://nsupdateinfo.readthedocs.io/\n\nSoftware project: https://github.com/nsupdate-info/nsupdate.info\n\n|doc| |build| |coverage| |package|\n\n.. |doc| image:: https://readthedocs.org/projects/nsupdateinfo/badge/?version=stable\n        :alt: Documentation\n        :target: https://nsupdateinfo.readthedocs.io/en/stable/\n\n.. |build| image:: https://github.com/nsupdate-info/nsupdate.info/workflows/CI/badge.svg?branch=master\n        :alt: Build Status\n        :target: https://github.com/nsupdate-info/nsupdate.info/actions\n\n.. |coverage| image:: https://codecov.io/gh/nsupdate-info/nsupdate.info/branch/master/graph/badge.svg?token=3qFlVUxINM\n        :alt: Test Coverage\n        :target: https://codecov.io/gh/nsupdate-info/nsupdate.info\n\n.. |package| image:: https://badge.fury.io/py/nsupdate.png\n        :alt: PyPI Package\n        :target: http://badge.fury.io/py/nsupdate\n\n(build and coverage are for latest repo code, package and downloads are for PyPI release)\n\nFeatures\n========\n\n* Frontend: Dynamic DNS updates via dyndns2 protocol (like supported\n  by many DSL/cable routers and client software).\n* Backends:\n\n  - Uses Dynamic DNS UPDATE protocol (RFC 2136) to update compatible\n    nameservers like BIND, PowerDNS and others (the nameserver itself is\n    **not** included).\n  - Optionally uses the dyndns2 protocol to update other services - we can\n    send updates to configurable third-party services when we receive an\n    update from the router / update client.\n\n* Prominently shows visitor's IP addresses (v4 and v6) on main view,\n  shows reverse DNS lookup results (on host overview view).\n* Multiple Hosts per user (using separate secrets for security)\n* Add own domains / nameservers (public or only for yourself)\n* Related Hosts: support updating DNS records of other hosts in same LAN by\n  a single updater (e.g. for IPv6 with changing prefix, IPv4 also works)\n* Login with local or remote accounts (Google, GitHub, Bitbucket, ...\n  accounts - everything supported by the python-social-auth package)\n* Manual IP updates via web interface\n* Browser-based update client for temporary/adhoc usage\n* Shows time since last update via API, whether it used TLS or not\n* Shows IP v4 and v6 addresses (from master nameserver records)\n* Shows client / server fault counters, available and abuse flags\n* Supports IP v4 and v6, TLS.\n* Easy and simple web interface, it tries to actively help to configure\n  routers / update clients / nameservers.\n* Made with security and privacy in mind\n* No nagging, no spamming, no ads - trying not to annoy users\n* Free and open source software, made with Python and Django\n",
        "num_commits": 1353,
        "project_age_days": 4045,
        "project_created_at": "2013-10-02",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-12",
        "num_contributors": 23,
        "num_pull": 183,
        "num_issues": 566,
        "num_opening_issue": 50,
        "project_size(kB)": 3978,
        "num_stargazers": 1041,
        "num_watchers": 1041,
        "num_forks": 115,
        "num_subscribers": 50,
        "SecurityPolicy_created_at": "2013-10-03 22:28:28",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "70ab4524842c2f3ae5958da3aa1dfac4902867c7",
                "url": "https://github.com/nsupdate-info/nsupdate.info/commit/70ab4524842c2f3ae5958da3aa1dfac4902867c7",
                "date": "2014-11-15 15:05:29"
            },
            {
                "commit_id": "1697941ad046cf9184dd93a6b5b38a69b5f24aa1",
                "url": "https://github.com/nsupdate-info/nsupdate.info/commit/1697941ad046cf9184dd93a6b5b38a69b5f24aa1",
                "date": "2014-11-15 14:46:14"
            },
            {
                "commit_id": "63c1cdbe6bd5a3bb0ae4ff1371f365cc4e143ffa",
                "url": "https://github.com/nsupdate-info/nsupdate.info/commit/63c1cdbe6bd5a3bb0ae4ff1371f365cc4e143ffa",
                "date": "2014-09-26 00:25:08"
            },
            {
                "commit_id": "4bb8301142bf5654e7ef724f115b921f607dcc7c",
                "url": "https://github.com/nsupdate-info/nsupdate.info/commit/4bb8301142bf5654e7ef724f115b921f607dcc7c",
                "date": "2014-09-16 22:08:30"
            },
            {
                "commit_id": "b6db7a33d8fd4f769e00cf181a8bef4dba1a3174",
                "url": "https://github.com/nsupdate-info/nsupdate.info/commit/b6db7a33d8fd4f769e00cf181a8bef4dba1a3174",
                "date": "2014-08-28 11:18:08"
            },
            {
                "commit_id": "d47793b71c191c4397e848de87f6f37f00f7a26d",
                "url": "https://github.com/nsupdate-info/nsupdate.info/commit/d47793b71c191c4397e848de87f6f37f00f7a26d",
                "date": "2014-05-29 23:18:50"
            },
            {
                "commit_id": "46008bf2cdd47f01ac40c252ce826215884946bb",
                "url": "https://github.com/nsupdate-info/nsupdate.info/commit/46008bf2cdd47f01ac40c252ce826215884946bb",
                "date": "2014-05-29 23:10:33"
            },
            {
                "commit_id": "0772874ead0f1df7fb38c87e0b6aa1ab762e53ad",
                "url": "https://github.com/nsupdate-info/nsupdate.info/commit/0772874ead0f1df7fb38c87e0b6aa1ab762e53ad",
                "date": "2013-11-29 10:30:14"
            },
            {
                "commit_id": "4589dd512bb839d05ae26cf54c90c37d9d81a97a",
                "url": "https://github.com/nsupdate-info/nsupdate.info/commit/4589dd512bb839d05ae26cf54c90c37d9d81a97a",
                "date": "2013-11-28 08:14:16"
            },
            {
                "commit_id": "dd09b6b5af546608153e92fe1e2d37f4579ce83c",
                "url": "https://github.com/nsupdate-info/nsupdate.info/commit/dd09b6b5af546608153e92fe1e2d37f4579ce83c",
                "date": "2013-11-24 04:04:07"
            },
            {
                "commit_id": "fe96c215922dc592a124de661de3b374d767cf2c",
                "url": "https://github.com/nsupdate-info/nsupdate.info/commit/fe96c215922dc592a124de661de3b374d767cf2c",
                "date": "2013-11-17 01:08:02"
            },
            {
                "commit_id": "89e18d9d6544a00dad6362b5967cc8e7fa2717a1",
                "url": "https://github.com/nsupdate-info/nsupdate.info/commit/89e18d9d6544a00dad6362b5967cc8e7fa2717a1",
                "date": "2013-11-16 04:14:03"
            },
            {
                "commit_id": "0d2184037a88971496555d6e2b4eb36f796c2124",
                "url": "https://github.com/nsupdate-info/nsupdate.info/commit/0d2184037a88971496555d6e2b4eb36f796c2124",
                "date": "2013-11-08 00:52:52"
            },
            {
                "commit_id": "f12539aee814449c58a10385d56bb364351328a0",
                "url": "https://github.com/nsupdate-info/nsupdate.info/commit/f12539aee814449c58a10385d56bb364351328a0",
                "date": "2013-11-03 20:13:08"
            },
            {
                "commit_id": "52c291621561857629d2606bfd61452adfdbb6ce",
                "url": "https://github.com/nsupdate-info/nsupdate.info/commit/52c291621561857629d2606bfd61452adfdbb6ce",
                "date": "2013-11-03 09:19:05"
            },
            {
                "commit_id": "7a9993559799d7529101720cc8435db6a78e31d2",
                "url": "https://github.com/nsupdate-info/nsupdate.info/commit/7a9993559799d7529101720cc8435db6a78e31d2",
                "date": "2013-11-03 08:52:11"
            },
            {
                "commit_id": "5cd14a9cd3e03f24179de8bc5a6f3f07a672fd20",
                "url": "https://github.com/nsupdate-info/nsupdate.info/commit/5cd14a9cd3e03f24179de8bc5a6f3f07a672fd20",
                "date": "2013-11-03 08:15:51"
            },
            {
                "commit_id": "24ad97c0ef6c991da98dcc587e56134a912bcd13",
                "url": "https://github.com/nsupdate-info/nsupdate.info/commit/24ad97c0ef6c991da98dcc587e56134a912bcd13",
                "date": "2013-10-05 14:24:45"
            },
            {
                "commit_id": "aa3fb3c746bf7f9e2cdbde75dd563f1e326106d0",
                "url": "https://github.com/nsupdate-info/nsupdate.info/commit/aa3fb3c746bf7f9e2cdbde75dd563f1e326106d0",
                "date": "2013-10-03 22:28:28"
            }
        ],
        "project_security_labels": [
            "security"
        ],
        "security_issues": [
            {
                "url": "https://github.com/nsupdate-info/nsupdate.info/issues/177",
                "title": "security: user could access/modify other user's related hosts / service updaters",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "ThomasWaldmann",
                "issue_author_association": "MEMBER",
                "number": 177,
                "id": 48169508,
                "state": "closed",
                "project_created_at": "2014-11-08T15:51:59Z",
                "closed_at": "2014-11-08T15:55:42Z",
                "body": "some checks were missing, so it was possible to access/modify other users' configuration for the related hosts and the (3rd party) service updaters.\n\naffected releases: 0.5 .. 0.9.0\nfixed in: 0.9.1\n",
                "comments": [
                    {
                        "body": "fixed by 271741fa46ec32555b0a2117efe7886c09fbe96a\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-11-08T15:55:42Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/177#issuecomment-62262621"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/nsupdate-info/nsupdate.info/issues/163",
                "title": "a host flagged as abuse_blocked can be deleted/recreated by owner",
                "labels": [
                    "bug",
                    "security",
                    "urgent"
                ],
                "user": "ThomasWaldmann",
                "issue_author_association": "MEMBER",
                "number": 163,
                "id": 42660055,
                "state": "closed",
                "project_created_at": "2014-09-12T19:01:33Z",
                "closed_at": "2014-09-12T19:02:22Z",
                "body": "and that removes the abuse_blocked flag, which is of course not wanted.\n",
                "comments": [
                    {
                        "body": "fixed by 6fc1f6469804753ab758ba2fa7b45512a2c0be02\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-09-12T19:02:22Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/163#issuecomment-55446510"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/nsupdate-info/nsupdate.info/issues/145",
                "title": "Custom domains hosting",
                "labels": [
                    "enhancement",
                    "needs help",
                    "security"
                ],
                "user": "ghost",
                "issue_author_association": "NONE",
                "number": 145,
                "id": 31683205,
                "state": "closed",
                "project_created_at": "2014-04-16T21:51:50Z",
                "closed_at": "2015-02-14T17:25:41Z",
                "body": "We should be able to add our own domain name and manage it directly in nsupdate-info.\nNow we are only able to update another nameserver through nsupdate-info.\n",
                "comments": [
                    {
                        "body": "This would require dynamically updating our nameserver with new zones (like owndomain.com).\nNot sure about the security implications of this, needs evaluation.\n\nAlso, usually one wants 2 nameservers for a domain...\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-04-27T23:33:21Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/145#issuecomment-41513149"
                    },
                    {
                        "body": "What is your use case? Do you want to add a subdomain for dydns (dyn.example.com?) and set an NS record to nsupdate.info nameserver?\n",
                        "user": "elnappo",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-12-28T12:23:39Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/145#issuecomment-68205738"
                    },
                    {
                        "body": "Note: this does not only need adding a new domain to the nameserver (that could be done automatically maybe), but also might need adding bind (nameserver specific) configuration, like:\n- allow/deny rules what in the zone may be updated\n- new key for dynamic updates of the zone\n\nSo, I fear this is getting a bit complicated / out of scope of the project (it's not a frontend to create nameserver-specific configuration) and thus I am closing this as \"won't fix\".\n\nIn general: if someone has a cool domain and wants to donate it for a longer period of time, we can always setup something manually on our DNS servers.\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2015-02-14T17:25:41Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/145#issuecomment-74383788"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/nsupdate-info/nsupdate.info/issues/115",
                "title": "security review(s) needed",
                "labels": [
                    "needs help",
                    "task",
                    "security"
                ],
                "user": "ThomasWaldmann",
                "issue_author_association": "MEMBER",
                "number": 115,
                "id": 24461922,
                "state": "open",
                "project_created_at": "2013-12-18T00:35:38Z",
                "closed_at": null,
                "body": "it would be great to have independant security reviews of the nsupdate.info project.\n\nNote: please read our security related docs:\n\nhttp://nsupdateinfo.readthedocs.org/en/latest/security.html\n\nas you see there, we had security in mind when designing/implementing this service, but more eyes would definitely help.\n",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/nsupdate-info/nsupdate.info/issues/81",
                "title": "security issue: update of foreign hosts possible",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "ThomasWaldmann",
                "issue_author_association": "MEMBER",
                "number": 81,
                "id": 22407467,
                "state": "closed",
                "project_created_at": "2013-11-10T13:07:15Z",
                "closed_at": "2013-11-10T13:07:58Z",
                "body": "in release 0.2.0b0, it is possible to authenticate for updating host x and then update host y.\n",
                "comments": [
                    {
                        "body": "fixed by 367bc70f568345911929fae80c54a9e1679e9441\n\nfix released in release 0.3.0\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-11-10T13:07:58Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/81#issuecomment-28150254"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/nsupdate-info/nsupdate.info/issues/79",
                "title": "check the official checklist",
                "labels": [
                    "task",
                    "security"
                ],
                "user": "ThomasWaldmann",
                "issue_author_association": "MEMBER",
                "number": 79,
                "id": 22248214,
                "state": "closed",
                "project_created_at": "2013-11-07T07:12:42Z",
                "closed_at": "2013-11-08T03:42:25Z",
                "body": "https://docs.djangoproject.com/en/1.6/howto/deployment/checklist/\n\nbe careful: this checklist is new in django 1.6 - so if we still use 1.5.x some stuff may not apply.\n",
                "comments": [
                    {
                        "body": "done.\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-11-08T03:42:25Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/79#issuecomment-28032318"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/nsupdate-info/nsupdate.info/issues/77",
                "title": "SSL only updates",
                "labels": [
                    "enhancement",
                    "needs help",
                    "security"
                ],
                "user": "ThomasWaldmann",
                "issue_author_association": "MEMBER",
                "number": 77,
                "id": 22138508,
                "state": "closed",
                "project_created_at": "2013-11-05T18:00:34Z",
                "closed_at": "2014-03-09T22:38:44Z",
                "body": "Option for host to disallow updates via http - making it SSL-updateable only.\n\nhttps://github.com/asmaps/hopper.pw/issues/4\n",
                "comments": [
                    {
                        "body": "Hmm, after thinking about it: is it really helpful?\n\nIf it is a per-host setting, the server would still listen to http updates. So if your router is insecurely configured or misbehaved, your password would go over the wire to the http service first (and then would be rejected as the host setting says SSL-only).\n\nWe currently display whether the updates are SSL or not in the hosts list, so it is the question what we would win with that setting.\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-11-06T14:10:33Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/77#issuecomment-27875740"
                    },
                    {
                        "body": "looks like the only application of this is if the host on the service gets configured/created by someone else than the router / update-client. with a ssl-only setting, you could FORCE the one configuring the router to use SSL, because nothing else would work.\nif the router does not support SSL (and/or SNI), it would not work at all, though.\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-11-16T04:39:15Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/77#issuecomment-28619649"
                    },
                    {
                        "body": "will close this as wontfix 3/2014 - except if someone really needs this and gives reasons here.\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-11-27T07:53:43Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/77#issuecomment-29365860"
                    },
                    {
                        "body": "won't fix, see above\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-03-09T22:38:44Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/77#issuecomment-37142347"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/nsupdate-info/nsupdate.info/issues/66",
                "title": "SECRET_KEY in repo / settings.py",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "ThomasWaldmann",
                "issue_author_association": "MEMBER",
                "number": 66,
                "id": 21645251,
                "state": "closed",
                "project_created_at": "2013-10-27T02:14:03Z",
                "closed_at": "2013-10-27T06:22:54Z",
                "body": "there is some secret-looking key, but it isn't secret\n\ncheck better options:\na) make it non-secret looking (empty, or some string that tells it's non-secret)\nb) remove it and check what happens\n\ndocument it.\n",
                "comments": [
                    {
                        "body": "fixed by 724f35225ec54e591a0e548d82dc07a2d8dded4f\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-10-27T06:22:54Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/66#issuecomment-27163718"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/nsupdate-info/nsupdate.info/issues/39",
                "title": "encourage SSL usage on the UI",
                "labels": [
                    "enhancement",
                    "security"
                ],
                "user": "ThomasWaldmann",
                "issue_author_association": "MEMBER",
                "number": 39,
                "id": 21353932,
                "state": "closed",
                "project_created_at": "2013-10-22T00:20:50Z",
                "closed_at": "2013-11-02T00:14:59Z",
                "body": "ThomasWaldmann wrote:\nif someone visits the service via http, encourage using it via https - without enforcing it.\n",
                "comments": [
                    {
                        "body": "Samuirai wrote:\nnot enforcing is insecure. MITM attacker can block https and every user would use the fallback plain http. Either force https or no ssl at all.\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-10-22T00:20:52Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/39#issuecomment-26768400"
                    },
                    {
                        "body": "ThomasWaldmann wrote:\nsamuirai: ok, so that basically means that login and all logged-in usage of the site has to be https only until the user logs out again.\n\nso the http site (if any) would only show general information that does not require a login/session.\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-10-22T00:20:52Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/39#issuecomment-26768401"
                    },
                    {
                        "body": "fixed by b45ae25b0a46fb7f45b106a8cb18b718daa15644\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-11-02T00:14:59Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/39#issuecomment-27610350"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/nsupdate-info/nsupdate.info/issues/26",
                "title": "DNSSEC",
                "labels": [
                    "enhancement",
                    "security"
                ],
                "user": "ThomasWaldmann",
                "issue_author_association": "MEMBER",
                "number": 26,
                "id": 21353900,
                "state": "closed",
                "project_created_at": "2013-10-22T00:20:28Z",
                "closed_at": "2015-12-28T20:16:49Z",
                "body": "document usage with DNSSEC, add a configuration example, useful links, ...\n",
                "comments": [
                    {
                        "body": "DNSSEC simply works when configured on the DNS server. Support in nsupdate shouldn't be needed.\n",
                        "user": "jluebbe",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2013-12-07T21:41:21Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/26#issuecomment-30065590"
                    },
                    {
                        "body": "maybe we would want to add some configuration example?\n\n(and sometimes I also confuse the nsupdate.info software todo and the nsupdate.info site / dns todo)\n\nwhat also was a bit unclear to me while reading DNSSEC docs: they keys seem to have a limited validity, so does this need regular intervention by the admin to install new keys?\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-12-08T11:17:44Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/26#issuecomment-30079523"
                    },
                    {
                        "body": "Runing DNSSEC with using a recent BIND is not that complicated. The only critical thing is that your domain provider is willing to add the DS records to the top level domain.\n\nFor my zone I have the following config for DNSSEC with nsupdate:\n\n```\nzone \"stratum0.net\" {\n        auto-dnssec maintain;\n        type master;\n        update-policy {\n                  ....\n        };\n        file \"/etc/bind/stratum0.net/stratum0.net\";\n        key-directory \"/etc/bind/stratum0.net\";\n};\n```\n\nOnly auto-dnssec maintain and key-directory \"/etc/bind/stratum0.net\" are relevant to DNSSEC. With this setup, you only need to use dnssec-keygen to generate the KSK and ZSK. Finally you generate the DS records with dnssec-dsfromkey -f <zonefile> and pass those to your domain provider. There is a short guide at http://fanf.livejournal.com/112476.html.\n\nIf your domain provider doesn't support DNSSEC, you can use [DLV (DNSSEC Look-aside Validation)](https://dlv.isc.org/). It's an alternative entry point and also very useful for initial testing.\n\nAlso very useful for debugging is http://dnsviz.net/d/stratum0.net/dnssec/, which shows you a graph of all keys and their relationships. The gray DNSKEYs are KSKs and the while ones are ZSKs. To keep DNS messages smaller, DNSSEC uses shorter keys and so they must be rotated regularly. The longer (2048 bit) KSKs have a lifetime on the order of years and the shorter (1024 bit) ZSKs on the order of months. Note that they do not expire after this time, it's just strongly recommended to perform a rollover after that time.\n\nWith auto-dnssec maintain, you just have to generate new keys. The metadata in the key files allows BIND to handle the rollover automatically. For KSK changes, you'd need to notify your domain provider again.\n\nThis setup has been running without problems for since two months on stratum0.net (which provides DYNDNS for our hackerspace).\n",
                        "user": "jluebbe",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2013-12-08T12:06:44Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/26#issuecomment-30080259"
                    },
                    {
                        "body": "see also #105\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-12-08T13:54:31Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/26#issuecomment-30082014"
                    },
                    {
                        "body": "http://securityblog.switch.ch/2014/11/13/dnssec-signing-your-domain-with-bind-inline-signing/\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-12-06T13:46:25Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/26#issuecomment-65897419"
                    },
                    {
                        "body": "also interesting: how does dnssec signing impact zone update performance?\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-12-06T13:57:52Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/26#issuecomment-65897742"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/nsupdate-info/nsupdate.info/issues/19",
                "title": "validate passwords / secrets",
                "labels": [
                    "enhancement",
                    "security"
                ],
                "user": "ThomasWaldmann",
                "issue_author_association": "MEMBER",
                "number": 19,
                "id": 21353884,
                "state": "closed",
                "project_created_at": "2013-10-22T00:20:11Z",
                "closed_at": "2013-11-02T23:53:31Z",
                "body": "ThomasWaldmann wrote:\nminimum length, etc.\n",
                "comments": [
                    {
                        "body": "asmaps wrote:\nwill be no problem if they are autogenerated\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-10-22T00:20:12Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/19#issuecomment-26768364"
                    },
                    {
                        "body": "only the update secret is autogenerated.\n\nwe could still do some minimal checks for the user login password.\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-10-23T03:24:26Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/19#issuecomment-26877990"
                    },
                    {
                        "body": "just enforcing some minimal length doesn't help much.\n\nmaybe just add some notes to the templates about how to choose a secure password?\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-11-02T00:38:50Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/19#issuecomment-27611043"
                    },
                    {
                        "body": "regarding that dynamic dns users are usually advanced users, they should know the usual pw rules.\n\nso we just let them use whatever login password they like.\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-11-02T23:53:31Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/19#issuecomment-27635491"
                    }
                ],
                "pull_request": null
            }
        ],
        "SecurityPolicy_reporting_mechanism": "not_mentioned",
        "num_security_issues_after_policy": 11,
        "num_security_issue_and_pull": 11,
        "security_issues_created_after_policy": [
            {
                "url": "https://github.com/nsupdate-info/nsupdate.info/issues/177",
                "title": "security: user could access/modify other user's related hosts / service updaters",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "ThomasWaldmann",
                "issue_author_association": "MEMBER",
                "number": 177,
                "id": 48169508,
                "state": "closed",
                "project_created_at": "2014-11-08T15:51:59Z",
                "closed_at": "2014-11-08T15:55:42Z",
                "body": "some checks were missing, so it was possible to access/modify other users' configuration for the related hosts and the (3rd party) service updaters.\n\naffected releases: 0.5 .. 0.9.0\nfixed in: 0.9.1\n",
                "comments": [
                    {
                        "body": "fixed by 271741fa46ec32555b0a2117efe7886c09fbe96a\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-11-08T15:55:42Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/177#issuecomment-62262621"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/nsupdate-info/nsupdate.info/issues/163",
                "title": "a host flagged as abuse_blocked can be deleted/recreated by owner",
                "labels": [
                    "bug",
                    "security",
                    "urgent"
                ],
                "user": "ThomasWaldmann",
                "issue_author_association": "MEMBER",
                "number": 163,
                "id": 42660055,
                "state": "closed",
                "project_created_at": "2014-09-12T19:01:33Z",
                "closed_at": "2014-09-12T19:02:22Z",
                "body": "and that removes the abuse_blocked flag, which is of course not wanted.\n",
                "comments": [
                    {
                        "body": "fixed by 6fc1f6469804753ab758ba2fa7b45512a2c0be02\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-09-12T19:02:22Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/163#issuecomment-55446510"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/nsupdate-info/nsupdate.info/issues/145",
                "title": "Custom domains hosting",
                "labels": [
                    "enhancement",
                    "needs help",
                    "security"
                ],
                "user": "ghost",
                "issue_author_association": "NONE",
                "number": 145,
                "id": 31683205,
                "state": "closed",
                "project_created_at": "2014-04-16T21:51:50Z",
                "closed_at": "2015-02-14T17:25:41Z",
                "body": "We should be able to add our own domain name and manage it directly in nsupdate-info.\nNow we are only able to update another nameserver through nsupdate-info.\n",
                "comments": [
                    {
                        "body": "This would require dynamically updating our nameserver with new zones (like owndomain.com).\nNot sure about the security implications of this, needs evaluation.\n\nAlso, usually one wants 2 nameservers for a domain...\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-04-27T23:33:21Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/145#issuecomment-41513149"
                    },
                    {
                        "body": "What is your use case? Do you want to add a subdomain for dydns (dyn.example.com?) and set an NS record to nsupdate.info nameserver?\n",
                        "user": "elnappo",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-12-28T12:23:39Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/145#issuecomment-68205738"
                    },
                    {
                        "body": "Note: this does not only need adding a new domain to the nameserver (that could be done automatically maybe), but also might need adding bind (nameserver specific) configuration, like:\n- allow/deny rules what in the zone may be updated\n- new key for dynamic updates of the zone\n\nSo, I fear this is getting a bit complicated / out of scope of the project (it's not a frontend to create nameserver-specific configuration) and thus I am closing this as \"won't fix\".\n\nIn general: if someone has a cool domain and wants to donate it for a longer period of time, we can always setup something manually on our DNS servers.\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2015-02-14T17:25:41Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/145#issuecomment-74383788"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/nsupdate-info/nsupdate.info/issues/115",
                "title": "security review(s) needed",
                "labels": [
                    "needs help",
                    "task",
                    "security"
                ],
                "user": "ThomasWaldmann",
                "issue_author_association": "MEMBER",
                "number": 115,
                "id": 24461922,
                "state": "open",
                "project_created_at": "2013-12-18T00:35:38Z",
                "closed_at": null,
                "body": "it would be great to have independant security reviews of the nsupdate.info project.\n\nNote: please read our security related docs:\n\nhttp://nsupdateinfo.readthedocs.org/en/latest/security.html\n\nas you see there, we had security in mind when designing/implementing this service, but more eyes would definitely help.\n",
                "comments": [],
                "pull_request": null
            },
            {
                "url": "https://github.com/nsupdate-info/nsupdate.info/issues/81",
                "title": "security issue: update of foreign hosts possible",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "ThomasWaldmann",
                "issue_author_association": "MEMBER",
                "number": 81,
                "id": 22407467,
                "state": "closed",
                "project_created_at": "2013-11-10T13:07:15Z",
                "closed_at": "2013-11-10T13:07:58Z",
                "body": "in release 0.2.0b0, it is possible to authenticate for updating host x and then update host y.\n",
                "comments": [
                    {
                        "body": "fixed by 367bc70f568345911929fae80c54a9e1679e9441\n\nfix released in release 0.3.0\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-11-10T13:07:58Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/81#issuecomment-28150254"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/nsupdate-info/nsupdate.info/issues/79",
                "title": "check the official checklist",
                "labels": [
                    "task",
                    "security"
                ],
                "user": "ThomasWaldmann",
                "issue_author_association": "MEMBER",
                "number": 79,
                "id": 22248214,
                "state": "closed",
                "project_created_at": "2013-11-07T07:12:42Z",
                "closed_at": "2013-11-08T03:42:25Z",
                "body": "https://docs.djangoproject.com/en/1.6/howto/deployment/checklist/\n\nbe careful: this checklist is new in django 1.6 - so if we still use 1.5.x some stuff may not apply.\n",
                "comments": [
                    {
                        "body": "done.\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-11-08T03:42:25Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/79#issuecomment-28032318"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/nsupdate-info/nsupdate.info/issues/77",
                "title": "SSL only updates",
                "labels": [
                    "enhancement",
                    "needs help",
                    "security"
                ],
                "user": "ThomasWaldmann",
                "issue_author_association": "MEMBER",
                "number": 77,
                "id": 22138508,
                "state": "closed",
                "project_created_at": "2013-11-05T18:00:34Z",
                "closed_at": "2014-03-09T22:38:44Z",
                "body": "Option for host to disallow updates via http - making it SSL-updateable only.\n\nhttps://github.com/asmaps/hopper.pw/issues/4\n",
                "comments": [
                    {
                        "body": "Hmm, after thinking about it: is it really helpful?\n\nIf it is a per-host setting, the server would still listen to http updates. So if your router is insecurely configured or misbehaved, your password would go over the wire to the http service first (and then would be rejected as the host setting says SSL-only).\n\nWe currently display whether the updates are SSL or not in the hosts list, so it is the question what we would win with that setting.\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-11-06T14:10:33Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/77#issuecomment-27875740"
                    },
                    {
                        "body": "looks like the only application of this is if the host on the service gets configured/created by someone else than the router / update-client. with a ssl-only setting, you could FORCE the one configuring the router to use SSL, because nothing else would work.\nif the router does not support SSL (and/or SNI), it would not work at all, though.\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-11-16T04:39:15Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/77#issuecomment-28619649"
                    },
                    {
                        "body": "will close this as wontfix 3/2014 - except if someone really needs this and gives reasons here.\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-11-27T07:53:43Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/77#issuecomment-29365860"
                    },
                    {
                        "body": "won't fix, see above\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-03-09T22:38:44Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/77#issuecomment-37142347"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/nsupdate-info/nsupdate.info/issues/66",
                "title": "SECRET_KEY in repo / settings.py",
                "labels": [
                    "bug",
                    "security"
                ],
                "user": "ThomasWaldmann",
                "issue_author_association": "MEMBER",
                "number": 66,
                "id": 21645251,
                "state": "closed",
                "project_created_at": "2013-10-27T02:14:03Z",
                "closed_at": "2013-10-27T06:22:54Z",
                "body": "there is some secret-looking key, but it isn't secret\n\ncheck better options:\na) make it non-secret looking (empty, or some string that tells it's non-secret)\nb) remove it and check what happens\n\ndocument it.\n",
                "comments": [
                    {
                        "body": "fixed by 724f35225ec54e591a0e548d82dc07a2d8dded4f\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-10-27T06:22:54Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/66#issuecomment-27163718"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/nsupdate-info/nsupdate.info/issues/39",
                "title": "encourage SSL usage on the UI",
                "labels": [
                    "enhancement",
                    "security"
                ],
                "user": "ThomasWaldmann",
                "issue_author_association": "MEMBER",
                "number": 39,
                "id": 21353932,
                "state": "closed",
                "project_created_at": "2013-10-22T00:20:50Z",
                "closed_at": "2013-11-02T00:14:59Z",
                "body": "ThomasWaldmann wrote:\nif someone visits the service via http, encourage using it via https - without enforcing it.\n",
                "comments": [
                    {
                        "body": "Samuirai wrote:\nnot enforcing is insecure. MITM attacker can block https and every user would use the fallback plain http. Either force https or no ssl at all.\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-10-22T00:20:52Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/39#issuecomment-26768400"
                    },
                    {
                        "body": "ThomasWaldmann wrote:\nsamuirai: ok, so that basically means that login and all logged-in usage of the site has to be https only until the user logs out again.\n\nso the http site (if any) would only show general information that does not require a login/session.\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-10-22T00:20:52Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/39#issuecomment-26768401"
                    },
                    {
                        "body": "fixed by b45ae25b0a46fb7f45b106a8cb18b718daa15644\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-11-02T00:14:59Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/39#issuecomment-27610350"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/nsupdate-info/nsupdate.info/issues/26",
                "title": "DNSSEC",
                "labels": [
                    "enhancement",
                    "security"
                ],
                "user": "ThomasWaldmann",
                "issue_author_association": "MEMBER",
                "number": 26,
                "id": 21353900,
                "state": "closed",
                "project_created_at": "2013-10-22T00:20:28Z",
                "closed_at": "2015-12-28T20:16:49Z",
                "body": "document usage with DNSSEC, add a configuration example, useful links, ...\n",
                "comments": [
                    {
                        "body": "DNSSEC simply works when configured on the DNS server. Support in nsupdate shouldn't be needed.\n",
                        "user": "jluebbe",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2013-12-07T21:41:21Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/26#issuecomment-30065590"
                    },
                    {
                        "body": "maybe we would want to add some configuration example?\n\n(and sometimes I also confuse the nsupdate.info software todo and the nsupdate.info site / dns todo)\n\nwhat also was a bit unclear to me while reading DNSSEC docs: they keys seem to have a limited validity, so does this need regular intervention by the admin to install new keys?\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-12-08T11:17:44Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/26#issuecomment-30079523"
                    },
                    {
                        "body": "Runing DNSSEC with using a recent BIND is not that complicated. The only critical thing is that your domain provider is willing to add the DS records to the top level domain.\n\nFor my zone I have the following config for DNSSEC with nsupdate:\n\n```\nzone \"stratum0.net\" {\n        auto-dnssec maintain;\n        type master;\n        update-policy {\n                  ....\n        };\n        file \"/etc/bind/stratum0.net/stratum0.net\";\n        key-directory \"/etc/bind/stratum0.net\";\n};\n```\n\nOnly auto-dnssec maintain and key-directory \"/etc/bind/stratum0.net\" are relevant to DNSSEC. With this setup, you only need to use dnssec-keygen to generate the KSK and ZSK. Finally you generate the DS records with dnssec-dsfromkey -f <zonefile> and pass those to your domain provider. There is a short guide at http://fanf.livejournal.com/112476.html.\n\nIf your domain provider doesn't support DNSSEC, you can use [DLV (DNSSEC Look-aside Validation)](https://dlv.isc.org/). It's an alternative entry point and also very useful for initial testing.\n\nAlso very useful for debugging is http://dnsviz.net/d/stratum0.net/dnssec/, which shows you a graph of all keys and their relationships. The gray DNSKEYs are KSKs and the while ones are ZSKs. To keep DNS messages smaller, DNSSEC uses shorter keys and so they must be rotated regularly. The longer (2048 bit) KSKs have a lifetime on the order of years and the shorter (1024 bit) ZSKs on the order of months. Note that they do not expire after this time, it's just strongly recommended to perform a rollover after that time.\n\nWith auto-dnssec maintain, you just have to generate new keys. The metadata in the key files allows BIND to handle the rollover automatically. For KSK changes, you'd need to notify your domain provider again.\n\nThis setup has been running without problems for since two months on stratum0.net (which provides DYNDNS for our hackerspace).\n",
                        "user": "jluebbe",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2013-12-08T12:06:44Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/26#issuecomment-30080259"
                    },
                    {
                        "body": "see also #105\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-12-08T13:54:31Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/26#issuecomment-30082014"
                    },
                    {
                        "body": "http://securityblog.switch.ch/2014/11/13/dnssec-signing-your-domain-with-bind-inline-signing/\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-12-06T13:46:25Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/26#issuecomment-65897419"
                    },
                    {
                        "body": "also interesting: how does dnssec signing impact zone update performance?\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2014-12-06T13:57:52Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/26#issuecomment-65897742"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/nsupdate-info/nsupdate.info/issues/19",
                "title": "validate passwords / secrets",
                "labels": [
                    "enhancement",
                    "security"
                ],
                "user": "ThomasWaldmann",
                "issue_author_association": "MEMBER",
                "number": 19,
                "id": 21353884,
                "state": "closed",
                "project_created_at": "2013-10-22T00:20:11Z",
                "closed_at": "2013-11-02T23:53:31Z",
                "body": "ThomasWaldmann wrote:\nminimum length, etc.\n",
                "comments": [
                    {
                        "body": "asmaps wrote:\nwill be no problem if they are autogenerated\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-10-22T00:20:12Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/19#issuecomment-26768364"
                    },
                    {
                        "body": "only the update secret is autogenerated.\n\nwe could still do some minimal checks for the user login password.\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-10-23T03:24:26Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/19#issuecomment-26877990"
                    },
                    {
                        "body": "just enforcing some minimal length doesn't help much.\n\nmaybe just add some notes to the templates about how to choose a secure password?\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-11-02T00:38:50Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/19#issuecomment-27611043"
                    },
                    {
                        "body": "regarding that dynamic dns users are usually advanced users, they should know the usual pw rules.\n\nso we just let them use whatever login password they like.\n",
                        "user": "ThomasWaldmann",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2013-11-02T23:53:31Z",
                        "url": "https://github.com/nsupdate-info/nsupdate.info/issues/19#issuecomment-27635491"
                    }
                ],
                "pull_request": null
            }
        ],
        "SecurityPolicy_content_category": [],
        "num_noncompliant_security_discuss_issue": 11,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": false
    },
    {
        "project_name": "dpgaspar/flask-appbuilder",
        "project_url": "https://github.com/dpgaspar/flask-appbuilder",
        "SSF": {
            "date": "2024-10-29T20:56:17+07:00",
            "repo": {
                "name": "github.com/dpgaspar/flask-appbuilder",
                "commit": "fab9013003a41c4e80da04f072201a8c7cc99187"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.9,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Info: status check found to merge onto on branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 8,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 out of 30 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 3,
                    "reason": "Found 9/27 approved changesets -- score normalized to 3",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: IOOSProfilingGliders contributor org/company found, DataJunction contributor org/company found, apache contributor org/company found, druid-io contributor org/company found, OpenLineage contributor org/company found, function contributor org/company found, astronomer contributor org/company found, preset-io contributor org/company found, preset-io @apache contributor org/company found, phriendlyinfo contributor org/company found, aosapps contributor org/company found, equifax contributor org/company found, government contributor org/company found, openstates contributor org/company found, srcbookdev contributor org/company found, cloudfoundry-community contributor org/company found, zenofdata contributor org/company found, pydap contributor org/company found, servicemesher contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 19 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: BSD 3-Clause \"New\" or \"Revised\" License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 7,
                    "reason": "8 commit(s) and 1 issue activity found in the last 90 days -- score normalized to 7",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:58: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:60: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:109: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:111: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:158: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:160: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:202: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:204: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:229: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yml:231: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ci.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:48: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/codeql-analysis.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ptlint.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/dpgaspar/Flask-AppBuilder/ptlint.yml/master?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:130",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:131",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:132",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:133",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/ci.yml:139",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:179",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:180",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:181",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:182",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/ci.yml:189",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:211",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:212",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:213",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:214",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:215",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/ci.yml:221",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:238",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:239",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:240",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:241",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:242",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/ci.yml:248",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:27",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:28",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:79",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:80",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:81",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yml:82",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/ci.yml:88",
                        "Info:   0 out of  15 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of  24 pipCommand dependencies pinned",
                        "Info:   0 out of   5 downloadThenRun dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Warn: 14 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 8,
                    "reason": "SAST tool detected but not run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: .github/SECURITY.md:1",
                        "Info: Found linked content: .github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: .github/SECURITY.md:1",
                        "Info: Found text in security policy: .github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql-analysis.yml:21",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql-analysis.yml:22",
                        "Warn: no topLevel permission defined: .github/workflows/ci.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/codeql-analysis.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/ptlint.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-67hx-6x53-jw92",
                        "Warn: Project is vulnerable to: GHSA-6chw-6frg-f759",
                        "Warn: Project is vulnerable to: GHSA-v88g-cgmw-v5xw",
                        "Warn: Project is vulnerable to: GHSA-whgm-jr23-g3j9",
                        "Warn: Project is vulnerable to: GHSA-93q8-gq69-wqmw",
                        "Warn: Project is vulnerable to: GHSA-fwr7-v2mv-hh25",
                        "Warn: Project is vulnerable to: GHSA-4w2v-q235-vp99",
                        "Warn: Project is vulnerable to: GHSA-cph5-m8f7-6c5x",
                        "Warn: Project is vulnerable to: GHSA-wf5p-g6vw-rhxx",
                        "Warn: Project is vulnerable to: GHSA-qwcr-r2fm-qrc7",
                        "Warn: Project is vulnerable to: GHSA-vc8w-jr9v-vj7f",
                        "Warn: Project is vulnerable to: GHSA-cwfw-4gq5-mrqx",
                        "Warn: Project is vulnerable to: GHSA-g95f-p29q-9xw4",
                        "Warn: Project is vulnerable to: GHSA-grv7-fg5c-xmjg",
                        "Warn: Project is vulnerable to: GHSA-x9w5-v3q2-3rhw",
                        "Warn: Project is vulnerable to: GHSA-w8qv-6jwh-64r5",
                        "Warn: Project is vulnerable to: GHSA-c6rq-rjc2-86v2",
                        "Warn: Project is vulnerable to: GHSA-257v-vj4p-3w2h",
                        "Warn: Project is vulnerable to: GHSA-pxg6-pf52-xh8x",
                        "Warn: Project is vulnerable to: GHSA-gxpj-cx7g-858c",
                        "Warn: Project is vulnerable to: GHSA-w573-4hg7-7wgq",
                        "Warn: Project is vulnerable to: GHSA-3wcq-x3mq-6r9p",
                        "Warn: Project is vulnerable to: GHSA-ff7x-qrg7-qggm",
                        "Warn: Project is vulnerable to: GHSA-phwq-j96m-2c2q",
                        "Warn: Project is vulnerable to: GHSA-ghr5-ch3p-vcr6",
                        "Warn: Project is vulnerable to: GHSA-vh7m-p724-62c2",
                        "Warn: Project is vulnerable to: GHSA-r9p9-mrjm-926w",
                        "Warn: Project is vulnerable to: GHSA-434g-2637-qmqr",
                        "Warn: Project is vulnerable to: GHSA-49q7-c7j4-3p7m",
                        "Warn: Project is vulnerable to: GHSA-977x-g7h5-7qgw",
                        "Warn: Project is vulnerable to: GHSA-f7q4-pwc6-w24p",
                        "Warn: Project is vulnerable to: GHSA-fc9h-whq2-v747",
                        "Warn: Project is vulnerable to: GHSA-3gx7-xhv7-5mx3",
                        "Warn: Project is vulnerable to: GHSA-6h5x-7c5m-7cr7",
                        "Warn: Project is vulnerable to: GHSA-rv95-896h-c2vc",
                        "Warn: Project is vulnerable to: GHSA-qw6h-vgh9-j6wx",
                        "Warn: Project is vulnerable to: GHSA-74fj-2j2h-c42q",
                        "Warn: Project is vulnerable to: GHSA-pw2r-vq6v-hr8c",
                        "Warn: Project is vulnerable to: GHSA-jchw-25xp-jwwc",
                        "Warn: Project is vulnerable to: GHSA-cxjh-pqwp-8mfp",
                        "Warn: Project is vulnerable to: GHSA-8r6j-v8pm-fqw3",
                        "Warn: Project is vulnerable to: MAL-2023-462",
                        "Warn: Project is vulnerable to: GHSA-w457-6q6x-cgp9",
                        "Warn: Project is vulnerable to: GHSA-62gr-4qp9-h98f",
                        "Warn: Project is vulnerable to: GHSA-f52g-6jhx-586p",
                        "Warn: Project is vulnerable to: GHSA-2cf5-4w76-r9qv",
                        "Warn: Project is vulnerable to: GHSA-3cqr-58rm-57f8",
                        "Warn: Project is vulnerable to: GHSA-g9r4-xpmj-mj65",
                        "Warn: Project is vulnerable to: GHSA-q2c6-c6pm-g3gh",
                        "Warn: Project is vulnerable to: GHSA-765h-qjxv-5f44",
                        "Warn: Project is vulnerable to: GHSA-f2jv-r9rf-7988",
                        "Warn: Project is vulnerable to: GHSA-c429-5p7v-vgjp",
                        "Warn: Project is vulnerable to: GHSA-43f8-2h32-f4cj",
                        "Warn: Project is vulnerable to: GHSA-pfq8-rq6v-vf5m",
                        "Warn: Project is vulnerable to: GHSA-6x33-pw7p-hmpq",
                        "Warn: Project is vulnerable to: GHSA-c7qv-q95q-8v27",
                        "Warn: Project is vulnerable to: GHSA-qqgx-2p2h-9c37",
                        "Warn: Project is vulnerable to: GHSA-78xj-cgh5-2h22",
                        "Warn: Project is vulnerable to: GHSA-2p57-rm9w-gvfp",
                        "Warn: Project is vulnerable to: GHSA-7r28-3m3f-r2pr",
                        "Warn: Project is vulnerable to: GHSA-r8j5-h5cx-65gg",
                        "Warn: Project is vulnerable to: GHSA-6c3j-c64m-qhgq",
                        "Warn: Project is vulnerable to: GHSA-gxr4-xjj5-5px2",
                        "Warn: Project is vulnerable to: GHSA-jpcq-cgw6-v4j6",
                        "Warn: Project is vulnerable to: GHSA-896r-f27r-55mw",
                        "Warn: Project is vulnerable to: GHSA-9c47-m6qq-7p4h",
                        "Warn: Project is vulnerable to: GHSA-6c8f-qphg-qjgp",
                        "Warn: Project is vulnerable to: GHSA-76p3-8jx3-jpfq",
                        "Warn: Project is vulnerable to: GHSA-3rfm-jhwj-7488",
                        "Warn: Project is vulnerable to: GHSA-hhq3-ff78-jv3g",
                        "Warn: Project is vulnerable to: GHSA-p6mc-m468-83gw",
                        "Warn: Project is vulnerable to: GHSA-29mw-wpgm-hmr9",
                        "Warn: Project is vulnerable to: GHSA-35jh-r3h4-6jhm",
                        "Warn: Project is vulnerable to: GHSA-4xcv-9jjx-gfj3",
                        "Warn: Project is vulnerable to: GHSA-7wpw-2hjm-89gp",
                        "Warn: Project is vulnerable to: GHSA-r6rj-9ch6-g264",
                        "Warn: Project is vulnerable to: GHSA-952p-6rrq-rcjv",
                        "Warn: Project is vulnerable to: GHSA-f8q6-p94x-37v3",
                        "Warn: Project is vulnerable to: GHSA-vh95-rmgr-6w4m / GHSA-xvch-5gv4-984h",
                        "Warn: Project is vulnerable to: GHSA-92xj-mqp7-vmcj",
                        "Warn: Project is vulnerable to: GHSA-wxgw-qj99-44c2",
                        "Warn: Project is vulnerable to: GHSA-5rrq-pxf6-6jx5",
                        "Warn: Project is vulnerable to: GHSA-8fr3-hfg3-gpgp",
                        "Warn: Project is vulnerable to: GHSA-gf8q-jrpm-jvxq",
                        "Warn: Project is vulnerable to: GHSA-2r2c-g63r-vccr",
                        "Warn: Project is vulnerable to: GHSA-cfm4-qjh2-4765",
                        "Warn: Project is vulnerable to: GHSA-x4jg-mjrx-434g",
                        "Warn: Project is vulnerable to: GHSA-5fw9-fq32-wv5p",
                        "Warn: Project is vulnerable to: GHSA-rp65-9cf3-cjxr",
                        "Warn: Project is vulnerable to: GHSA-hj48-42vr-x3v9",
                        "Warn: Project is vulnerable to: GHSA-9wv6-86v2-598j",
                        "Warn: Project is vulnerable to: GHSA-566m-qj78-rww5",
                        "Warn: Project is vulnerable to: GHSA-7fh5-64p2-3v2j",
                        "Warn: Project is vulnerable to: GHSA-hwj9-h5mp-3pm3",
                        "Warn: Project is vulnerable to: GHSA-hrpp-h998-j3pp",
                        "Warn: Project is vulnerable to: GHSA-5q6m-3h65-w53x",
                        "Warn: Project is vulnerable to: GHSA-p8p7-x288-28g6",
                        "Warn: Project is vulnerable to: GHSA-c2qf-rxjj-qqgw",
                        "Warn: Project is vulnerable to: GHSA-m6fv-jmcg-4jfg",
                        "Warn: Project is vulnerable to: GHSA-h9rv-jmmf-4pgx",
                        "Warn: Project is vulnerable to: GHSA-hxcc-f52p-wc94",
                        "Warn: Project is vulnerable to: GHSA-cm22-4g7w-348p",
                        "Warn: Project is vulnerable to: GHSA-g4rg-993r-mgx7",
                        "Warn: Project is vulnerable to: GHSA-c9g6-9335-x697",
                        "Warn: Project is vulnerable to: GHSA-vx3p-948g-6vhq",
                        "Warn: Project is vulnerable to: GHSA-j44m-qm6p-hp7m",
                        "Warn: Project is vulnerable to: GHSA-3jfq-g458-7qm9",
                        "Warn: Project is vulnerable to: GHSA-r628-mhmh-qjhw",
                        "Warn: Project is vulnerable to: GHSA-9r2w-394v-53qc",
                        "Warn: Project is vulnerable to: GHSA-5955-9wpr-37jh",
                        "Warn: Project is vulnerable to: GHSA-qq89-hq3f-393p",
                        "Warn: Project is vulnerable to: GHSA-f5x3-32g6-xq36",
                        "Warn: Project is vulnerable to: GHSA-4wf5-vphf-c2xc",
                        "Warn: Project is vulnerable to: GHSA-jgrx-mgxx-jf9v",
                        "Warn: Project is vulnerable to: GHSA-72xf-g2v4-qvf3",
                        "Warn: Project is vulnerable to: GHSA-cf4h-3jhx-xvhq",
                        "Warn: Project is vulnerable to: GHSA-9m6j-fcg5-2442",
                        "Warn: Project is vulnerable to: GHSA-hh27-ffr2-f2jc",
                        "Warn: Project is vulnerable to: GHSA-rqff-837h-mm52",
                        "Warn: Project is vulnerable to: GHSA-8v38-pw62-9cw2",
                        "Warn: Project is vulnerable to: GHSA-hgjh-723h-mx2j",
                        "Warn: Project is vulnerable to: GHSA-jf5r-8hm2-f872",
                        "Warn: Project is vulnerable to: GHSA-wr3j-pwj9-hqq6",
                        "Warn: Project is vulnerable to: GHSA-g78m-2chm-r7qv",
                        "Warn: Project is vulnerable to: GHSA-6fc8-4gx4-v693",
                        "Warn: Project is vulnerable to: GHSA-3h5v-q93c-6h6q",
                        "Warn: Project is vulnerable to: GHSA-c4w7-xm78-47vh",
                        "Warn: Project is vulnerable to: GHSA-p9pc-299p-vxgp",
                        "Warn: Project is vulnerable to: GHSA-9mvj-f7w8-pvh2"
                    ],
                    "score": 0,
                    "reason": "129 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/dpgaspar/flask-appbuilder/contents/.github/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Reporting Vulnerabilities\n\n** Please do not file GitHub issues for security vulnerabilities as they are public! **\n\nIf you have any concern or believe you have found a vulnerability in Flask-AppBuilder,\nplease get in touch privately at\ne-mail address [danielvazgaspar@gmail.com](mailto:danielvazgaspar@gmail.com).\n\nWe kindly ask you to include the following information in your report:\n- Output from `pip freeze`\n- Detailed steps to reproduce the vulnerability\n",
        "project_all_labels": [
            "api",
            "breaking-change",
            "bug",
            "closed-automatically",
            "dependency-bump",
            "deployment",
            "discussion-needed",
            "docs",
            "duplicate",
            "enhancement",
            "github_actions",
            "Help-Needed",
            "install",
            "invalid",
            "javascript",
            "mongo",
            "more-information-needed",
            "mvc",
            "pending",
            "python",
            "question",
            "security:auth",
            "security:crud",
            "security:permission",
            "stale",
            "urgent",
            "wontfix"
        ],
        "README_content": "Flask App Builder\n=================\n\n.. image:: https://github.com/dpgaspar/Flask-AppBuilder/workflows/Python/badge.svg\n        :target: https://github.com/dpgaspar/Flask-AppBuilder/actions\n\n.. image:: https://img.shields.io/pypi/v/Flask-AppBuilder.svg\n        :alt: PyPI\n        :target: https://pypi.org/project/Flask-AppBuilder/\n\n.. image:: https://img.shields.io/badge/pyversions-3.8%2C%203.9%2C%203.10%2C%203.11%2C%203.12-blue.svg\n        :target: https://www.python.org/\n\n.. image:: https://codecov.io/github/dpgaspar/Flask-AppBuilder/coverage.svg?branch=master\n        :target: https://codecov.io/github/dpgaspar/Flask-AppBuilder\n\n.. image:: https://img.shields.io/badge/code%20style-black-000000.svg\n    :target: https://github.com/psf/black\n\n\nSimple and rapid application development framework, built on top of `Flask <http://flask.pocoo.org/>`_.\nincludes detailed security, auto CRUD generation for your models, google charts and much more.\n\nExtensive configuration of all functionality, easily integrate with normal Flask/Jinja2 development.\n\n- Documentation: `Documentation <http://flask-appbuilder.readthedocs.org/en/latest/>`_\n\n- Mailing list: `Google group <https://groups.google.com/forum/#!forum/flask-appbuilder>`_\n\n- Chat: `Gitter <https://gitter.im/dpgaspar/Flask-AppBuilder>`_\n\n- Examples: `examples <https://github.com/dpgaspar/Flask-AppBuilder/tree/master/examples>`_\n\nCheckout installation video on `YouTube <http://youtu.be/xvum4vfwldg>`_\n\nQuick how to `Demo from the docs <http://flaskappbuilder.pythonanywhere.com/>`_ (login has guest/welcome).\n\nChange Log\n----------\n\n`Versions <https://github.com/dpgaspar/Flask-AppBuilder/tree/master/CHANGELOG.rst>`_ for further detail on what changed.\n\nFixes, Bugs and contributions\n-----------------------------\n\nYou're welcome to report bugs, propose new features, or even better contribute to this project.\n\n`Issues, bugs and new features <https://github.com/dpgaspar/Flask-AppBuilder/issues/new>`_\n\n`Contribute <https://github.com/dpgaspar/Flask-AppBuilder/fork>`_\n\nIncludes:\n---------\n\n  - Database\n      - SQLAlchemy, multiple database support: sqlite, MySQL, ORACLE, MSSQL, DB2 etc.\n      - Partial support for MongoDB using MongoEngine.\n      - Multiple database connections support (Vertical partitioning).\n      - Easy mixin audit to models (created/changed by user, and timestamps).\n  - Security\n      - Automatic permissions lookup, based on exposed methods. It will grant all permissions to the Admin Role.\n      - Inserts on the Database all the detailed permissions possible on your application.\n      - Public (no authentication needed) and Private permissions.\n      - Role based permissions.\n      - Authentication support for OAuth, OpenID, Database, LDAP and REMOTE_USER environ var.\n      - Support for self user registration.\n  - Views and Widgets\n      - Automatic menu generation.\n      - Automatic CRUD generation.\n      - Multiple actions on db records.\n      - Big variety of filters for your lists.\n      - Various view widgets: lists, master-detail, list of thumbnails etc\n      - Select2, Datepicker, DateTimePicker\n      - Related Select2 fields.\n      - Google charts with automatic group by or direct values and filters.\n      - AddOn system, write your own and contribute.\n  - CRUD REST API\n      - Automatic CRUD RESTful APIs.\n      - Internationalization\n      - Integration with flask-jwt-extended extension to protect your endpoints.\n      - Metadata for dynamic rendering.\n      - Selectable columns and metadata keys.\n      - Automatic and configurable data validation.\n  - Forms\n      - Automatic, Add, Edit and Show from Database Models\n      - Labels and descriptions for each field.\n      - Automatic base validators from model's definition.\n      - Custom validators, extra fields, custom filters for related dropdown lists.\n      - Image and File support for upload and database field association. It will handle everything for you.\n      - Field sets for Form's (Django style).\n  - i18n\n      - Support for multi-language via Babel\n  - Bootstrap 3.1.1 CSS and js, with Select2 and DatePicker\n  - Font-Awesome icons, for menu icons and actions.\n\n\nSome pictures\n-------------\n\nLogin page (with AUTH_DB)\n\n.. image:: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/login_db.png\n    :width: 480px\n    :target: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/login_db.png\n\n\nLogin page (with AUTH_OAUTH)\n\n.. image:: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/login_oauth.png\n    :width: 480px\n    :target: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/login_oauth.png\n\n\nSecurity\n\n.. image:: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/security.png\n    :width: 480px\n    :target: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/security.png\n\n\nLists:\n\nList contacts example\n\n.. image:: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/contact_list.png\n    :width: 480px\n    :target: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/contact_list.png\n\n\nList Group example with search\n\n.. image:: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/group_list.png\n    :width: 480px\n    :target: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/group_list.png\n\n\n\nCharts:\n\nGroup by pie chart\n\n.. image:: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/grouped_chart.png\n    :width: 480px\n    :target: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/grouped_chart.png\n\nDirect time chart\n\n.. image:: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/direct_chart.png\n    :width: 480px\n    :target: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/chart_time1.png\n\nGroup by time chart\n\n.. image:: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/chart_time2.png\n    :width: 480px\n    :target: https://raw.github.com/dpgaspar/flask-AppBuilder/master/images/chart_time2.png\n\n\nProjects/Organizations using FAB\n--------------------------------\n\nIf you would like to share your project, or let everyone know that you're using FAB\non your organization please submit a PR or send me an email with the details.\n\nProjects:\n\n- `Superset <https://github.com/apache/incubator-superset>`_ - a data exploration platform designed to be visual, intuitive, and interactive\n\n- `Airflow <https://github.com/apache/airflow>`_ - a platform to programmatically author, schedule, and monitor workflows.\n\n\nOrganizations:\n\n- Miniclip\n- EuroBIC\n- `On Beat Digital <https://onbeat.digital/>`_\n\n\nDepends on:\n-----------\n\n- flask\n- click\n- colorama\n- flask-sqlalchemy\n- flask-login\n- flask-openid\n- flask-wtform\n- flask-Babel\n",
        "num_commits": 3981,
        "project_age_days": 4007,
        "project_created_at": "2013-11-09",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-23",
        "num_contributors": 172,
        "num_pull": 994,
        "num_issues": 2280,
        "num_opening_issue": 204,
        "project_size(kB)": 44088,
        "num_stargazers": 4681,
        "num_watchers": 4681,
        "num_forks": 1359,
        "num_subscribers": 154,
        "SecurityPolicy_created_at": "2023-10-27 14:00:56",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "1c3af9b665ed9a3daf36673fee3327d0abf43e5b",
                "url": "https://github.com/dpgaspar/Flask-AppBuilder/commit/1c3af9b665ed9a3daf36673fee3327d0abf43e5b",
                "date": "2023-10-27 14:00:56"
            }
        ],
        "project_security_labels": [
            "security:crud",
            "security:permission",
            "security:auth"
        ],
        "security_issues": [
            {
                "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861",
                "title": "update `Authlib` requirement to allow version 1.0.1",
                "labels": [
                    "dependency-bump",
                    "security:auth"
                ],
                "user": "thesuperzapper",
                "issue_author_association": "CONTRIBUTOR",
                "number": 1861,
                "id": 1274704062,
                "state": "closed",
                "project_created_at": "2022-06-17T07:58:52Z",
                "closed_at": "2022-07-12T10:46:34Z",
                "body": "Currently, we are [restricting `Authlib` to `<1.0.0`](https://github.com/dpgaspar/Flask-AppBuilder/blob/v4.1.1/setup.py#L72) in our requirements, authlib has now released version [1.0.1](https://docs.authlib.org/en/latest/changelog.html) with lots of fixes and security patches, we should update our pin to allow 1.0.1.\r\n\r\nLots of people have been inadvertently testing using 1.0.1 for us! This is because airflow [forgot to pin `authlib`](https://github.com/apache/airflow/commit/6d7fa874ff201af7f602be9c58a827998814bdd1#diff-60f61ab7a8d1910d86d9fda2261620314edcae5894d5aaa236b821c7256badd7R274) to the same versions as `Flask-AppBuilder`, so the latest `authlib` is always installed with airflow.\r\n\r\n@potiuk you may want to look at that!\r\n\r\n----\r\n\r\nThe main issues I see from people who have already tried to use 1.0.1, are related to `jwks_uri` not being set (rather than any actual issue with Flask-AppBuilder). \r\n\r\nThe error text is: `Error authorizing OAuth access token: Missing \"jwks_uri\" in metadata`, see related issues:\r\n- https://github.com/apache/superset/issues/13948#issuecomment-856981962\r\n- https://github.com/dpgaspar/Flask-AppBuilder/issues/1821\r\n- https://stackoverflow.com/questions/72035617/runtimeerror-missing-jwks-uri-in-metadata-for-flask-and-azure-ad-authlib\r\n\r\n---\r\n\r\nCurrently, all of our [OAUTH security examples](https://flask-appbuilder.readthedocs.io/en/latest/security.html#authentication-oauth) don't show setting `jwks_uri` which is [now required](https://docs.authlib.org/en/latest/client/frameworks.html#parsing-id-token) when using `id_token` auth.\r\nWe need to update our examples to set `jwks_uri` so they continue to work with `authlib` 1.0.1.\r\n\r\n__Example for Google with `jwks_url`:__\r\n\r\n```python\r\nOAUTH_PROVIDERS = [\r\n    {\r\n        \"name\": \"google\",\r\n        \"icon\": \"fa-google\",\r\n        \"token_key\": \"access_token\",\r\n        \"remote_app\": {\r\n            \"client_id\": \"GOOGLE_KEY\",\r\n            \"client_secret\": \"GOOGLE_SECRET\",\r\n            \"api_base_url\": \"https://www.googleapis.com/oauth2/v2/\",\r\n            \"client_kwargs\": {\"scope\": \"email profile\"},\r\n            \"access_token_url\": \"https://accounts.google.com/o/oauth2/token\",\r\n            \"authorize_url\": \"https://accounts.google.com/o/oauth2/auth\",\r\n            \"jwks_uri\": \"https://www.googleapis.com/oauth2/v3/certs\",\r\n        },\r\n    },\r\n]\r\n```\r\n\r\n---\r\n\r\nWe may also want to show setting `server_metadata_url` to an OpenID `/.well-known/openid-configuration` URL, (which replaces the need to set `authorize_url`, `access_token_url`, and `jwks_uri` so is a bit easier for people).\r\n\r\n__Example for Google with `server_metadata_url`:__\r\n\r\n```python\r\nOAUTH_PROVIDERS = [\r\n    {\r\n        \"name\": \"google\",\r\n        \"icon\": \"fa-google\",\r\n        \"token_key\": \"access_token\",\r\n        \"remote_app\": {\r\n            \"client_id\": \"GOOGLE_KEY\",\r\n            \"client_secret\": \"GOOGLE_SECRET\",\r\n            \"api_base_url\": \"https://www.googleapis.com/oauth2/v2/\",\r\n            \"server_metadata_url\": \"https://accounts.google.com/.well-known/openid-configuration\",\r\n            \"client_kwargs\": {\"scope\": \"email profile\"},\r\n        },\r\n    },\r\n]\r\n```\r\n\r\n__Example for Okta with `sever_metadata_url`:__\r\n\r\n```python\r\nOAUTH_PROVIDERS = [\r\n  {\r\n      \"name\": \"okta\",\r\n      \"icon\": \"fa-circle-o\",\r\n      \"token_key\": \"access_token\",\r\n      \"remote_app\": {\r\n          \"client_id\": \"OKTA_KEY\",\r\n          \"client_secret\": \"OKTA_SECRET\",\r\n          \"api_base_url\": \"https://OKTA_DOMAIN.okta.com/oauth2/v1/\",\r\n          \"server_metadata_url\": \"https://OKTA_DOMAIN.okta.com/.well-known/openid-configuration\",\r\n          \"client_kwargs\": {\"scope\": \"openid profile email groups\"},\r\n      },\r\n  },\r\n]\r\n```",
                "comments": [
                    {
                        "body": "@dpgaspar thoughts on this?",
                        "user": "thesuperzapper",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-06-17T07:59:08Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1158603746"
                    },
                    {
                        "body": "> @potiuk you may want to look at that!\r\n\r\nAh. Cool yhanks for that. I will update it. Actually the setup.py entry is wrong in a different way. We should use \"flask-app-builder[oauth]\" as dependency there so that we do not have to manually sync dependencies when FAB updates it.\r\n\r\nBTW. We have just started to migrate to FAB 4.0 @thesuperzapper - you might want to join our crew of people who will help with testing it (there are many breaking changes in the underlying libraries). I've added you so to that you are aware and possibly help us with testing Airfflow  https://github.com/apache/airflow/issues/22397#issuecomment-1156603972 \r\n\r\nIn the meantime - indeed upgrading of the authlib in FAB 4.1.2 might be a good idea indeed (and once we use oauth extra, airflow deps will update automatically) \r\n",
                        "user": "potiuk",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-06-17T08:21:37Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1158625004"
                    },
                    {
                        "body": "I'll open a PR to bump and test authlib",
                        "user": "dpgaspar",
                        "issue_author_association": "OWNER",
                        "project_created_at": "2022-06-17T08:24:05Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1158626998"
                    },
                    {
                        "body": "Also @thesuperzapper we have a way to fix that for you users too (and ours). I am going to update constraint and re-generate docker images with authlib=1.0.0 ",
                        "user": "potiuk",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-06-17T08:28:12Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1158630479"
                    },
                    {
                        "body": "@potiuk actually the version would need to be the last `0.X` version (which is `0.15.5`) for this `jwks_uri` issue not to be a problem.\r\n\r\nBut I think we may as well keep `1.0.1` as the authlib version in the docker containers (it's only installed in the 2.2.0 containers and later anyway). There are large amounts of fixes in the 1.0.X branch.",
                        "user": "thesuperzapper",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-06-17T08:33:41Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1158635340"
                    },
                    {
                        "body": "Right....",
                        "user": "potiuk",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-06-17T09:32:05Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1158690299"
                    },
                    {
                        "body": "I will fix it though anyway. \r\n",
                        "user": "potiuk",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-06-17T09:32:58Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1158691025"
                    },
                    {
                        "body": "I prefer to get it \"*updated to latest authlib*\" in upcoming 2.3.3 (I hope we will upgrade to FAB 4 by then rather than break oauth for 2.2.5 - 2.3.2 users :)",
                        "user": "potiuk",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-06-17T09:47:27Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1158702879"
                    },
                    {
                        "body": "BTW. 2.2.4 and below had 0.15.5",
                        "user": "potiuk",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-06-17T09:48:13Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1158703458"
                    },
                    {
                        "body": "@thesuperzapper - FYI: all constraints and images of Airlfow 2.2.5, 2.3.0, 2.3.1. 2.3.2 are refreshed now.",
                        "user": "potiuk",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-06-17T11:39:07Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1158786215"
                    },
                    {
                        "body": "the `authlib` bump (now is <2) is merge into master.\r\n\r\nThank you once more @thesuperzapper",
                        "user": "dpgaspar",
                        "issue_author_association": "OWNER",
                        "project_created_at": "2022-07-12T10:46:34Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1181607305"
                    },
                    {
                        "body": "when i am using azure authentication in flask app builder getting this error :\r\n\r\nError returning OAuth user info: %s 'upn'\r\n2023-08-01 12:04:40,989:ERROR:flask_appbuilder.security.views:Error returning OAuth user info: 'upn'\r\n\r\ni have got jwt token credentials are verified but getting UPN key error\r\n\r\n\r\nhow can i resolve it \r\n",
                        "user": "Narender-007",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-08-01T06:38:12Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1861#issuecomment-1659660737"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1825",
                "title": "LDAPS Multiple Times Need to Signin",
                "labels": [
                    "question",
                    "pending",
                    "security:auth"
                ],
                "user": "caxefaizan",
                "issue_author_association": "NONE",
                "number": 1825,
                "id": 1194159698,
                "state": "open",
                "project_created_at": "2022-04-06T07:16:14Z",
                "closed_at": null,
                "body": "### Environment\r\n\r\nFlask-Appbuilder version: Flask-AppBuilder==3.4.1\r\n\r\npip freeze output:\r\nadal==1.2.7\r\nalembic==1.7.5\r\namqp==5.0.7\r\nanyio==3.4.0\r\napache-airflow==2.2.3\r\napache-airflow-providers-amazon==2.4.0\r\napache-airflow-providers-celery==2.1.0\r\napache-airflow-providers-cncf-kubernetes==2.2.0\r\napache-airflow-providers-docker==2.3.0\r\napache-airflow-providers-elasticsearch==2.1.0\r\napache-airflow-providers-ftp==2.0.1\r\napache-airflow-providers-google==6.2.0\r\napache-airflow-providers-grpc==2.0.1\r\napache-airflow-providers-hashicorp==2.1.1\r\napache-airflow-providers-http==2.0.1\r\napache-airflow-providers-imap==2.0.1\r\napache-airflow-providers-microsoft-azure==3.4.0\r\napache-airflow-providers-mysql==2.1.1\r\napache-airflow-providers-odbc==2.0.1\r\napache-airflow-providers-postgres==2.4.0\r\napache-airflow-providers-redis==2.0.1\r\napache-airflow-providers-sendgrid==2.0.1\r\napache-airflow-providers-sftp==2.3.0\r\napache-airflow-providers-slack==4.1.0\r\napache-airflow-providers-sqlite==2.0.1\r\napache-airflow-providers-ssh==2.3.0\r\napispec==3.3.2\r\nargcomplete==1.12.3\r\nasn1crypto==1.4.0\r\nattrs==20.3.0\r\nAuthlib==0.15.5\r\nazure-batch==11.0.0\r\nazure-common==1.1.27\r\nazure-core==1.21.1\r\nazure-cosmos==4.2.0\r\nazure-datalake-store==0.0.52\r\nazure-identity==1.7.1\r\nazure-keyvault==4.1.0\r\nazure-keyvault-certificates==4.3.0\r\nazure-keyvault-keys==4.4.0\r\nazure-keyvault-secrets==4.3.0\r\nazure-kusto-data==0.0.45\r\nazure-mgmt-containerinstance==1.5.0\r\nazure-mgmt-core==1.3.0\r\nazure-mgmt-datafactory==1.1.0\r\nazure-mgmt-datalake-nspkg==3.0.1\r\nazure-mgmt-datalake-store==0.5.0\r\nazure-mgmt-nspkg==3.0.2\r\nazure-mgmt-resource==20.0.0\r\nazure-nspkg==3.0.2\r\nazure-storage-blob==12.8.1\r\nazure-storage-common==2.1.0\r\nazure-storage-file==2.1.0\r\nBabel==2.9.1\r\nbackports.entry-points-selectable==1.1.1\r\nbcrypt==3.2.0\r\nbeautifulsoup4==4.10.0\r\nbilliard==3.6.4.0\r\nblinker==1.4\r\nboto3==1.18.65\r\nbotocore==1.21.65\r\ncached-property==1.5.2\r\ncachetools==4.2.2\r\ncattrs==1.5.0\r\ncelery==5.2.1\r\ncertifi==2020.12.5\r\ncffi==1.15.0\r\ncharset-normalizer==2.0.9\r\nclick==8.0.3\r\nclick-didyoumean==0.3.0\r\nclick-plugins==1.1.1\r\nclick-repl==0.2.0\r\nclickclick==20.10.2\r\ncloudpickle==1.4.1\r\ncolorama==0.4.4\r\ncolorlog==4.8.0\r\ncommonmark==0.9.1\r\ncroniter==1.0.15\r\ncryptography==3.4.8\r\ndask==2021.6.0\r\ndecorator==5.1.0\r\ndefusedxml==0.7.1\r\ndill==0.3.1.1\r\ndistlib==0.3.4\r\ndistributed==2.19.0\r\ndnspython==2.1.0\r\ndocker==5.0.3\r\ndocutils==0.16\r\nelasticsearch==7.13.4\r\nelasticsearch-dbapi==0.2.7\r\nelasticsearch-dsl==7.4.0\r\nemail-validator==1.1.3\r\neventlet==0.33.0\r\nfilelock==3.4.0\r\nFlask==1.1.2\r\nFlask-AppBuilder==3.4.1\r\nFlask-Babel==2.0.0\r\nFlask-Caching==1.10.1\r\nFlask-JWT-Extended==3.25.1\r\nFlask-Login==0.4.1\r\nFlask-OpenID==1.3.0\r\nFlask-SQLAlchemy==2.5.1\r\nFlask-WTF==0.14.3\r\nflower==1.0.0\r\nfsspec==2021.11.1\r\ngevent==21.12.0\r\ngoogle-ads==14.0.0\r\ngoogle-api-core==1.31.4\r\ngoogle-api-python-client==1.12.8\r\ngoogle-auth==1.35.0\r\ngoogle-auth-httplib2==0.1.0\r\ngoogle-auth-oauthlib==0.4.6\r\ngoogle-cloud-appengine-logging==1.1.0\r\ngoogle-cloud-audit-log==0.2.0\r\ngoogle-cloud-automl==2.5.2\r\ngoogle-cloud-bigquery==2.31.0\r\ngoogle-cloud-bigquery-datatransfer==3.4.1\r\ngoogle-cloud-bigquery-storage==2.10.1\r\ngoogle-cloud-bigtable==1.7.0\r\ngoogle-cloud-build==3.7.1\r\ngoogle-cloud-container==1.0.1\r\ngoogle-cloud-core==1.7.2\r\ngoogle-cloud-datacatalog==3.6.1\r\ngoogle-cloud-dataproc==3.1.1\r\ngoogle-cloud-dataproc-metastore==1.3.1\r\ngoogle-cloud-dlp==1.0.0\r\ngoogle-cloud-kms==2.10.1\r\ngoogle-cloud-language==1.3.0\r\ngoogle-cloud-logging==2.7.0\r\ngoogle-cloud-memcache==1.0.0\r\ngoogle-cloud-monitoring==2.8.0\r\ngoogle-cloud-os-login==2.5.1\r\ngoogle-cloud-pubsub==2.9.0\r\ngoogle-cloud-redis==2.5.0\r\ngoogle-cloud-secret-manager==1.0.0\r\ngoogle-cloud-spanner==1.19.1\r\ngoogle-cloud-speech==1.3.2\r\ngoogle-cloud-storage==1.43.0\r\ngoogle-cloud-tasks==2.7.1\r\ngoogle-cloud-texttospeech==1.0.1\r\ngoogle-cloud-translate==1.7.0\r\ngoogle-cloud-videointelligence==1.16.1\r\ngoogle-cloud-vision==1.0.0\r\ngoogle-cloud-workflows==1.5.0\r\ngoogle-crc32c==1.3.0\r\ngoogle-resumable-media==2.1.0\r\ngoogleapis-common-protos==1.54.0\r\ngraphviz==0.19.1\r\ngreenlet==1.1.2\r\ngrpc-google-iam-v1==0.12.3\r\ngrpcio==1.42.0\r\ngrpcio-gcp==0.2.2\r\ngunicorn==20.1.0\r\nh11==0.12.0\r\nHeapDict==1.0.1\r\nhttpcore==0.13.7\r\nhttplib2==0.19.1\r\nhttpx==0.19.0\r\nhumanize==3.13.1\r\nhvac==0.11.2\r\nidna==3.3\r\nimportlib-metadata==4.8.2\r\nimportlib-resources==5.4.0\r\ninflection==0.5.1\r\niso8601==1.0.2\r\nisodate==0.6.0\r\nitsdangerous==1.1.0\r\nJinja2==3.0.3\r\njmespath==0.10.0\r\njson-merge-patch==0.2\r\njsonpath-ng==1.5.3\r\njsonschema==3.2.0\r\nkombu==5.2.2\r\nkubernetes==11.0.0\r\nlazy-object-proxy==1.4.3\r\nldap3==2.9.1\r\nlibcst==0.3.23\r\nlocket==0.2.1\r\nlockfile==0.12.2\r\nlxml==4.7.0\r\nMako==1.1.6\r\nMarkdown==3.3.6\r\nMarkupSafe==2.0.1\r\nmarshmallow==3.14.1\r\nmarshmallow-enum==1.5.1\r\nmarshmallow-oneofschema==3.0.1\r\nmarshmallow-sqlalchemy==0.26.1\r\nmsal==1.16.0\r\nmsal-extensions==0.3.1\r\nmsgpack==1.0.3\r\nmsrest==0.6.21\r\nmsrestazure==0.6.4\r\nmypy-extensions==0.4.3\r\nmysql-connector-python==8.0.27\r\nmysqlclient==2.1.0\r\nnox==2020.12.31\r\nnumpy==1.20.3\r\noauthlib==3.1.1\r\nopenapi-schema-validator==0.1.5\r\nopenapi-spec-validator==0.3.1\r\npackaging==21.3\r\npandas==1.3.5\r\npandas-gbq==0.14.1\r\nparamiko==2.8.1\r\npartd==1.2.0\r\npendulum==2.1.2\r\nplatformdirs==2.4.0\r\nply==3.11\r\nportalocker==2.3.2\r\nprison==0.2.1\r\nprometheus-client==0.12.0\r\nprompt-toolkit==3.0.24\r\nproto-plus==1.18.1\r\nprotobuf==3.19.1\r\npsutil==5.8.0\r\npsycopg2-binary==2.9.2\r\npy==1.11.0\r\npyarrow==5.0.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycparser==2.21\r\npydata-google-auth==1.3.0\r\nPygments==2.10.0\r\nPyJWT==1.7.1\r\nPyNaCl==1.4.0\r\npyodbc==4.0.32\r\npyOpenSSL==20.0.1\r\npyparsing==2.4.7\r\npyrsistent==0.18.0\r\npysftp==0.2.9\r\npython-daemon==2.3.0\r\npython-dateutil==2.8.2\r\npython-http-client==3.3.4\r\npython-ldap==3.4.0\r\npython-nvd3==0.15.0\r\npython-slugify==4.0.1\r\npython3-openid==3.2.0\r\npytz==2021.3\r\npytzdata==2020.1\r\nPyYAML==5.4.1\r\nredis==3.5.3\r\nredshift-connector==2.0.901\r\nrequests==2.26.0\r\nrequests-oauthlib==1.3.0\r\nrfc3986==1.5.0\r\nrich==10.16.0\r\nrsa==4.8\r\ns3transfer==0.5.0\r\nscramp==1.4.1\r\nsendgrid==6.9.2\r\nsetproctitle==1.2.2\r\nsix==1.16.0\r\nslack-sdk==3.13.0\r\nsniffio==1.2.0\r\nsortedcontainers==2.4.0\r\nsoupsieve==2.3.1\r\nSQLAlchemy==1.3.24\r\nSQLAlchemy-JSONField==1.0.0\r\nsqlalchemy-redshift==0.8.8\r\nSQLAlchemy-Utils==0.37.9\r\nsshtunnel==0.4.0\r\nstarkbank-ecdsa==2.0.3\r\nstatsd==3.3.0\r\nswagger-ui-bundle==0.0.9\r\ntabulate==0.8.9\r\ntblib==1.7.0\r\ntenacity==8.0.1\r\ntermcolor==1.1.0\r\ntext-unidecode==1.3\r\ntoolz==0.11.2\r\ntornado==6.1\r\ntyping-extensions==3.10.0.2\r\ntyping-inspect==0.7.1\r\nunicodecsv==0.14.1\r\nuritemplate==3.0.1\r\nurllib3==1.26.7\r\nvine==5.0.0\r\nvirtualenv==20.10.0\r\nwatchtower==1.0.6\r\nwcwidth==0.2.5\r\nwebsocket-client==1.2.3\r\nWerkzeug==1.0.1\r\nWTForms==2.3.3\r\nzict==2.0.0\r\nzipp==3.6.0\r\nzope.event==4.5.0\r\nzope.interface==5.4.0\r\n### Describe the expected results\r\n\r\nLogin should happen on the first attempt itself.\r\n\r\n### Describe the actual results\r\nIn the logs of the webserver i see this\r\n{manager.py:1153} ERROR - {'result': -1, 'desc': \"Can't contact LDAP server\", 'ctrls': [], 'info': '(unknown error code)'}\r\nMultiple Simultaneous Clicks logs us in.\r\n\r\n### Steps to reproduce\r\n\r\nThis is the webserver file in apache-airflow.\r\n```\r\n#webserver_config.py\r\n\r\nimport os\r\nfrom airflow.www.fab_security.manager import AUTH_LDAP\r\n\r\nAUTH_TYPE = AUTH_LDAP\r\nAUTH_LDAP_SERVER = \"ldaps://corporate.example.com.au:636\"\r\nAUTH_LDAP_USE_TLS = False\r\nAUTH_LDAP_ALLOW_SELF_SIGNED = False\r\nAUTH_LDAP_TLS_CACERTFILE = \"/usr/local/airflow/ldapcert/cert.crt\"\r\n\r\n# registration configs\r\nAUTH_USER_REGISTRATION = True  # allow users who are not already in the FAB DB\r\nAUTH_USER_REGISTRATION_ROLE = \"Public\"  # this role will be given in addition to any AUTH_ROLES_MAPPING\r\nAUTH_LDAP_FIRSTNAME_FIELD = \"givenName\"\r\nAUTH_LDAP_LASTNAME_FIELD = \"sn\"\r\nAUTH_LDAP_EMAIL_FIELD = \"mail\"  # if null in LDAP, email is set to: \"{username}@email.notfound\"\r\n\r\nAUTH_LDAP_SEARCH = \"ou=WFL,dc=corporate,dc=example,dc=com,dc=au\"  # the LDAP search base\r\nAUTH_LDAP_UID_FIELD = \"sAMAccountName\"  # the username field\r\nAUTH_LDAP_BIND_USER = \"{{ LDAP_BIND_USER }}\"  # the special bind username for search\r\nAUTH_LDAP_BIND_PASSWORD = \"{{ LDAP_PASSWORD }}\"\r\n\r\n# a mapping from LDAP DN to a list of FAB roles\r\nAUTH_ROLES_MAPPING = {\r\n    \"CN=Airflow2-Admin,OU=Security,OU=Groups,OU=WFL,DC=corporate,DC=example,DC=com,DC=au\": [\"Admin\"],\r\n    \"CN=Airflow2-Data-Engineers,OU=Security,OU=Groups,OU=WFL,DC=corporate,DC=example,DC=com,DC=au\": [\"Op\"],\r\n}\r\n\r\n# the LDAP user attribute which has their role DNs\r\nAUTH_LDAP_GROUP_FIELD = \"memberOf\"\r\n\r\n# if we should replace ALL the user's roles each login, or only on registration\r\nAUTH_ROLES_SYNC_AT_LOGIN = True\r\n\r\n# force users to re-auth after 30min of inactivity (to keep roles in sync)\r\nPERMANENT_SESSION_LIFETIME = 1800\r\n```\r\n\r\n",
                "comments": [
                    {
                        "body": "My first impression is that it could be something related with network, are you using a load balancer?\r\n\r\nHave you tried reproducing the issue using:\r\n```\r\nopenssl s_client -connect ldaps://corporate.example.com.au:636\r\n```\r\nfrom inside you Airflow web server?\r\n",
                        "user": "dpgaspar",
                        "issue_author_association": "OWNER",
                        "project_created_at": "2022-04-29T13:16:06Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1825#issuecomment-1113298656"
                    },
                    {
                        "body": "@caxefaizan I've found that the image for 2.3.0 (in my case specifically, we went from `apache/airflow:2.2.5-python3.9` to `apache/airflow:2.3.0-python3.9`), turns out the underlying base image went from being Debian 10 to Debian 11 and with this change, the `/etc/ldap/ldap.conf` is no longer present which exhibits this exact behavior and the super cryptic error. After spending half a day trying to find a solution, all what's really needed is to add `libldap-common` to the docker image and Airflow starts working again with LDAP just fine.\r\n \r\nSo, hopefully this will help you and someone else in the future!",
                        "user": "NikolaySokolov",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-05-13T18:24:40Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1825#issuecomment-1126322058"
                    },
                    {
                        "body": "@caxefaizan this might be related to https://github.com/dpgaspar/Flask-AppBuilder/pull/1846.\r\nYould you please give https://github.com/dpgaspar/Flask-AppBuilder/pull/1846 a try and see if it fixes you problem? You can get a idea on how to patch your flask installation here https://github.com/stackabletech/docker-images/pull/116",
                        "user": "sbernauer",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-05-17T12:15:56Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1825#issuecomment-1128795732"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1822",
                "title": "Can't evaluate criteria against alternate class <class 'app.sec_models.MyUser'>",
                "labels": [
                    "question",
                    "security:auth"
                ],
                "user": "soundmaking",
                "issue_author_association": "NONE",
                "number": 1822,
                "id": 1180132586,
                "state": "closed",
                "project_created_at": "2022-03-24T22:49:21Z",
                "closed_at": "2022-04-22T09:46:22Z",
                "body": "Not sure exactly when the issue began, but it might have been when upgrading from `Flask-AppBuilder==3.1.1` to `Flask-AppBuilder==3.4.4`\r\n\r\n\r\n### Environment\r\n\r\nFlask-Appbuilder version: 3.4.4\r\n\r\npip freeze output:\r\n\r\nalembic==1.5.2\r\napispec==3.3.2\r\nattrs==20.3.0\r\nBabel==2.9.0\r\nblack==22.1.0\r\nblinker==1.4\r\ncachetools==4.2.1\r\ncertifi==2020.12.5\r\ncffi==1.14.4\r\nchardet==4.0.0\r\nclick==8.0.4\r\ncolorama==0.4.4\r\ndefusedxml==0.6.0\r\ndnspython==2.1.0\r\nemail-validator==1.1.2\r\nFlask==1.1.2\r\nFlask-AppBuilder==3.4.4\r\nFlask-Babel==1.0.0\r\nFlask-JWT-Extended==3.25.0\r\nFlask-Login==0.4.1\r\nFlask-Mail==0.9.1\r\nflask-marshmallow==0.11.0\r\nFlask-Migrate==2.6.0\r\nFlask-Misaka==1.0.0\r\nFlask-OpenID==1.2.5\r\nFlask-SQLAlchemy==2.4.4\r\nFlask-WTF==0.14.3\r\ngoogle-api-core==1.25.0\r\ngoogle-api-python-client==1.12.8\r\ngoogle-auth==1.24.0\r\ngoogle-auth-httplib2==0.0.4\r\ngoogle-auth-oauthlib==0.4.2\r\ngoogleapis-common-protos==1.52.0\r\ngspread==3.6.0\r\nhttplib2==0.18.1\r\nidna==2.10\r\nimportlib-metadata==3.4.0\r\nitsdangerous==1.1.0\r\nJinja2==2.11.2\r\njsonschema==3.2.0\r\nMako==1.1.4\r\nMarkupSafe==1.1.1\r\nmarshmallow==3.10.0\r\nmarshmallow-enum==1.5.1\r\nmarshmallow-sqlalchemy==0.23.1\r\nmisaka==2.1.1\r\nmypy-extensions==0.4.3\r\noauth2client==4.1.3\r\noauthlib==3.1.0\r\npathspec==0.9.0\r\npkg_resources==0.0.0\r\nplatformdirs==2.5.1\r\nprison==0.2.1\r\nprotobuf==3.14.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycparser==2.20\r\nPyJWT==1.7.1\r\npyrsistent==0.17.3\r\npython-dateutil==2.8.1\r\npython-editor==1.0.4\r\npython3-openid==3.2.0\r\npytz==2020.5\r\nPyYAML==5.4.1\r\nrequests==2.25.1\r\nrequests-oauthlib==1.3.0\r\nrsa==4.7\r\nsdfspu==0.2.1\r\nsheetfu==1.5.4\r\nsix==1.15.0\r\nSQLAlchemy==1.3.22\r\nSQLAlchemy-Utils==0.36.8\r\ntomli==2.0.1\r\ntyped-ast==1.5.2\r\ntyping_extensions==4.1.1\r\nuritemplate==3.0.1\r\nurllib3==1.26.2\r\nWerkzeug==1.0.1\r\nWTForms==2.3.3\r\nzipp==3.4.0\r\n\r\n\r\n### Describe the expected results\r\n\r\nExpected no errors on /login.\r\n\r\n### Describe the actual results\r\n\r\nI was checking for something else in the error.log on app in production, and instead found many error \r\nwith `raise exception\r\nsqlalchemy.exc.InvalidRequestError: Could not evaluate current criteria in Python: \"Can't evaluate criteria against alternate class <class 'app.sec_models.MyUser'>\". Specify 'fetch' or False for the synchronize_session execution option.\r\n`\r\n\r\nFrom the error.log:\r\n\r\n```pytb\r\n2022-03-24 21:30:43,564: Exception on /login/ [POST]\r\nTraceback (most recent call last):\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py\", line 1938, in _do_pre_synchronize_evaluate\r\n    eval_condition = evaluator_compiler.process(*crit)\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/sqlalchemy/orm/evaluator.py\", line 85, in process\r\n    return meth(clause)\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/sqlalchemy/orm/evaluator.py\", line 181, in visit_binary\r\n    map(self.process, [clause.left, clause.right])\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/sqlalchemy/orm/evaluator.py\", line 85, in process\r\n    return meth(clause)\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/sqlalchemy/orm/evaluator.py\", line 107, in visit_column\r\n    % parentmapper.class_\r\nsqlalchemy.orm.evaluator.UnevaluatableError: Can't evaluate criteria against alternate class <class 'app.sec_models.MyUser'>\r\n**NO MATCH**\r\nThe above exception was the direct cause of the following exception:\r\n**NO MATCH**\r\nTraceback (most recent call last):\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/flask/app.py\", line 2447, in wsgi_app\r\n    response = self.full_dispatch_request()\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/flask/app.py\", line 1952, in full_dispatch_request\r\n    rv = self.handle_user_exception(e)\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/flask/app.py\", line 1821, in handle_user_exception\r\n    reraise(exc_type, exc_value, tb)\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/flask/_compat.py\", line 39, in reraise\r\n    raise value\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/flask/app.py\", line 1950, in full_dispatch_request\r\n    rv = self.dispatch_request()\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/flask/app.py\", line 1936, in dispatch_request\r\n    return self.view_functions[rule.endpoint](**req.view_args)\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/flask_appbuilder/security/views.py\", line 518, in login\r\n    form.username.data, form.password.data\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/flask_appbuilder/security/manager.py\", line 874, in auth_user_db\r\n    self.noop_user_update(first_user)\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/flask_appbuilder/security/sqla/manager.py\", line 247, in noop_user_update\r\n    self.get_session.execute(stmt)\r\n  File \"<string>\", line 2, in execute\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/sqlalchemy/orm/session.py\", line 1646, in execute\r\n    _parent_execute_state is not None,\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py\", line 1823, in orm_pre_session_exec\r\n    update_options,\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py\", line 1951, in _do_pre_synchronize_evaluate\r\n    from_=err,\r\n  File \"/home/client/envs/ppoc2022/lib/python3.7/site-packages/sqlalchemy/util/compat.py\", line 207, in raise_\r\n    raise exception\r\nsqlalchemy.exc.InvalidRequestError: Could not evaluate current criteria in Python: \"Can't evaluate criteria against alternate class <class 'app.sec_models.MyUser'>\". Specify 'fetch' or False for the synchronize_session execution option.\r\n\r\n```\r\n\r\n### From app/sec_models.py\r\n```python\r\n\"\"\"Models needed by the security manager\r\n\"\"\"\r\n\r\nimport datetime\r\n\r\nfrom flask_appbuilder import Model\r\nfrom flask_appbuilder.models.mixins import AuditMixin\r\nfrom flask_appbuilder.security.sqla.models import User\r\nfrom sqlalchemy import Column, Integer, ForeignKey, String, Table, DateTime, Text\r\nfrom sqlalchemy.orm import relationship\r\n\r\nfrom .util_models import AuditMixinExtra\r\n\r\n\r\nclass MyUser(User):\r\n    __tablename__ = 'ab_user'\r\n    extra = Column(String(256))\r\n\r\n    def __repr__(self):\r\n        return str(self.username)\r\n\r\n\r\nassoc_user_emailaddr = Table(\r\n    'user_emailaddr',\r\n    Model.metadata,\r\n    Column('id', Integer, primary_key=True),\r\n    Column('user_id', Integer, ForeignKey('ab_user.id')),\r\n    Column('email_addr', Integer, ForeignKey('email_address_record.id')),\r\n)\r\n\r\n\r\nclass EmailAddressRecord(AuditMixinExtra, Model):\r\n    \"\"\"An EmailAddress might be seen before a user is registered with it;\r\n\r\n    this object has backref from other objects, such as GoogleFormResponse,\r\n    which include an email address.\r\n\r\n    If a user then does register, it can link to other objects via this record.\r\n    \"\"\"\r\n\r\n    id = Column(Integer, primary_key=True)\r\n    email = Column(String(64), unique=True, nullable=False)\r\n    user = relationship(\r\n        'MyUser',\r\n        secondary=assoc_user_emailaddr,\r\n        backref='email_address_record'\r\n    )\r\n\r\n    def __repr__(self):\r\n        return '@:{}'.format(self.id)\r\n\r\n```\r\n\r\n### Steps to reproduce\r\n\r\nI am still investigating the situation, but posting this incomplete report now with the hopes that someone might have enough info in the above to suggest what might be the issue.  \r\n\r\nI intend to to post again when I have have reproduced the error.\r\n\r\nThanks for reading.\r\n",
                "comments": [
                    {
                        "body": "Interesting, seems like it comes from: https://github.com/dpgaspar/Flask-AppBuilder/blob/e2d3f017bfeb30e863a25fa63de4699db20bc8d4/flask_appbuilder/security/sqla/manager.py#L241\r\n\r\nplease update if you reach any conclusion\r\n",
                        "user": "dpgaspar",
                        "issue_author_association": "OWNER",
                        "project_created_at": "2022-03-25T16:17:47Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1822#issuecomment-1079185066"
                    },
                    {
                        "body": "Thanks, Daniel.  Yes, I will look at how my MyUser class, or other custom security manager stuff might be interacting with that no-op function...\r\n\r\n### further detail\r\n\r\n#### Login values tested to reproduce the error\r\n\r\n- non-valid username: ERROR as described above, user get a server error 500 page\r\n- valid username, valid password: OK, no error\r\n- valid username, wrong password: OK, no error, FAB gives flash message as expected\r\n\r\n\r\n#### from config.py\r\n```python\r\n# ...\r\nSQLALCHEMY_DATABASE_URI = 'sqlite:///' + os.path.join(basedir, 'appdata.db') \r\n# ...\r\nAUTH_TYPE = AUTH_DB\r\n# ...\r\nAUTH_USER_REGISTRATION = True\r\n```\r\n\r\n### could not (and then could) reproduce in dev\r\n\r\nOn my current main dev machine FAB is flashing the \"Invalid login. Please try again.\" message as expected, with this in the log:\r\n\r\n```pylog\r\n2022-03-25 19:39:12,308:INFO:flask_appbuilder.security.manager:Login Failed for user: null\r\n2022-03-25 19:39:12,339:INFO:werkzeug:192.168.1.239 - - [25/Mar/2022 19:39:12] \"POST /login/ HTTP/1.1\" 302 -\r\n2022-03-25 19:39:12,606:INFO:werkzeug:192.168.1.239 - - [25/Mar/2022 19:39:12] \"GET /login/ HTTP/1.1\" 200 -\r\n```\r\n\r\n(edit to update...) On a new computer being set up, a windows 10 box, I was able to reproduce the `Can't evaluate criteria against alternate class <class 'app.sec_models.MyUser'>` error by trying to login with an invalid username.    So far I have only compared `python --version` on the three loactions, but given the values I don't think that's the issue... will look more into it.\r\n\r\nPython versions:\r\n- Dev : 3.7.3\r\n- Production : 3.7.0\r\n- New Dev : 3.7.9\r\n\r\n",
                        "user": "soundmaking",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-03-25T19:21:31Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1822#issuecomment-1079362973"
                    },
                    {
                        "body": "This seems to have fixed it: letting the noop update function use `self.user_model` instead of `User` on this line\r\n\r\nhttps://github.com/dpgaspar/Flask-AppBuilder/blob/e2d3f017bfeb30e863a25fa63de4699db20bc8d4/flask_appbuilder/security/sqla/manager.py#L243\r\n\r\n\r\nAdded in my app/sec.py:\r\n\r\n```python\r\nfrom sqlalchemy import update\r\n# . . . \r\n\r\nclass MySecurityManager(SecurityManager):\r\n    # . . .\r\n    # minor change to SecurityManager.noop_user_update\r\n    def noop_user_update(self, user: \"User\") -> None:\r\n        stmt = (\r\n            update(self.user_model)  # was update(User)\r\n                .where(self.user_model.id == user.id)\r\n                .values(login_count=user.login_count)\r\n        )\r\n        self.get_session.execute(stmt)\r\n        self.get_session.commit()\r\n```\r\n\r\n",
                        "user": "soundmaking",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-04-03T14:40:38Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1822#issuecomment-1086883138"
                    },
                    {
                        "body": "Right makes perfect sense @soundmaking, I'll make a PR for the fix",
                        "user": "dpgaspar",
                        "issue_author_association": "OWNER",
                        "project_created_at": "2022-04-22T09:13:39Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1822#issuecomment-1106224996"
                    },
                    {
                        "body": "@soundmaking ok merged the fix, will be out on the next release 4.0.1 (should be soon 1/2 weeks)",
                        "user": "dpgaspar",
                        "issue_author_association": "OWNER",
                        "project_created_at": "2022-04-22T09:46:22Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/issues/1822#issuecomment-1106275367"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1642",
                "title": "fix: add warning text to roles when AUTH_ROLES_SYNC_AT_LOGIN",
                "labels": [
                    "security:crud"
                ],
                "user": "dpgaspar",
                "issue_author_association": "OWNER",
                "number": 1642,
                "id": 894581293,
                "state": "closed",
                "project_created_at": "2021-05-18T16:46:54Z",
                "closed_at": "2021-05-24T08:35:16Z",
                "body": "### Description\r\n\r\nAdds a warning message when creating or editing a user and `AUTH_ROLES_SYNC_AT_LOGIN` is enabled.\r\n\r\n<img width=\"1182\" alt=\"Screenshot 2021-05-20 at 09 51 29\" src=\"https://user-images.githubusercontent.com/4025227/118949312-fe4e5200-b950-11eb-9e11-ab65065cd51d.png\">\r\n\r\ncc: @cccs-rc @thesuperzapper \r\n\r\n### ADDITIONAL INFORMATION\r\n- [X] Has associated issue: #1627\r\n- [X] Is CRUD MVC related.\r\n- [ ] Is Auth, RBAC security related.\r\n- [ ] Changes the security db schema.\r\n- [ ] Introduces new feature\r\n- [ ] Removes existing feature\r\n",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/dpgaspar/Flask-AppBuilder/pulls/1642",
                    "merged_at": "2021-05-24T08:35:15Z"
                }
            },
            {
                "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1640",
                "title": "fix: Issue #1638 - replaced id_token by access_token for azure",
                "labels": [
                    "stale",
                    "security:auth"
                ],
                "user": "melazarus",
                "issue_author_association": "NONE",
                "number": 1640,
                "id": 887105926,
                "state": "closed",
                "project_created_at": "2021-05-11T12:22:00Z",
                "closed_at": "2022-04-16T05:25:04Z",
                "body": "### Description\r\n\r\nThis fixes the issue descript in #1638 where the upn can't be located in id_token but actually is present in access_token.\r\n\r\n### ADDITIONAL INFORMATION\r\n- [x] Has associated issue: 1638\r\n- [x] Is Auth, RBAC security related.\r\n",
                "comments": [
                    {
                        "body": "@melazarus can you clarify if something has changed on the azure end, and why we would have previously used `id_token`?\r\n\r\nIf possibly can you link me the relevant Azure docs?",
                        "user": "thesuperzapper",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-05-17T10:00:06Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1640#issuecomment-842192363"
                    },
                    {
                        "body": "@thesuperzapper, as far as I can see, but I'm not an expert, this did not change in azure.\r\nWhen I look at the documentation for [id_token](https://docs.microsoft.com/en-us/azure/active-directory/develop/id-tokens) and [access_token](https://docs.microsoft.com/en-us/azure/active-directory/develop/access-tokens) on the ms docs pages I see that the UPN is included in the payload of the access_token but it is not in the claims of the id_token.",
                        "user": "melazarus",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-05-25T14:38:11Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1640#issuecomment-847925636"
                    },
                    {
                        "body": "@melazarus @thesuperzapper \r\n\r\nYes, this makes some sense according to docs, has a reference this new feature was added here: https://github.com/dpgaspar/Flask-AppBuilder/pull/615\r\n\r\nLooking at the docs:\r\nThe unique fields `email` and `username` use `upn` and `oid` respectively. Where in fact `upn` is not present on the `id_token` but `email` is, so it probably makes more sense to use this field (config would need to change to include the email option claim), and a fall back to construct a unique email based on the username has a best effort and to preserve uniqueness.\r\n\r\nOn the other hand `given_name` and `family_name` belong to the `access_token` claims. \r\n\r\nNot an expert on Azure AD, but `id_token` is more compliant to OpenID OAuth and `access_token` seems more Azure proprietary is this a right assumption @melazarus ?\r\n",
                        "user": "dpgaspar",
                        "issue_author_association": "OWNER",
                        "project_created_at": "2021-06-11T10:35:06Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1640#issuecomment-859485342"
                    },
                    {
                        "body": "This issue has been automatically marked as stale because it has not had recent activity. It will be closed in 7 days if no further activity occurs.  Feel free to reopen it if it's still relevant to you. Thank you \n",
                        "user": "stale[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-03-30T05:51:21Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1640#issuecomment-1082648767"
                    },
                    {
                        "body": "Any details on why this PR was closed? `upn` issue still exists",
                        "user": "haripraghash",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-07-14T08:57:16Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1640#issuecomment-1184183385"
                    },
                    {
                        "body": "> Any details on why this PR was closed? `upn` issue still exists\r\n\r\n@haripraghash this was closed by a stalebot (not a human) due to inactivity.\r\nCan you explain what you mean by `upn` issue?",
                        "user": "thesuperzapper",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-07-14T22:29:37Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1640#issuecomment-1184955669"
                    },
                    {
                        "body": "@thesuperzapper Thank you for that.\r\n\r\nI am referring to the issue #1638 . In that, it mentions that `upn` is not present in `id_token` but in `access_token`",
                        "user": "haripraghash",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-07-15T11:58:44Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1640#issuecomment-1185474473"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/dpgaspar/Flask-AppBuilder/pulls/1640",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1618",
                "title": "refactor: OAuth - redirect direct to provider if just one provider exists",
                "labels": [
                    "security:crud"
                ],
                "user": "hyunjong-lee",
                "issue_author_association": "CONTRIBUTOR",
                "number": 1618,
                "id": 865792162,
                "state": "closed",
                "project_created_at": "2021-04-23T06:32:34Z",
                "closed_at": "2021-06-11T10:55:33Z",
                "body": "<!--- Thank you for contributing to Flask-Appbuilder. -->\r\n<!--- This repo uses a PR lint bot (https://github.com/apps/prlint), make sure to prefix your PR title with one of: -->\r\n<!--- build|chore|ci|docs|feat|fix|perf|refactor|style|test|other -->\r\n\r\n### Description\r\n\r\nIn AuthOAuthView, redirection is always needed.\r\nIf just one provider exists, users can go to the provider auth page directly without selection.\r\nThis PR refactor the above situation. \r\n\r\n<!--- Describe the change below, including rationale and design decisions -->\r\n\r\n### ADDITIONAL INFORMATION\r\n<!--- Check any relevant boxes with \"x\" -->\r\n<!--- HINT: Include \"Fixes #nnn\" if you are fixing an existing issue -->\r\n- [ ] Has associated issue:\r\n- [ ] Is CRUD MVC related.\r\n- [x] Is Auth, RBAC security related.\r\n- [ ] Changes the security db schema.\r\n- [ ] Introduces new feature\r\n- [ ] Removes existing feature\r\n",
                "comments": [
                    {
                        "body": "@hyunjong-lee manually tested it, thank you for the improvement!\r\n",
                        "user": "dpgaspar",
                        "issue_author_association": "OWNER",
                        "project_created_at": "2021-06-11T10:55:23Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1618#issuecomment-859497675"
                    },
                    {
                        "body": "Hi.\r\nWhy this PR is missing in version  >= 3.4.0 ???\r\nplease add to version 3.4.0+ ",
                        "user": "melnikovmaksimv",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-02-07T11:43:49Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1618#issuecomment-1031375865"
                    },
                    {
                        "body": "Hi, \r\nThis issue persists in superset version 3.1.1. Is anyone facing this issue? Do you have any workaround for this?",
                        "user": "manikandantk88",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-03-17T18:14:31Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1618#issuecomment-2002562521"
                    },
                    {
                        "body": "Hi,\r\n\r\nI also face the same issue. Any idea for a workaround ? We are using 3.1.0 and also 3.1.1",
                        "user": "oldchurch12",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-04-03T11:49:45Z",
                        "url": "https://github.com/dpgaspar/Flask-AppBuilder/pull/1618#issuecomment-2034369111"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/dpgaspar/Flask-AppBuilder/pulls/1618",
                    "merged_at": "2021-06-11T10:55:33Z"
                }
            }
        ],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 6,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "ethyca/fides",
        "project_url": "https://github.com/ethyca/fides",
        "SSF": {
            "date": "2024-10-29T21:53:39+07:00",
            "repo": {
                "name": "github.com/ethyca/fides",
                "commit": "4af14dc3215bbbad43c82234cd3af2169f079149"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.4,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'release-2.48.0'",
                        "Warn: branch protection not enabled for branch 'release-2.47.1'",
                        "Warn: branch protection not enabled for branch 'release-2.47.0'",
                        "Warn: branch protection not enabled for branch 'release-2.46.2'",
                        "Warn: branch protection not enabled for branch 'release-2.46.1'",
                        "Warn: branch protection not enabled for branch 'release-2.46.0'",
                        "Warn: branch protection not enabled for branch 'release-2.45.2'",
                        "Warn: branch protection not enabled for branch 'release-2.45.1'",
                        "Warn: branch protection not enabled for branch 'release-2.45.0'",
                        "Warn: branch protection not enabled for branch 'release-2.44.0'",
                        "Warn: branch protection not enabled for branch 'release-2.43.2'",
                        "Warn: branch protection not enabled for branch 'release-2.43.1'",
                        "Warn: branch protection not enabled for branch 'release-2.43.0'",
                        "Warn: branch protection not enabled for branch 'release-2.42.1'",
                        "Warn: branch protection not enabled for branch 'release-2.42.0'",
                        "Warn: branch protection not enabled for branch 'release-2.41.0'",
                        "Warn: branch protection not enabled for branch 'release-2.40.0'",
                        "Warn: branch protection not enabled for branch 'release-2.39.2'",
                        "Warn: branch protection not enabled for branch 'release-2.39.1'",
                        "Warn: branch protection not enabled for branch 'release-2.39.0'",
                        "Warn: branch protection not enabled for branch 'release-2.38.1'",
                        "Warn: branch protection not enabled for branch 'release-2.38.0'",
                        "Warn: branch protection not enabled for branch 'release-2.37.0'",
                        "Warn: branch protection not enabled for branch 'release-2.36.0'",
                        "Warn: branch protection not enabled for branch 'release-2.35.1'",
                        "Warn: branch protection not enabled for branch 'release-2.35.0'",
                        "Warn: branch protection not enabled for branch 'release-2.34.0'",
                        "Warn: branch protection not enabled for branch 'release-2.33.1'",
                        "Warn: branch protection not enabled for branch 'release-2.33.0'",
                        "Warn: branch protection not enabled for branch 'release-2.32.0'",
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: required approving review count is 1 on branch 'main'",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Warn: no status checks found to merge onto branch 'main'",
                        "Info: PRs are required in order to make changes on branch 'main'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 out of 30 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: xyvora contributor org/company found, ethyca contributor org/company found, camunda contributor org/company found, datatriadian contributor org/company found, pbs-data-solutions contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 5 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yaml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/backend_checks.yml:44"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:436: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:448: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:451: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:460: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:53: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:57: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:60: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:71: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:167: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:176: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:179: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:188: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:312: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:321: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:327: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:358: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:367: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:373: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:97: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:100: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:123: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:132: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:135: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:150: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:211: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:220: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:223: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:232: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:260: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:269: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:272: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:281: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/backend_checks.yml:290: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/backend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cli_checks.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/cli_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cli_checks.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/cli_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:56: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:70: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/codeql-analysis.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cypress_e2e.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/cypress_e2e.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cypress_e2e.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/cypress_e2e.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/cypress_e2e.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/cypress_e2e.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/cypress_e2e.yml:52: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/cypress_e2e.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/frontend_checks.yml:31: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/frontend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/frontend_checks.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/frontend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/frontend_checks.yml:67: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/frontend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/frontend_checks.yml:70: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/frontend_checks.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/frontend_checks.yml:81: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/frontend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/frontend_checks.yml:89: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/frontend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/frontend_checks.yml:107: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/frontend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/frontend_checks.yml:110: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/frontend_checks.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/frontend_checks.yml:121: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/frontend_checks.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_docker.yaml:70: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/publish_docker.yaml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish_docker.yaml:75: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/publish_docker.yaml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish_docker.yaml:115: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/publish_docker.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_docs.yaml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/publish_docs.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_docs.yaml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/publish_docs.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_package.yaml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/publish_package.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_package.yaml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/publish_package.yaml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_package.yaml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/publish_package.yaml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish_package.yaml:113: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/publish_package.yaml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release_event.yml:12: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/release_event.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release_event.yml:23: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/release_event.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release_event.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/ethyca/fides/release_event.yml/main?enable=pin",
                        "Warn: containerImage not pinned by hash: Dockerfile:6",
                        "Warn: containerImage not pinned by hash: Dockerfile:58",
                        "Warn: containerImage not pinned by hash: Dockerfile:102",
                        "Warn: containerImage not pinned by hash: Dockerfile:113",
                        "Warn: containerImage not pinned by hash: Dockerfile:130",
                        "Warn: containerImage not pinned by hash: Dockerfile:140",
                        "Warn: containerImage not pinned by hash: Dockerfile:161",
                        "Warn: containerImage not pinned by hash: clients/sample-app/Dockerfile:1",
                        "Warn: containerImage not pinned by hash: docs/fides/Dockerfile:1",
                        "Warn: containerImage not pinned by hash: docs/fides/Dockerfile:34",
                        "Warn: pipCommand not pinned by hash: Dockerfile:38",
                        "Warn: pipCommand not pinned by hash: Dockerfile:48",
                        "Warn: pipCommand not pinned by hash: Dockerfile:50",
                        "Warn: pipCommand not pinned by hash: Dockerfile:53",
                        "Warn: npmCommand not pinned by hash: Dockerfile:123",
                        "Warn: pipCommand not pinned by hash: Dockerfile:170",
                        "Warn: pipCommand not pinned by hash: docs/fides/Dockerfile:31",
                        "Warn: pipCommand not pinned by hash: docs/fides/Dockerfile:31",
                        "Warn: pipCommand not pinned by hash: docs/fides/Dockerfile:31",
                        "Warn: pipCommand not pinned by hash: .github/workflows/backend_checks.yml:40",
                        "Warn: pipCommand not pinned by hash: .github/workflows/backend_checks.yml:186",
                        "Warn: pipCommand not pinned by hash: .github/workflows/backend_checks.yml:279",
                        "Warn: pipCommand not pinned by hash: .github/workflows/backend_checks.yml:371",
                        "Warn: pipCommand not pinned by hash: .github/workflows/backend_checks.yml:446",
                        "Warn: pipCommand not pinned by hash: .github/workflows/backend_checks.yml:107",
                        "Warn: pipCommand not pinned by hash: .github/workflows/backend_checks.yml:110",
                        "Warn: downloadThenRun not pinned by hash: .github/workflows/backend_checks.yml:142",
                        "Warn: pipCommand not pinned by hash: .github/workflows/backend_checks.yml:148",
                        "Warn: pipCommand not pinned by hash: .github/workflows/backend_checks.yml:230",
                        "Warn: pipCommand not pinned by hash: .github/workflows/backend_checks.yml:325",
                        "Warn: pipCommand not pinned by hash: .github/workflows/cli_checks.yml:37",
                        "Warn: pipCommand not pinned by hash: .github/workflows/cli_checks.yml:40",
                        "Warn: pipCommand not pinned by hash: .github/workflows/cypress_e2e.yml:31",
                        "Warn: npmCommand not pinned by hash: .github/workflows/cypress_e2e.yml:49",
                        "Warn: npmCommand not pinned by hash: .github/workflows/frontend_checks.yml:40",
                        "Warn: npmCommand not pinned by hash: .github/workflows/frontend_checks.yml:76",
                        "Warn: npmCommand not pinned by hash: .github/workflows/frontend_checks.yml:116",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish_docker.yaml:82",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish_docs.yaml:31",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish_docs.yaml:34",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish_docs.yaml:37",
                        "Warn: npmCommand not pinned by hash: .github/workflows/publish_package.yaml:31",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish_package.yaml:40",
                        "Info:   0 out of  45 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of  21 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of  10 containerImage dependencies pinned",
                        "Info:   1 out of  27 pipCommand dependencies pinned",
                        "Info:   0 out of   6 npmCommand dependencies pinned",
                        "Info:   0 out of   1 downloadThenRun dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: all commits (30) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/backend_checks.yml:428",
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql-analysis.yml:28",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql-analysis.yml:29",
                        "Warn: no topLevel permission defined: .github/workflows/backend_checks.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/cli_checks.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/codeql-analysis.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/cypress_e2e.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/frontend_checks.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish_docker.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish_docs.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish_package.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release_event.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-p8p7-x288-28g6",
                        "Warn: Project is vulnerable to: GHSA-952p-6rrq-rcjv",
                        "Warn: Project is vulnerable to: GHSA-72xf-g2v4-qvf3",
                        "Warn: Project is vulnerable to: GHSA-8hc4-vh64-cxmj",
                        "Warn: Project is vulnerable to: GHSA-pxg6-pf52-xh8x",
                        "Warn: Project is vulnerable to: GHSA-g77x-44xx-532m",
                        "Warn: Project is vulnerable to: GHSA-gp8f-8m3g-qvj9",
                        "Warn: Project is vulnerable to: GHSA-9wv6-86v2-598j",
                        "Warn: Project is vulnerable to: GHSA-gcx4-mw62-g8wm",
                        "Warn: Project is vulnerable to: GHSA-fr5h-rqp8-mj6g",
                        "Warn: Project is vulnerable to: GHSA-c2qf-rxjj-qqgw",
                        "Warn: Project is vulnerable to: GHSA-6vqw-3v5j-54x4",
                        "Warn: Project is vulnerable to: GHSA-9v9h-cgj8-h64p",
                        "Warn: Project is vulnerable to: GHSA-h4gh-qq45-vh27",
                        "Warn: Project is vulnerable to: GHSA-6c5p-j8vq-pqhj",
                        "Warn: Project is vulnerable to: GHSA-cjwg-qfpm-7377"
                    ],
                    "score": 0,
                    "reason": "16 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/ethyca/fides/contents/SECURITY.md",
        "SecurityPolicy_content": "# Reporting a Vulnerability\n\nIf you believe youve discovered a potential vulnerability, please let us know by emailing us at security@ethyca.com.\n\nAlthough Ethyca does not currently operate a bug bounty program, we welcome the submission of vulnerability reports and aim to acknowlege your email within one week.\n",
        "project_all_labels": [
            "Access Control for Fine Grained Data Map Editing",
            "AWS Scanning UI",
            "bug",
            "Consent Enforcement in Web Browser",
            "CPRA/VCDPA Consent Laws (Fides Version)",
            "CPRA/VCDPA Consent Laws (Pro Version)",
            "customer-request",
            "dependabot",
            "dependencies",
            "dev experience",
            "discussion",
            "Distributed Fides",
            "do not merge",
            "documentation",
            "dont build",
            "DSR Error Handling",
            "DSR Implementation Improvements",
            "duplicate",
            "feedback",
            "Fides Classify UI",
            "Fides NUX Improvements",
            "Fides Product Analytics",
            "Fides System Configuration",
            "FidesCls Enhancements",
            "github_actions",
            "Global Privacy Control Support in Fides",
            "good first issue",
            "hacktoberfest-accepted",
            "help wanted",
            "high-risk",
            "invalid",
            "javascript",
            "maintenance",
            "needs design",
            "Okta Scanning UI",
            "Pro -> Fides Migration Tooling",
            "proof of concept",
            "python",
            "run unsafe ci checks",
            "SaaS Connector",
            "SaaS Connector Builder",
            "SMS-based Privacy Request Fulfillment",
            "System Management",
            "Taxonomy Management",
            "Tech Debt",
            "Test Automation Improvements",
            "testing",
            "UI",
            "Unified Fides",
            "Unified Fides Resources",
            "wontfix"
        ],
        "README_content": "# Meet Fides: Privacy as Code\n\n[![Latest Release Version][release-image]][release-url]\n[![Docker][docker-workflow-image]][docker-actions-url]\n[![Docs][docs-workflow-image]][docs-actions-url]\n[![Package][release-workflow-image]][publish-actions-url]\n[![License][license-image]][license-url]\n[![Code style: black][black-image]][black-url]\n[![Checked with mypy][mypy-image]][mypy-url]\n[![Twitter][twitter-image]][twitter-url]\n[![Coverage](https://codecov.io/github/ethyca/fides/coverage.svg?branch=main)](https://codecov.io/gh/ethyca/fides)\n\n![Fides banner](docs/fides/docs/img/fides-banner.png \"Fides banner\")\n\n## :zap: Overview\n\nFides (pronounced */fee-dhez/*, from Latin: Fids) is an open-source privacy engineering platform for managing the fulfillment of data privacy requests in your runtime environment, and the enforcement of privacy regulations in your code.\n\n## :rocket: Quick Start\n\n### Getting Started\n\nIn order to get started quickly with Fides, a sample project is bundled within the Fides CLI that will set up a server, privacy center, and a sample application for you to experiment with.\n\n#### Minimum requirements (for all platforms)\n\n* [Docker](https://www.docker.com/products/docker-desktop) (version 20.10.11 or later)\n* [Python](https://www.python.org/downloads/) (version 3.9 through 3.10)\n\n#### Download and install Fides\n\n> [!TIP]\n> We highly recommend setting up a Python virtual environment such as `venv` to install Fides into. For example:\n>\n> ```sh\n> mkdir ~/fides\n> cd ~/fides\n> python3 -m venv venv\n> source venv/bin/activate\n> ```\n\nOnce your virtual environment is ready, you can easily download and install Fides using `pip`. Run the following command to get started:\n\n```\npip install ethyca-fides\n```\n\n#### Deploy the Fides sample project\n\nBy default, Fides ships with a small project belonging to a fictional e-commerce store. Running the `fides deploy up` command builds a Fides project with all you need to run your first Data Subject Request against real databases.\n\n```sh\nfides deploy up\n```\n\n#### Explore the sample project\n\nWhen your deployment finishes, a welcome screen will explain the key components of Fides and the sample \"Cookie House\" project.\n\nIf your browser does not open automatically, you should navigate to <http://localhost:3000/landing>.\n\nThe project contains:\n\n* The Fides Admin UI for managing privacy requests\n* The Fides [Privacy Center](https://ethyca.com/docs/dev-docs/privacy-requests/privacy-center) for submitting requests\n* The sample \"Cookie House\" eCommerce site for testing\n* A DSR Directory on your computer to view results (`./fides_uploads`)\n\n#### Run your first Privacy Access Request\n\nNavigate to the Fides Privacy Center (<http://localhost:3001>), submit a \"Download your data\" request, provide the email address for the sample user (`jane@example.com`), and submit the request.\n\nThen, navigate to the Fides Admin UI (<http://localhost:8080>) to review the pending privacy request.\n\nUse username `root_user` and password `Testpassword1!` to login, approve the request, and review the resulting package in your `./fides_uploads` folder!\n\n### Next Steps\n\nCongratulations! You've just run an entire privacy request in under 5 minutes! Fides offers many more tools to help take control of your data privacy. To find out more, you can run a privacy request on [your own infrastructure](https://ethyca.com/docs/tutorials/privacy-requests), discover [data mapping](https://ethyca.com/docs/tutorials/data-mapping), or learn about the [Fides Taxonomy](https://ethyca.github.io/fideslang/).\n\n## :book: Learn More\n\nThe Fides core team is committed to providing a variety of documentation to help get you started using Fides.  As such, all interactions are governed by the [Fides Code of Conduct](https://ethyca.com/docs/community/code_of_conduct).\n\n### Documentation\n\nFor more information on getting started with Fides, how to configure and set up Fides, and more about the Fides ecosystem of open source projects:\n\n* Documentation: <https://docs.ethyca.com>\n* Website: www.ethyca.com/fides\n\n### Support\n\nJoin the conversation on:\n\n* [Slack](https://fid.es/join-slack)\n* [Twitter](https://twitter.com/ethyca)\n* [Discussions](https://github.com/ethyca/fides/discussions)\n\n### Contributing\n\nWe welcome and encourage all types of contributions and improvements!  Please see our [contribution guide](https://ethyca.com/docs/community) to opening issues for bugs, new features, and security or experience enhancements.\n\nRead about the [Fides community](https://ethyca.com/docs/community/hints_tips) or dive into the [contributor guides](https://ethyca.com/docs/community/development/overview) for information about contributions, documentation, code style, testing and more. Ethyca is committed to fostering a safe and collaborative environment, such that all interactions are governed by the [Fides Code of Conduct](https://ethyca.com/docs/community/code_of_conduct).\n\n## :balance_scale: License\n\nThe [Fides](https://github.com/ethyca/fides) ecosystem of tools are licensed under the [Apache Software License Version 2.0](https://www.apache.org/licenses/LICENSE-2.0).\nFides tools are built on [fideslang](https://github.com/ethyca/privacy-taxonomy), the Fides language specification, which is licensed under [CC by 4](https://github.com/ethyca/privacy-taxonomy/blob/main/LICENSE).\n\nFides is created and sponsored by Ethyca: a developer tools company building the trust infrastructure of the internet. If you have questions or need assistance getting started, let us know at fides@ethyca.com!\n\n[release-image]: https://img.shields.io/github/release/ethyca/fides.svg\n[release-url]: https://github.com/ethyca/fides/releases\n[docker-workflow-image]: https://github.com/ethyca/fides/workflows/Docker%20Build%20&%20Push/badge.svg\n[docs-workflow-image]: https://github.com/ethyca/fides/workflows/Publish%20Docs/badge.svg\n[release-workflow-image]: https://github.com/ethyca/fides/actions/workflows/publish_package.yaml/badge.svg\n[docker-actions-url]: https://github.com/ethyca/fides/actions/workflows/publish_docker.yaml\n[docs-actions-url]: https://github.com/ethyca/fides/actions/workflows/publish_docs.yaml\n[publish-actions-url]: https://github.com/ethyca/fides/actions/workflows/publish_package.yaml\n[license-image]: https://img.shields.io/:license-Apache%202-blue.svg\n[license-url]: https://www.apache.org/licenses/LICENSE-2.0.txt\n[black-image]: https://img.shields.io/badge/code%20style-black-000000.svg\n[black-url]: https://github.com/psf/black/\n[mypy-image]: http://www.mypy-lang.org/static/mypy_badge.svg\n[mypy-url]: http://mypy-lang.org/\n[twitter-image]: https://img.shields.io/twitter/follow/ethyca?style=social\n[twitter-url]: https://twitter.com/ethyca\n\n##  Advanced Setup for Microsoft SQL Server (MSSQL) Support\n\nBy default, running `pip install ethyca-fides` locally will not install the optional Python libraries needed for Microsoft SQL Server, since these rely on additional system dependencies (`freetds`)! However, if you *do* want to connect to MSSQL, you have two options:\n1. Use our pre-built Docker images which install these optional dependencies automatically: [`ethyca/fides`](https://hub.docker.com/r/ethyca/fides). See our [Deployment Guide](https://ethyca.com/docs/dev-docs/configuration/deployment) for more!\n2. Install the required dependencies on your local development machine and run `pip install \"ethyca-fides[all]\"` to include \"all\" the optional libraries. Keep reading to learn more about this!\n\nFor local development setup on macOS, follow these steps:\n1. Install the required development libraries from Homebrew:\n```bash\nbrew install freetds openssl\n```\n2. Add the following to your shell (i.e. `.zshrc`) to ensure your compiler can access the `freetds` and `openssl` libraries, updating the paths & versions to match your local install:\n```bash\nexport LDFLAGS=\"-L/opt/homebrew/Cellar/freetds/1.3.18/lib -L/opt/homebrew/Cellar/openssl@1.1/1.1.1u/lib\"\nexport CFLAGS=\"-I/opt/homebrew/Cellar/freetds/1.3.18/include\"\n```\n3. Reinstall Fides with MSSQL support by including the `all` extra requirement:\n```bash\npip install ethyca-fides[all]\n```\n",
        "num_commits": 2619,
        "project_age_days": 1363,
        "project_created_at": "2021-02-04",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-30",
        "num_contributors": 60,
        "num_pull": 3261,
        "num_issues": 5364,
        "num_opening_issue": 280,
        "project_size(kB)": 106942,
        "num_stargazers": 359,
        "num_watchers": 359,
        "num_forks": 72,
        "num_subscribers": 22,
        "SecurityPolicy_created_at": "2022-11-08 16:22:11",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "11588fec85da5229cfaba41cf1ca2c7137efc21f",
                "url": "https://github.com/ethyca/fides/commit/11588fec85da5229cfaba41cf1ca2c7137efc21f",
                "date": "2022-11-08 16:22:11"
            }
        ],
        "project_security_labels": [
            "high-risk"
        ],
        "security_issues": [
            {
                "url": "https://github.com/ethyca/fides/pull/3933",
                "title": "[DANGER] Update to Fideslang 2.0",
                "labels": [
                    "high-risk",
                    "run unsafe ci checks"
                ],
                "user": "ThomasLaPiana",
                "issue_author_association": "CONTRIBUTOR",
                "number": 3933,
                "id": 1854368330,
                "state": "closed",
                "project_created_at": "2023-08-17T06:48:25Z",
                "closed_at": "2023-09-13T18:55:32Z",
                "body": "Closes #3795\r\n\r\n Customer `config.json` files should be updated as they are migrated to the accompanying release.\r\n\r\n### Description Of Changes\r\n\r\nThis PR is focused on bumping the `Fideslang` version and ensuring that the application is working as expected when set u as a new instance. There is a separate PR for handling migrations for current users, as they are both sufficiently complex pieces to warrant handling separately.\r\n\r\nMuch of the inspiration/work here is inspired by [this PR](https://github.com/ethyca/fides/pull/3343) that handled an earlier, similar change\r\n\r\nThe Data Migration work is happening here: #4030\r\n\r\n_*WARNING: Merging this change as-is will break any existing instance due to default taxonomy model conflicts*_\r\n\r\n### Code Changes\r\n\r\n* [x] bump `requirements.txt`\r\n* [x] add a migration for the new `version` fields\r\n* Update `DataCategories`\r\n  * [x] datasets (including collections/fields)\r\n  * [x] policy rule **(tested previously, code is copy/pasta)**\r\n  * [x] privacy declaration **(tested previously, code is copy/pasta)**\r\n  * [x] data flows (egress and ingress on `System` models)\r\n* Update `DataUse`s\r\n  * [x] privacy declaration **(tested previously, code is copy/pasta)**\r\n  * [x] policy rule **(tested previously, code is copy/pasta)**\r\n* [x] do find/replace for the old categories/uses\r\n\r\n### Steps to Confirm\r\n\r\nBecause this PR is focused on getting _new_ instances working instead of migrating data, the `Steps to Confirm` here are very simple. Tests passing is what we care about here! [This PR](https://github.com/ethyca/fides/pull/4030) is where the complex data migration will take place\r\n\r\n* [ ] after running `nox -s teardown -- volumes` and `nox -s dev`, everything works as intended\r\n\r\n### Pre-Merge Checklist\r\n\r\n* [ ] All CI Pipelines Succeeded\r\n* Documentation:\r\n  * [ ] documentation complete, [PR opened in fidesdocs](https://github.com/ethyca/fidesdocs/pulls)\r\n  * [ ] documentation [issue created in fidesdocs](https://github.com/ethyca/fidesdocs/issues/new/choose)\r\n* [ ] Issue Requirements are Met\r\n* [ ] Relevant Follow-Up Issues Created\r\n* [ ] Update `CHANGELOG.md`\r\n* [ ] For API changes, the [Postman collection](https://github.com/ethyca/fides/blob/main/docs/fides/docs/development/postman/Fides.postman_collection.json) has been updated\r\n",
                "comments": [
                    {
                        "body": "\n## Passing [run #4110 ](https://cloud.cypress.io/projects/bauzeh/runs/4110/overview?utm_source=github&utm_medium=PASSED&utm_campaign=run%20number)\n\n<table>\n<tr>\n  <td><a href=\"https://cloud.cypress.io/projects/bauzeh/runs/4110/overview?reviewViewBy=FAILED&utm_source=github&utm_medium=PASSED&utm_campaign=failed%20tests\" style=\"text-decoration: none;\"><img src=\"https://assets.cypress.io/github-pr-comment-icons/red-x-v2.png\" width=\"14\" height=\"14\" title=\"Failed\" /></a> <b title=\"Failed\"><a href=\"https://cloud.cypress.io/projects/bauzeh/runs/4110/overview?reviewViewBy=FAILED&utm_source=github&utm_medium=PASSED&utm_campaign=failed%20tests\">0</a></b></td>\n  <td><a href=\"https://cloud.cypress.io/projects/bauzeh/runs/4110/overview?utm_source=github&utm_medium=PASSED&utm_campaign=passed%20tests\"><img src=\"https://assets.cypress.io/github-pr-comment-icons/green-check-mark-v2.png\" width=\"14\" height=\"14\" title=\"Passed\" /></a> <b title=\"Passed\"><a href=\"https://cloud.cypress.io/projects/bauzeh/runs/4110/overview?utm_source=github&utm_medium=PASSED&utm_campaign=passed%20tests\" style=\"text-decoration: none;\">4<a/></b></td>\n  <td><a href=\"https://cloud.cypress.io/projects/bauzeh/runs/4110/test-results?utm_source=github&utm_medium=PASSED&utm_campaign=pending%20tests&statuses=%5B%7B%22value%22%3A%22PENDING%22%2C%22label%22%3A%22PENDING%22%7D%5D\"><img src=\"https://assets.cypress.io/github-pr-comment-icons/gray-circle-v2.png\" width=\"14\" height=\"14\" title=\"Tests that did not run due to a developer annotating a test with .skip\" /></a> <b title=\"Pending\"><a href=\"https://cloud.cypress.io/projects/bauzeh/runs/4110/test-results?utm_source=github&utm_medium=PASSED&utm_campaign=pending%20tests&statuses=%5B%7B%22value%22%3A%22PENDING%22%2C%22label%22%3A%22PENDING%22%7D%5D\" style=\"text-decoration: none;\">0</a></b></td>\n  <td><a href=\"https://cloud.cypress.io/projects/bauzeh/runs/4110/test-results?utm_source=github&utm_medium=PASSED&utm_campaign=skipped%20tests&statuses=%5B%7B%22value%22%3A%22SKIPPED%22%2C%22label%22%3A%22SKIPPED%22%7D%5D\"><img src=\"https://assets.cypress.io/github-pr-comment-icons/skipped-v2.png\" width=\"14\" height=\"14\" title=\"Tests that did not run due to a failure in a mocha hook\" /></a> <b title=\"Skipped\"><a href=\"https://cloud.cypress.io/projects/bauzeh/runs/4110/test-results?utm_source=github&utm_medium=PASSED&utm_campaign=skipped%20tests&statuses=%5B%7B%22value%22%3A%22SKIPPED%22%2C%22label%22%3A%22SKIPPED%22%7D%5D\" style=\"text-decoration: none;\">0<a/></b></td>\n  <td><a href=\"https://cloud.cypress.io/projects/bauzeh/runs/4110/overview?reviewViewBy=FLAKY&utm_source=github&utm_medium=PASSED&utm_campaign=flaky%20tests\"><img src=\"https://assets.cypress.io/github-pr-comment-icons/flaky-v2.png\" width=\"29\" height=\"14\" title=\"Tests that were flaky\" alt=\"Flakiness\" /></a> <b title=\"Flaky\"><a href=\"https://cloud.cypress.io/projects/bauzeh/runs/4110/overview?reviewViewBy=FLAKY&utm_source=github&utm_medium=PASSED&utm_campaign=flaky%20tests\" style=\"text-decoration: none;\">0</a></b></td>\n</tr>\n<tr><td colspan=\"5\"><b> You've recorded test results over your free plan limit.<br /><a href=\"https://cloud.cypress.io/organizations/653f2b3f-47dd-4359-b4a6-e8fa761efeb7/billing?utm_source=github&utm_medium=PASSED&utm_campaign=upgrade%20plan\">Upgrade your plan to view test results</a>.</b></td></tr>\n\n</table>\n\n<b>Details:</b>\n\n<table>\n  <tr>\n    <td colspan=\"4\">Merge 4a271f9293f9b40a88f7cc845915d7de88eb1b1c into 7f53a75654ffadcefd3746e12797...</td>\n  </tr>\n  <tr />\n  <tr>\n    <td><b>Project:</b> fides</td>\n    <td><b>Commit:</b> <code>97e809de64 <span style=\"cursor:help;\" title=\"Your CI provider generated this commit by merging this branch into the target branch.\"></span></code></td>\n  </tr>\n  <tr />\n  <tr>\n    <td><b>Status:</b> Passed</td>\n    <td><b>Duration:</b> 01:18 <a href=\"https://on.cypress.io/parallelization?utm_source=github&utm_medium=PASSED&utm_campaign=parallelization%20docs\" title=\"Learn about optimizing your runs with parallelization\"></a></td>\n  </tr>\n  <tr />\n  <tr>\n    <td><b>Started:</b> Sep 13, 2023 6:48 PM</td>\n    <td><b>Ended:</b> Sep 13, 2023 6:49 PM</td>\n  </tr>\n</table>\n\n\n\n\n\n<p align=\"center\">\n  <sub\n    >This comment has been generated by cypress-bot as a result of this\n    project's <a href=\"https://cloud.cypress.io/projects/bauzeh/settings?utm_source=github&utm_medium=PASSED&utm_campaign=footer\">GitHub integration settings</a>.</sub\n  >\n</p>\n",
                        "user": "cypress[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-08-17T07:02:24Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1681736940"
                    },
                    {
                        "body": "@adamsachs update for you before I sign off!\r\n\r\nIn the description I've linked the `fideslang` PR where I'm making changes as needed\r\n\r\nI'm currently working through a local dev env and shell to run specific tests and try to diagnose why some of the breaks are happening. Focused primarily on the `ctl` tests as they were easier to run and faster",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-17T17:43:01Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1682707465"
                    },
                    {
                        "body": "@ThomasLaPiana stepping away for a bit now, made a few changes that i think should help get things greener...tried to break it up reasonably by commit so that my changes are easy to follow -- everything is pretty straightforward cleanup so far.\r\n\r\nwill see if i can circle back a bit later this evening to knock out some more, but leaving this update here in case i don't  ",
                        "user": "adamsachs",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-17T21:30:05Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1683005954"
                    },
                    {
                        "body": "@adamsachs Thank you! picking it up now",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-18T03:37:19Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1683301794"
                    },
                    {
                        "body": "there's a final system update test failing here that I suspect @pattisdr might understand, other than that the `ctl` tests are looking good!",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-18T10:48:11Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1683732092"
                    },
                    {
                        "body": "> there's a final system update test failing here that I suspect @pattisdr might understand, other than that the `ctl` tests are looking good!\r\n\r\n nice @ThomasLaPiana! i think i wrote those system update tests related to privacy declarations so i can take a look, i'll loop in @pattisdr if needed.\r\n\r\n@ThomasLaPiana are you working on the ops tests or should i also take a look at that? i've got some bandwidth so i'm happy to, but if you're already on it then i'll let you continue",
                        "user": "adamsachs",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-18T10:59:01Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1683744389"
                    },
                    {
                        "body": "@adamsachs Go for it! I'm signing off for now",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-18T11:02:59Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1683748821"
                    },
                    {
                        "body": "@adamsachs once we get tests passing, we'll merge and ship fideslang 2.0.1 and pin this to a real version",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-18T11:08:24Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1683754587"
                    },
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca) Report\nPatch coverage: **`100.00%`** and project coverage change: **`-0.04%`** :warning:\n> Comparison is base [(`7f53a75`)](https://app.codecov.io/gh/ethyca/fides/commit/7f53a75654ffadcefd3746e12797dbaf740188eb?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca) 87.39% compared to head [(`e7ecbb4`)](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca) 87.36%.\n\n<details><summary>Additional details and impacted files</summary>\n\n\n```diff\n@@            Coverage Diff             @@\n##             main    #3933      +/-   ##\n==========================================\n- Coverage   87.39%   87.36%   -0.04%     \n==========================================\n  Files         320      320              \n  Lines       19602    19617      +15     \n  Branches     2512     2512              \n==========================================\n+ Hits        17132    17139       +7     \n- Misses       2033     2040       +7     \n- Partials      437      438       +1     \n```\n\n\n| [Files Changed](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca) | Coverage  | |\n|---|---|---|\n| [.../api/api/v1/endpoints/consent\\_request\\_endpoints.py](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca#diff-c3JjL2ZpZGVzL2FwaS9hcGkvdjEvZW5kcG9pbnRzL2NvbnNlbnRfcmVxdWVzdF9lbmRwb2ludHMucHk=) | `85.12% <> ()` | |\n| [.../api/api/v1/endpoints/privacy\\_request\\_endpoints.py](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca#diff-c3JjL2ZpZGVzL2FwaS9hcGkvdjEvZW5kcG9pbnRzL3ByaXZhY3lfcmVxdWVzdF9lbmRwb2ludHMucHk=) | `90.34% <> ()` | |\n| [src/fides/api/db/seed.py](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca#diff-c3JjL2ZpZGVzL2FwaS9kYi9zZWVkLnB5) | `89.20% <> ()` | |\n| [src/fides/api/models/privacy\\_request.py](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca#diff-c3JjL2ZpZGVzL2FwaS9tb2RlbHMvcHJpdmFjeV9yZXF1ZXN0LnB5) | `96.30% <> ()` | |\n| [src/fides/api/schemas/privacy\\_request.py](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca#diff-c3JjL2ZpZGVzL2FwaS9zY2hlbWFzL3ByaXZhY3lfcmVxdWVzdC5weQ==) | `100.00% <> ()` | |\n| [.../api/service/connectors/consent\\_email\\_connector.py](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca#diff-c3JjL2ZpZGVzL2FwaS9zZXJ2aWNlL2Nvbm5lY3RvcnMvY29uc2VudF9lbWFpbF9jb25uZWN0b3IucHk=) | `97.14% <> ()` | |\n| [...vice/saas\\_request/saas\\_request\\_override\\_factory.py](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca#diff-c3JjL2ZpZGVzL2FwaS9zZXJ2aWNlL3NhYXNfcmVxdWVzdC9zYWFzX3JlcXVlc3Rfb3ZlcnJpZGVfZmFjdG9yeS5weQ==) | `100.00% <> ()` | |\n| [src/fides/api/util/data\\_category.py](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca#diff-c3JjL2ZpZGVzL2FwaS91dGlsL2RhdGFfY2F0ZWdvcnkucHk=) | `100.00% <> ()` | |\n| [.../fides/api/api/v1/endpoints/messaging\\_endpoints.py](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca#diff-c3JjL2ZpZGVzL2FwaS9hcGkvdjEvZW5kcG9pbnRzL21lc3NhZ2luZ19lbmRwb2ludHMucHk=) | `92.94% <100.00%> (+0.12%)` | :arrow_up: |\n| [src/fides/api/models/sql\\_models.py](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca#diff-c3JjL2ZpZGVzL2FwaS9tb2RlbHMvc3FsX21vZGVscy5weQ==) | `98.12% <100.00%> (+0.07%)` | :arrow_up: |\n\n... and [2 files with indirect coverage changes](https://app.codecov.io/gh/ethyca/fides/pull/3933/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca)\n\n\n</details>\n\n[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca).   \n:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca).\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-08-18T14:38:08Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1684017538"
                    },
                    {
                        "body": "OK! i think we've got all non-external tests passing now!\r\n\r\n@pattisdr would you mind taking a quick peak at the ops tests i fixed in https://github.com/ethyca/fides/pull/3933/commits/8ec6a87331fde0b328cab0045950ec361340c6ce, since some of them are touching consent-related tests and i want to be extra sure i'm not misunderstanding the tests and invalidating them  \r\n\r\nif that looks good, i think we've got our non-external/unsafe tests good to go! the remaining items to get this ready to merge would be:\r\n- [ ] look into external test failures to determine whether these are expected/in `main` already or caused by some code changes here\r\n- [ ] holistic review of this PR (i've focused on getting CI green up to this point)\r\n- [x] cut `fideslang 2.0.1` per @ThomasLaPiana's note above, and update our dependency here\r\n\r\ni should be able to make some progress on the first two items shortly...",
                        "user": "adamsachs",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-18T15:21:49Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1684075473"
                    },
                    {
                        "body": "Yes, starting review!",
                        "user": "pattisdr",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-18T15:27:29Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1684082503"
                    },
                    {
                        "body": "@adamsachs the major final step here is updating the categories in the data migration. I only did the uses because I could copy/pasta the logic from a previous migration, but now I also need to write them for data categories which live in a lot more places",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-19T08:03:22Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1684887423"
                    },
                    {
                        "body": "@adamsachs I think I've just about gotten this into a place where we can start testing it, but it's definitely tricky",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-21T23:56:23Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1687214654"
                    },
                    {
                        "body": "working on testing steps now\r\n\r\nEdit: finding some bugs, so the steps are still broken\r\n\r\nEdit 2: It looks like policy rule loading is broken due to the `version` changes in Fideslang 2",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-22T20:35:37Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1688896839"
                    },
                    {
                        "body": "this is almost getting ready for merge, I'll polish the steps to test and assign some reviewers",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-23T23:24:23Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1690768934"
                    },
                    {
                        "body": "Starting review..",
                        "user": "pattisdr",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-25T16:59:16Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1693671843"
                    },
                    {
                        "body": "I ran through the `Steps to Confirm` with the latest code and it all looks good, ready for another review",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-28T03:30:45Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1694950804"
                    },
                    {
                        "body": "sorry for breaking things a bit with merging https://github.com/ethyca/fides/commit/b07cf87cfb95185aed7815597f7e42a6a487dfad into `main`. i can update this branch to resolve the issues, i think we'll just want to:\r\n- [x] cut a new `2.0.2` release of `fideslang` that includes the same thing as `1.4.5` but is made on top of `2.0.1`, and then update `requirements.txt` here to point to `fideslang==2.0.2`\r\n- [x] merge `main` into this branch to get the new revision here\r\n- [x] update the `down_revision` of the [first migration to point to `3038667ba898`](https://github.com/ethyca/fides/pull/3933/files#diff-39abd1f52f655ead64e74fd79e75c4b1f224ee343e5160a1d8aabfc4c7ced2fcR13)\r\n\r\nupdate -- completed this, hope it's OK! ",
                        "user": "adamsachs",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-29T15:58:53Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1697733652"
                    },
                    {
                        "body": "@allisonking do we need to find/replace the typescript references for these now-outdated data categories and uses? Or is there a script that can/will generate them?",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-31T07:15:04Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1700490767"
                    },
                    {
                        "body": "reposting for visibility: https://github.com/ethyca/fides/pull/3933#discussion_r1309340895\r\n\r\nOK we reached some general consensus in [slack](https://ethyca.slack.com/archives/CBKK8TS74/p1693323605019939), it seems like we do want to:\r\n\r\n* [x] remove the deprecated taxonomy elements (probably should be done here within the migration itself?)\r\n* [x] update all references to those taxonomy elements in-place (i.e. the blunt string replace)\r\n* [x] give some steps for a \"fallback\" plan upon upgrade if desired, i.e. don't automigrate, take a db backup and migrate manually\r\n\r\nEdit: I knew (hoped) I wasn't crazy! We've done this before: https://github.com/ethyca/fides/blob/main/src/fides/api/alembic/migrations/versions/5307999c0dac_remove_deprecated_data_uses_for_.py",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-31T07:24:13Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1700504551"
                    },
                    {
                        "body": "@adamsachs @pattisdr sorry for the never-ending back and forth here! I made changes according to what was agreed upon so this should be ready for another look-see",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-31T10:04:23Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1700743819"
                    },
                    {
                        "body": "> @allisonking do we need to find/replace the typescript references for these now-outdated data categories and uses? Or is there a script that can/will generate them?\r\n\r\nI don't think there are any references to specific data categories in the code other than in the tests, which it looks like you've already updated! The TS models are generally updated by running `npm run openapi:generate` in `clients/admin-ui` against fidesplus. If that doesn't have any changes, then we should be good to go  (but also it probably will have _some_ changes, as it's probably been a little bit since we last ran it. you can just see if there are any changes directly related to this work)",
                        "user": "allisonking",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-31T13:38:12Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1701057790"
                    },
                    {
                        "body": "Thanks for your changes @ThomasLaPiana.  The migration was crashing so I added some changes here: https://github.com/ethyca/fides/pull/3933/commits/9308569ad9e9342d9e43256f65a3f9bd266c20cd to move this forward, but there's still more work to do.  Let's all continue to test and figure out where the gaps are.\r\n\r\nHere's some current TODO items I'm seeing after another round of testing:\r\n\r\n- [x] I think this is the biggest potential issue.  Migrate custom data uses and custom data categories that build off of the affected 2.0 uses and categories.   \r\n    -  For example, say I have a custom data use, \"user.search_history.work\" that I am using on a PrivacyDeclaration. We migrate that to \"user.behavior.search_history.work\" on the Declaration.  However, there is no \"DataUse\" that matches, and you get errors later when trying to update the System as a result.   \r\n\r\n- [x] New column `PrivacyDeclaration.shared_categories` going out in the current release needs to be migrated now that this migration has been delayed for a followup release.  Resurfacing [earlier comment](https://github.com/ethyca/fides/pull/3933#discussion_r1305942158)\r\n\r\n- [x] `PrivacyNotice`, `PrivacyNoticeTemplate`, and `PrivacyNoticeHistory` `data_uses` columns likely need to be migrated.  None of our out of the box notices have data uses at risk, but customers could have added custom notices, or added data uses to existing notices. \r\n\r\n- [x] ~Mysterious error on data subjects and sometimes data uses endpoint after running these migrations, usually where we have a data use mismatch somewhere~. As Thomas noted below, this is unrelated to this work\r\n```\r\n2023-08-31 17:53:52 2023-08-31 22:53:52.876 | INFO     | fides.api.main:log_request:150 - Request received | {'method': 'GET', 'status_code': 200, 'handler_time': '25.242ms', 'path': '/api/v1/data_category/'}\r\n2023-08-31 17:53:52 2023-08-31 22:53:52.878 | ERROR    | fides.api.util.logger:_log_exception:31 - unhandled errors in a TaskGroup (1 sub-exception)\r\n2023-08-31 17:53:52 Traceback (most recent call last):\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/anyio/streams/memory.py\", line 97, in receive\r\n2023-08-31 17:53:52     return self.receive_nowait()\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/anyio/streams/memory.py\", line 92, in receive_nowait\r\n2023-08-31 17:53:52     raise WouldBlock\r\n2023-08-31 17:53:52 anyio.WouldBlock\r\n2023-08-31 17:53:52 \r\n2023-08-31 17:53:52 During handling of the above exception, another exception occurred:\r\n2023-08-31 17:53:52 \r\n2023-08-31 17:53:52 Traceback (most recent call last):\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/starlette/middleware/base.py\", line 77, in call_next\r\n2023-08-31 17:53:52     message = await recv_stream.receive()\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/anyio/streams/memory.py\", line 112, in receive\r\n2023-08-31 17:53:52     raise EndOfStream\r\n2023-08-31 17:53:52 anyio.EndOfStream\r\n2023-08-31 17:53:52 Traceback (most recent call last):\r\n2023-08-31 17:53:52   File \"<string>\", line 1, in <module>\r\n2023-08-31 17:53:52   File \"/usr/local/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\r\n2023-08-31 17:53:52     exitcode = _main(fd, parent_sentinel)\r\n2023-08-31 17:53:52   File \"/usr/local/lib/python3.10/multiprocessing/spawn.py\", line 129, in _main\r\n2023-08-31 17:53:52     return self._bootstrap(parent_sentinel)\r\n2023-08-31 17:53:52   File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\r\n2023-08-31 17:53:52     self.run()\r\n2023-08-31 17:53:52   File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 108, in run\r\n2023-08-31 17:53:52     self._target(*self._args, **self._kwargs)\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/uvicorn/_subprocess.py\", line 76, in subprocess_started\r\n2023-08-31 17:53:52     target(sockets=sockets)\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/uvicorn/server.py\", line 61, in run\r\n2023-08-31 17:53:52     return asyncio.run(self.serve(sockets=sockets))\r\n2023-08-31 17:53:52   File \"/usr/local/lib/python3.10/asyncio/runners.py\", line 44, in run\r\n2023-08-31 17:53:52     return loop.run_until_complete(main)\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/starlette/middleware/base.py\", line 69, in coro\r\n2023-08-31 17:53:52     await self.app(scope, receive_or_disconnect, send_no_error)\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/starlette/middleware/base.py\", line 106, in __call__\r\n2023-08-31 17:53:52     response = await self.dispatch_func(request, call_next)\r\n2023-08-31 17:53:52 > File \"/fides/src/fides/api/main.py\", line 73, in dispatch_log_request\r\n2023-08-31 17:53:52     response = await call_next(request)\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/starlette/middleware/base.py\", line 80, in call_next\r\n2023-08-31 17:53:52     raise app_exc\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/starlette/middleware/base.py\", line 69, in coro\r\n2023-08-31 17:53:52     await self.app(scope, receive_or_disconnect, send_no_error)\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/starlette/middleware/cors.py\", line 84, in __call__\r\n2023-08-31 17:53:52     await self.app(scope, receive, send)\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/starlette/middleware/base.py\", line 104, in __call__\r\n2023-08-31 17:53:52     async with anyio.create_task_group() as task_group:\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 664, in __aexit__\r\n2023-08-31 17:53:52     raise BaseExceptionGroup(\r\n2023-08-31 17:53:52 exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\r\n```\r\n",
                        "user": "pattisdr",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-31T23:04:24Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1701891183"
                    },
                    {
                        "body": "these failures are being seen elsewhere too...unrelated to this change. I already fixed one in `main` but apparently not the root cause",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-01T12:07:09Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1702644058"
                    },
                    {
                        "body": "but is it possible bad data is still triggering it underneath? ",
                        "user": "pattisdr",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-01T14:09:51Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1702810801"
                    },
                    {
                        "body": "ah yikes I'm seeing this in unit tests, separate PR.  I wonder if mixing db sessions - synchronous/async is related\r\n\r\nhttps://github.com/ethyca/fides/pull/3990#discussion_r1313209584",
                        "user": "pattisdr",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-01T15:20:28Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1702922693"
                    },
                    {
                        "body": "> ah yikes I'm seeing this in unit tests, separate PR. I wonder if mixing db sessions - synchronous/async is related\r\n> \r\n> [#3990 (comment)](https://github.com/ethyca/fides/pull/3990#discussion_r1313209584)\r\n\r\nI'm 90% sure it is caused by an undetected dependency change....I'll post an update in slack so the rest of the team is aware",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-01T16:17:45Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1703001011"
                    },
                    {
                        "body": "In a separate PR https://github.com/ethyca/fides/pull/3990#discussion_r1313209584, this error was happening when we were using a synchronous session in a ctl endpoint - the underlying error was ` sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_() here. Was IO attempted in an unexpected place?`",
                        "user": "pattisdr",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-01T16:58:29Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1703060972"
                    },
                    {
                        "body": "spoke a bit with @pattisdr and one theory that _could_ explain this `exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup` type of error from cropping up in all sorts of (seemingly unrelated) places all of a sudden is that some recent change (likely in a dependency of ours?) is causing underlying errors to get swallowed and instead be thrown up with this generic exception type.\r\n\r\n@ThomasLaPiana do you have any further leads? i haven't dug into this much, just wanted to put this theory down on paper here. i think @pattisdr is also continuing further investigation on her end  ",
                        "user": "adamsachs",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-01T20:40:44Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1703297617"
                    },
                    {
                        "body": "> spoke a bit with @pattisdr and one theory that _could_ explain this `exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup` type of error from cropping up in all sorts of (seemingly unrelated) places all of a sudden is that some recent change (likely in a dependency of ours?) is causing underlying errors to get swallowed and instead be thrown up with this generic exception type.\r\n> \r\n> @ThomasLaPiana do you have any further leads? i haven't dug into this much, just wanted to put this theory down on paper here. i think @pattisdr is also continuing further investigation on her end \r\n\r\nI moved this to a new issue: https://github.com/ethyca/fides/issues/4020",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-02T11:57:45Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1703813236"
                    },
                    {
                        "body": "I'm moving the migration-specific work to a new PR, to de-clutter this PR and focus it specifically on getting `fides` running with 2.0",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-05T04:43:33Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1705932759"
                    },
                    {
                        "body": "I think we need to update the config.json files we ship with, PR here https://github.com/ethyca/fides/pull/4076 although I'm going to need some FE assistance\r\n\r\nEDIT: done, thank you Allison!",
                        "user": "pattisdr",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-12T19:07:00Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1716271063"
                    },
                    {
                        "body": "OK @ThomasLaPiana, Allison helped me with the FE, so these `config.json` changes are merged here - ",
                        "user": "pattisdr",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-13T02:22:26Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1716842458"
                    },
                    {
                        "body": "it looks like `fideslang 2.0` was missing a change that got patched into `1.4.6`, I cut another release of Fideslang (`2.0.3`) that should contain the change and get things working here",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-13T09:59:49Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1717324635"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/ethyca/fides/pulls/3933",
                    "merged_at": "2023-09-13T18:55:32Z"
                }
            },
            {
                "url": "https://github.com/ethyca/fides/issues/1695",
                "title": "fides GET /api/v1/system endpoint pagination",
                "labels": [
                    "dev experience",
                    "high-risk"
                ],
                "user": "LKCSmith",
                "issue_author_association": "CONTRIBUTOR",
                "number": 1695,
                "id": 1436597559,
                "state": "closed",
                "project_created_at": "2022-11-04T20:06:49Z",
                "closed_at": "2024-05-16T13:04:49Z",
                "body": "### Is your feature request related to a specific problem?\r\n\r\nWe need pagination for the system endpoint in Fides in order to complete the pagination task outlined originally in [this issue](https://github.com/ethyca/fidesctl-plus/issues/238).\r\n\r\n### Describe the solution you'd like\r\n\r\nBE change for pagination to fides `GET /api/v1/system` endpoint\r\n\r\n### Describe alternatives you've considered, if any\r\n\r\n_A description of any alternative solutions or features you've considered._\r\n\r\n### Additional context\r\n\r\n_Add any other context or screenshots about the feature request here._\n\n",
                "comments": [
                    {
                        "body": "This would need to be implemented for all of the `GET /api/v1/{resource_model}` endpoints because of the programmatic implementation:\r\n\r\nhttps://github.com/ethyca/fides/blob/11f24e745f90d74da0a6f0cae5ff4b3fb733c534/src/fides/api/ctl/routes/crud.py#L35\r\n\r\n@ThomasLaPiana @NevilleS This represents a breaking change, even if it's a small one. Any objections to this work?",
                        "user": "PSalant726",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-04T22:35:00Z",
                        "url": "https://github.com/ethyca/fides/issues/1695#issuecomment-1304312462"
                    },
                    {
                        "body": "Considering that these endpoints are not designed to be user-facing, and are _supposed_ to be used only by the CLI to persist data, I'm ok with this but think this warrants a minor version bump\r\n\r\nThe CLI logic that parses responses from the server will also need an update, so this is a 5 to me from a points standpoint.",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-07T02:42:59Z",
                        "url": "https://github.com/ethyca/fides/issues/1695#issuecomment-1305008526"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/ethyca/fides/pull/1643",
                "title": "Prompt for marketing registration via the CLI",
                "labels": [
                    "high-risk",
                    "python"
                ],
                "user": "PSalant726",
                "issue_author_association": "CONTRIBUTOR",
                "number": 1643,
                "id": 1430638638,
                "state": "closed",
                "project_created_at": "2022-10-31T23:48:36Z",
                "closed_at": "2022-11-01T15:09:39Z",
                "body": "Closes #1366\r\n\r\n### Code Changes\r\n\r\nPrompt for registration if not already registered:\r\n* [x] In the `cli` parent command group\r\n* [x] In the `fides init` command\r\n* [x] In the `fides deploy` command\r\n\r\n### Steps to Confirm\r\n\r\n* [ ] Remove all default opt-out and registration config (`docker-compose.yml`, `fides.toml`, local DB, etc.)\r\n* [ ] `nox -s dev -- shell`\r\n* [ ] Execute various `fides` CLI commands\r\n* [ ] Confirm that registration prompts appear when expected\r\n\r\n### Pre-Merge Checklist\r\n\r\n* [ ] All CI Pipelines Succeeded\r\n* Documentation Updated:\r\n  * [ ] documentation complete, or draft/outline provided (tag docs-team to complete/review on this branch)\r\n  * [ ] documentation issue created (tag docs-team to complete issue separately)\r\n* [x] Issue Requirements are Met\r\n* [ ] Relevant Follow-Up Issues Created\r\n* [ ] Update `CHANGELOG.md`",
                "comments": [
                    {
                        "body": "@NevilleS FYI `fid.es/privacy' 404s",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-01T09:03:08Z",
                        "url": "https://github.com/ethyca/fides/pull/1643#issuecomment-1298237747"
                    },
                    {
                        "body": "still getting an error here when I try to run it without a `.fides` directory, going to confirm that the `create_config_file` function is getting called correctly",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-01T09:28:01Z",
                        "url": "https://github.com/ethyca/fides/pull/1643#issuecomment-1298260508"
                    },
                    {
                        "body": "also lots of broken tests here",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-01T09:28:28Z",
                        "url": "https://github.com/ethyca/fides/pull/1643#issuecomment-1298261031"
                    },
                    {
                        "body": "Oof, right - our tests assume the ability to run various CLI commands against servers, but this PR changes that to prompt the user to register when those commands run!\r\n\r\nTo minimize changes here, we'll need to make it less clever and only ask once for both analytics & registration. That's not ideal but it's safer. I can push a quick commit to try that out",
                        "user": "NevilleS",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-01T10:22:54Z",
                        "url": "https://github.com/ethyca/fides/pull/1643#issuecomment-1298319222"
                    },
                    {
                        "body": "> All checks have passed\r\n\r\n   ",
                        "user": "NevilleS",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-01T11:29:19Z",
                        "url": "https://github.com/ethyca/fides/pull/1643#issuecomment-1298384066"
                    },
                    {
                        "body": "@NevilleS reviewing now",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-01T13:54:55Z",
                        "url": "https://github.com/ethyca/fides/pull/1643#issuecomment-1298546398"
                    },
                    {
                        "body": "I'm still getting an error here if I, for instance, run any normal commands before running `fides init`, going to fix that bug and push a fix and then I think we're good to go here",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-01T13:55:53Z",
                        "url": "https://github.com/ethyca/fides/pull/1643#issuecomment-1298547627"
                    },
                    {
                        "body": "@NevilleS there is a fix here, but it now will always run `init` basically if it doesn't detect the config file",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-01T14:18:48Z",
                        "url": "https://github.com/ethyca/fides/pull/1643#issuecomment-1298580241"
                    },
                    {
                        "body": "OK, I confirmed that config file requirement is already a legacy issue on 1.9.5\r\n```\r\n(venv) ~/git/sandbox/fides-deploy-test% fidesctl --version\r\nNo config file found\r\nUsing default configuration values.\r\nfidesctl, version 1.9.5\r\n(venv) ~/git/sandbox/fides-deploy-test% fidesctl status\r\nNo config file found\r\nUsing default configuration values.\r\nWARNING: 'Fidesctl' has been deprecated and replaced by a more robust 'Fides' tool, which includes existing 'fidesctl' functionality. Run `pip install ethyca-fides` to get the latest version of Fides and visit 'https://ethyca.github.io/fides/' for up-to-date documentation.\r\n\r\nNo config file found\r\nUsing default configuration values.\r\n\r\nFides needs your permission to send Ethyca a limited set of anonymous usage statistics.\r\nEthyca will only use this anonymous usage data to improve the product experience, and will never collect sensitive or personal data.\r\n\r\nDon't believe us? Check out the open-source code here:\r\n    https://github.com/ethyca/fideslog\r\n\r\n\r\nTo opt out of all telemetry, press \"n\". To continue with telemetry, press any other key.n\r\nTraceback (most recent call last):\r\n  File \"/Users/neville/git/sandbox/fides-deploy-test/venv/bin/fidesctl\", line 8, in <module>\r\n    sys.exit(cli())\r\n  File \"/Users/neville/git/sandbox/fides-deploy-test/venv/lib/python3.10/site-packages/click/core.py\", line 1130, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"/Users/neville/git/sandbox/fides-deploy-test/venv/lib/python3.10/site-packages/click/core.py\", line 1055, in main\r\n    rv = self.invoke(ctx)\r\n  File \"/Users/neville/git/sandbox/fides-deploy-test/venv/lib/python3.10/site-packages/click/core.py\", line 1654, in invoke\r\n    super().invoke(ctx)\r\n  File \"/Users/neville/git/sandbox/fides-deploy-test/venv/lib/python3.10/site-packages/click/core.py\", line 1404, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"/Users/neville/git/sandbox/fides-deploy-test/venv/lib/python3.10/site-packages/click/core.py\", line 760, in invoke\r\n    return __callback(*args, **kwargs)\r\n  File \"/Users/neville/git/sandbox/fides-deploy-test/venv/lib/python3.10/site-packages/click/decorators.py\", line 26, in new_func\r\n    return f(get_current_context(), *args, **kwargs)\r\n  File \"/Users/neville/git/sandbox/fides-deploy-test/venv/lib/python3.10/site-packages/fidesctl/cli/__init__.py\", line 92, in cli\r\n    check_and_update_analytics_config(ctx, config_path)\r\n  File \"/Users/neville/git/sandbox/fides-deploy-test/venv/lib/python3.10/site-packages/fidesctl/cli/utils.py\", line 117, in check_and_update_analytics_config\r\n    is_analytics_opt_out_config_empty = get_config_from_file(\r\n  File \"/Users/neville/git/sandbox/fides-deploy-test/venv/lib/python3.10/site-packages/fidesctl/ctl/core/config/utils.py\", line 24, in get_config_from_file\r\n    raise error\r\n  File \"/Users/neville/git/sandbox/fides-deploy-test/venv/lib/python3.10/site-packages/fidesctl/ctl/core/config/utils.py\", line 20, in get_config_from_file\r\n    config_path = config_path_override or load_file(\r\n  File \"/Users/neville/git/sandbox/fides-deploy-test/venv/lib/python3.10/site-packages/fideslib/core/config.py\", line 215, in load_file\r\n    raise FileNotFoundError\r\nFileNotFoundError\r\n```\r\n\r\nThat workaround is reasonable and will provide a QOL improvement. Let's ship it",
                        "user": "NevilleS",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-11-01T14:53:46Z",
                        "url": "https://github.com/ethyca/fides/pull/1643#issuecomment-1298624854"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/ethyca/fides/pulls/1643",
                    "merged_at": "2022-11-01T15:09:39Z"
                }
            },
            {
                "url": "https://github.com/ethyca/fides/pull/1171",
                "title": "Make `optional-requirements.txt` a source of version truth",
                "labels": [
                    "dev experience",
                    "high-risk",
                    "dependencies",
                    "python",
                    "Unified Fides",
                    "run unsafe ci checks"
                ],
                "user": "PSalant726",
                "issue_author_association": "CONTRIBUTOR",
                "number": 1171,
                "id": 1393159126,
                "state": "closed",
                "project_created_at": "2022-10-01T00:55:08Z",
                "closed_at": "2022-10-03T19:59:30Z",
                "body": "Closes #1170\r\n### Code Changes\r\n\r\n* [x] Make `isort` know that `versioneer` is a first party dependency\r\n* [x] Allow engineers to set optional dependency versions only once\r\n\r\n### Steps to Confirm\r\n\r\n* [ ] Install `fides` with various optional dependency configurations\r\n\r\n### Pre-Merge Checklist\r\n\r\n* [ ] All CI Pipelines Succeeded\r\n* [x] Issue Requirements are Met\r\n* [x] Update `CHANGELOG.md`",
                "comments": [
                    {
                        "body": "@PSalant726 `dependency truth` is the name of my recently-formed nordic numetal band, what a coincidence",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-10-03T02:10:32Z",
                        "url": "https://github.com/ethyca/fides/pull/1171#issuecomment-1264838906"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/ethyca/fides/pulls/1171",
                    "merged_at": "2022-10-03T19:59:30Z"
                }
            },
            {
                "url": "https://github.com/ethyca/fides/issues/1170",
                "title": "Enable a single source of truth for requirements",
                "labels": [
                    "dev experience",
                    "high-risk",
                    "Unified Fides"
                ],
                "user": "PSalant726",
                "issue_author_association": "CONTRIBUTOR",
                "number": 1170,
                "id": 1393142773,
                "state": "closed",
                "project_created_at": "2022-10-01T00:22:37Z",
                "closed_at": "2022-10-03T20:04:44Z",
                "body": "### Is your feature request related to a specific problem?\r\n\r\nCurrently it's not enough to bump the version of an imported package in the corresponding requirements file (`dev-requirements.txt`, `optional-requirements.txt`, or `requirements.txt`). Some dependencies must also have their versions updated in `setup.py`. This requires engineers to \"just know\" that the version must be updated in both places, and occasionally it will be forgotten.\r\n\r\n### Describe the solution you'd like\r\n\r\nThe `setup.py` file should include a function with a signature like:\r\n\r\n```py\r\nfind_requirement(requirements_file: str, dependency_name: str) -> str\r\n```\r\n\r\nthat, when called, will search the provided requirements file and return the line containing the name of the desired dependency.\r\n\r\n### Describe alternatives you've considered, if any\r\n\r\nWe can do nothing, and continue to facepalm when we forget to double-update dependency versions.\n\n",
                "comments": [
                    {
                        "body": "Completed in #1171.",
                        "user": "PSalant726",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-10-03T20:04:44Z",
                        "url": "https://github.com/ethyca/fides/issues/1170#issuecomment-1265967003"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/ethyca/fides/pull/421",
                "title": "`fidesctl apply` \"upserts\" resources",
                "labels": [
                    "high-risk"
                ],
                "user": "PSalant726",
                "issue_author_association": "CONTRIBUTOR",
                "number": 421,
                "id": 1181340739,
                "state": "closed",
                "project_created_at": "2022-03-25T22:56:11Z",
                "closed_at": "2022-03-30T21:18:44Z",
                "body": "Closes #279\r\n\r\n### Code Changes\r\n\r\n* [x] Revert `upsert_resources` changes such that it genuinely upserts resources\r\n* [x] Prevent `default_organization` resources from being overwritten by default taxonomy upserts\r\n* [x] Add an `/upsert` endpoint for each `resource_type` to fidesapi\r\n* [x] Enable `fidesctl apply` to upsert resources\r\n\r\n### Steps to Confirm\r\n\r\n* [ ] Run `make cli` and ensure everything starts, no errors are logged\r\n* [ ] Run `fidesctl apply --dry demo_resources/` and ensure things look correct compared to your local database\r\n* [ ] Run `fidesctl apply demo_resources/` and ensure your local database is modified as expected\r\n\r\n### Pre-Merge Checklist\r\n\r\n* [x] All CI Pipelines Succeeded\r\n* [x] Issue Requirements are Met",
                "comments": [
                    {
                        "body": "did some testing, looks good to me:\r\n\r\nOutput:\r\n\r\n```python\r\nroot@bb44cb7bba94:/fides/fidesctl# fidesctl apply demo_resources/\r\nLoading resource manifests from: demo_resources/\r\nTaxonomy successfully created.\r\n----------\r\nProcessing organization resources...\r\nCREATED 0 organization resources.   \r\nUPDATED 1 organization resources.   \r\n----------\r\nProcessing registry resources...    \r\nCREATED 0 registry resources. \r\nUPDATED 1 registry resources. \r\n----------\r\nProcessing system resources...\r\nCREATED 0 system resources.\r\nUPDATED 2 system resources.\r\n----------\r\nProcessing dataset resources...\r\nCREATED 0 dataset resources.\r\nUPDATED 1 dataset resources.\r\n----------\r\nProcessing data_use resources...\r\nCREATED 0 data_use resources.\r\nUPDATED 2 data_use resources.\r\n----------\r\nProcessing policy resources...\r\nCREATED 0 policy resources.\r\nUPDATED 1 policy resources.\r\n----------\r\n```\r\n\r\n```python\r\nroot@bb44cb7bba94:/fides/fidesctl# fidesctl apply --dry demo_resources/\r\nLoading resource manifests from: demo_resources/\r\nTaxonomy successfully created.\r\n----------\r\nProcessing registry resources...\r\nWOULD CREATE 0 registry resources.\r\nWOULD UPDATE 1 registry resources.\r\n----------\r\nProcessing organization resources...\r\nWOULD CREATE 0 organization resources.\r\nWOULD UPDATE 1 organization resources.\r\n----------\r\nProcessing dataset resources...\r\nWOULD CREATE 0 dataset resources.\r\nWOULD UPDATE 1 dataset resources.\r\n----------\r\nProcessing system resources...\r\nWOULD CREATE 0 system resources.\r\nWOULD UPDATE 2 system resources.\r\n----------\r\nProcessing policy resources...\r\nWOULD CREATE 0 policy resources.\r\nWOULD UPDATE 1 policy resources.\r\n----------\r\nProcessing data_use resources...\r\nWOULD CREATE 0 data_use resources.\r\nWOULD UPDATE 2 data_use resources.\r\n----------\r\n```",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-03-29T19:08:20Z",
                        "url": "https://github.com/ethyca/fides/pull/421#issuecomment-1082268066"
                    },
                    {
                        "body": "@PSalant726 when I run a non dry `apply` over and over again, it keeps saying `UPDATED 1`, but it shouldn't do anything there right?\r\n\r\n```python\r\nroot@bb44cb7bba94:/fides/fidesctl# fidesctl apply --diff demo_resources/       \r\nLoading resource manifests from: demo_resources/\r\nTaxonomy successfully created.\r\n----------\r\nProcessing organization resources...\r\nCREATED 0 organization resources.\r\nUPDATED 1 organization resources.\r\n----------\r\nProcessing policy resources...\r\nCREATED 0 policy resources.\r\nUPDATED 1 policy resources.\r\n----------\r\nProcessing registry resources...\r\nCREATED 0 registry resources.\r\nUPDATED 1 registry resources.\r\n----------\r\nProcessing system resources...\r\nCREATED 0 system resources.\r\nUPDATED 2 system resources.\r\n----------\r\nProcessing data_use resources...\r\nCREATED 0 data_use resources.\r\nUPDATED 2 data_use resources.\r\n----------\r\nProcessing dataset resources...\r\nCREATED 0 dataset resources.\r\nUPDATED 1 dataset resources.\r\n----------\r\nroot@bb44cb7bba94:/fides/fidesctl# fidesctl apply --diff --dry demo_resources/ \r\nLoading resource manifests from: demo_resources/\r\nTaxonomy successfully created.      \r\n----------\r\nProcessing organization resources...\r\n\r\nUpdated resource with fides_key: default_organization\r\n{}\r\nWOULD CREATE 0 organization resources.\r\nWOULD UPDATE 1 organization resources.\r\n----------\r\nProcessing system resources...        \r\n\r\nUpdated resource with fides_key: demo_analytics_system\r\n{}\r\n\r\nUpdated resource with fides_key: demo_marketing_system\r\n{}\r\nWOULD CREATE 0 system resources.\r\nWOULD UPDATE 2 system resources.\r\n----------\r\nProcessing data_use resources...\r\n\r\nUpdated resource with fides_key: third_party_sharing.legal_obligation.payroll  \r\n{}\r\n\r\nUpdated resource with fides_key: third_party_sharing.personalized_advertising.direct_marketing\r\n{}\r\nWOULD CREATE 0 data_use resources.\r\nWOULD UPDATE 2 data_use resources.\r\n----------\r\nProcessing policy resources...\r\n\r\nUpdated resource with fides_key: demo_privacy_policy\r\n{}\r\nWOULD CREATE 0 policy resources.\r\nWOULD UPDATE 1 policy resources.\r\n----------\r\nProcessing registry resources...\r\n\r\nUpdated resource with fides_key: demo_registry      \r\n{}\r\nWOULD CREATE 0 registry resources.\r\nWOULD UPDATE 1 registry resources.\r\n----------\r\nProcessing dataset resources...\r\n\r\nUpdated resource with fides_key: demo_users_dataset\r\n{}\r\nWOULD CREATE 0 dataset resources.\r\nWOULD UPDATE 1 dataset resources.\r\n----------\r\n```\r\n\r\nit looks like we got rid of the `unchanged` list, so now `update` is either `unchanged or updated`?",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-03-29T19:14:06Z",
                        "url": "https://github.com/ethyca/fides/pull/421#issuecomment-1082273390"
                    },
                    {
                        "body": "another example:\r\n\r\n```python\r\nroot@bb44cb7bba94:/fides/fidesctl# fidesctl apply --diff .fides/\r\nLoading resource manifests from: .fides/\r\nTaxonomy successfully created.\r\n----------\r\nProcessing system resources...\r\nCREATED 1 system resources.\r\nUPDATED 0 system resources.\r\n----------\r\nProcessing policy resources...\r\nCREATED 2 policy resources.\r\nUPDATED 0 policy resources.\r\n----------\r\nProcessing dataset resources...\r\nCREATED 1 dataset resources.\r\nUPDATED 0 dataset resources.\r\n----------\r\nroot@bb44cb7bba94:/fides/fidesctl# fidesctl apply --diff .fides/\r\nLoading resource manifests from: .fides/\r\nTaxonomy successfully created.\r\n----------\r\nProcessing dataset resources...\r\nCREATED 0 dataset resources.\r\nUPDATED 1 dataset resources.\r\n----------\r\nProcessing system resources...\r\nCREATED 0 system resources.\r\nUPDATED 1 system resources.\r\n----------\r\nProcessing policy resources...\r\nCREATED 0 policy resources.\r\nUPDATED 2 policy resources.\r\n----------\r\n```",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-03-29T19:17:34Z",
                        "url": "https://github.com/ethyca/fides/pull/421#issuecomment-1082276310"
                    },
                    {
                        "body": "I guess diff also only works when its `--dry`? ",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-03-29T19:17:59Z",
                        "url": "https://github.com/ethyca/fides/pull/421#issuecomment-1082276686"
                    },
                    {
                        "body": "@ThomasLaPiana \r\n\r\n> when I run a non dry `apply` over and over again, it keeps saying `UPDATED 1`, but it shouldn't do anything there right?\r\n\r\nThis is because we're using a \"naive\" or \"greedy\" upsert query (`ON CONFLICT DO UPDATE`). This type of query isn't smart enough to skip an `UPDATE` if the applied change would result in an otherwise identical record. IOW, if we attempt to `INSERT` a record, and that `INSERT` would result in a database constraint violation, then an `UPDATE` is _always_ performed (even if nothing about the record changes). From the perspective of the code, this is by far the simplest way to achieve an upsert action. From the perspective of the database, this is generally inefficient, and could result in some side-effects.\r\n\r\n<details>\r\n<summary>What kind of side-effects?</summary>\r\n\r\n- It might fire triggers that should not be fired.\r\n- It write-locks \"innocent\" (unchanging) rows, possibly incurring costs for concurrent transactions.\r\n- It might make the row seem new, even though it's old (transaction timestamp).\r\n- Most importantly, with [PostgreSQL's MVCC model](https://www.postgresql.org/docs/current/mvcc-intro.html) a new row version is written for every `UPDATE`, regardless of whether the row data changed. This incurs a performance penalty for the `UPSERT` itself, table bloat, index bloat, performance penalty for subsequent operations on the table, and `VACUUM` cost. These effects are minor for queries encountering few duplicates, but massive for queries encountering many duplicates.\r\n\r\nI went ahead with this implementation because none of those drawbacks seem to be applicable to the fidesctl database. We don't use database triggers for anything, we don't have concurrency concerns, we don't care how old records are, and even when upserting the default taxonomy over an already-persisted default taxonomy, the query still runs quickly.\r\n\r\n</details>\r\n\r\n<details>\r\n<summary>What could we do differently?</summary>\r\n\r\n**IF** we want to iterate on this approach in the future, we can create a more complex (read: smarter) upsert query like:\r\n\r\n```sql\r\nWITH input_rows(columns...) AS (\r\n\tVALUES (value1, value2, ...)\r\n), ins AS (\r\n\tINSERT INTO table_name (columns...) \r\n\tSELECT * FROM input_rows\r\n\tON CONFLICT (targets...) DO NOTHING\r\n\tRETURNING column1, column2, ...\r\n)\r\nSELECT 'i' AS source                           -- 'i' for 'inserted'\r\n     , column1, column2\r\nFROM   ins\r\nUNION  ALL\r\nSELECT 's' AS source                           -- 's' for 'selected'\r\n     , c.column1, c.column2\r\nFROM   input_rows\r\nJOIN   table_name c USING (targets...);\r\n```\r\nbut I wasn't going to be able to build that with sqlalchemy in any reasonable amount of time.\r\n\r\nThe result would be a more efficient upsert action that enables us to skip rows that wouldn't receive any effective update when `ON CONFLICT` is enacted, and return to logging the \"unchanged\" values as we were previously.\r\n\r\n</details>\r\n\r\n> it looks like we got rid of the `unchanged` list, so now `update` is either `unchanged or updated`?\r\n\r\nUnfortunately no, the `unchanged` list no longer applies because we always `UPDATE` when we don't `INSERT`.\r\n\r\n> I guess diff also only works when its `--dry`?\r\n\r\nThis was not intended, but yes. I think I see a way of enabling `--diff` without also using `--dry`. Gonna try hacking at it for a bit.",
                        "user": "PSalant726",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-03-29T20:25:18Z",
                        "url": "https://github.com/ethyca/fides/pull/421#issuecomment-1082340207"
                    },
                    {
                        "body": "@PSalant726 it looks like you removed the logic from `sort_create_update` that actually checked for the unchanged objects. I think adding that code back in should fix this issue. Does it seem like that'll work?\r\n\r\nThe real benefit of this PR would be removing the initial call to the database altogether, but this current implementation still makes that call. So while it does change to using a single endpoint, it hasn't reduced the total volume of calls.\r\n\r\nWe can either strip out the calls altogether as originally planned and do a:\r\n\r\n```\r\nCREATED: 1\r\nUPDATED OR UNCHANGED: 3\r\n```\r\n\r\nor back to the original:\r\n\r\n```\r\nCREATED: 2\r\nUPDATED: 2\r\nUNCHANGED: 1\r\n```",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-03-29T21:39:43Z",
                        "url": "https://github.com/ethyca/fides/pull/421#issuecomment-1082398773"
                    },
                    {
                        "body": "> it looks like you removed the logic from `sort_create_update` that actually checked for the unchanged objects. I think adding that code back in should fix this issue. Does it seem like that'll work?\r\n\r\nThis was intentional to avoid misleading users, although I suppose it's not always clear now either. I guess it's worth deciding if we want to 1) accurately represent what `fidesctl apply` is doing under-the-hood or 2) reassure users that nothing is changing when nothing should be changing. Regardless, reverting this change would only lead to \"unchanged\" returning while using `--dry`, since it's not possible to detect unchanged rows during the \"real\" upsert (since all rows are always _technically_ modified).\r\n\r\nPersonally, I prefer the current state of the code, and I would encourage users to use the `--diff` flag to see what's changing.",
                        "user": "PSalant726",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-03-29T21:47:49Z",
                        "url": "https://github.com/ethyca/fides/pull/421#issuecomment-1082404366"
                    },
                    {
                        "body": "@PSalant726 while it is _technically_ an update even if it doesn't change, that isn't _really_ an update...as a user I would be really confused if I did an apply, changed nothing, did another apply and was told things were updated. I would probably assume there was a bug in either fidesctl or my manifest files.\r\n\r\nTo avoid this problem, maybe we can skip the detailed logging altogether?\r\n\r\n```python\r\nroot@bb44cb7bba94:/fides/fidesctl# fidesctl apply demo_resources/       \r\nLoading resource manifests from: demo_resources/\r\nTaxonomy successfully created.\r\n----------\r\nProcessing organization resources...\r\nApplied 1 organization resource(s).\r\n----------\r\nProcessing policy resources...\r\nApplied 0 policy resource(s).\r\n----------\r\nProcessing registry resources...\r\nApplied 3 registry resource(s).\r\n----------\r\n```\r\n\r\nand as you suggested, leave the more verbose `--diff` command in there for debugging as a user",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-03-30T01:02:59Z",
                        "url": "https://github.com/ethyca/fides/pull/421#issuecomment-1082511969"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/ethyca/fides/pulls/421",
                    "merged_at": "2022-03-30T21:18:44Z"
                }
            },
            {
                "url": "https://github.com/ethyca/fides/pull/386",
                "title": "Integrate fideslog for anonymous CLI analytics",
                "labels": [
                    "documentation",
                    "high-risk"
                ],
                "user": "SteveDMurphy",
                "issue_author_association": "CONTRIBUTOR",
                "number": 386,
                "id": 1158667128,
                "state": "closed",
                "project_created_at": "2022-03-03T17:04:38Z",
                "closed_at": "2022-03-16T17:59:16Z",
                "body": "Closes #336\r\n\r\n### Code Changes\r\n\r\n* [x] Populate IDs and default value for opt out\r\n* [x] Build the opt out routine\r\n* [x] Create fall back if `fides init` is not used\r\n* [x] Include event tracking in the cli\r\n\r\n### Steps to Confirm\r\n\r\n* [x] `fidesctl init` generates the correct `fidesctl.toml`\r\n* [x] A user is only asked one time if they would like to opt in\r\n* [ ] Manually tested by at least one other person (add your name and check the box)\r\n\r\n### Pre-Merge Checklist\r\n\r\n* [x] All CI Pipelines Succeeded\r\n* [x] Documentation Updated\r\n\r\n### Description Of Changes\r\n\r\nThis PR is working slightly ahead of the release of fideslog, so some errors are expected until the package can be appropriately installed.\r\n\r\nI believe this PR merging will coincide with the 1.0 release of fideslog\r\n\r\n\r\n#### How to dive in:\r\n\r\n##### Test the opt-out routine\r\n* delete the `fidesctl.toml` file and run `fidesctl init`\r\n    * This should recreate `fidesctl.toml` with the appropriate ID and an opt out value based on input\r\n* delete the newly added values from `fidesctl.toml` (cli.analytics_id, user.analytics_opt_out)\r\n* Run `fidesctl apply demo_resources/ --dry` (or any `fidesctl` command minus `init`)\r\n    * The opt-out routine should be triggered and the appropriate values written to `fidesctl.toml`\r\n\r\n##### Validating event data\r\n* Once opted in, any cli events should be written to Snowflake (see information in 1pass)\r\n\r\nCatches:\r\n* `init` only command not included with event tracking",
                "comments": [
                    {
                        "body": "@ThomasLaPiana do you have any thoughts or guidance on how we might handle the api key for `fideslog`?",
                        "user": "SteveDMurphy",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-03-04T15:44:36Z",
                        "url": "https://github.com/ethyca/fides/pull/386#issuecomment-1059276006"
                    },
                    {
                        "body": "> @ThomasLaPiana do you have any thoughts or guidance on how we might handle the api key for `fideslog`?\r\n\r\napi key being the ID used, right? ",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-03-04T16:28:55Z",
                        "url": "https://github.com/ethyca/fides/pull/386#issuecomment-1059316350"
                    },
                    {
                        "body": "I was able to finally recreate the ci errors after using the remote containers extension ! Unfortunately, resolving those didn't translate here as expected :(\r\n\r\nOverall really digging all of the updates and the way the event sending is being done @PSalant726  the only thing I found in testing was for the sdk itself, where we will need to make some minor adjustments to resolve some errors for the `resource_counts` and `status_code` - great work!!",
                        "user": "SteveDMurphy",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-03-11T05:59:40Z",
                        "url": "https://github.com/ethyca/fides/pull/386#issuecomment-1064799925"
                    },
                    {
                        "body": "@PSalant726 - two early findings from testing a local install of this branch this morning, let me know what you think  \r\n\r\nOther than these two, we've been successful in writing events without issue  I'm still looking at trying to force writing an `error` as well\r\n\r\n* Any `fidesctl` command in a subdirectory will not find the config file, resulting in triggering the opt-out question (and resulting failure to find a config file)\r\n* `fidesctl init` does not currently send an event (I think we want to capture this?)",
                        "user": "SteveDMurphy",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-03-14T15:31:21Z",
                        "url": "https://github.com/ethyca/fides/pull/386#issuecomment-1066952224"
                    },
                    {
                        "body": "Running through the QA scenario again and the changes from @PSalant726  look good to me  (especially dig the notification of the values written to the config file)\r\n\r\nI think an assumption made early on was writing the `analytics_id` by default even when opting out would be acceptable but can completely understand the confusion that might bring to a user to see an ID written to their config when opting out (even though no events are written)\r\n\r\nGreat finds all around @iamkelllly (I could have tested for days and not found the issues you did) thank you for the time and effort to surface these!!!",
                        "user": "SteveDMurphy",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-03-16T02:26:22Z",
                        "url": "https://github.com/ethyca/fides/pull/386#issuecomment-1068666232"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/ethyca/fides/pulls/386",
                    "merged_at": "2022-03-16T17:59:16Z"
                }
            },
            {
                "url": "https://github.com/ethyca/fides/pull/263",
                "title": "Parallelize CI Jobs",
                "labels": [
                    "help wanted",
                    "testing",
                    "dev experience",
                    "high-risk"
                ],
                "user": "PSalant726",
                "issue_author_association": "CONTRIBUTOR",
                "number": 263,
                "id": 1067828213,
                "state": "closed",
                "project_created_at": "2021-12-01T00:57:17Z",
                "closed_at": "2021-12-10T17:26:14Z",
                "body": "Closes #228 \r\n\r\n### Code Changes\r\n\r\n* [x] Parallelize the CI pipeline\r\n\r\n### Steps to Confirm\r\n\r\n* [x] Review pipeline config\r\n* [x] Review pipeline output\r\n\r\n### Pre-Merge Checklist\r\n\r\n* [x] All CI Pipelines Succeeded\r\n\r\n### Description Of Changes\r\n\r\nAttempts to create and store a fidesctl Docker image artifact that is then shared between CI jobs within a single workflow.",
                "comments": [
                    {
                        "body": "im very confused at this point...it _is_ loading the cache from the image but not using it for some reason? \r\n\r\nhttps://github.com/ethyca/fides/runs/4438492231?check_suite_focus=true#step:5:62",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-12-07T01:40:44Z",
                        "url": "https://github.com/ethyca/fides/pull/263#issuecomment-987489408"
                    },
                    {
                        "body": "@PSalant726 can you give this a quick review? i finally got it! but want to make sure what I did isn't too crazy ",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-12-08T23:50:00Z",
                        "url": "https://github.com/ethyca/fides/pull/263#issuecomment-989319907"
                    },
                    {
                        "body": "i merged main and tested the new pre-commit checks, they work as well",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-12-08T23:52:34Z",
                        "url": "https://github.com/ethyca/fides/pull/263#issuecomment-989321116"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/ethyca/fides/pulls/263",
                    "merged_at": "2021-12-10T17:26:14Z"
                }
            },
            {
                "url": "https://github.com/ethyca/fides/pull/236",
                "title": "Improve API Error Handling",
                "labels": [
                    "high-risk"
                ],
                "user": "PSalant726",
                "issue_author_association": "CONTRIBUTOR",
                "number": 236,
                "id": 1058008537,
                "state": "closed",
                "project_created_at": "2021-11-19T00:45:37Z",
                "closed_at": "2021-11-23T17:26:33Z",
                "body": "Closes #212 \r\nCloses #233 \r\n\r\n### Code Changes\r\n\r\n* [x] Improve the consistency of DAL function signatures\r\n* [x] Handle exceptions throughout `fidesapi/` using `HTTPException`\r\n\r\n### Steps to Confirm\r\n\r\n* [x] Hit all the API endpoints, with reckless abandon\r\n\r\n### Pre-Merge Checklist\r\n\r\n* [x] All CI Pipelines Succeeded\r\n* [x] Documentation Updated\r\n\r\n### Description Of Changes\r\n\r\nThe [FastAPI documentation on error handling](https://fastapi.tiangolo.com/tutorial/handling-errors) defines the `HTTPException` as the best way to handle errors and return useful information to the caller.",
                "comments": [
                    {
                        "body": "i'm digging in to this  ",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-11-19T04:09:46Z",
                        "url": "https://github.com/ethyca/fides/pull/236#issuecomment-973718168"
                    },
                    {
                        "body": "@PSalant726 i went to the docs site and abused the \"try it out\", and was able to get the unhelpful `Internal Server Error` in these 2 cases:\r\n\r\n* Submitted a data category that was invalid (fides_key matched parent_key)\r\n* Submitted a data category that was valid but already existed\r\n\r\nIf someone is using the CLI these errors would be impossible because the `parse` and `apply` commands would catch them before they hit the server, but since we're here we might as well add those checks and treat this as a zero trust environment\r\n\r\nPydantic should be catching the invalid object error, but for some reason isn't surfacing it. I vaguely recall that that was working before but I'm not sure what changed that could've affected that",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-11-19T06:42:20Z",
                        "url": "https://github.com/ethyca/fides/pull/236#issuecomment-973795744"
                    },
                    {
                        "body": "I'd also like more verbose logging by fastapi/uvicorn. If i attach to the logs of the api container, i can see the startup logs (upserts) but I don't see any logs after that related to incoming requests, errors, etc. ",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-11-19T07:03:28Z",
                        "url": "https://github.com/ethyca/fides/pull/236#issuecomment-973804895"
                    },
                    {
                        "body": "@ThomasLaPiana \r\n> - Submitted a data category that was invalid (fides_key matched parent_key)\r\n> - Submitted a data category that was valid but already existed\r\n\r\nI'll add error handling for these cases, and try to improve the test coverage as well.\r\n\r\n> I'd also like more verbose logging by fastapi/uvicorn. If i attach to the logs of the api container, i can see the startup logs (upserts) but I don't see any logs after that related to incoming requests, errors, etc.\r\n\r\nI completely agree, but I think unifying our logging practices and improving the output/verbosity is a larger project that deserves it's own issue/PR. I can create one to track that work.",
                        "user": "PSalant726",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-11-19T16:33:43Z",
                        "url": "https://github.com/ethyca/fides/pull/236#issuecomment-974223927"
                    },
                    {
                        "body": "> @ThomasLaPiana\r\n> \r\n> > * Submitted a data category that was invalid (fides_key matched parent_key)\r\n> > * Submitted a data category that was valid but already existed\r\n> \r\n> I'll add error handling for these cases, and try to improve the test coverage as well.\r\n> \r\n> > I'd also like more verbose logging by fastapi/uvicorn. If i attach to the logs of the api container, i can see the startup logs (upserts) but I don't see any logs after that related to incoming requests, errors, etc.\r\n> \r\n> I completely agree, but I think unifying our logging practices and improving the output/verbosity is a larger project that deserves it's own issue/PR. I can create one to track that work.\r\n\r\nyeah, I think for the CLI itself leaving everything as print/echo is fine, but let's open an issue to make all output in the API be proper logging.\r\n\r\nThat being said, can you check if fastapi has some kind of logging switch we turned off? I do recall that we used to get much more robust logging. It might have to do with how we're running uvicorn? ",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-11-19T17:57:42Z",
                        "url": "https://github.com/ethyca/fides/pull/236#issuecomment-974286392"
                    },
                    {
                        "body": "@PSalant726 i took a shot at it, different approach than yours so lmk what you think. I'm happy with the error-handling as it is now, we can revisit this later but for now I think its sufficient",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-11-20T03:41:14Z",
                        "url": "https://github.com/ethyca/fides/pull/236#issuecomment-974586573"
                    },
                    {
                        "body": "@ThomasLaPiana Nice! I just moved the error definitions to their own file. Also, I added a generic `QueryError` just to make sure we're rolling back transactions on failed queries. Like you said, I think we can revisit the messaging in #241.",
                        "user": "PSalant726",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-11-22T16:50:06Z",
                        "url": "https://github.com/ethyca/fides/pull/236#issuecomment-975722443"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/ethyca/fides/pulls/236",
                    "merged_at": "2021-11-23T17:26:33Z"
                }
            },
            {
                "url": "https://github.com/ethyca/fides/issues/82",
                "title": "Rewrite FidesAPI in Python",
                "labels": [
                    "high-risk"
                ],
                "user": "ThomasLaPiana",
                "issue_author_association": "CONTRIBUTOR",
                "number": 82,
                "id": 979211077,
                "state": "closed",
                "project_created_at": "2021-08-25T14:24:23Z",
                "closed_at": "2021-09-22T05:05:33Z",
                "body": "This also includes the following requirements:\r\n\r\n* Remove some server-side logic i.e. evaluations, dry-evaluations, so that generally the primary purpose of FidesAPI is to manage CRUD operations\r\n* Remove the concept of \"id's\", instead allowing the `fides_key` to be the primary key for all resource types\r\n* rename field names to be pythonic (snake_case) instead of camelCase\r\n* An evaluations endpoint that accepts Evaluation objects from fidesctl, and `evaluate` updated on the fidesctl to send it\r\n* Policy objects need to have a `systems` field that specifies which policies apply to which systems",
                "comments": [
                    {
                        "body": "Server rewrite in python ~3 weeks, estimate includes consideration that...\r\n* There will be reduced functionality since only will be CRUD ops\r\n* Validation logic will have been extricated with the implementation of #79 ",
                        "user": "iamkelllly",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2021-08-25T18:53:35Z",
                        "url": "https://github.com/ethyca/fides/issues/82#issuecomment-905789616"
                    }
                ],
                "pull_request": null
            }
        ],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 1,
        "num_security_issue_and_pull": 10,
        "security_issues_created_after_policy": [
            {
                "url": "https://github.com/ethyca/fides/pull/3933",
                "title": "[DANGER] Update to Fideslang 2.0",
                "labels": [
                    "high-risk",
                    "run unsafe ci checks"
                ],
                "user": "ThomasLaPiana",
                "issue_author_association": "CONTRIBUTOR",
                "number": 3933,
                "id": 1854368330,
                "state": "closed",
                "project_created_at": "2023-08-17T06:48:25Z",
                "closed_at": "2023-09-13T18:55:32Z",
                "body": "Closes #3795\r\n\r\n Customer `config.json` files should be updated as they are migrated to the accompanying release.\r\n\r\n### Description Of Changes\r\n\r\nThis PR is focused on bumping the `Fideslang` version and ensuring that the application is working as expected when set u as a new instance. There is a separate PR for handling migrations for current users, as they are both sufficiently complex pieces to warrant handling separately.\r\n\r\nMuch of the inspiration/work here is inspired by [this PR](https://github.com/ethyca/fides/pull/3343) that handled an earlier, similar change\r\n\r\nThe Data Migration work is happening here: #4030\r\n\r\n_*WARNING: Merging this change as-is will break any existing instance due to default taxonomy model conflicts*_\r\n\r\n### Code Changes\r\n\r\n* [x] bump `requirements.txt`\r\n* [x] add a migration for the new `version` fields\r\n* Update `DataCategories`\r\n  * [x] datasets (including collections/fields)\r\n  * [x] policy rule **(tested previously, code is copy/pasta)**\r\n  * [x] privacy declaration **(tested previously, code is copy/pasta)**\r\n  * [x] data flows (egress and ingress on `System` models)\r\n* Update `DataUse`s\r\n  * [x] privacy declaration **(tested previously, code is copy/pasta)**\r\n  * [x] policy rule **(tested previously, code is copy/pasta)**\r\n* [x] do find/replace for the old categories/uses\r\n\r\n### Steps to Confirm\r\n\r\nBecause this PR is focused on getting _new_ instances working instead of migrating data, the `Steps to Confirm` here are very simple. Tests passing is what we care about here! [This PR](https://github.com/ethyca/fides/pull/4030) is where the complex data migration will take place\r\n\r\n* [ ] after running `nox -s teardown -- volumes` and `nox -s dev`, everything works as intended\r\n\r\n### Pre-Merge Checklist\r\n\r\n* [ ] All CI Pipelines Succeeded\r\n* Documentation:\r\n  * [ ] documentation complete, [PR opened in fidesdocs](https://github.com/ethyca/fidesdocs/pulls)\r\n  * [ ] documentation [issue created in fidesdocs](https://github.com/ethyca/fidesdocs/issues/new/choose)\r\n* [ ] Issue Requirements are Met\r\n* [ ] Relevant Follow-Up Issues Created\r\n* [ ] Update `CHANGELOG.md`\r\n* [ ] For API changes, the [Postman collection](https://github.com/ethyca/fides/blob/main/docs/fides/docs/development/postman/Fides.postman_collection.json) has been updated\r\n",
                "comments": [
                    {
                        "body": "\n## Passing [run #4110 ](https://cloud.cypress.io/projects/bauzeh/runs/4110/overview?utm_source=github&utm_medium=PASSED&utm_campaign=run%20number)\n\n<table>\n<tr>\n  <td><a href=\"https://cloud.cypress.io/projects/bauzeh/runs/4110/overview?reviewViewBy=FAILED&utm_source=github&utm_medium=PASSED&utm_campaign=failed%20tests\" style=\"text-decoration: none;\"><img src=\"https://assets.cypress.io/github-pr-comment-icons/red-x-v2.png\" width=\"14\" height=\"14\" title=\"Failed\" /></a> <b title=\"Failed\"><a href=\"https://cloud.cypress.io/projects/bauzeh/runs/4110/overview?reviewViewBy=FAILED&utm_source=github&utm_medium=PASSED&utm_campaign=failed%20tests\">0</a></b></td>\n  <td><a href=\"https://cloud.cypress.io/projects/bauzeh/runs/4110/overview?utm_source=github&utm_medium=PASSED&utm_campaign=passed%20tests\"><img src=\"https://assets.cypress.io/github-pr-comment-icons/green-check-mark-v2.png\" width=\"14\" height=\"14\" title=\"Passed\" /></a> <b title=\"Passed\"><a href=\"https://cloud.cypress.io/projects/bauzeh/runs/4110/overview?utm_source=github&utm_medium=PASSED&utm_campaign=passed%20tests\" style=\"text-decoration: none;\">4<a/></b></td>\n  <td><a href=\"https://cloud.cypress.io/projects/bauzeh/runs/4110/test-results?utm_source=github&utm_medium=PASSED&utm_campaign=pending%20tests&statuses=%5B%7B%22value%22%3A%22PENDING%22%2C%22label%22%3A%22PENDING%22%7D%5D\"><img src=\"https://assets.cypress.io/github-pr-comment-icons/gray-circle-v2.png\" width=\"14\" height=\"14\" title=\"Tests that did not run due to a developer annotating a test with .skip\" /></a> <b title=\"Pending\"><a href=\"https://cloud.cypress.io/projects/bauzeh/runs/4110/test-results?utm_source=github&utm_medium=PASSED&utm_campaign=pending%20tests&statuses=%5B%7B%22value%22%3A%22PENDING%22%2C%22label%22%3A%22PENDING%22%7D%5D\" style=\"text-decoration: none;\">0</a></b></td>\n  <td><a href=\"https://cloud.cypress.io/projects/bauzeh/runs/4110/test-results?utm_source=github&utm_medium=PASSED&utm_campaign=skipped%20tests&statuses=%5B%7B%22value%22%3A%22SKIPPED%22%2C%22label%22%3A%22SKIPPED%22%7D%5D\"><img src=\"https://assets.cypress.io/github-pr-comment-icons/skipped-v2.png\" width=\"14\" height=\"14\" title=\"Tests that did not run due to a failure in a mocha hook\" /></a> <b title=\"Skipped\"><a href=\"https://cloud.cypress.io/projects/bauzeh/runs/4110/test-results?utm_source=github&utm_medium=PASSED&utm_campaign=skipped%20tests&statuses=%5B%7B%22value%22%3A%22SKIPPED%22%2C%22label%22%3A%22SKIPPED%22%7D%5D\" style=\"text-decoration: none;\">0<a/></b></td>\n  <td><a href=\"https://cloud.cypress.io/projects/bauzeh/runs/4110/overview?reviewViewBy=FLAKY&utm_source=github&utm_medium=PASSED&utm_campaign=flaky%20tests\"><img src=\"https://assets.cypress.io/github-pr-comment-icons/flaky-v2.png\" width=\"29\" height=\"14\" title=\"Tests that were flaky\" alt=\"Flakiness\" /></a> <b title=\"Flaky\"><a href=\"https://cloud.cypress.io/projects/bauzeh/runs/4110/overview?reviewViewBy=FLAKY&utm_source=github&utm_medium=PASSED&utm_campaign=flaky%20tests\" style=\"text-decoration: none;\">0</a></b></td>\n</tr>\n<tr><td colspan=\"5\"><b> You've recorded test results over your free plan limit.<br /><a href=\"https://cloud.cypress.io/organizations/653f2b3f-47dd-4359-b4a6-e8fa761efeb7/billing?utm_source=github&utm_medium=PASSED&utm_campaign=upgrade%20plan\">Upgrade your plan to view test results</a>.</b></td></tr>\n\n</table>\n\n<b>Details:</b>\n\n<table>\n  <tr>\n    <td colspan=\"4\">Merge 4a271f9293f9b40a88f7cc845915d7de88eb1b1c into 7f53a75654ffadcefd3746e12797...</td>\n  </tr>\n  <tr />\n  <tr>\n    <td><b>Project:</b> fides</td>\n    <td><b>Commit:</b> <code>97e809de64 <span style=\"cursor:help;\" title=\"Your CI provider generated this commit by merging this branch into the target branch.\"></span></code></td>\n  </tr>\n  <tr />\n  <tr>\n    <td><b>Status:</b> Passed</td>\n    <td><b>Duration:</b> 01:18 <a href=\"https://on.cypress.io/parallelization?utm_source=github&utm_medium=PASSED&utm_campaign=parallelization%20docs\" title=\"Learn about optimizing your runs with parallelization\"></a></td>\n  </tr>\n  <tr />\n  <tr>\n    <td><b>Started:</b> Sep 13, 2023 6:48 PM</td>\n    <td><b>Ended:</b> Sep 13, 2023 6:49 PM</td>\n  </tr>\n</table>\n\n\n\n\n\n<p align=\"center\">\n  <sub\n    >This comment has been generated by cypress-bot as a result of this\n    project's <a href=\"https://cloud.cypress.io/projects/bauzeh/settings?utm_source=github&utm_medium=PASSED&utm_campaign=footer\">GitHub integration settings</a>.</sub\n  >\n</p>\n",
                        "user": "cypress[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-08-17T07:02:24Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1681736940"
                    },
                    {
                        "body": "@adamsachs update for you before I sign off!\r\n\r\nIn the description I've linked the `fideslang` PR where I'm making changes as needed\r\n\r\nI'm currently working through a local dev env and shell to run specific tests and try to diagnose why some of the breaks are happening. Focused primarily on the `ctl` tests as they were easier to run and faster",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-17T17:43:01Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1682707465"
                    },
                    {
                        "body": "@ThomasLaPiana stepping away for a bit now, made a few changes that i think should help get things greener...tried to break it up reasonably by commit so that my changes are easy to follow -- everything is pretty straightforward cleanup so far.\r\n\r\nwill see if i can circle back a bit later this evening to knock out some more, but leaving this update here in case i don't  ",
                        "user": "adamsachs",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-17T21:30:05Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1683005954"
                    },
                    {
                        "body": "@adamsachs Thank you! picking it up now",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-18T03:37:19Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1683301794"
                    },
                    {
                        "body": "there's a final system update test failing here that I suspect @pattisdr might understand, other than that the `ctl` tests are looking good!",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-18T10:48:11Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1683732092"
                    },
                    {
                        "body": "> there's a final system update test failing here that I suspect @pattisdr might understand, other than that the `ctl` tests are looking good!\r\n\r\n nice @ThomasLaPiana! i think i wrote those system update tests related to privacy declarations so i can take a look, i'll loop in @pattisdr if needed.\r\n\r\n@ThomasLaPiana are you working on the ops tests or should i also take a look at that? i've got some bandwidth so i'm happy to, but if you're already on it then i'll let you continue",
                        "user": "adamsachs",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-18T10:59:01Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1683744389"
                    },
                    {
                        "body": "@adamsachs Go for it! I'm signing off for now",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-18T11:02:59Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1683748821"
                    },
                    {
                        "body": "@adamsachs once we get tests passing, we'll merge and ship fideslang 2.0.1 and pin this to a real version",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-18T11:08:24Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1683754587"
                    },
                    {
                        "body": "## [Codecov](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca) Report\nPatch coverage: **`100.00%`** and project coverage change: **`-0.04%`** :warning:\n> Comparison is base [(`7f53a75`)](https://app.codecov.io/gh/ethyca/fides/commit/7f53a75654ffadcefd3746e12797dbaf740188eb?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca) 87.39% compared to head [(`e7ecbb4`)](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca) 87.36%.\n\n<details><summary>Additional details and impacted files</summary>\n\n\n```diff\n@@            Coverage Diff             @@\n##             main    #3933      +/-   ##\n==========================================\n- Coverage   87.39%   87.36%   -0.04%     \n==========================================\n  Files         320      320              \n  Lines       19602    19617      +15     \n  Branches     2512     2512              \n==========================================\n+ Hits        17132    17139       +7     \n- Misses       2033     2040       +7     \n- Partials      437      438       +1     \n```\n\n\n| [Files Changed](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca) | Coverage  | |\n|---|---|---|\n| [.../api/api/v1/endpoints/consent\\_request\\_endpoints.py](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca#diff-c3JjL2ZpZGVzL2FwaS9hcGkvdjEvZW5kcG9pbnRzL2NvbnNlbnRfcmVxdWVzdF9lbmRwb2ludHMucHk=) | `85.12% <> ()` | |\n| [.../api/api/v1/endpoints/privacy\\_request\\_endpoints.py](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca#diff-c3JjL2ZpZGVzL2FwaS9hcGkvdjEvZW5kcG9pbnRzL3ByaXZhY3lfcmVxdWVzdF9lbmRwb2ludHMucHk=) | `90.34% <> ()` | |\n| [src/fides/api/db/seed.py](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca#diff-c3JjL2ZpZGVzL2FwaS9kYi9zZWVkLnB5) | `89.20% <> ()` | |\n| [src/fides/api/models/privacy\\_request.py](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca#diff-c3JjL2ZpZGVzL2FwaS9tb2RlbHMvcHJpdmFjeV9yZXF1ZXN0LnB5) | `96.30% <> ()` | |\n| [src/fides/api/schemas/privacy\\_request.py](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca#diff-c3JjL2ZpZGVzL2FwaS9zY2hlbWFzL3ByaXZhY3lfcmVxdWVzdC5weQ==) | `100.00% <> ()` | |\n| [.../api/service/connectors/consent\\_email\\_connector.py](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca#diff-c3JjL2ZpZGVzL2FwaS9zZXJ2aWNlL2Nvbm5lY3RvcnMvY29uc2VudF9lbWFpbF9jb25uZWN0b3IucHk=) | `97.14% <> ()` | |\n| [...vice/saas\\_request/saas\\_request\\_override\\_factory.py](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca#diff-c3JjL2ZpZGVzL2FwaS9zZXJ2aWNlL3NhYXNfcmVxdWVzdC9zYWFzX3JlcXVlc3Rfb3ZlcnJpZGVfZmFjdG9yeS5weQ==) | `100.00% <> ()` | |\n| [src/fides/api/util/data\\_category.py](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca#diff-c3JjL2ZpZGVzL2FwaS91dGlsL2RhdGFfY2F0ZWdvcnkucHk=) | `100.00% <> ()` | |\n| [.../fides/api/api/v1/endpoints/messaging\\_endpoints.py](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca#diff-c3JjL2ZpZGVzL2FwaS9hcGkvdjEvZW5kcG9pbnRzL21lc3NhZ2luZ19lbmRwb2ludHMucHk=) | `92.94% <100.00%> (+0.12%)` | :arrow_up: |\n| [src/fides/api/models/sql\\_models.py](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca#diff-c3JjL2ZpZGVzL2FwaS9tb2RlbHMvc3FsX21vZGVscy5weQ==) | `98.12% <100.00%> (+0.07%)` | :arrow_up: |\n\n... and [2 files with indirect coverage changes](https://app.codecov.io/gh/ethyca/fides/pull/3933/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca)\n\n\n</details>\n\n[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/ethyca/fides/pull/3933?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca).   \n:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=ethyca).\n",
                        "user": "codecov[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-08-18T14:38:08Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1684017538"
                    },
                    {
                        "body": "OK! i think we've got all non-external tests passing now!\r\n\r\n@pattisdr would you mind taking a quick peak at the ops tests i fixed in https://github.com/ethyca/fides/pull/3933/commits/8ec6a87331fde0b328cab0045950ec361340c6ce, since some of them are touching consent-related tests and i want to be extra sure i'm not misunderstanding the tests and invalidating them  \r\n\r\nif that looks good, i think we've got our non-external/unsafe tests good to go! the remaining items to get this ready to merge would be:\r\n- [ ] look into external test failures to determine whether these are expected/in `main` already or caused by some code changes here\r\n- [ ] holistic review of this PR (i've focused on getting CI green up to this point)\r\n- [x] cut `fideslang 2.0.1` per @ThomasLaPiana's note above, and update our dependency here\r\n\r\ni should be able to make some progress on the first two items shortly...",
                        "user": "adamsachs",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-18T15:21:49Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1684075473"
                    },
                    {
                        "body": "Yes, starting review!",
                        "user": "pattisdr",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-18T15:27:29Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1684082503"
                    },
                    {
                        "body": "@adamsachs the major final step here is updating the categories in the data migration. I only did the uses because I could copy/pasta the logic from a previous migration, but now I also need to write them for data categories which live in a lot more places",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-19T08:03:22Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1684887423"
                    },
                    {
                        "body": "@adamsachs I think I've just about gotten this into a place where we can start testing it, but it's definitely tricky",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-21T23:56:23Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1687214654"
                    },
                    {
                        "body": "working on testing steps now\r\n\r\nEdit: finding some bugs, so the steps are still broken\r\n\r\nEdit 2: It looks like policy rule loading is broken due to the `version` changes in Fideslang 2",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-22T20:35:37Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1688896839"
                    },
                    {
                        "body": "this is almost getting ready for merge, I'll polish the steps to test and assign some reviewers",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-23T23:24:23Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1690768934"
                    },
                    {
                        "body": "Starting review..",
                        "user": "pattisdr",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-25T16:59:16Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1693671843"
                    },
                    {
                        "body": "I ran through the `Steps to Confirm` with the latest code and it all looks good, ready for another review",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-28T03:30:45Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1694950804"
                    },
                    {
                        "body": "sorry for breaking things a bit with merging https://github.com/ethyca/fides/commit/b07cf87cfb95185aed7815597f7e42a6a487dfad into `main`. i can update this branch to resolve the issues, i think we'll just want to:\r\n- [x] cut a new `2.0.2` release of `fideslang` that includes the same thing as `1.4.5` but is made on top of `2.0.1`, and then update `requirements.txt` here to point to `fideslang==2.0.2`\r\n- [x] merge `main` into this branch to get the new revision here\r\n- [x] update the `down_revision` of the [first migration to point to `3038667ba898`](https://github.com/ethyca/fides/pull/3933/files#diff-39abd1f52f655ead64e74fd79e75c4b1f224ee343e5160a1d8aabfc4c7ced2fcR13)\r\n\r\nupdate -- completed this, hope it's OK! ",
                        "user": "adamsachs",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-29T15:58:53Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1697733652"
                    },
                    {
                        "body": "@allisonking do we need to find/replace the typescript references for these now-outdated data categories and uses? Or is there a script that can/will generate them?",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-31T07:15:04Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1700490767"
                    },
                    {
                        "body": "reposting for visibility: https://github.com/ethyca/fides/pull/3933#discussion_r1309340895\r\n\r\nOK we reached some general consensus in [slack](https://ethyca.slack.com/archives/CBKK8TS74/p1693323605019939), it seems like we do want to:\r\n\r\n* [x] remove the deprecated taxonomy elements (probably should be done here within the migration itself?)\r\n* [x] update all references to those taxonomy elements in-place (i.e. the blunt string replace)\r\n* [x] give some steps for a \"fallback\" plan upon upgrade if desired, i.e. don't automigrate, take a db backup and migrate manually\r\n\r\nEdit: I knew (hoped) I wasn't crazy! We've done this before: https://github.com/ethyca/fides/blob/main/src/fides/api/alembic/migrations/versions/5307999c0dac_remove_deprecated_data_uses_for_.py",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-31T07:24:13Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1700504551"
                    },
                    {
                        "body": "@adamsachs @pattisdr sorry for the never-ending back and forth here! I made changes according to what was agreed upon so this should be ready for another look-see",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-31T10:04:23Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1700743819"
                    },
                    {
                        "body": "> @allisonking do we need to find/replace the typescript references for these now-outdated data categories and uses? Or is there a script that can/will generate them?\r\n\r\nI don't think there are any references to specific data categories in the code other than in the tests, which it looks like you've already updated! The TS models are generally updated by running `npm run openapi:generate` in `clients/admin-ui` against fidesplus. If that doesn't have any changes, then we should be good to go  (but also it probably will have _some_ changes, as it's probably been a little bit since we last ran it. you can just see if there are any changes directly related to this work)",
                        "user": "allisonking",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-31T13:38:12Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1701057790"
                    },
                    {
                        "body": "Thanks for your changes @ThomasLaPiana.  The migration was crashing so I added some changes here: https://github.com/ethyca/fides/pull/3933/commits/9308569ad9e9342d9e43256f65a3f9bd266c20cd to move this forward, but there's still more work to do.  Let's all continue to test and figure out where the gaps are.\r\n\r\nHere's some current TODO items I'm seeing after another round of testing:\r\n\r\n- [x] I think this is the biggest potential issue.  Migrate custom data uses and custom data categories that build off of the affected 2.0 uses and categories.   \r\n    -  For example, say I have a custom data use, \"user.search_history.work\" that I am using on a PrivacyDeclaration. We migrate that to \"user.behavior.search_history.work\" on the Declaration.  However, there is no \"DataUse\" that matches, and you get errors later when trying to update the System as a result.   \r\n\r\n- [x] New column `PrivacyDeclaration.shared_categories` going out in the current release needs to be migrated now that this migration has been delayed for a followup release.  Resurfacing [earlier comment](https://github.com/ethyca/fides/pull/3933#discussion_r1305942158)\r\n\r\n- [x] `PrivacyNotice`, `PrivacyNoticeTemplate`, and `PrivacyNoticeHistory` `data_uses` columns likely need to be migrated.  None of our out of the box notices have data uses at risk, but customers could have added custom notices, or added data uses to existing notices. \r\n\r\n- [x] ~Mysterious error on data subjects and sometimes data uses endpoint after running these migrations, usually where we have a data use mismatch somewhere~. As Thomas noted below, this is unrelated to this work\r\n```\r\n2023-08-31 17:53:52 2023-08-31 22:53:52.876 | INFO     | fides.api.main:log_request:150 - Request received | {'method': 'GET', 'status_code': 200, 'handler_time': '25.242ms', 'path': '/api/v1/data_category/'}\r\n2023-08-31 17:53:52 2023-08-31 22:53:52.878 | ERROR    | fides.api.util.logger:_log_exception:31 - unhandled errors in a TaskGroup (1 sub-exception)\r\n2023-08-31 17:53:52 Traceback (most recent call last):\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/anyio/streams/memory.py\", line 97, in receive\r\n2023-08-31 17:53:52     return self.receive_nowait()\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/anyio/streams/memory.py\", line 92, in receive_nowait\r\n2023-08-31 17:53:52     raise WouldBlock\r\n2023-08-31 17:53:52 anyio.WouldBlock\r\n2023-08-31 17:53:52 \r\n2023-08-31 17:53:52 During handling of the above exception, another exception occurred:\r\n2023-08-31 17:53:52 \r\n2023-08-31 17:53:52 Traceback (most recent call last):\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/starlette/middleware/base.py\", line 77, in call_next\r\n2023-08-31 17:53:52     message = await recv_stream.receive()\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/anyio/streams/memory.py\", line 112, in receive\r\n2023-08-31 17:53:52     raise EndOfStream\r\n2023-08-31 17:53:52 anyio.EndOfStream\r\n2023-08-31 17:53:52 Traceback (most recent call last):\r\n2023-08-31 17:53:52   File \"<string>\", line 1, in <module>\r\n2023-08-31 17:53:52   File \"/usr/local/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\r\n2023-08-31 17:53:52     exitcode = _main(fd, parent_sentinel)\r\n2023-08-31 17:53:52   File \"/usr/local/lib/python3.10/multiprocessing/spawn.py\", line 129, in _main\r\n2023-08-31 17:53:52     return self._bootstrap(parent_sentinel)\r\n2023-08-31 17:53:52   File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\r\n2023-08-31 17:53:52     self.run()\r\n2023-08-31 17:53:52   File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 108, in run\r\n2023-08-31 17:53:52     self._target(*self._args, **self._kwargs)\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/uvicorn/_subprocess.py\", line 76, in subprocess_started\r\n2023-08-31 17:53:52     target(sockets=sockets)\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/uvicorn/server.py\", line 61, in run\r\n2023-08-31 17:53:52     return asyncio.run(self.serve(sockets=sockets))\r\n2023-08-31 17:53:52   File \"/usr/local/lib/python3.10/asyncio/runners.py\", line 44, in run\r\n2023-08-31 17:53:52     return loop.run_until_complete(main)\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/starlette/middleware/base.py\", line 69, in coro\r\n2023-08-31 17:53:52     await self.app(scope, receive_or_disconnect, send_no_error)\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/starlette/middleware/base.py\", line 106, in __call__\r\n2023-08-31 17:53:52     response = await self.dispatch_func(request, call_next)\r\n2023-08-31 17:53:52 > File \"/fides/src/fides/api/main.py\", line 73, in dispatch_log_request\r\n2023-08-31 17:53:52     response = await call_next(request)\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/starlette/middleware/base.py\", line 80, in call_next\r\n2023-08-31 17:53:52     raise app_exc\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/starlette/middleware/base.py\", line 69, in coro\r\n2023-08-31 17:53:52     await self.app(scope, receive_or_disconnect, send_no_error)\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/starlette/middleware/cors.py\", line 84, in __call__\r\n2023-08-31 17:53:52     await self.app(scope, receive, send)\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/starlette/middleware/base.py\", line 104, in __call__\r\n2023-08-31 17:53:52     async with anyio.create_task_group() as task_group:\r\n2023-08-31 17:53:52   File \"/opt/fides/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 664, in __aexit__\r\n2023-08-31 17:53:52     raise BaseExceptionGroup(\r\n2023-08-31 17:53:52 exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\r\n```\r\n",
                        "user": "pattisdr",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-08-31T23:04:24Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1701891183"
                    },
                    {
                        "body": "these failures are being seen elsewhere too...unrelated to this change. I already fixed one in `main` but apparently not the root cause",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-01T12:07:09Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1702644058"
                    },
                    {
                        "body": "but is it possible bad data is still triggering it underneath? ",
                        "user": "pattisdr",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-01T14:09:51Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1702810801"
                    },
                    {
                        "body": "ah yikes I'm seeing this in unit tests, separate PR.  I wonder if mixing db sessions - synchronous/async is related\r\n\r\nhttps://github.com/ethyca/fides/pull/3990#discussion_r1313209584",
                        "user": "pattisdr",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-01T15:20:28Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1702922693"
                    },
                    {
                        "body": "> ah yikes I'm seeing this in unit tests, separate PR. I wonder if mixing db sessions - synchronous/async is related\r\n> \r\n> [#3990 (comment)](https://github.com/ethyca/fides/pull/3990#discussion_r1313209584)\r\n\r\nI'm 90% sure it is caused by an undetected dependency change....I'll post an update in slack so the rest of the team is aware",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-01T16:17:45Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1703001011"
                    },
                    {
                        "body": "In a separate PR https://github.com/ethyca/fides/pull/3990#discussion_r1313209584, this error was happening when we were using a synchronous session in a ctl endpoint - the underlying error was ` sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_() here. Was IO attempted in an unexpected place?`",
                        "user": "pattisdr",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-01T16:58:29Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1703060972"
                    },
                    {
                        "body": "spoke a bit with @pattisdr and one theory that _could_ explain this `exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup` type of error from cropping up in all sorts of (seemingly unrelated) places all of a sudden is that some recent change (likely in a dependency of ours?) is causing underlying errors to get swallowed and instead be thrown up with this generic exception type.\r\n\r\n@ThomasLaPiana do you have any further leads? i haven't dug into this much, just wanted to put this theory down on paper here. i think @pattisdr is also continuing further investigation on her end  ",
                        "user": "adamsachs",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-01T20:40:44Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1703297617"
                    },
                    {
                        "body": "> spoke a bit with @pattisdr and one theory that _could_ explain this `exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup` type of error from cropping up in all sorts of (seemingly unrelated) places all of a sudden is that some recent change (likely in a dependency of ours?) is causing underlying errors to get swallowed and instead be thrown up with this generic exception type.\r\n> \r\n> @ThomasLaPiana do you have any further leads? i haven't dug into this much, just wanted to put this theory down on paper here. i think @pattisdr is also continuing further investigation on her end \r\n\r\nI moved this to a new issue: https://github.com/ethyca/fides/issues/4020",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-02T11:57:45Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1703813236"
                    },
                    {
                        "body": "I'm moving the migration-specific work to a new PR, to de-clutter this PR and focus it specifically on getting `fides` running with 2.0",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-05T04:43:33Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1705932759"
                    },
                    {
                        "body": "I think we need to update the config.json files we ship with, PR here https://github.com/ethyca/fides/pull/4076 although I'm going to need some FE assistance\r\n\r\nEDIT: done, thank you Allison!",
                        "user": "pattisdr",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-12T19:07:00Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1716271063"
                    },
                    {
                        "body": "OK @ThomasLaPiana, Allison helped me with the FE, so these `config.json` changes are merged here - ",
                        "user": "pattisdr",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-13T02:22:26Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1716842458"
                    },
                    {
                        "body": "it looks like `fideslang 2.0` was missing a change that got patched into `1.4.6`, I cut another release of Fideslang (`2.0.3`) that should contain the change and get things working here",
                        "user": "ThomasLaPiana",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-09-13T09:59:49Z",
                        "url": "https://github.com/ethyca/fides/pull/3933#issuecomment-1717324635"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/ethyca/fides/pulls/3933",
                    "merged_at": "2023-09-13T18:55:32Z"
                }
            }
        ],
        "SecurityPolicy_content_category": [
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 1,
        "has_generic_policy": true
    },
    {
        "project_name": "berriai/litellm",
        "project_url": "https://github.com/berriai/litellm",
        "SSF": {
            "date": "2024-10-29T19:03:49+07:00",
            "repo": {
                "name": "github.com/berriai/litellm",
                "commit": "f9ba74ef87ba66424332cd15b6c05e5700a0f850"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.3,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'main'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "14 out of 14 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 0/19 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: superagent-ai contributor org/company found, traceloop contributor org/company found, develop-health contributor org/company found, adobe contributor org/company found, prisma-korea contributor org/company found, svelte-seoul contributor org/company found, lunary.ai contributor org/company found, intellegam @weconnect-ai contributor org/company found, ifood contributor org/company found, aimoda contributor org/company found, ibm contributor org/company found, lunary-ai contributor org/company found, rane network contributor org/company found, langfuse contributor org/company found, messari contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 15 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yaml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/ghcr_deploy.yml:119"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Info: Possibly incomplete results: error parsing shell code: if statement must end with \"fi\": .github/workflows/main.yml:30",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/auto_update_price_and_context_window.yml:12: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/auto_update_price_and_context_window.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ghcr_deploy.yml:126: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/ghcr_deploy.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ghcr_deploy.yml:165: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/ghcr_deploy.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ghcr_deploy.yml:204: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/ghcr_deploy.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ghcr_deploy.yml:241: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/ghcr_deploy.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ghcr_deploy.yml:283: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/ghcr_deploy.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ghcr_deploy.yml:314: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/ghcr_deploy.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ghcr_deploy.yml:339: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/ghcr_deploy.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ghcr_deploy.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/ghcr_deploy.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ghcr_deploy.yml:43: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/ghcr_deploy.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ghcr_deploy.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/ghcr_deploy.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ghcr_deploy.yml:49: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/ghcr_deploy.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ghcr_deploy.yml:55: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/ghcr_deploy.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ghcr_deploy.yml:62: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/ghcr_deploy.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ghcr_deploy.yml:70: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/ghcr_deploy.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ghcr_deploy.yml:86: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/ghcr_deploy.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ghcr_helm_deploy.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/ghcr_helm_deploy.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ghcr_helm_deploy.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/ghcr_helm_deploy.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ghcr_helm_deploy.yml:48: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/ghcr_helm_deploy.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/lint.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/lint.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/load_test.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/load_test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/load_test.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/load_test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/load_test.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/load_test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/load_test.yml:52: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/load_test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:12: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/main.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/main.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/read_pyproject_version.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/read_pyproject_version.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/read_pyproject_version.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/BerriAI/litellm/read_pyproject_version.yml/main?enable=pin",
                        "Warn: containerImage not pinned by hash: Dockerfile:7",
                        "Warn: containerImage not pinned by hash: Dockerfile:50",
                        "Warn: containerImage not pinned by hash: cookbook/litellm-ollama-docker-image/Dockerfile:1",
                        "Warn: containerImage not pinned by hash: deploy/Dockerfile.ghcr_base:2: pin your Docker image by updating ghcr.io/berriai/litellm:main-latest to ghcr.io/berriai/litellm:main-latest@sha256:7a58d576a2136008975d6f6f41600319fb49fc465b08116d5d732043f44c1a66",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.alpine:8",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.alpine:37",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.custom_ui:2: pin your Docker image by updating ghcr.io/berriai/litellm:litellm_fwd_server_root_path-dev to ghcr.io/berriai/litellm:litellm_fwd_server_root_path-dev@sha256:3202585e5e4b0c8a840dcd3c4f6ed728ec9658b3fa2810a25b433f9c29a04381",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.database:7",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.database:39",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.non_root:7",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.non_root:39",
                        "Warn: containerImage not pinned by hash: docs/my-website/Dockerfile:1: pin your Docker image by updating python:3.10 to python:3.10@sha256:fd0fa50d997eb56ce560c6e5ca6a1f5cf8fdff87572a16ac07fb1f5ca01eb608",
                        "Warn: containerImage not pinned by hash: litellm-js/spend-logs/Dockerfile:2: pin your Docker image by updating node:20.11.0 to node:20.11.0@sha256:7bf4a586b423aac858176b3f683e35f08575c84500fbcfd1d433ad8568972ec6",
                        "Warn: containerImage not pinned by hash: litellm/proxy/proxy_load_test/litellm_router_proxy/Dockerfile:2: pin your Docker image by updating python:3.9-slim to python:3.9-slim@sha256:7a9cd42706c174cdcf578880ab9ae3b6551323a7ddbc2a89ad6e5b20a28fbfbe",
                        "Warn: containerImage not pinned by hash: ui/Dockerfile:2: pin your Docker image by updating node:18-alpine to node:18-alpine@sha256:02376a266c84acbf45bd19440e08e48b1c8b98037417334046029ab585de03e2",
                        "Warn: pipCommand not pinned by hash: Dockerfile:17-18",
                        "Warn: pipCommand not pinned by hash: Dockerfile:17-18",
                        "Warn: pipCommand not pinned by hash: Dockerfile:39",
                        "Warn: pipCommand not pinned by hash: Dockerfile:44",
                        "Warn: pipCommand not pinned by hash: Dockerfile:65",
                        "Warn: pipCommand not pinned by hash: cookbook/litellm-ollama-docker-image/Dockerfile:23",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.alpine:18-19",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.alpine:18-19",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.alpine:49",
                        "Warn: npmCommand not pinned by hash: docker/Dockerfile.custom_ui:20",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.database:17-18",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.database:17-18",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.database:54",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.database:57",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.database:62",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.non_root:17-18",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.non_root:17-18",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.non_root:54",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.non_root:57",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.non_root:62",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.non_root:71",
                        "Warn: pipCommand not pinned by hash: docker/Dockerfile.non_root:72",
                        "Warn: pipCommand not pinned by hash: docs/my-website/Dockerfile:5",
                        "Warn: npmCommand not pinned by hash: litellm-js/spend-logs/Dockerfile:11",
                        "Warn: npmCommand not pinned by hash: litellm-js/spend-logs/Dockerfile:14",
                        "Warn: pipCommand not pinned by hash: litellm/proxy/proxy_load_test/litellm_router_proxy/Dockerfile:11",
                        "Warn: npmCommand not pinned by hash: ui/Dockerfile:11",
                        "Warn: downloadThenRun not pinned by hash: docker/build_admin_ui.sh:43",
                        "Warn: npmCommand not pinned by hash: docker/build_admin_ui.sh:47",
                        "Warn: downloadThenRun not pinned by hash: ui/litellm-dashboard/build_ui.sh:6",
                        "Warn: downloadThenRun not pinned by hash: ui/litellm-dashboard/build_ui_custom_path.sh:16",
                        "Warn: pipCommand not pinned by hash: .github/workflows/auto_update_price_and_context_window.yml:15",
                        "Warn: pipCommand not pinned by hash: .github/workflows/load_test.yml:23",
                        "Warn: pipCommand not pinned by hash: .github/workflows/load_test.yml:24",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:21",
                        "Warn: pipCommand not pinned by hash: .github/workflows/read_pyproject_version.yml:23",
                        "Info:   0 out of  18 GitHub-owned GitHubAction dependencies pinned",
                        "Info:  22 out of  33 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of  15 containerImage dependencies pinned",
                        "Info:   4 out of  32 pipCommand dependencies pinned",
                        "Info:   0 out of   5 npmCommand dependencies pinned",
                        "Info:   0 out of   3 downloadThenRun dependencies pinned"
                    ],
                    "score": 2,
                    "reason": "dependency not pinned by hash detected -- score normalized to 2",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 24 commits out of 25 are checked with a SAST tool"
                    ],
                    "score": 9,
                    "reason": "SAST tool is not run on all commits -- score normalized to 9",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: security.md:1",
                        "Info: Found linked content: security.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: security.md:1",
                        "Info: Found text in security policy: security.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact v1.51.0.dev1 not signed: https://api.github.com/repos/BerriAI/litellm/releases/182334425",
                        "Warn: release artifact v1.51.0-stable not signed: https://api.github.com/repos/BerriAI/litellm/releases/182070042",
                        "Warn: release artifact v1.51.0 not signed: https://api.github.com/repos/BerriAI/litellm/releases/182068446",
                        "Warn: release artifact v1.50.4-stable not signed: https://api.github.com/repos/BerriAI/litellm/releases/181800195",
                        "Warn: release artifact v1.50.4 not signed: https://api.github.com/repos/BerriAI/litellm/releases/181790579",
                        "Warn: release artifact v1.51.0.dev1 does not have provenance: https://api.github.com/repos/BerriAI/litellm/releases/182334425",
                        "Warn: release artifact v1.51.0-stable does not have provenance: https://api.github.com/repos/BerriAI/litellm/releases/182070042",
                        "Warn: release artifact v1.51.0 does not have provenance: https://api.github.com/repos/BerriAI/litellm/releases/182068446",
                        "Warn: release artifact v1.50.4-stable does not have provenance: https://api.github.com/repos/BerriAI/litellm/releases/181800195",
                        "Warn: release artifact v1.50.4 does not have provenance: https://api.github.com/repos/BerriAI/litellm/releases/181790579"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/ghcr_deploy.yml:81",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/ghcr_deploy.yml:122",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/ghcr_deploy.yml:161",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/ghcr_deploy.yml:200",
                        "Warn: no topLevel permission defined: .github/workflows/auto_update_price_and_context_window.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/ghcr_deploy.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/ghcr_helm_deploy.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/lint.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/load_test.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/main.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/read_pyproject_version.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-wf5p-g6vw-rhxx",
                        "Warn: Project is vulnerable to: GHSA-grv7-fg5c-xmjg",
                        "Warn: Project is vulnerable to: GHSA-w8qv-6jwh-64r5",
                        "Warn: Project is vulnerable to: GHSA-pxg6-pf52-xh8x",
                        "Warn: Project is vulnerable to: GHSA-pfrx-2q88-qq97",
                        "Warn: Project is vulnerable to: GHSA-7wwv-vh3v-89cq",
                        "Warn: Project is vulnerable to: GHSA-rc47-6667-2j5j",
                        "Warn: Project is vulnerable to: GHSA-33f9-j839-rf8h",
                        "Warn: Project is vulnerable to: GHSA-c36v-fmgq-m8hx",
                        "Warn: Project is vulnerable to: GHSA-76p3-8jx3-jpfq",
                        "Warn: Project is vulnerable to: GHSA-3rfm-jhwj-7488",
                        "Warn: Project is vulnerable to: GHSA-hhq3-ff78-jv3g",
                        "Warn: Project is vulnerable to: GHSA-35jh-r3h4-6jhm",
                        "Warn: Project is vulnerable to: GHSA-952p-6rrq-rcjv",
                        "Warn: Project is vulnerable to: GHSA-f8q6-p94x-37v3",
                        "Warn: Project is vulnerable to: GHSA-rp65-9cf3-cjxr",
                        "Warn: Project is vulnerable to: GHSA-9wv6-86v2-598j",
                        "Warn: Project is vulnerable to: GHSA-7fh5-64p2-3v2j",
                        "Warn: Project is vulnerable to: GHSA-p8p7-x288-28g6",
                        "Warn: Project is vulnerable to: GHSA-44c6-4v22-4mhx",
                        "Warn: Project is vulnerable to: GHSA-4x5v-gmq8-25ch",
                        "Warn: Project is vulnerable to: GHSA-m6fv-jmcg-4jfg",
                        "Warn: Project is vulnerable to: GHSA-54xq-cgqr-rpm3",
                        "Warn: Project is vulnerable to: GHSA-g4rg-993r-mgx7",
                        "Warn: Project is vulnerable to: GHSA-72xf-g2v4-qvf3",
                        "Warn: Project is vulnerable to: GHSA-w5p7-h5w8-2hfq",
                        "Warn: Project is vulnerable to: GHSA-7p7h-4mm5-852v",
                        "Warn: Project is vulnerable to: GHSA-fj7x-q9j7-g6q6 / PYSEC-2024-48",
                        "Warn: Project is vulnerable to: GHSA-h4gh-qq45-vh27",
                        "Warn: Project is vulnerable to: GHSA-9wx4-h78v-vm56",
                        "Warn: Project is vulnerable to: GHSA-f96h-pmfr-66vw",
                        "Warn: Project is vulnerable to: GHSA-g92j-qhmh-64v2"
                    ],
                    "score": 0,
                    "reason": "32 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/berriai/litellm/contents/security.md",
        "SecurityPolicy_content": "# Data Privacy and Security\n\n## Security Measures\n\n### LiteLLM Github\n\n- All commits run through Github's CodeQL checking\n\n### Self-hosted Instances LiteLLM\n\n- **No data or telemetry is stored on LiteLLM Servers when you self host**\n- For installation and configuration, see: [Self-hosting guided](https://docs.litellm.ai/docs/proxy/deploy)\n- **Telemetry** We run no telemetry when you self host LiteLLM\n\n### LiteLLM Cloud\n\n- We encrypt all data stored using your `LITELLM_MASTER_KEY` and in transit using TLS.\n- Our database and application run on GCP, AWS infrastructure, partly managed by NeonDB.\n    - US data region: Northern California (AWS/GCP `us-west-1`) & Virginia (AWS `us-east-1`)\n    - EU data region Germany/Frankfurt (AWS/GCP `eu-central-1`)\n- All users have access to SSO (Single Sign-On) through OAuth 2.0 with Google, Okta, Microsoft, KeyCloak. \n- Audit Logs with retention policy\n- Control Allowed IP Addresses that can access your Cloud LiteLLM Instance\n\nFor security inquiries, please contact us at support@berri.ai\n\n\nFor security inquiries, please contact us at support@berri.ai\n\n#### Supported data regions for LiteLLM Cloud\n\nLiteLLM supports the following data regions:\n\n- US, Northern California (AWS/GCP `us-west-1`)\n- Europe, Frankfurt, Germany (AWS/GCP `eu-central-1`)\n\nAll data, user accounts, and infrastructure are completely separated between these two regions\n\n### Security Vulnerability Reporting Guidelines\n\nWe value the security community's role in protecting our systems and users. To report a security vulnerability:\n\n- Email support@berri.ai with details\n- Include steps to reproduce the issue\n- Provide any relevant additional information\n\nWe'll review all reports promptly. Note that we don't currently offer a bug bounty program.\n",
        "project_all_labels": [
            "aixcc",
            "awaiting: user response",
            "blocked",
            "bug",
            "caching",
            "changes requested",
            "dependencies",
            "discussions",
            "documentation",
            "duplicate",
            "enhancement",
            "github_actions",
            "good first issue",
            "help wanted",
            "high priority",
            "important",
            "integrations",
            "invalid",
            "javascript",
            "mlops user request",
            "new model",
            "openai v1",
            "pending updates",
            "priority",
            "proxy",
            "python",
            "question",
            "ready to merge",
            "router",
            "spend tracking",
            "spend-tracking",
            "sweep",
            "testing",
            "ui",
            "unable to repro",
            "under review",
            "urgent",
            "user request",
            "wontfix"
        ],
        "README_content": "<h1 align=\"center\">\n         LiteLLM\n    </h1>\n    <p align=\"center\">\n        <p align=\"center\">\n        <a href=\"https://render.com/deploy?repo=https://github.com/BerriAI/litellm\" target=\"_blank\" rel=\"nofollow\"><img src=\"https://render.com/images/deploy-to-render-button.svg\" alt=\"Deploy to Render\"></a>\n        <a href=\"https://railway.app/template/HLP0Ub?referralCode=jch2ME\">\n          <img src=\"https://railway.app/button.svg\" alt=\"Deploy on Railway\">\n        </a>\n        </p>\n        <p align=\"center\">Call all LLM APIs using the OpenAI format [Bedrock, Huggingface, VertexAI, TogetherAI, Azure, OpenAI, Groq etc.]\n        <br>\n    </p>\n<h4 align=\"center\"><a href=\"https://docs.litellm.ai/docs/simple_proxy\" target=\"_blank\">LiteLLM Proxy Server (LLM Gateway)</a> | <a href=\"https://docs.litellm.ai/docs/hosted\" target=\"_blank\"> Hosted Proxy (Preview)</a> | <a href=\"https://docs.litellm.ai/docs/enterprise\"target=\"_blank\">Enterprise Tier</a></h4>\n<h4 align=\"center\">\n    <a href=\"https://pypi.org/project/litellm/\" target=\"_blank\">\n        <img src=\"https://img.shields.io/pypi/v/litellm.svg\" alt=\"PyPI Version\">\n    </a>\n    <a href=\"https://dl.circleci.com/status-badge/redirect/gh/BerriAI/litellm/tree/main\" target=\"_blank\">\n        <img src=\"https://dl.circleci.com/status-badge/img/gh/BerriAI/litellm/tree/main.svg?style=svg\" alt=\"CircleCI\">\n    </a>\n    <a href=\"https://www.ycombinator.com/companies/berriai\">\n        <img src=\"https://img.shields.io/badge/Y%20Combinator-W23-orange?style=flat-square\" alt=\"Y Combinator W23\">\n    </a>\n    <a href=\"https://wa.link/huol9n\">\n        <img src=\"https://img.shields.io/static/v1?label=Chat%20on&message=WhatsApp&color=success&logo=WhatsApp&style=flat-square\" alt=\"Whatsapp\">\n    </a>\n    <a href=\"https://discord.gg/wuPM9dRgDw\">\n        <img src=\"https://img.shields.io/static/v1?label=Chat%20on&message=Discord&color=blue&logo=Discord&style=flat-square\" alt=\"Discord\">\n    </a>\n</h4>\n\nLiteLLM manages:\n\n- Translate inputs to provider's `completion`, `embedding`, and `image_generation` endpoints\n- [Consistent output](https://docs.litellm.ai/docs/completion/output), text responses will always be available at `['choices'][0]['message']['content']`\n- Retry/fallback logic across multiple deployments (e.g. Azure/OpenAI) - [Router](https://docs.litellm.ai/docs/routing)\n- Set Budgets & Rate limits per project, api key, model [LiteLLM Proxy Server (LLM Gateway)](https://docs.litellm.ai/docs/simple_proxy)\n\n[**Jump to LiteLLM Proxy (LLM Gateway) Docs**](https://github.com/BerriAI/litellm?tab=readme-ov-file#openai-proxy---docs) <br>\n[**Jump to Supported LLM Providers**](https://github.com/BerriAI/litellm?tab=readme-ov-file#supported-providers-docs)\n\n **Stable Release:** Use docker images with the `-stable` tag. These have undergone 12 hour load tests, before being published. \n\nSupport for more providers. Missing a provider or LLM Platform, raise a [feature request](https://github.com/BerriAI/litellm/issues/new?assignees=&labels=enhancement&projects=&template=feature_request.yml&title=%5BFeature%5D%3A+).\n\n# Usage ([**Docs**](https://docs.litellm.ai/docs/))\n\n> [!IMPORTANT]\n> LiteLLM v1.0.0 now requires `openai>=1.0.0`. Migration guide [here](https://docs.litellm.ai/docs/migration)  \n> LiteLLM v1.40.14+ now requires `pydantic>=2.0.0`. No changes required.\n\n<a target=\"_blank\" href=\"https://colab.research.google.com/github/BerriAI/litellm/blob/main/cookbook/liteLLM_Getting_Started.ipynb\">\n  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a>\n\n```shell\npip install litellm\n```\n\n```python\nfrom litellm import completion\nimport os\n\n## set ENV variables\nos.environ[\"OPENAI_API_KEY\"] = \"your-openai-key\"\nos.environ[\"COHERE_API_KEY\"] = \"your-cohere-key\"\n\nmessages = [{ \"content\": \"Hello, how are you?\",\"role\": \"user\"}]\n\n# openai call\nresponse = completion(model=\"gpt-3.5-turbo\", messages=messages)\n\n# cohere call\nresponse = completion(model=\"command-nightly\", messages=messages)\nprint(response)\n```\n\nCall any model supported by a provider, with `model=<provider_name>/<model_name>`. There might be provider-specific details here, so refer to [provider docs for more information](https://docs.litellm.ai/docs/providers)\n\n## Async ([Docs](https://docs.litellm.ai/docs/completion/stream#async-completion))\n\n```python\nfrom litellm import acompletion\nimport asyncio\n\nasync def test_get_response():\n    user_message = \"Hello, how are you?\"\n    messages = [{\"content\": user_message, \"role\": \"user\"}]\n    response = await acompletion(model=\"gpt-3.5-turbo\", messages=messages)\n    return response\n\nresponse = asyncio.run(test_get_response())\nprint(response)\n```\n\n## Streaming ([Docs](https://docs.litellm.ai/docs/completion/stream))\n\nliteLLM supports streaming the model response back, pass `stream=True` to get a streaming iterator in response.  \nStreaming is supported for all models (Bedrock, Huggingface, TogetherAI, Azure, OpenAI, etc.)\n\n```python\nfrom litellm import completion\nresponse = completion(model=\"gpt-3.5-turbo\", messages=messages, stream=True)\nfor part in response:\n    print(part.choices[0].delta.content or \"\")\n\n# claude 2\nresponse = completion('claude-2', messages, stream=True)\nfor part in response:\n    print(part.choices[0].delta.content or \"\")\n```\n\n## Logging Observability ([Docs](https://docs.litellm.ai/docs/observability/callbacks))\n\nLiteLLM exposes pre defined callbacks to send data to Lunary, Langfuse, DynamoDB, s3 Buckets, Helicone, Promptlayer, Traceloop, Athina, Slack\n\n```python\nfrom litellm import completion\n\n## set env variables for logging tools\nos.environ[\"LUNARY_PUBLIC_KEY\"] = \"your-lunary-public-key\"\nos.environ[\"HELICONE_API_KEY\"] = \"your-helicone-auth-key\"\nos.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"\"\nos.environ[\"LANGFUSE_SECRET_KEY\"] = \"\"\nos.environ[\"ATHINA_API_KEY\"] = \"your-athina-api-key\"\n\nos.environ[\"OPENAI_API_KEY\"]\n\n# set callbacks\nlitellm.success_callback = [\"lunary\", \"langfuse\", \"athina\", \"helicone\"] # log input/output to lunary, langfuse, supabase, athina, helicone etc\n\n#openai call\nresponse = completion(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": \"Hi  - i'm openai\"}])\n```\n\n# LiteLLM Proxy Server (LLM Gateway) - ([Docs](https://docs.litellm.ai/docs/simple_proxy))\n\nTrack spend + Load Balance across multiple projects\n\n[Hosted Proxy (Preview)](https://docs.litellm.ai/docs/hosted)\n\nThe proxy provides:\n\n1. [Hooks for auth](https://docs.litellm.ai/docs/proxy/virtual_keys#custom-auth)\n2. [Hooks for logging](https://docs.litellm.ai/docs/proxy/logging#step-1---create-your-custom-litellm-callback-class)\n3. [Cost tracking](https://docs.litellm.ai/docs/proxy/virtual_keys#tracking-spend)\n4. [Rate Limiting](https://docs.litellm.ai/docs/proxy/users#set-rate-limits)\n\n##  Proxy Endpoints - [Swagger Docs](https://litellm-api.up.railway.app/)\n\n\n## Quick Start Proxy - CLI\n\n```shell\npip install 'litellm[proxy]'\n```\n\n### Step 1: Start litellm proxy\n\n```shell\n$ litellm --model huggingface/bigcode/starcoder\n\n#INFO: Proxy running on http://0.0.0.0:4000\n```\n\n### Step 2: Make ChatCompletions Request to Proxy\n\n\n> [!IMPORTANT]\n>  [Use LiteLLM Proxy with Langchain (Python, JS), OpenAI SDK (Python, JS) Anthropic SDK, Mistral SDK, LlamaIndex, Instructor, Curl](https://docs.litellm.ai/docs/proxy/user_keys)  \n\n```python\nimport openai # openai v1.0.0+\nclient = openai.OpenAI(api_key=\"anything\",base_url=\"http://0.0.0.0:4000\") # set proxy to base_url\n# request sent to model set on litellm proxy, `litellm --model`\nresponse = client.chat.completions.create(model=\"gpt-3.5-turbo\", messages = [\n    {\n        \"role\": \"user\",\n        \"content\": \"this is a test request, write a short poem\"\n    }\n])\n\nprint(response)\n```\n\n## Proxy Key Management ([Docs](https://docs.litellm.ai/docs/proxy/virtual_keys))\n\nConnect the proxy with a Postgres DB to create proxy keys\n\n```bash\n# Get the code\ngit clone https://github.com/BerriAI/litellm\n\n# Go to folder\ncd litellm\n\n# Add the master key - you can change this after setup\necho 'LITELLM_MASTER_KEY=\"sk-1234\"' > .env\n\n# Add the litellm salt key - you cannot change this after adding a model\n# It is used to encrypt / decrypt your LLM API Key credentials\n# We recommned - https://1password.com/password-generator/ \n# password generator to get a random hash for litellm salt key\necho 'LITELLM_SALT_KEY=\"sk-1234\"' > .env\n\nsource .env\n\n# Start\ndocker-compose up\n```\n\n\nUI on `/ui` on your proxy server\n![ui_3](https://github.com/BerriAI/litellm/assets/29436595/47c97d5e-b9be-4839-b28c-43d7f4f10033)\n\nSet budgets and rate limits across multiple projects\n`POST /key/generate`\n\n### Request\n\n```shell\ncurl 'http://0.0.0.0:4000/key/generate' \\\n--header 'Authorization: Bearer sk-1234' \\\n--header 'Content-Type: application/json' \\\n--data-raw '{\"models\": [\"gpt-3.5-turbo\", \"gpt-4\", \"claude-2\"], \"duration\": \"20m\",\"metadata\": {\"user\": \"ishaan@berri.ai\", \"team\": \"core-infra\"}}'\n```\n\n### Expected Response\n\n```shell\n{\n    \"key\": \"sk-kdEXbIqZRwEeEiHwdg7sFA\", # Bearer token\n    \"expires\": \"2023-11-19T01:38:25.838000+00:00\" # datetime object\n}\n```\n\n## Supported Providers ([Docs](https://docs.litellm.ai/docs/providers))\n\n| Provider                                                                            | [Completion](https://docs.litellm.ai/docs/#basic-usage) | [Streaming](https://docs.litellm.ai/docs/completion/stream#streaming-responses) | [Async Completion](https://docs.litellm.ai/docs/completion/stream#async-completion) | [Async Streaming](https://docs.litellm.ai/docs/completion/stream#async-streaming) | [Async Embedding](https://docs.litellm.ai/docs/embedding/supported_embedding) | [Async Image Generation](https://docs.litellm.ai/docs/image_generation) |\n|-------------------------------------------------------------------------------------|---------------------------------------------------------|---------------------------------------------------------------------------------|-------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------|-------------------------------------------------------------------------------|-------------------------------------------------------------------------|\n| [openai](https://docs.litellm.ai/docs/providers/openai)                             |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                              |                                                                        |\n| [azure](https://docs.litellm.ai/docs/providers/azure)                               |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                              |                                                                        |\n| [aws - sagemaker](https://docs.litellm.ai/docs/providers/aws_sagemaker)             |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                              |                                                                         |\n| [aws - bedrock](https://docs.litellm.ai/docs/providers/bedrock)                     |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                              |                                                                         |\n| [google - vertex_ai](https://docs.litellm.ai/docs/providers/vertex)                 |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                              |                                                                        |\n| [google - palm](https://docs.litellm.ai/docs/providers/palm)                        |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                               |                                                                         |\n| [google AI Studio - gemini](https://docs.litellm.ai/docs/providers/gemini)          |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                               |                                                                         |\n| [mistral ai api](https://docs.litellm.ai/docs/providers/mistral)                    |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                              |                                                                         |\n| [cloudflare AI Workers](https://docs.litellm.ai/docs/providers/cloudflare_workers)  |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                               |                                                                         |\n| [cohere](https://docs.litellm.ai/docs/providers/cohere)                             |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                              |                                                                         |\n| [anthropic](https://docs.litellm.ai/docs/providers/anthropic)                       |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                               |                                                                         |\n| [empower](https://docs.litellm.ai/docs/providers/empower)                    |                                                       |                                                                               |                                                                                   |                                                                                 |\n| [huggingface](https://docs.litellm.ai/docs/providers/huggingface)                   |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                              |                                                                         |\n| [replicate](https://docs.litellm.ai/docs/providers/replicate)                       |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                               |                                                                         |\n| [together_ai](https://docs.litellm.ai/docs/providers/togetherai)                    |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                               |                                                                         |\n| [openrouter](https://docs.litellm.ai/docs/providers/openrouter)                     |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                               |                                                                         |\n| [ai21](https://docs.litellm.ai/docs/providers/ai21)                                 |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                               |                                                                         |\n| [baseten](https://docs.litellm.ai/docs/providers/baseten)                           |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                               |                                                                         |\n| [vllm](https://docs.litellm.ai/docs/providers/vllm)                                 |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                               |                                                                         |\n| [nlp_cloud](https://docs.litellm.ai/docs/providers/nlp_cloud)                       |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                               |                                                                         |\n| [aleph alpha](https://docs.litellm.ai/docs/providers/aleph_alpha)                   |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                               |                                                                         |\n| [petals](https://docs.litellm.ai/docs/providers/petals)                             |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                               |                                                                         |\n| [ollama](https://docs.litellm.ai/docs/providers/ollama)                             |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                              |                                                                         |\n| [deepinfra](https://docs.litellm.ai/docs/providers/deepinfra)                       |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                               |                                                                         |\n| [perplexity-ai](https://docs.litellm.ai/docs/providers/perplexity)                  |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                               |                                                                         |\n| [Groq AI](https://docs.litellm.ai/docs/providers/groq)                              |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                               |                                                                         |\n| [Deepseek](https://docs.litellm.ai/docs/providers/deepseek)                         |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                               |                                                                         |\n| [anyscale](https://docs.litellm.ai/docs/providers/anyscale)                         |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                               |                                                                         |\n| [IBM - watsonx.ai](https://docs.litellm.ai/docs/providers/watsonx)                  |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                              |                                                                         |\n| [voyage ai](https://docs.litellm.ai/docs/providers/voyage)                          |                                                         |                                                                                 |                                                                                     |                                                                                   |                                                                              |                                                                         |\n| [xinference [Xorbits Inference]](https://docs.litellm.ai/docs/providers/xinference) |                                                         |                                                                                 |                                                                                     |                                                                                   |                                                                              |                                                                         |\n| [FriendliAI](https://docs.litellm.ai/docs/providers/friendliai)                              |                                                        |                                                                                |                                                                                    |                                                                                  |                                                                               |                                                                         |\n\n[**Read the Docs**](https://docs.litellm.ai/docs/)\n\n## Contributing\n\nTo contribute: Clone the repo locally -> Make a change -> Submit a PR with the change.\n\nHere's how to modify the repo locally:\nStep 1: Clone the repo\n\n```\ngit clone https://github.com/BerriAI/litellm.git\n```\n\nStep 2: Navigate into the project, and install dependencies:\n\n```\ncd litellm\npoetry install -E extra_proxy -E proxy\n```\n\nStep 3: Test your change:\n\n```\ncd litellm/tests # pwd: Documents/litellm/litellm/tests\npoetry run flake8\npoetry run pytest .\n```\n\nStep 4: Submit a PR with your changes! \n\n- push your fork to your GitHub repo\n- submit a PR from there\n\n# Enterprise\nFor companies that need better security, user management and professional support\n\n[Talk to founders](https://calendly.com/d/4mp-gd3-k5k/litellm-1-1-onboarding-chat)\n\nThis covers: \n-  **Features under the [LiteLLM Commercial License](https://docs.litellm.ai/docs/proxy/enterprise):**\n-  **Feature Prioritization**\n-  **Custom Integrations**\n-  **Professional Support - Dedicated discord + slack**\n-  **Custom SLAs**\n-  **Secure access with Single Sign-On**\n\n# Support / talk with founders\n\n- [Schedule Demo ](https://calendly.com/d/4mp-gd3-k5k/berriai-1-1-onboarding-litellm-hosted-version)\n- [Community Discord ](https://discord.gg/wuPM9dRgDw)\n- Our numbers  +1 (770) 8783-106 / +1 (412) 618-6238\n- Our emails  ishaan@berri.ai / krrish@berri.ai\n\n# Why did we build this\n\n- **Need for simplicity**: Our code started to get extremely complicated managing & translating calls between Azure, OpenAI and Cohere.\n\n# Contributors\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n\n<a href=\"https://github.com/BerriAI/litellm/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=BerriAI/litellm\" />\n</a>\n",
        "num_commits": 18205,
        "project_age_days": 461,
        "project_created_at": "2023-07-27",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-30",
        "num_contributors": 324,
        "num_pull": 2890,
        "num_issues": 6332,
        "num_opening_issue": 724,
        "project_size(kB)": 277182,
        "num_stargazers": 13356,
        "num_watchers": 13356,
        "num_forks": 1567,
        "num_subscribers": 72,
        "SecurityPolicy_created_at": "2024-09-02 14:41:29",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "41114f1c25a47b309b193835ebca47a42340e5f9",
                "url": "https://github.com/BerriAI/litellm/commit/41114f1c25a47b309b193835ebca47a42340e5f9",
                "date": "2024-09-02 14:41:29"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Generic policy",
            "User guideline",
            "User guideline",
            "User guideline",
            "User guideline",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "mar10/wsgidav",
        "project_url": "https://github.com/mar10/wsgidav",
        "SSF": {
            "date": "2024-10-30T00:59:40+07:00",
            "repo": {
                "name": "github.com/mar10/wsgidav",
                "commit": "34f361f3087fac220001288e41bc6705de7cb9ee"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.4,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'master'",
                        "Warn: branch protection not enabled for branch 'maintain_2.x'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "1 out of 1 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 1/30 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: university of copenhagen contributor org/company found, "
                    ],
                    "score": 3,
                    "reason": "project has 1 contributing companies or organizations -- score normalized to 3",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: :0"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "10 commit(s) and 2 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/mar10/wsgidav/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:50: update your workflow using https://app.stepsecurity.io/secureworkflow/mar10/wsgidav/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:64: update your workflow using https://app.stepsecurity.io/secureworkflow/mar10/wsgidav/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:77: update your workflow using https://app.stepsecurity.io/secureworkflow/mar10/wsgidav/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codespell.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/mar10/wsgidav/codespell.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/codespell.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/mar10/wsgidav/codespell.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/stale.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/mar10/wsgidav/stale.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:32: update your workflow using https://app.stepsecurity.io/secureworkflow/mar10/wsgidav/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:35: update your workflow using https://app.stepsecurity.io/secureworkflow/mar10/wsgidav/tests.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/tests.yml:67: update your workflow using https://app.stepsecurity.io/secureworkflow/mar10/wsgidav/tests.yml/master?enable=pin",
                        "Warn: containerImage not pinned by hash: Dockerfile:13: pin your Docker image by updating python:3-alpine to python:3-alpine@sha256:c38ead8bcf521573dad837d7ecfdebbc87792202e89953ba8b2b83a9c5a520b6",
                        "Warn: pipCommand not pinned by hash: Dockerfile:16-18",
                        "Warn: pipCommand not pinned by hash: Dockerfile:20",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:42",
                        "Warn: pipCommand not pinned by hash: .github/workflows/tests.yml:43",
                        "Info:   0 out of   8 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   2 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   1 containerImage dependencies pinned",
                        "Info:   0 out of   4 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: all commits (1) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: .github/SECURITY.md:1",
                        "Info: Found linked content: .github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: .github/SECURITY.md:1",
                        "Info: Found text in security policy: .github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact v4.3.3 not signed: https://api.github.com/repos/mar10/wsgidav/releases/154270449",
                        "Warn: release artifact v4.3.2 not signed: https://api.github.com/repos/mar10/wsgidav/releases/149024216",
                        "Warn: release artifact v4.3.1 not signed: https://api.github.com/repos/mar10/wsgidav/releases/148075228",
                        "Warn: release artifact v4.3.0 not signed: https://api.github.com/repos/mar10/wsgidav/releases/122349853",
                        "Warn: release artifact v4.2.0 not signed: https://api.github.com/repos/mar10/wsgidav/releases/92918698",
                        "Warn: release artifact v4.3.3 does not have provenance: https://api.github.com/repos/mar10/wsgidav/releases/154270449",
                        "Warn: release artifact v4.3.2 does not have provenance: https://api.github.com/repos/mar10/wsgidav/releases/149024216",
                        "Warn: release artifact v4.3.1 does not have provenance: https://api.github.com/repos/mar10/wsgidav/releases/148075228",
                        "Warn: release artifact v4.3.0 does not have provenance: https://api.github.com/repos/mar10/wsgidav/releases/122349853",
                        "Warn: release artifact v4.2.0 does not have provenance: https://api.github.com/repos/mar10/wsgidav/releases/92918698"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql.yml:29",
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql.yml:28",
                        "Warn: no topLevel permission defined: .github/workflows/codeql.yml:1",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/codespell.yml:11",
                        "Warn: no topLevel permission defined: .github/workflows/stale.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/tests.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-3f84-rpwh-47g6",
                        "Warn: Project is vulnerable to: GHSA-9298-4cf8-g4wj"
                    ],
                    "score": 8,
                    "reason": "2 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/mar10/wsgidav/contents/.github/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nThese project versions are currently being supported with security updates:\n\n| Version | Supported          |\n| ------- | ------------------ |\n| 4.0.x   | :white_check_mark: |\n| < 4.0   | :x:                |\n\n\n## Reporting a Vulnerability\n\n<!--\nUse this section to tell people how to report a vulnerability.\n\nTell them where to go, how often they can expect to get an update on a\nreported vulnerability, what to expect if the vulnerability is accepted or\ndeclined, etc.\n-->\n\nThank you for reporting a security related issue using a private channel \ninstead of opening a public issue!\n\nThe security team (i.e. me) will try to acknowledge and respond as quick as \npossible.\n\nTo report a security issue, please email \n\n> security(at)wwwendt.de\n\nand, to your best knowledge, please\n\n- Include your name and affiliation (if any).\n- Include the scope of the vulnerability. Let us know who could use this exploit.\n- Mention the affected versions.\n- Document steps to identify the vulnerability. It is important that we can \n  reproduce your findings.\n- Describe how to exploit vulnerability, give us an attack scenario.\n- If known, describe mitigations for the issue.\n\nThis project follows a 90 day disclosure timeline.\n\n(See also [Vulnerability Disclosure Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Vulnerability_Disclosure_Cheat_Sheet.html#initial-report).)\n",
        "project_all_labels": [
            "authentication",
            "bug",
            "build-chain",
            "cli",
            "client-miniredir",
            "client-related",
            "core",
            "deferred",
            "dependencies",
            "dir-browser",
            "docker",
            "documentation",
            "duplicate",
            "enhancement",
            "fs-provider",
            "help-wanted",
            "invalid",
            "need-test",
            "no-issue-activity",
            "question",
            "stale",
            "waiting",
            "windows",
            "wontfix"
        ],
        "README_content": "# ![logo](https://raw.githubusercontent.com/mar10/wsgidav/master/docs/source/logo.png) WsgiDAV\n\n[![Tests](https://github.com/mar10/wsgidav/actions/workflows/tests.yml/badge.svg)](https://github.com/mar10/wsgidav/actions/workflows/tests.yml)\n[![Latest Version](https://img.shields.io/pypi/v/wsgidav.svg)](https://pypi.python.org/pypi/WsgiDAV/)\n[![License](https://img.shields.io/pypi/l/wsgidav.svg)](https://github.com/mar10/wsgidav/blob/master/LICENSE)\n[![Documentation Status](https://readthedocs.org/projects/wsgidav/badge/?version=latest)](http://wsgidav.readthedocs.io/)\n[![codecov](https://codecov.io/gh/mar10/wsgidav/graph/badge.svg?token=0hNADSIxDz)](https://codecov.io/gh/mar10/wsgidav)\n[![Released with: Yabs](https://img.shields.io/badge/released%20with-yabs-yellowgreen)](https://github.com/mar10/yabs)\n[![StackOverflow: WsgiDAV](https://img.shields.io/badge/StackOverflow-WsgiDAV-blue.svg)](https://stackoverflow.com/questions/tagged/WsgiDAV)\n\n[![Edit online in vscode.dev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc) ](https://vscode.dev/github/mar10/wsgidav)\n\nA generic and extendable [WebDAV](http://www.ietf.org/rfc/rfc4918.txt) server\nwritten in Python and based on [WSGI](http://www.python.org/dev/peps/pep-3333/).\n\nMain features:\n\n- WsgiDAV is a stand-alone WebDAV server with SSL support, that can be\n  installed and run as Python command line script on Linux, OSX, and Windows:<br>\n\n  ```\n  $ pip install wsgidav cheroot\n  $ wsgidav --host=0.0.0.0 --port=80 --root=/tmp --auth=anonymous\n  Running without configuration file.\n  10:54:16.597 - INFO    : WsgiDAV/4.0.0-a1 Python/3.9.1 macOS-12.0.1-x86_64-i386-64bit\n  10:54:16.598 - INFO    : Registered DAV providers by route:\n  10:54:16.598 - INFO    :   - '/:dir_browser': FilesystemProvider for path '/Users/martin/prj/git/wsgidav/wsgidav/dir_browser/htdocs' (Read-Only) (anonymous)\n  10:54:16.599 - INFO    :   - '/': FilesystemProvider for path '/tmp' (Read-Write) (anonymous)\n  10:54:16.599 - WARNING : Basic authentication is enabled: It is highly recommended to enable SSL.\n  10:54:16.599 - WARNING : Share '/' will allow anonymous write access.\n  10:54:16.813 - INFO    : Running WsgiDAV/4.0.0-a1 Cheroot/8.5.2 Python 3.9.1\n  10:54:16.813 - INFO    : Serving on http://0.0.0.0:80 ...\n  ```\n\n  Run `wsgidav --help` for a list of available options.<br>\n\n- The [python-pam](https://github.com/FirefighterBlu3/python-pam) library is\n  needed as extra requirement if pam-login authentication is used on Linux\n  or OSX:\n\n  ```\n  $ pip install wsgidav[pam]\n  $ wsgidav --host=0.0.0.0 --port=8080 --root=/tmp --auth=pam-login\n  ```\n\n- **Note:** Windows users may prefer the\n  [MSI Installer](https://github.com/mar10/wsgidav/releases/latest)\n  (see <kbd>Assets</kbd> section), or use _winget_:\n\n  ```ps1\n  > winget install wsgidav\n  ```\n\n- WebDAV is a superset of HTTP, so WsgiDAV is also a performant, multi-threaded\n  web server with SSL support.\n\n- WsgiDAV is also a Python library that implements the WSGI protocol and can\n  be run behind any WSGI compliant web server.<br>\n\n- WsgiDAV is implemented as a configurable stack of WSGI middleware\n  applications.<br>\n  Its open architecture allows to extend the functionality and integrate\n  WebDAV services into your project.<br>\n  Typical use cases are:\n  - Expose data structures as virtual, editable file systems.\n  - Allow online editing of MS Office documents.\n\n## Status\n\n[![Latest Version](https://img.shields.io/pypi/v/wsgidav.svg)](https://pypi.python.org/pypi/WsgiDAV/)\nSee the ([change log](https://github.com/mar10/wsgidav/blob/master/CHANGELOG.md)) for details.\n\n**Note:** Release 4.0 introduces some refactorings and breaking changes.<br>\nSee the ([change log](https://github.com/mar10/wsgidav/blob/master/CHANGELOG.md)) for details.\n\n## More info\n\n- [Read The Docs](http://wsgidav.rtfd.org) for details.\n- [Discussion Group](https://github.com/mar10/wsgidav/discussions)\n- [Stackoverflow](http://stackoverflow.com/questions/tagged/wsgidav)\n\n## Credits\n\nContributors:\n\n- WsgiDAV is a [refactored version](https://github.com/mar10/wsgidav/blob/master/docs/source/changelog04.md)\n  of [PyFileServer 0.2](https://github.com/cwho/pyfileserver),\n  Copyright (c) 2005 Ho Chun Wei.<br>\n  Chun gave his approval to change the license from LGPL to MIT-License for\n  this project.\n- <https://github.com/mar10/wsgidav/contributors>\n- Markus Majer for providing the logo (a mixture of the international\n  maritime signal flag for 'W (Whiskey)' and a dove.)\n\nAny kind of feedback is very welcome!<br>\nHave fun :-)<br>\nMartin\n",
        "num_commits": 919,
        "project_age_days": 3964,
        "project_created_at": "2013-12-22",
        "latest_updated_at": "2024-10-28",
        "latest_pushed_at": "2024-10-20",
        "num_contributors": 44,
        "num_pull": 131,
        "num_issues": 317,
        "num_opening_issue": 6,
        "project_size(kB)": 9654,
        "num_stargazers": 978,
        "num_watchers": 978,
        "num_forks": 150,
        "num_subscribers": 23,
        "SecurityPolicy_created_at": "2022-11-05 18:16:27",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "f9b40df61ecb3be2307e03d1627e5b601f0b4f28",
                "url": "https://github.com/mar10/wsgidav/commit/f9b40df61ecb3be2307e03d1627e5b601f0b4f28",
                "date": "2022-11-05 18:16:27"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "python-imaging/pillow",
        "project_url": "https://github.com/python-imaging/pillow",
        "SSF": {
            "date": "2024-10-29T19:53:47+07:00",
            "repo": {
                "name": "github.com/python-imaging/pillow",
                "commit": "2d1d801ec032bfb760bede88da6dcaab5ff3c75e"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 7.8,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'main'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "13 out of 13 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 8,
                    "reason": "Found 11/13 approved changesets -- score normalized to 8",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: unitedstates contributor org/company found, zopefoundation contributor org/company found, python-ldap contributor org/company found, apple contributor org/company found, qgiscloud contributor org/company found, fatiando contributor org/company found, python-humanize contributor org/company found, endoflife-date contributor org/company found, thumbor contributor org/company found, voxmedia contributor org/company found, NaPoGenMo contributor org/company found, nordsoftware contributor org/company found, python-twitter-tools contributor org/company found, railsadminteam contributor org/company found, kcsry contributor org/company found, NaNoGenMo contributor org/company found, nimh-nif contributor org/company found, uploadcare contributor org/company found, WahKazoo contributor org/company found, buildout contributor org/company found, pioneer valley books contributor org/company found, resampling-stats contributor org/company found, termcolor contributor org/company found, collective contributor org/company found, Pioneer-Valley-Books contributor org/company found, mingwpy contributor org/company found, python contributor org/company found, helsinki-python contributor org/company found, qwc-services contributor org/company found, phasorpy contributor org/company found, FactoryBoy contributor org/company found, urllib3 contributor org/company found, whyaretheflagsup contributor org/company found, openambitproject contributor org/company found, nteract contributor org/company found, python-pillow contributor org/company found, pylast contributor org/company found, citybikes contributor org/company found, pyparsing contributor org/company found, literallycanvas contributor org/company found, python-babel contributor org/company found, step mobile contributor org/company found, deadsetbit contributor org/company found, aclark.net contributor org/company found, qgis contributor org/company found, wurstfabrik contributor org/company found, cycle148hki contributor org/company found, django contributor org/company found, healius pathology pty ltd contributor org/company found, pytest-dev contributor org/company found, plone contributor org/company found, requests contributor org/company found, dawan contributor org/company found, 6aika contributor org/company found, mobbler contributor org/company found, jazzband contributor org/company found, flake8-implicit-str-concat contributor org/company found, python-distro contributor org/company found, sourcepole contributor org/company found, asana but not on this account contributor org/company found, koodiklinikka contributor org/company found, ultrajson contributor org/company found, django-mptt contributor org/company found, django-auth-ldap contributor org/company found, nipy contributor org/company found, valohai contributor org/company found, kompisar contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 67 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: RenovateBot: .github/renovate.json:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Info: OSSFuzz integration found",
                        "Info: PythonAtherisFuzzer integration found: Tests/oss-fuzz/fuzz_font.py:16",
                        "Info: PythonAtherisFuzzer integration found: Tests/oss-fuzz/fuzz_pillow.py:16"
                    ],
                    "score": 10,
                    "reason": "project is fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 22 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/wheels.yml:288"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Info: Possibly incomplete results: error parsing shell code: \"foo(\" must be followed by ): .github/workflows/test-docker.yml:91",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/cifuzz.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/cifuzz.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/cifuzz.yml:40: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/cifuzz.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cifuzz.yml:47: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/cifuzz.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/cifuzz.yml:53: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/cifuzz.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:35: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/docs.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/docs.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs.yml:50: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/docs.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:23: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/lint.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:26: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/lint.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:34: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/lint.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-drafter.yml:26: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/release-drafter.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/stale.yml:23: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/stale.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test-cygwin.yml:50: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test-cygwin.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test-cygwin.yml:53: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test-cygwin.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test-cygwin.yml:86: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test-cygwin.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test-cygwin.yml:95: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test-cygwin.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test-cygwin.yml:125: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test-cygwin.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test-cygwin.yml:136: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test-cygwin.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test-docker.yml:66: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test-docker.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test-docker.yml:100: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test-docker.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test-mingw.yml:48: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test-mingw.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test-mingw.yml:86: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test-mingw.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test-valgrind.yml:42: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test-valgrind.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test-windows.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test-windows.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test-windows.yml:49: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test-windows.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test-windows.yml:55: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test-windows.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test-windows.yml:62: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test-windows.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test-windows.yml:109: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test-windows.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test-windows.yml:210: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test-windows.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test-windows.yml:222: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test-windows.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:65: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:68: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:79: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:95: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:146: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test.yml:157: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/test.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:133: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/wheels.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:137: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/wheels.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:158: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/wheels.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:175: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/wheels.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:178: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/wheels.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:183: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/wheels.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:240: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/wheels.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:246: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/wheels.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:255: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/wheels.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:258: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/wheels.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:266: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/wheels.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:277: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/wheels.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:299: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/wheels.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/wheels.yml:305: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/wheels.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:62: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/wheels.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:66: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/wheels.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/wheels.yml:72: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/wheels.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:92: update your workflow using https://app.stepsecurity.io/secureworkflow/python-pillow/Pillow/wheels.yml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: .ci/after_success.sh:4",
                        "Warn: pipCommand not pinned by hash: .ci/install.sh:29",
                        "Warn: pipCommand not pinned by hash: .ci/install.sh:30",
                        "Warn: pipCommand not pinned by hash: .ci/install.sh:31",
                        "Warn: pipCommand not pinned by hash: .ci/install.sh:32",
                        "Warn: pipCommand not pinned by hash: .ci/install.sh:33",
                        "Warn: pipCommand not pinned by hash: .ci/install.sh:34",
                        "Warn: pipCommand not pinned by hash: .ci/install.sh:35",
                        "Warn: pipCommand not pinned by hash: .ci/install.sh:36",
                        "Warn: pipCommand not pinned by hash: .ci/install.sh:37",
                        "Warn: pipCommand not pinned by hash: .ci/install.sh:38",
                        "Warn: pipCommand not pinned by hash: .ci/install.sh:41",
                        "Warn: pipCommand not pinned by hash: .ci/install.sh:47",
                        "Warn: pipCommand not pinned by hash: .ci/install.sh:53",
                        "Warn: pipCommand not pinned by hash: .github/workflows/macos-install.sh:24",
                        "Warn: pipCommand not pinned by hash: .github/workflows/macos-install.sh:25",
                        "Warn: pipCommand not pinned by hash: .github/workflows/macos-install.sh:26",
                        "Warn: pipCommand not pinned by hash: .github/workflows/macos-install.sh:27",
                        "Warn: pipCommand not pinned by hash: .github/workflows/macos-install.sh:28",
                        "Warn: pipCommand not pinned by hash: .github/workflows/macos-install.sh:29",
                        "Warn: pipCommand not pinned by hash: .github/workflows/macos-install.sh:30",
                        "Warn: pipCommand not pinned by hash: .github/workflows/macos-install.sh:31",
                        "Warn: pipCommand not pinned by hash: .github/workflows/macos-install.sh:32",
                        "Warn: pipCommand not pinned by hash: .github/workflows/wheels-dependencies.sh:54",
                        "Warn: pipCommand not pinned by hash: .github/workflows/wheels-test.sh:16",
                        "Warn: pipCommand not pinned by hash: Tests/oss-fuzz/build.sh:18",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint.yml:45",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint.yml:46",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:127",
                        "Warn: pipCommand not pinned by hash: .github/workflows/wheels.yml:76",
                        "Warn: pipCommand not pinned by hash: .github/workflows/wheels.yml:143",
                        "Info:   0 out of  41 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   1 out of  14 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of  31 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 28 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: .github/SECURITY.md:1",
                        "Info: Found linked content: .github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: .github/SECURITY.md:1",
                        "Info: Found text in security policy: .github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/release-drafter.yml:20",
                        "Info: found token with 'none' permissions: .github/workflows/test-cygwin.yml:145",
                        "Info: found token with 'none' permissions: .github/workflows/test-docker.yml:109",
                        "Info: found token with 'none' permissions: .github/workflows/test-windows.yml:231",
                        "Info: found token with 'none' permissions: .github/workflows/test.yml:166",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/cifuzz.yml:21",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/docs.yml:19",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/lint.yml:9",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/release-drafter.yml:11",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/test-cygwin.yml:23",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/test-docker.yml:23",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/test-mingw.yml:23",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/test-valgrind.yml:21",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/test-windows.yml:23",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/test.yml:23",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/wheels.yml:33"
                    ],
                    "score": 10,
                    "reason": "GitHub workflow tokens follow principle of least privilege",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/python-imaging/pillow/contents/.github/SECURITY.md",
        "SecurityPolicy_content": "# Security policy\n\nTo report sensitive vulnerability information, please use the [Tidelift security contact](https://tidelift.com/security). Tidelift will coordinate the fix and disclosure.\n\nIf your organisation/employer is a distributor of Pillow and would like advance notification of security-related bugs, please let us know your preferred contact method.\n",
        "project_all_labels": [
            "Anaconda",
            "automerge",
            "Awaiting OP Action",
            "Big-endian",
            "Blocked",
            "Blocker",
            "BMP",
            "Bug",
            "Build",
            "changelog: skip",
            "Cleanup",
            "Compatibility",
            "Conversion",
            "Cool",
            "Debian",
            "Dependency",
            "Deprecation",
            "Do Not Merge",
            "Documentation",
            "Duplicate",
            "Enhancement",
            "Exif",
            "File Closing",
            "Font Rendering",
            "Fonts",
            "Free-threading",
            "FreeBSD",
            "Ghostscript",
            "GIF",
            "Hacktoberfest",
            "Hacktoberfest-accepted",
            "Hasn't worked in 20 years",
            "Infrastructure",
            "Installation",
            "Invalid",
            "JPEG",
            "Library Linking",
            "License",
            "Linux",
            "macOS",
            "Memory",
            "Needs Documentation",
            "Needs Example",
            "Needs Rebase",
            "Needs Release Notes",
            "Needs Review",
            "Needs Test Case",
            "Needs Tests",
            "No Auto",
            "NumPy",
            "olefile",
            "Packaging",
            "Palette",
            "Performance",
            "Pillow scripts",
            "Platform",
            "Preventative Maintenance",
            "Python 2-only",
            "Qt",
            "Question",
            "Ready For Merge",
            "Regression",
            "Release",
            "Removal",
            "Screen grab",
            "SPARC",
            "Stale",
            "Sticky",
            "Testing",
            "Third Party Framework",
            "TIFF",
            "Type hints",
            "Unsupported",
            "WebP",
            "Windows",
            "Wontfix",
            "Works in Python 2"
        ],
        "README_content": "<p align=\"center\">\n    <img width=\"248\" height=\"250\" src=\"https://raw.githubusercontent.com/python-pillow/pillow-logo/main/pillow-logo-248x250.png\" alt=\"Pillow logo\">\n</p>\n\n# Pillow\n\n## Python Imaging Library (Fork)\n\nPillow is the friendly PIL fork by [Jeffrey A. Clark and\ncontributors](https://github.com/python-pillow/Pillow/graphs/contributors).\nPIL is the Python Imaging Library by Fredrik Lundh and contributors.\nAs of 2019, Pillow development is\n[supported by Tidelift](https://tidelift.com/subscription/pkg/pypi-pillow?utm_source=pypi-pillow&utm_medium=readme&utm_campaign=enterprise).\n\n<table>\n    <tr>\n        <th>docs</th>\n        <td>\n            <a href=\"https://pillow.readthedocs.io/?badge=latest\"><img\n                alt=\"Documentation Status\"\n                src=\"https://readthedocs.org/projects/pillow/badge/?version=latest\"></a>\n        </td>\n    </tr>\n    <tr>\n        <th>tests</th>\n        <td>\n            <a href=\"https://github.com/python-pillow/Pillow/actions/workflows/lint.yml\"><img\n                alt=\"GitHub Actions build status (Lint)\"\n                src=\"https://github.com/python-pillow/Pillow/workflows/Lint/badge.svg\"></a>\n            <a href=\"https://github.com/python-pillow/Pillow/actions/workflows/test.yml\"><img\n                alt=\"GitHub Actions build status (Test Linux and macOS)\"\n                src=\"https://github.com/python-pillow/Pillow/workflows/Test/badge.svg\"></a>\n            <a href=\"https://github.com/python-pillow/Pillow/actions/workflows/test-windows.yml\"><img\n                alt=\"GitHub Actions build status (Test Windows)\"\n                src=\"https://github.com/python-pillow/Pillow/workflows/Test%20Windows/badge.svg\"></a>\n            <a href=\"https://github.com/python-pillow/Pillow/actions/workflows/test-mingw.yml\"><img\n                alt=\"GitHub Actions build status (Test MinGW)\"\n                src=\"https://github.com/python-pillow/Pillow/workflows/Test%20MinGW/badge.svg\"></a>\n            <a href=\"https://github.com/python-pillow/Pillow/actions/workflows/test-cygwin.yml\"><img\n                alt=\"GitHub Actions build status (Test Cygwin)\"\n                src=\"https://github.com/python-pillow/Pillow/workflows/Test%20Cygwin/badge.svg\"></a>\n            <a href=\"https://github.com/python-pillow/Pillow/actions/workflows/test-docker.yml\"><img\n                alt=\"GitHub Actions build status (Test Docker)\"\n                src=\"https://github.com/python-pillow/Pillow/workflows/Test%20Docker/badge.svg\"></a>\n            <a href=\"https://ci.appveyor.com/project/python-pillow/Pillow\"><img\n                alt=\"AppVeyor CI build status (Windows)\"\n                src=\"https://img.shields.io/appveyor/build/python-pillow/Pillow/main.svg?label=Windows%20build\"></a>\n            <a href=\"https://github.com/python-pillow/Pillow/actions/workflows/wheels.yml\"><img\n                alt=\"GitHub Actions build status (Wheels)\"\n                src=\"https://github.com/python-pillow/Pillow/workflows/Wheels/badge.svg\"></a>\n            <a href=\"https://app.codecov.io/gh/python-pillow/Pillow\"><img\n                alt=\"Code coverage\"\n                src=\"https://codecov.io/gh/python-pillow/Pillow/branch/main/graph/badge.svg\"></a>\n            <a href=\"https://issues.oss-fuzz.com/issues?q=title:pillow\"><img\n                alt=\"Fuzzing Status\"\n                src=\"https://oss-fuzz-build-logs.storage.googleapis.com/badges/pillow.svg\"></a>\n        </td>\n    </tr>\n    <tr>\n        <th>package</th>\n        <td>\n            <a href=\"https://zenodo.org/badge/latestdoi/17549/python-pillow/Pillow\"><img\n                alt=\"Zenodo\"\n                src=\"https://zenodo.org/badge/17549/python-pillow/Pillow.svg\"></a>\n            <a href=\"https://tidelift.com/subscription/pkg/pypi-pillow?utm_source=pypi-pillow&utm_medium=badge\"><img\n                alt=\"Tidelift\"\n                src=\"https://tidelift.com/badges/package/pypi/pillow?style=flat\"></a>\n            <a href=\"https://pypi.org/project/pillow/\"><img\n                alt=\"Newest PyPI version\"\n                src=\"https://img.shields.io/pypi/v/pillow.svg\"></a>\n            <a href=\"https://pypi.org/project/pillow/\"><img\n                alt=\"Number of PyPI downloads\"\n                src=\"https://img.shields.io/pypi/dm/pillow.svg\"></a>\n            <a href=\"https://www.bestpractices.dev/projects/6331\"><img\n                alt=\"OpenSSF Best Practices\"\n                src=\"https://www.bestpractices.dev/projects/6331/badge\"></a>\n        </td>\n    </tr>\n    <tr>\n        <th>social</th>\n        <td>\n            <a href=\"https://gitter.im/python-pillow/Pillow?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge\"><img\n                alt=\"Join the chat at https://gitter.im/python-pillow/Pillow\"\n                src=\"https://badges.gitter.im/python-pillow/Pillow.svg\"></a>\n            <a href=\"https://fosstodon.org/@pillow\"><img\n                alt=\"Follow on https://fosstodon.org/@pillow\"\n                src=\"https://img.shields.io/badge/publish-on%20Mastodon-595aff.svg\"\n                rel=\"me\"></a>\n        </td>\n    </tr>\n</table>\n\n## Overview\n\nThe Python Imaging Library adds image processing capabilities to your Python interpreter.\n\nThis library provides extensive file format support, an efficient internal representation, and fairly powerful image processing capabilities.\n\nThe core image library is designed for fast access to data stored in a few basic pixel formats. It should provide a solid foundation for a general image processing tool.\n\n## More Information\n\n- [Documentation](https://pillow.readthedocs.io/)\n  - [Installation](https://pillow.readthedocs.io/en/latest/installation/basic-installation.html)\n  - [Handbook](https://pillow.readthedocs.io/en/latest/handbook/index.html)\n- [Contribute](https://github.com/python-pillow/Pillow/blob/main/.github/CONTRIBUTING.md)\n  - [Issues](https://github.com/python-pillow/Pillow/issues)\n  - [Pull requests](https://github.com/python-pillow/Pillow/pulls)\n- [Release notes](https://pillow.readthedocs.io/en/stable/releasenotes/index.html)\n- [Changelog](https://github.com/python-pillow/Pillow/blob/main/CHANGES.rst)\n  - [Pre-fork](https://github.com/python-pillow/Pillow/blob/main/CHANGES.rst#pre-fork)\n\n## Report a Vulnerability\n\nTo report a security vulnerability, please follow the procedure described in the [Tidelift security policy](https://tidelift.com/docs/security).\n",
        "num_commits": 18767,
        "project_age_days": 4480,
        "project_created_at": "2012-07-24",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 384,
        "num_pull": 5149,
        "num_issues": 8324,
        "num_opening_issue": 120,
        "project_size(kB)": 204269,
        "num_stargazers": 12228,
        "num_watchers": 12228,
        "num_forks": 2226,
        "num_subscribers": 220,
        "SecurityPolicy_created_at": "2019-05-24 12:45:48",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "2d1135d41b406764525b4e983867f60890459b5e",
                "url": "https://github.com/python-pillow/Pillow/commit/2d1135d41b406764525b4e983867f60890459b5e",
                "date": "2019-05-24 12:45:48"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "ome/omero-web",
        "project_url": "https://github.com/ome/omero-web",
        "SSF": {
            "date": "2024-10-29T18:59:03+07:00",
            "repo": {
                "name": "github.com/ome/omero-web",
                "commit": "da5b7d11f5375f024d3881db2dcc63899b4087da"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.8,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'master'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "9 out of 9 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 5,
                    "reason": "Found 8/14 approved changesets -- score normalized to 5",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: jai-imageio contributor org/company found, bigdataviewer contributor org/company found, virtualcell contributor org/company found, openjournals contributor org/company found, conda-forge contributor org/company found, sa-tre contributor org/company found, knime-ip contributor org/company found, CellMigStandOrg contributor org/company found, scverse contributor org/company found, CellProfiler contributor org/company found, PyTables contributor org/company found, HumanCellAtlas contributor org/company found, NEUBIAS contributor org/company found, trakem2 contributor org/company found, apposed contributor org/company found, jupyterhub contributor org/company found, imglib contributor org/company found, manicstreetpreacher contributor org/company found, uk-tre contributor org/company found, MacRuby contributor org/company found, jenkinsci contributor org/company found, SpatialHackathon contributor org/company found, bioconda contributor org/company found, BioContainers contributor org/company found, rse-tre contributor org/company found, ManhattanMetric contributor org/company found, openmicroscopy contributor org/company found, fiji contributor org/company found, flimlib contributor org/company found, trackmate-sc contributor org/company found, eliceiri/loci lab uw-madison contributor org/company found, numfocus contributor org/company found, rseng contributor org/company found, glencoe software contributor org/company found, wnd-charm contributor org/company found, uw-loci contributor org/company found, openspim contributor org/company found, scijava contributor org/company found, MicronOxford contributor org/company found, HicResearch contributor org/company found, k8tre contributor org/company found, glencoesoftware contributor org/company found, imagej contributor org/company found, zarr-developers contributor org/company found, InsightSoftwareConsortium contributor org/company found, microscopepony contributor org/company found, German-BioImaging contributor org/company found, bonej-org contributor org/company found, imaging-tools contributor org/company found, ome contributor org/company found, idr-contrib contributor org/company found, spacetx contributor org/company found, czi-hca-comp-tools contributor org/company found, jump-cellpainting contributor org/company found, university of dundee contributor org/company found, crs4 contributor org/company found, visad contributor org/company found, IDR contributor org/company found, scifio contributor org/company found, bioimage-io contributor org/company found, NFDI4BIOIMAGE contributor org/company found, hic-infra contributor org/company found, hhu contributor org/company found, scenerygraphics contributor org/company found, weso contributor org/company found, bio-tools-community contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 66 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Warn: project does not have a license file"
                    ],
                    "score": 0,
                    "reason": "license file not detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "20 commit(s) and 7 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/publish_pypi.yml:6"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/ome/omero-web/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/ome/omero-web/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:57: update your workflow using https://app.stepsecurity.io/secureworkflow/ome/omero-web/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:71: update your workflow using https://app.stepsecurity.io/secureworkflow/ome/omero-web/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/install.yml:12: update your workflow using https://app.stepsecurity.io/secureworkflow/ome/omero-web/install.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/install.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/ome/omero-web/install.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_pypi.yml:10: update your workflow using https://app.stepsecurity.io/secureworkflow/ome/omero-web/publish_pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish_pypi.yml:11: update your workflow using https://app.stepsecurity.io/secureworkflow/ome/omero-web/publish_pypi.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish_pypi.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/ome/omero-web/publish_pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tox.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/ome/omero-web/tox.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tox.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/ome/omero-web/tox.yml/master?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/install.yml:22",
                        "Info:   0 out of  10 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   1 out of   2 pipCommand dependencies pinned"
                    ],
                    "score": 2,
                    "reason": "dependency not pinned by hash detected -- score normalized to 2",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: all commits (24) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/ome/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/ome/.github/SECURITY.md:1",
                        "Warn: One or no descriptive hints of disclosure, vulnerability, and/or timelines in security policy",
                        "Info: Found text in security policy: github.com/ome/.github/SECURITY.md:1"
                    ],
                    "score": 9,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/codeql-analysis.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/install.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish_pypi.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/tox.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/ome/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "## Reporting security issues\n\nThe OME team and community take security bugs seriously.\n\nIf you discover a security vulnerability or would like to report a security issue privately and securely, please email us at security@openmicroscopy.org. You can use GPG keys to communicate with us securely - see\nhttps://www.openmicroscopy.org/security/ for details about the OME security key.\n\nMore information about past security advisories is available at https://www.openmicroscopy.org/security/advisories/.\n",
        "project_all_labels": [
            "bug",
            "documentation",
            "duplicate",
            "enhancement",
            "good first issue",
            "help wanted",
            "include",
            "invalid",
            "question",
            "wontfix"
        ],
        "README_content": "OMERO.web\n=========\n.. image::  https://github.com/ome/omero-web/workflows/Tox/badge.svg\n    :target: https://github.com/ome/omero-web/actions\n\n.. image:: https://img.shields.io/badge/code%20style-black-000000.svg\n    :target: https://github.com/psf/black\n\n.. image:: https://badge.fury.io/py/omero-web.svg\n    :target: https://badge.fury.io/py/omero-web\n\nIntroduction\n------------\n\nOMERO.web provides a web based client and plugin infrastructure.\n\nDependencies\n------------\n\nDirect dependencies of OMERO.web are:\n\n- `OMERO.py`_\n- `ZeroC IcePy`_\n- `Pillow`_\n- `NumPy`_\n- A WSGI capable web server\n\nInstallation\n------------\n\nWe recommend installing ``omero-web`` in a Python virtual environment.\n\nBefore installing ``omero-web``, we recommend to install the `ZeroC IcePy`_ Python bindings.\nOur commercial partner `Glencoe Software <https://www.glencoesoftware.com/blog/2023/12/08/ice-binaries-for-omero.html>`_ has produced several Python wheels to install the Ice-Python bindings depending on the desired Python version and the operating system. Please visit `OMERO Python language bindings <https://omero.readthedocs.io/en/stable/developers/Python.html>`_ for a list of supported platforms and Python versions.\n\nWhen the wheel is installed, activate the virtual environment and install ``omero-web`` from `PyPI <https://pypi.org/>`_.\n\n::\n\n    $  pip install -U omero-web\n\nSetting of the environment variable ``OMERODIR`` is required.\n``$OMERODIR/var/log/`` directory will contain log files.\n``$OMERODIR/etc/grid/config.xml`` is used to store config::\n\n    $ export OMERODIR=$(pwd)\n\nUsage\n-----\n\nFor running omero-web in production with NGINX, see See: `OMERO.web install`_ documentation.\nTo run in development mode, see below.\n\nContributing\n------------\n\nSee: `OMERO`_ documentation\n\nDeveloper installation\n----------------------\n\nFor a development installation we recommend creating a virtual environment as described above.\nThen install OMERO.web into your virtual environment as an editable package, so that any edits\nto source files will be reflected in your installation.\n\n::\n\n    $ git clone https://github.com/ome/omero-web\n    $ cd omero-web\n    $ pip install -e .\n\nNote some ``omero-web`` tests may not run when this module and/or ``omero-py`` are installed in editable mode.\n\nConfiguration for developer usage::\n\n    $ omero config set omero.web.debug True\n    $ omero config set omero.web.application_server development\n\n    # If you want to connect to OMERO.server other than 'localhost'\n    $ omero config append omero.web.server_list '[\"demo.openmicroscopy.org\", 4064, \"demo\"]'\n\nThen run omero-web in the foreground with::\n\n    $ omero web start\n    ...\n    Starting development server at http://127.0.0.1:4080/\n\nOr, run Django directly::\n\n    $ cd omero-web\n    $ python omeroweb/manage.py runserver 4080\n    ...\n    Starting development server at http://127.0.0.1:4080/\n\nUpgrading\n---------\n\nPlugin developers should review the `Upgrading <UPGRADING.md>`_\ndocument highlighting steps that may need to be taken\nwhen upgrading OMERO.web to ensure plugins or other customizations\ncontinue to function as expected.\n\nRunning tests\n-------------\n\nUnit tests are located under the `test` directory and can be run with pytest.\n\nIntegration tests\n^^^^^^^^^^^^^^^^^\n\nIntegration tests are stored in the main repository (ome/openmicroscopy) and depend on the\nOMERO integration testing framework. Reading about `Running and writing tests`_ in the `OMERO`_ documentation\nis essential.\n\nRelease process\n---------------\n\nThis repository uses `bump2version <https://pypi.org/project/bump2version/>`_ to manage version numbers.\nTo tag a release run::\n\n    $ bumpversion release\n\nThis will remove the ``.dev0`` suffix from the current version, commit, and tag the release.\n\nTo switch back to a development version run::\n\n    $ bumpversion --no-tag patch\n\nNB: this assumes next release will be a ``patch`` (see below).\nTo complete the release, push the master branch and the release tag to origin::\n\n    $ git push origin master v5.8.0\n\nIf any PRs are merged that would require the next release to be a ``major`` or ``minor`` version\n(see `semver.org <https://semver.org/>`_) then that PR can include a version bump created via::\n\n    $ bumpversion --no-tag minor|major\n\nIf this hasn't been performed prior to release and you wish to specify the next version\nnumber directly when creating the release, this can be achieved with::\n\n    $ bumpversion --new-version 5.9.0 release\n\nomero-web-docker\n^^^^^^^^^^^^^^^^\n\nFollowing ``omero-web`` release, need to update and release ``omero-web-docker``.\n\nLicense\n-------\n\nOMERO.web is released under the AGPL.\n\nCopyright\n---------\n\n2009-2024, The Open Microscopy Environment, Glencoe Software, Inc.\n\n.. _OMERO: https://www.openmicroscopy.org/omero\n.. _OMERO.web install: https://omero.readthedocs.io/en/stable/sysadmins/unix/install-web/web-deployment.html\n.. _OMERO.py: https://pypi.python.org/pypi/omero-py\n.. _ZeroC IcePy: https://zeroc.com/downloads/ice/3.6\n.. _Pillow: https://python-pillow.org/\n.. _NumPy: http://matplotlib.org/\n.. _Running and writing tests: https://omero.readthedocs.io/en/stable/omero/developers/testing.html\n",
        "num_commits": 13442,
        "project_age_days": 1912,
        "project_created_at": "2019-08-05",
        "latest_updated_at": "2024-09-10",
        "latest_pushed_at": "2024-10-08",
        "num_contributors": 37,
        "num_pull": 380,
        "num_issues": 589,
        "num_opening_issue": 136,
        "project_size(kB)": 26406,
        "num_stargazers": 16,
        "num_watchers": 16,
        "num_forks": 30,
        "num_subscribers": 12,
        "SecurityPolicy_created_at": "2019-08-02 15:06:47",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "ca235e2f0b10ebfcbd3ece11deece338641c3579",
                "url": "https://github.com/ome/.github/commit/ca235e2f0b10ebfcbd3ece11deece338641c3579",
                "date": "2019-08-05 11:00:07"
            },
            {
                "commit_id": "277d2f7be9036d5568569b165141dff141356f52",
                "url": "https://github.com/ome/.github/commit/277d2f7be9036d5568569b165141dff141356f52",
                "date": "2019-08-05 10:41:19"
            },
            {
                "commit_id": "0c08913d6d00544d7108552f52ad5a38e0e4a518",
                "url": "https://github.com/ome/.github/commit/0c08913d6d00544d7108552f52ad5a38e0e4a518",
                "date": "2019-08-02 15:06:47"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "mlflow/mlflow",
        "project_url": "https://github.com/mlflow/mlflow",
        "SSF": {
            "date": "2024-10-30T03:50:51+07:00",
            "repo": {
                "name": "github.com/mlflow/mlflow",
                "commit": "967eeb8f251e4504e21434f1a6ab30b1235c8ca0"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 7.2,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'allow deletion' disabled on branch 'branch-2.15'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'branch-2.15'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: branch 'branch-2.15' does not require approvers",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Warn: codeowners review is not required on branch 'branch-2.15'",
                        "Info: status check found to merge onto on branch 'master'",
                        "Warn: no status checks found to merge onto branch 'branch-2.15'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 4,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 out of 30 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 9,
                    "reason": "Found 29/30 approved changesets -- score normalized to 9",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: dmatrix consulting inc contributor org/company found, mlflow contributor org/company found, databricks. ex linkedin contributor org/company found, mesos contributor org/company found, radlab contributor org/company found, databricks contributor org/company found, RiazApp contributor org/company found, bigdatagenomics contributor org/company found, criteo contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 9 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: :0"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.txt:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE.txt:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 15 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/push-images.yml:13"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "internal error: internal error: invalid Dockerfile",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: jobLevel 'statuses' permission set to 'write': .github/workflows/autoformat.yml:196",
                        "Warn: jobLevel 'statuses' permission set to 'write': .github/workflows/autoformat.yml:21",
                        "Info: jobLevel 'pull-requests' permission set to 'read': .github/workflows/autoformat.yml:59",
                        "Warn: jobLevel 'actions' permission set to 'write': .github/workflows/cancel.yml:17",
                        "Info: jobLevel 'pull-requests' permission set to 'read': .github/workflows/closing-pr.yml:21",
                        "Warn: jobLevel 'actions' permission set to 'write': .github/workflows/cross-version-test-runner.yml:20",
                        "Info: jobLevel 'issues' permission set to 'read': .github/workflows/cross-version-tests.yml:63",
                        "Warn: jobLevel 'packages' permission set to 'write': .github/workflows/devcontainer.yml:33",
                        "Warn: jobLevel 'packages' permission set to 'write': .github/workflows/devcontainer.yml:106",
                        "Info: jobLevel 'statuses' permission set to 'read': .github/workflows/preview-docs.yml:14",
                        "Info: jobLevel 'pull-requests' permission set to 'read': .github/workflows/release-note.yml:35",
                        "Warn: jobLevel 'actions' permission set to 'write': .github/workflows/rerun-cross-version-tests.yml:22",
                        "Warn: jobLevel 'actions' permission set to 'write': .github/workflows/rerun.yml:20",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/advice.yml:9",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/autoformat.yml:9",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/build-wheel.yml:23",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/cancel.yml:10",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/cherry-picks-warn.yml:11",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/closing-pr.yml:14",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/cross-version-test-runner.yml:7",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/cross-version-tests.yml:43",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/deployments.yml:16",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/dev-setup.yml:33",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/devcontainer.yml:17",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/examples.yml:30",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/gateway.yml:16",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/js.yml:22",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/labeling.yml:14",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/lint.yml:16",
                        "Info: topLevel 'pull-requests' permission set to 'read': .github/workflows/maintainer-approval.yml:7",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/master.yml:16",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/patch.yml:11",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/preview-docs.yml:7",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/protect.yml:12",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/protobuf-cross-test.yml:20",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/protos.yml:22",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/push-images.yml:10",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/r.yml:19",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/recipe-template.yml:20",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/recipe.yml:16",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/release-note.yml:20",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/requirements.yml:19",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/rerun-cross-version-tests.yml:14",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/rerun.yml:12",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/slow-tests.yml:30",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/stale.yml:7",
                        "Warn: no topLevel permission defined: .github/workflows/team-review.yml:1"
                    ],
                    "score": 9,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-jwhx-xcg6-8xhj",
                        "Warn: Project is vulnerable to: GHSA-fj7x-q9j7-g6q6 / PYSEC-2024-48",
                        "Warn: Project is vulnerable to: GHSA-248v-346w-9cwc",
                        "Warn: Project is vulnerable to: GHSA-h4gh-qq45-vh27",
                        "Warn: Project is vulnerable to: PYSEC-2024-38",
                        "Warn: Project is vulnerable to: GHSA-43c4-9qgj-x742",
                        "Warn: Project is vulnerable to: GHSA-76cg-cfhx-373f",
                        "Warn: Project is vulnerable to: GHSA-7p8j-qv6x-f4g4",
                        "Warn: Project is vulnerable to: GHSA-cv6c-7963-wxcg",
                        "Warn: Project is vulnerable to: GHSA-cwgg-w6mp-w9hg",
                        "Warn: Project is vulnerable to: GHSA-ghv6-9r9j-wh4j",
                        "Warn: Project is vulnerable to: GHSA-j8mg-pqc5-x9gj",
                        "Warn: Project is vulnerable to: GHSA-wf7f-8fxf-xfxc",
                        "Warn: Project is vulnerable to: GHSA-x38x-g6gr-jqff",
                        "Warn: Project is vulnerable to: GHSA-cgvx-9447-vcch",
                        "Warn: Project is vulnerable to: GHSA-jw8x-6495-233v / PYSEC-2024-110",
                        "Warn: Project is vulnerable to: GHSA-74m5-2c7w-9w3x / PYSEC-2023-48",
                        "Warn: Project is vulnerable to: GHSA-f96h-pmfr-66vw",
                        "Warn: Project is vulnerable to: GHSA-v5gw-mw7f-84px / PYSEC-2023-83",
                        "Warn: Project is vulnerable to: GHSA-f9vj-2wh5-fj8j",
                        "Warn: Project is vulnerable to: GHSA-q34m-jh98-gwm2",
                        "Warn: Project is vulnerable to: GHSA-43fp-rhv2-5gv8 / PYSEC-2022-42986",
                        "Warn: Project is vulnerable to: GHSA-xqr8-7jwr-rhp7 / PYSEC-2023-135",
                        "Warn: Project is vulnerable to: GHSA-m2qf-hxjv-5gpq / PYSEC-2023-62",
                        "Warn: Project is vulnerable to: GHSA-2mqj-m65w-jghx / PYSEC-2024-4",
                        "Warn: Project is vulnerable to: GHSA-cwvm-v4w8-q58c / PYSEC-2023-165",
                        "Warn: Project is vulnerable to: GHSA-hcpj-qp55-gfph / PYSEC-2022-42992",
                        "Warn: Project is vulnerable to: GHSA-pr76-5cm5-w9cj / PYSEC-2023-137",
                        "Warn: Project is vulnerable to: GHSA-wfm5-v35h-vwf4 / PYSEC-2023-161",
                        "Warn: Project is vulnerable to: GHSA-w3h3-4rj7-4ph4",
                        "Warn: Project is vulnerable to: GHSA-jjg7-2v4v-x38h / PYSEC-2024-60",
                        "Warn: Project is vulnerable to: GHSA-h5c8-rqwp-cp95",
                        "Warn: Project is vulnerable to: GHSA-h75v-3vvj-5mfj",
                        "Warn: Project is vulnerable to: GHSA-6hrg-qmvc-2xh8 / PYSEC-2022-288",
                        "Warn: Project is vulnerable to: GHSA-v973-fxgf-6xhp / PYSEC-2022-260",
                        "Warn: Project is vulnerable to: GHSA-3v79-q7ph-j75h",
                        "Warn: Project is vulnerable to: GHSA-4qq5-mxxx-m6gg",
                        "Warn: Project is vulnerable to: GHSA-554w-xh4j-8w64 / PYSEC-2023-253",
                        "Warn: Project is vulnerable to: GHSA-59v3-898r-qwhj",
                        "Warn: Project is vulnerable to: GHSA-5mvj-wmgj-7q8c",
                        "Warn: Project is vulnerable to: GHSA-5p3h-7fwh-92rc",
                        "Warn: Project is vulnerable to: GHSA-5q6c-ffvg-xcm9",
                        "Warn: Project is vulnerable to: GHSA-5r3q-93q3-f978 / PYSEC-2023-252",
                        "Warn: Project is vulnerable to: GHSA-6749-m5cp-6cg7",
                        "Warn: Project is vulnerable to: GHSA-83fm-w79m-64r5",
                        "Warn: Project is vulnerable to: GHSA-8f8q-q2j7-7j2m",
                        "Warn: Project is vulnerable to: GHSA-cxfr-5q3r-2rc2",
                        "Warn: Project is vulnerable to: GHSA-f42m-mvfv-cgw5",
                        "Warn: Project is vulnerable to: GHSA-f798-qm4r-23r5",
                        "Warn: Project is vulnerable to: GHSA-f82r-jj5r-6g97",
                        "Warn: Project is vulnerable to: GHSA-ffw3-6378-cqgp",
                        "Warn: Project is vulnerable to: GHSA-fmxj-6h9g-6vw3",
                        "Warn: Project is vulnerable to: GHSA-hh8p-p8mp-gqhm",
                        "Warn: Project is vulnerable to: GHSA-hq88-wg7q-gp4g",
                        "Warn: Project is vulnerable to: GHSA-hvc6-42vf-jhf8",
                        "Warn: Project is vulnerable to: GHSA-j46q-5pxx-8vmw",
                        "Warn: Project is vulnerable to: GHSA-j62r-wxqq-f3gf",
                        "Warn: Project is vulnerable to: GHSA-m49c-5c52-6696",
                        "Warn: Project is vulnerable to: GHSA-p4jx-q62p-x5jr",
                        "Warn: Project is vulnerable to: GHSA-pqcv-qw2r-r859",
                        "Warn: Project is vulnerable to: GHSA-qg8p-32gr-gh6x",
                        "Warn: Project is vulnerable to: GHSA-v945-r3rc-6fjm",
                        "Warn: Project is vulnerable to: GHSA-vqj2-4v8m-8vrq / PYSEC-2022-28",
                        "Warn: Project is vulnerable to: GHSA-vwhf-3v6x-wff8 / PYSEC-2023-260",
                        "Warn: Project is vulnerable to: GHSA-wc6j-5g83-xfm6 / PYSEC-2023-70",
                        "Warn: Project is vulnerable to: GHSA-wjq3-7jxx-whj9 / PYSEC-2023-69",
                        "Warn: Project is vulnerable to: GHSA-wp72-7hj9-5265 / PYSEC-2023-28",
                        "Warn: Project is vulnerable to: GHSA-wqxf-447m-6f5f",
                        "Warn: Project is vulnerable to: GHSA-wv8q-4f85-2p8p",
                        "Warn: Project is vulnerable to: GHSA-x422-6qhv-p29g / PYSEC-2023-68",
                        "Warn: Project is vulnerable to: GHSA-xg73-94fp-g449",
                        "Warn: Project is vulnerable to: GHSA-fpfv-jqm9-f5jm",
                        "Warn: Project is vulnerable to: GHSA-8gq9-2x98-w8hf",
                        "Warn: Project is vulnerable to: GHSA-9wx4-h78v-vm56",
                        "Warn: Project is vulnerable to: GHSA-j8r2-6x86-q33q / PYSEC-2023-74",
                        "Warn: Project is vulnerable to: GHSA-jxfp-4rvq-9h9m",
                        "Warn: Project is vulnerable to: PYSEC-2023-102",
                        "Warn: Project is vulnerable to: PYSEC-2023-114",
                        "Warn: Project is vulnerable to: GHSA-2m57-hf25-phgg",
                        "Warn: Project is vulnerable to: GHSA-rrm6-wvj7-cwh2 / PYSEC-2023-87",
                        "Warn: Project is vulnerable to: GHSA-34jh-p97f-mpxf",
                        "Warn: Project is vulnerable to: GHSA-g4mx-q9vg-27p4 / PYSEC-2023-212",
                        "Warn: Project is vulnerable to: GHSA-v845-jxx5-vc9f / PYSEC-2023-192",
                        "Warn: Project is vulnerable to: GHSA-2g68-c3qc-8985",
                        "Warn: Project is vulnerable to: GHSA-hrfv-mqp8-q5rw / PYSEC-2023-221",
                        "Warn: Project is vulnerable to: GHSA-px8h-6qxv-m22q / PYSEC-2023-57",
                        "Warn: Project is vulnerable to: GHSA-xg9f-g7g7-2323 / PYSEC-2023-58",
                        "Warn: Project is vulnerable to: PYSEC-2022-203",
                        "Warn: Project is vulnerable to: GHSA-jfmj-5v4g-7637",
                        "Warn: Project is vulnerable to: GHSA-4jrv-ppp4-jm57",
                        "Warn: Project is vulnerable to: GHSA-5mg8-w23w-74h3",
                        "Warn: Project is vulnerable to: GHSA-7g45-4rm6-3mm3",
                        "Warn: Project is vulnerable to: GHSA-4gg5-vx3j-xwc7",
                        "Warn: Project is vulnerable to: GHSA-735f-pc8j-v9w8",
                        "Warn: Project is vulnerable to: GHSA-g5ww-5jh7-63cx",
                        "Warn: Project is vulnerable to: GHSA-h4h5-3hr4-j3g2",
                        "Warn: Project is vulnerable to: GHSA-78wr-2p64-hpwj",
                        "Warn: Project is vulnerable to: GHSA-gwrp-pvrq-jmwv",
                        "Warn: Project is vulnerable to: GHSA-7r82-7xv7-xcpj",
                        "Warn: Project is vulnerable to: GHSA-288c-cq4h-88gq",
                        "Warn: Project is vulnerable to: GHSA-3x8x-79m2-3w2w",
                        "Warn: Project is vulnerable to: GHSA-57j2-w4cx-62h2",
                        "Warn: Project is vulnerable to: GHSA-jjjh-jjxp-wpff",
                        "Warn: Project is vulnerable to: GHSA-rgv9-q543-rqg4",
                        "Warn: Project is vulnerable to: GHSA-77rm-9x9h-xj3g",
                        "Warn: Project is vulnerable to: GHSA-wrvw-hg22-4m67",
                        "Warn: Project is vulnerable to: GHSA-f94m-mqhr-mc29",
                        "Warn: Project is vulnerable to: GHSA-q8xj-8xg3-w432",
                        "Warn: Project is vulnerable to: GHSA-cj7v-27pg-wf7q",
                        "Warn: Project is vulnerable to: GHSA-hmr7-m48g-48f6",
                        "Warn: Project is vulnerable to: GHSA-qh8g-58pp-2wxh",
                        "Warn: Project is vulnerable to: GHSA-26vr-8j45-3r4w",
                        "Warn: Project is vulnerable to: GHSA-7vx9-xjhr-rw6h",
                        "Warn: Project is vulnerable to: GHSA-86wm-rrjm-8wh8",
                        "Warn: Project is vulnerable to: GHSA-g8m5-722r-8whq",
                        "Warn: Project is vulnerable to: GHSA-h2f4-v4c4-6wx4",
                        "Warn: Project is vulnerable to: GHSA-m394-8rww-3jr7",
                        "Warn: Project is vulnerable to: GHSA-m6cp-vxjx-65j6",
                        "Warn: Project is vulnerable to: GHSA-p26g-97m4-6q7c",
                        "Warn: Project is vulnerable to: GHSA-qw69-rqj8-6qw8",
                        "Warn: Project is vulnerable to: GHSA-r28m-g6j9-r2h5",
                        "Warn: Project is vulnerable to: GHSA-xc67-hjx6-cgg6",
                        "Warn: Project is vulnerable to: GHSA-3mc7-4q67-w48m",
                        "Warn: Project is vulnerable to: GHSA-98wm-3w3q-mw94",
                        "Warn: Project is vulnerable to: GHSA-9w3m-gqgf-c4p9",
                        "Warn: Project is vulnerable to: GHSA-c4r9-r8fh-9vj2",
                        "Warn: Project is vulnerable to: GHSA-hhhw-99gj-p3c3",
                        "Warn: Project is vulnerable to: GHSA-mjmj-j48q-9wg2",
                        "Warn: Project is vulnerable to: GHSA-rvwf-54qp-4r6v",
                        "Warn: Project is vulnerable to: GHSA-w37g-rhq8-7m4j",
                        "Warn: Project is vulnerable to: GHSA-mvr2-9pj6-7w5j",
                        "Warn: Project is vulnerable to: GHSA-973x-65j7-xcf4",
                        "Warn: Project is vulnerable to: GHSA-5jpm-x58v-624v",
                        "Warn: Project is vulnerable to: GHSA-xpw8-rcwv-8f8p",
                        "Warn: Project is vulnerable to: GHSA-r7pg-v2c8-mfg3",
                        "Warn: Project is vulnerable to: GHSA-rhrv-645h-fjfh",
                        "Warn: Project is vulnerable to: GHSA-4265-ccf5-phj5",
                        "Warn: Project is vulnerable to: GHSA-4g9r-vxhx-9pgx",
                        "Warn: Project is vulnerable to: GHSA-cgwf-w82q-5jrr",
                        "Warn: Project is vulnerable to: GHSA-2jc4-r94c-rp7h",
                        "Warn: Project is vulnerable to: GHSA-7286-pgfv-vxvh",
                        "Warn: Project is vulnerable to: GHSA-r978-9m6m-6gm6",
                        "Warn: Project is vulnerable to: GHSA-55g7-9cwv-5qfv",
                        "Warn: Project is vulnerable to: GHSA-crh6-fp67-6883",
                        "Warn: Project is vulnerable to: GHSA-v88g-cgmw-v5xw",
                        "Warn: Project is vulnerable to: GHSA-93q8-gq69-wqmw",
                        "Warn: Project is vulnerable to: GHSA-qwcr-r2fm-qrc7",
                        "Warn: Project is vulnerable to: GHSA-grv7-fg5c-xmjg",
                        "Warn: Project is vulnerable to: GHSA-x9w5-v3q2-3rhw",
                        "Warn: Project is vulnerable to: GHSA-pxg6-pf52-xh8x",
                        "Warn: Project is vulnerable to: GHSA-36jr-mh4h-2g58",
                        "Warn: Project is vulnerable to: GHSA-w573-4hg7-7wgq",
                        "Warn: Project is vulnerable to: GHSA-f6v4-cf5j-vf3w",
                        "Warn: Project is vulnerable to: GHSA-434g-2637-qmqr",
                        "Warn: Project is vulnerable to: GHSA-49q7-c7j4-3p7m",
                        "Warn: Project is vulnerable to: GHSA-977x-g7h5-7qgw",
                        "Warn: Project is vulnerable to: GHSA-f7q4-pwc6-w24p",
                        "Warn: Project is vulnerable to: GHSA-fc9h-whq2-v747",
                        "Warn: Project is vulnerable to: GHSA-4gmj-3p3h-gm8h",
                        "Warn: Project is vulnerable to: GHSA-qw6h-vgh9-j6wx",
                        "Warn: Project is vulnerable to: GHSA-jchw-25xp-jwwc",
                        "Warn: Project is vulnerable to: GHSA-cxjh-pqwp-8mfp",
                        "Warn: Project is vulnerable to: GHSA-8r6j-v8pm-fqw3",
                        "Warn: Project is vulnerable to: MAL-2023-462",
                        "Warn: Project is vulnerable to: GHSA-9pv7-vfvm-6vr7",
                        "Warn: Project is vulnerable to: GHSA-vfrc-7r7c-w9mx",
                        "Warn: Project is vulnerable to: GHSA-7wwv-vh3v-89cq",
                        "Warn: Project is vulnerable to: GHSA-c7qv-q95q-8v27",
                        "Warn: Project is vulnerable to: GHSA-78xj-cgh5-2h22",
                        "Warn: Project is vulnerable to: GHSA-2p57-rm9w-gvfp",
                        "Warn: Project is vulnerable to: GHSA-hhhv-q57g-882q",
                        "Warn: Project is vulnerable to: GHSA-wgfq-7857-4jcc",
                        "Warn: Project is vulnerable to: GHSA-76p3-8jx3-jpfq",
                        "Warn: Project is vulnerable to: GHSA-3rfm-jhwj-7488",
                        "Warn: Project is vulnerable to: GHSA-hhq3-ff78-jv3g",
                        "Warn: Project is vulnerable to: GHSA-952p-6rrq-rcjv",
                        "Warn: Project is vulnerable to: GHSA-rp65-9cf3-cjxr",
                        "Warn: Project is vulnerable to: GHSA-9wv6-86v2-598j",
                        "Warn: Project is vulnerable to: GHSA-87hq-q4gp-9wr4 / GHSA-wgrm-67xf-hhpq",
                        "Warn: Project is vulnerable to: GHSA-wjc4-73q6-gv3m",
                        "Warn: Project is vulnerable to: GHSA-7fh5-64p2-3v2j",
                        "Warn: Project is vulnerable to: GHSA-wvhm-4hhf-97x9",
                        "Warn: Project is vulnerable to: GHSA-h4hr-7fg3-h35w",
                        "Warn: Project is vulnerable to: GHSA-gj77-59wh-66hg",
                        "Warn: Project is vulnerable to: GHSA-hqhp-5p83-hx96",
                        "Warn: Project is vulnerable to: GHSA-3949-f494-cm99",
                        "Warn: Project is vulnerable to: GHSA-gcx4-mw62-g8wm",
                        "Warn: Project is vulnerable to: GHSA-rjqq-98f6-6j3r",
                        "Warn: Project is vulnerable to: GHSA-mjxr-4v3x-q3m4",
                        "Warn: Project is vulnerable to: GHSA-cgfm-xwp7-2cvr",
                        "Warn: Project is vulnerable to: GHSA-rm97-x556-q36h",
                        "Warn: Project is vulnerable to: GHSA-c2qf-rxjj-qqgw",
                        "Warn: Project is vulnerable to: GHSA-m6fv-jmcg-4jfg",
                        "Warn: Project is vulnerable to: GHSA-cm22-4g7w-348p",
                        "Warn: Project is vulnerable to: GHSA-vx3p-948g-6vhq",
                        "Warn: Project is vulnerable to: GHSA-3jfq-g458-7qm9",
                        "Warn: Project is vulnerable to: GHSA-r628-mhmh-qjhw",
                        "Warn: Project is vulnerable to: GHSA-9r2w-394v-53qc",
                        "Warn: Project is vulnerable to: GHSA-5955-9wpr-37jh",
                        "Warn: Project is vulnerable to: GHSA-qq89-hq3f-393p",
                        "Warn: Project is vulnerable to: GHSA-f5x3-32g6-xq36",
                        "Warn: Project is vulnerable to: GHSA-4wf5-vphf-c2xc",
                        "Warn: Project is vulnerable to: GHSA-72xf-g2v4-qvf3",
                        "Warn: Project is vulnerable to: GHSA-w5p7-h5w8-2hfq",
                        "Warn: Project is vulnerable to: GHSA-7p7h-4mm5-852v",
                        "Warn: Project is vulnerable to: GHSA-fhg7-m89q-25r3",
                        "Warn: Project is vulnerable to: GHSA-4vvj-4cpr-p986",
                        "Warn: Project is vulnerable to: GHSA-wr3j-pwj9-hqq6",
                        "Warn: Project is vulnerable to: GHSA-3h5v-q93c-6h6q",
                        "Warn: Project is vulnerable to: GHSA-3ww4-gg4f-jr7f",
                        "Warn: Project is vulnerable to: GHSA-5cpq-8wj7-hf2v",
                        "Warn: Project is vulnerable to: GHSA-6vqw-3v5j-54x4",
                        "Warn: Project is vulnerable to: GHSA-9v9h-cgj8-h64p",
                        "Warn: Project is vulnerable to: GHSA-jfhm-5ghh-2f97 / PYSEC-2023-254",
                        "Warn: Project is vulnerable to: GHSA-jm77-qphf-c4w8",
                        "Warn: Project is vulnerable to: GHSA-v8gr-m533-ghj9",
                        "Warn: Project is vulnerable to: GHSA-45pg-36p6-83v9",
                        "Warn: Project is vulnerable to: GHSA-5wvp-7f3h-6wmm / PYSEC-2023-238",
                        "Warn: Project is vulnerable to: GHSA-mr82-8j83-vxmv",
                        "Warn: Project is vulnerable to: GHSA-753j-mpmx-qq6g",
                        "Warn: Project is vulnerable to: GHSA-hj3f-6gcp-jg8j / PYSEC-2023-75",
                        "Warn: Project is vulnerable to: GHSA-qppv-j76h-2rpx",
                        "Warn: Project is vulnerable to: GHSA-w235-7p84-xx57"
                    ],
                    "score": 0,
                    "reason": "223 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/mlflow/mlflow/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\nMLflow and its community take security bugs seriously. We appreciate efforts to improve the security of MLflow\nand follow the [GitHub coordinated disclosure of security vulnerabilities](https://docs.github.com/en/code-security/security-advisories/about-coordinated-disclosure-of-security-vulnerabilities#about-reporting-and-disclosing-vulnerabilities-in-projects-on-github)\nfor responsible disclosure and prompt mitigation. We are committed to working with security researchers to\nresolve the vulnerabilities they discover.\n\n## Supported Versions\n\nThe latest version of MLflow has continued support. If a critical vulnerability is found in the current version\nof MLflow, we may opt to backport patches to previous versions.\n\n## Reporting a Vulnerability\n\nWhen finding a security vulnerability in MLflow, please perform the following actions:\n\n- [Open an issue](https://github.com/mlflow/mlflow/issues/new?assignees=&labels=bug&template=bug_report_template.md&title=%5BBUG%5D%20Security%20Vulnerability) on the MLflow repository. Ensure that you use `[BUG] Security Vulnerability` as the title and _do not_ mention any vulnerability details in the issue post.\n- Send a notification [email](mailto:mlflow-oss-maintainers@googlegroups.com) to `mlflow-oss-maintainers@googlegroups.com` that contains, at a minimum:\n  - The link to the filed issue stub.\n  - Your GitHub handle.\n  - Detailed information about the security vulnerability, evidence that supports the relevance of the finding and any reproducibility instructions for independent confirmation.\n\nThis first stage of reporting is to ensure that a rapid validation can occur without wasting the time and effort of a reporter. Future communication and vulnerability resolution will be conducted after validating\nthe veracity of the reported issue.\n\nAn MLflow maintainer will, after validating the report:\n\n- Acknowledge the [bug](ISSUE_POLICY.md#bug-reports) during [triage](ISSUE_TRIAGE.rst)\n- Mark the issue as `priority/critical-urgent`\n- Open a draft [GitHub Security Advisory](https://docs.github.com/en/code-security/security-advisories/creating-a-security-advisory)\n  to discuss the vulnerability details in private.\n\nThe private Security Advisory will be used to confirm the issue, prepare a fix, and publicly disclose it after the fix has been released.\n",
        "project_all_labels": [
            "2.0",
            "Acknowledged",
            "area/artifacts",
            "area/build",
            "area/deployments",
            "area/docker",
            "area/docs",
            "area/examples",
            "area/model-registry",
            "area/models",
            "area/projects",
            "area/recipes",
            "area/scoring",
            "area/server-infra",
            "area/sqlalchemy",
            "area/tracking",
            "area/uiux",
            "area/windows",
            "auth",
            "autoformat",
            "bug",
            "dependencies",
            "do-not-merge",
            "enable-dev-tests",
            "enhancement",
            "fail-fast",
            "gateway",
            "gateway-migration",
            "good first issue",
            "has-closing-pr",
            "help wanted",
            "integrations/azure",
            "integrations/databricks",
            "integrations/pytorch",
            "integrations/sagemaker",
            "java",
            "javascript",
            "language/java",
            "language/new",
            "language/r",
            "LGTM",
            "needs author feedback",
            "needs committer feedback",
            "needs design",
            "needs review",
            "needs-decision",
            "only-latest",
            "patch-2.11.2",
            "patch-2.11.4",
            "patch-2.12.1",
            "patch-2.12.2",
            "patch-2.12.3",
            "patch-2.13.1",
            "patch-2.13.2",
            "patch-2.13.3",
            "patch-2.14.1",
            "patch-2.14.2",
            "patch-2.14.3",
            "patch-2.14.4",
            "patch-2.15.0",
            "patch-2.15.1",
            "patch-2.15.2",
            "patch-2.16.1",
            "patch-2.16.2",
            "patch-2.16.3",
            "patch-2.17.0",
            "patch-2.17.1",
            "patch-2.17.2",
            "priority/awaiting-more-evidence",
            "priority/backlog",
            "priority/critical-urgent",
            "priority/important-longterm",
            "priority/important-soon",
            "py39",
            "python",
            "rn/breaking-change",
            "rn/bug-fix",
            "rn/documentation",
            "rn/feature",
            "rn/none",
            "stale",
            "UIUX LGTM"
        ],
        "README_content": "=============================================\nMLflow: A Machine Learning Lifecycle Platform\n=============================================\n\nMLflow is a platform to streamline machine learning development, including tracking experiments, packaging code\ninto reproducible runs, and sharing and deploying models. MLflow offers a set of lightweight APIs that can be\nused with any existing machine learning application or library (TensorFlow, PyTorch, XGBoost, etc), wherever you\ncurrently run ML code (e.g. in notebooks, standalone applications or the cloud). MLflow's current components are:\n\n* `MLflow Tracking <https://mlflow.org/docs/latest/tracking.html>`_: An API to log parameters, code, and\n  results in machine learning experiments and compare them using an interactive UI.\n* `MLflow Projects <https://mlflow.org/docs/latest/projects.html>`_: A code packaging format for reproducible\n  runs using Conda and Docker, so you can share your ML code with others.\n* `MLflow Models <https://mlflow.org/docs/latest/models.html>`_: A model packaging format and tools that let\n  you easily deploy the same model (from any ML library) to batch and real-time scoring on platforms such as\n  Docker, Apache Spark, Azure ML and AWS SageMaker.\n* `MLflow Model Registry <https://mlflow.org/docs/latest/model-registry.html>`_: A centralized model store, set of APIs, and UI, to collaboratively manage the full lifecycle of MLflow Models.\n\n|docs| |license| |downloads| |slack| |twitter|\n\n.. |docs| image:: https://img.shields.io/badge/docs-latest-success.svg?style=for-the-badge\n    :target: https://mlflow.org/docs/latest/index.html\n    :alt: Latest Docs\n.. |license| image:: https://img.shields.io/badge/license-Apache%202-brightgreen.svg?style=for-the-badge&logo=apache\n    :target: https://github.com/mlflow/mlflow/blob/master/LICENSE.txt\n    :alt: Apache 2 License\n.. |downloads| image:: https://img.shields.io/pypi/dw/mlflow?style=for-the-badge&logo=pypi&logoColor=white\n    :target: https://pepy.tech/project/mlflow\n    :alt: Total Downloads\n.. |slack| image:: https://img.shields.io/badge/slack-@mlflow--users-CF0E5B.svg?logo=slack&logoColor=white&labelColor=3F0E40&style=for-the-badge\n    :target: `Slack`_\n    :alt: Slack\n.. |twitter| image:: https://img.shields.io/twitter/follow/MLflow?style=for-the-badge&labelColor=00ACEE&logo=twitter&logoColor=white\n    :target: https://twitter.com/MLflow\n    :alt: Account Twitter\n\nPackages\n\n+---------------+-------------------------------------------------------------+\n| PyPI          | |pypi-mlflow| |pypi-skinny|                                 |\n+---------------+-------------------------------------------------------------+\n| conda-forge   | |conda-mlflow| |conda-skinny|                               |\n+---------------+-------------------------------------------------------------+\n| CRAN          | |cran-mlflow|                                               |\n+---------------+-------------------------------------------------------------+\n| Maven Central | |maven-client| |maven-parent| |maven-scoring| |maven-spark| |\n+---------------+-------------------------------------------------------------+\n\n.. |pypi-mlflow| image:: https://img.shields.io/pypi/v/mlflow.svg?style=for-the-badge&logo=pypi&logoColor=white&label=mlflow\n    :target: https://pypi.org/project/mlflow/\n    :alt: PyPI - mlflow\n.. |pypi-skinny| image:: https://img.shields.io/pypi/v/mlflow-skinny.svg?style=for-the-badge&logo=pypi&logoColor=white&label=mlflow-skinny\n    :target: https://pypi.org/project/mlflow-skinny/\n    :alt: PyPI - mlflow-skinny\n.. |conda-mlflow| image:: https://img.shields.io/conda/vn/conda-forge/mlflow.svg?style=for-the-badge&logo=anaconda&label=mlflow\n    :target: https://anaconda.org/conda-forge/mlflow\n    :alt: Conda - mlflow\n.. |conda-skinny| image:: https://img.shields.io/conda/vn/conda-forge/mlflow.svg?style=for-the-badge&logo=anaconda&label=mlflow-skinny\n    :target: https://anaconda.org/conda-forge/mlflow-skinny\n    :alt: Conda - mlflow-skinny\n.. |cran-mlflow| image:: https://img.shields.io/cran/v/mlflow.svg?style=for-the-badge&logo=r&label=mlflow\n    :target: https://cran.r-project.org/package=mlflow\n    :alt: CRAN - mlflow\n.. |maven-client| image:: https://img.shields.io/maven-central/v/org.mlflow/mlflow-parent.svg?style=for-the-badge&logo=apache-maven&label=mlflow-client\n    :target: https://mvnrepository.com/artifact/org.mlflow/mlflow-client\n    :alt: Maven Central - mlflow-client\n.. |maven-parent| image:: https://img.shields.io/maven-central/v/org.mlflow/mlflow-parent.svg?style=for-the-badge&logo=apache-maven&label=mlflow-parent\n    :target: https://mvnrepository.com/artifact/org.mlflow/mlflow-parent\n    :alt: Maven Central - mlflow-parent\n.. |maven-scoring| image:: https://img.shields.io/maven-central/v/org.mlflow/mlflow-parent.svg?style=for-the-badge&logo=apache-maven&label=mlflow-scoring\n    :target: https://mvnrepository.com/artifact/org.mlflow/mlflow-scoring\n    :alt: Maven Central - mlflow-scoring\n.. |maven-spark| image:: https://img.shields.io/maven-central/v/org.mlflow/mlflow-parent.svg?style=for-the-badge&logo=apache-maven&label=mlflow-spark\n    :target: https://mvnrepository.com/artifact/org.mlflow/mlflow-spark\n    :alt: Maven Central - mlflow-spark\n\n.. _Slack: https://mlflow.org/slack\n\nJob Statuses\n\n|examples| |cross-version-tests| |r-devel| |test-requirements| |stale| |push-images| |slow-tests| |website-e2e|\n\n.. |examples| image:: https://img.shields.io/github/actions/workflow/status/mlflow-automation/mlflow/examples.yml.svg?branch=master&event=schedule&label=Examples&style=for-the-badge&logo=github\n    :target: https://github.com/mlflow-automation/mlflow/actions/workflows/examples.yml?query=workflow%3AExamples+event%3Aschedule\n    :alt: Examples Action Status\n.. |cross-version-tests| image:: https://img.shields.io/github/actions/workflow/status/mlflow-automation/mlflow/cross-version-tests.yml.svg?branch=master&event=schedule&label=Cross%20version%20tests&style=for-the-badge&logo=github\n    :target: https://github.com/mlflow-automation/mlflow/actions/workflows/cross-version-tests.yml?query=workflow%3A%22Cross+version+tests%22+event%3Aschedule\n.. |r-devel| image:: https://img.shields.io/github/actions/workflow/status/mlflow-automation/mlflow/r.yml.svg?branch=master&event=schedule&label=r-devel&style=for-the-badge&logo=github\n    :target: https://github.com/mlflow-automation/mlflow/actions/workflows/r.yml?query=workflow%3AR+event%3Aschedule\n.. |test-requirements| image:: https://img.shields.io/github/actions/workflow/status/mlflow-automation/mlflow/requirements.yml.svg?branch=master&event=schedule&label=test%20requirements&logo=github&style=for-the-badge\n    :target: https://github.com/mlflow-automation/mlflow/actions/workflows/requirements.yml?query=workflow%3A\"Test+requirements\"+event%3Aschedule\n.. |stale| image:: https://img.shields.io/github/actions/workflow/status/mlflow/mlflow/stale.yml.svg?branch=master&event=schedule&label=stale&logo=github&style=for-the-badge\n    :target: https://github.com/mlflow/mlflow/actions?query=workflow%3AStale+event%3Aschedule\n.. |push-images| image:: https://img.shields.io/github/actions/workflow/status/mlflow/mlflow/push-images.yml.svg?event=release&label=push-images&logo=github&style=for-the-badge\n    :target: https://github.com/mlflow/mlflow/actions/workflows/push-images.yml?query=event%3Arelease\n.. |slow-tests| image:: https://img.shields.io/github/actions/workflow/status/mlflow-automation/mlflow/slow-tests.yml.svg?branch=master&event=schedule&label=slow-tests&logo=github&style=for-the-badge\n    :target: https://github.com/mlflow-automation/mlflow/actions/workflows/slow-tests.yml?query=event%3Aschedule\n.. |website-e2e| image:: https://img.shields.io/github/actions/workflow/status/mlflow/mlflow-website/e2e.yml.svg?branch=main&event=schedule&label=website-e2e&logo=github&style=for-the-badge\n    :target: https://github.com/mlflow/mlflow-website/actions/workflows/e2e.yml?query=event%3Aschedule\n\nInstalling\n----------\nInstall MLflow from PyPI via ``pip install mlflow``\n\nMLflow requires ``conda`` to be on the ``PATH`` for the projects feature.\n\nNightly snapshots of MLflow master are also available `here <https://mlflow-snapshots.s3-us-west-2.amazonaws.com/>`_.\n\nInstall a lower dependency subset of MLflow from PyPI via ``pip install mlflow-skinny``\nExtra dependencies can be added per desired scenario.\nFor example, ``pip install mlflow-skinny pandas numpy`` allows for mlflow.pyfunc.log_model support.\n\nDocumentation\n-------------\nOfficial documentation for MLflow can be found at https://mlflow.org/docs/latest/index.html.\n\nRoadmap\n-------\nThe current MLflow Roadmap is available at https://github.com/mlflow/mlflow/milestone/3. We are\nseeking contributions to all of our roadmap items with the ``help wanted`` label. Please see the\n`Contributing`_ section for more information.\n\nCommunity\n---------\nFor help or questions about MLflow usage (e.g. \"how do I do X?\") see the `docs <https://mlflow.org/docs/latest/index.html>`_\nor `Stack Overflow <https://stackoverflow.com/questions/tagged/mlflow>`_.\n\nTo report a bug, file a documentation issue, or submit a feature request, please open a GitHub issue.\n\nFor release announcements and other discussions, please subscribe to our mailing list (mlflow-users@googlegroups.com)\nor join us on `Slack`_.\n\nRunning a Sample App With the Tracking API\n------------------------------------------\nThe programs in ``examples`` use the MLflow Tracking API. For instance, run::\n\n    python examples/quickstart/mlflow_tracking.py\n\nThis program will use `MLflow Tracking API <https://mlflow.org/docs/latest/tracking.html>`_,\nwhich logs tracking data in ``./mlruns``. This can then be viewed with the Tracking UI.\n\n\nLaunching the Tracking UI\n-------------------------\nThe MLflow Tracking UI will show runs logged in ``./mlruns`` at `<http://localhost:5000>`_.\nStart it with::\n\n    mlflow ui\n\n**Note:** Running ``mlflow ui`` from within a clone of MLflow is not recommended - doing so will\nrun the dev UI from source. We recommend running the UI from a different working directory,\nspecifying a backend store via the ``--backend-store-uri`` option. Alternatively, see\ninstructions for running the dev UI in the `contributor guide <CONTRIBUTING.md>`_.\n\n\nRunning a Project from a URI\n----------------------------\nThe ``mlflow run`` command lets you run a project packaged with a MLproject file from a local path\nor a Git URI::\n\n    mlflow run examples/sklearn_elasticnet_wine -P alpha=0.4\n\n    mlflow run https://github.com/mlflow/mlflow-example.git -P alpha=0.4\n\nSee ``examples/sklearn_elasticnet_wine`` for a sample project with an MLproject file.\n\n\nSaving and Serving Models\n-------------------------\nTo illustrate managing models, the ``mlflow.sklearn`` package can log scikit-learn models as\nMLflow artifacts and then load them again for serving. There is an example training application in\n``examples/sklearn_logistic_regression/train.py`` that you can run as follows::\n\n    $ python examples/sklearn_logistic_regression/train.py\n    Score: 0.666\n    Model saved in run <run-id>\n\n    $ mlflow models serve --model-uri runs:/<run-id>/model\n\n    $ curl -d '{\"dataframe_split\": {\"columns\":[0],\"index\":[0,1],\"data\":[[1],[-1]]}}' -H 'Content-Type: application/json'  localhost:5000/invocations\n\n**Note:** If using MLflow skinny (``pip install mlflow-skinny``) for model serving, additional\nrequired dependencies (namely, ``flask``) will need to be installed for the MLflow server to function.\n\nOfficial MLflow Docker Image\n----------------------------\n\nThe official MLflow Docker image is available on GitHub Container Registry at https://ghcr.io/mlflow/mlflow.\n\n.. code-block:: shell\n\n    export CR_PAT=YOUR_TOKEN\n    echo $CR_PAT | docker login ghcr.io -u USERNAME --password-stdin\n    # Pull the latest version\n    docker pull ghcr.io/mlflow/mlflow\n    # Pull 2.2.1\n    docker pull ghcr.io/mlflow/mlflow:v2.2.1\n\nContributing\n------------\nWe happily welcome contributions to MLflow. We are also seeking contributions to items on the\n`MLflow Roadmap <https://github.com/mlflow/mlflow/milestone/3>`_. Please see our\n`contribution guide <CONTRIBUTING.md>`_ to learn more about contributing to MLflow.\n\nCore Members\n------------\n\nMLflow is currently maintained by the following core members with significant contributions from hundreds of exceptionally talented community members.\n\n- `Ben Wilson <https://github.com/BenWilson2>`_\n- `Corey Zumar <https://github.com/dbczumar>`_\n- `Daniel Lok <https://github.com/daniellok-db>`_\n- `Gabriel Fu <https://github.com/gabrielfu>`_\n- `Harutaka Kawamura <https://github.com/harupy>`_\n- `Serena Ruan <https://github.com/serena-ruan>`_\n- `Weichen Xu <https://github.com/WeichenXu123>`_\n- `Yuki Watanabe <https://github.com/B-Step62>`_\n",
        "num_commits": 6682,
        "project_age_days": 2338,
        "project_created_at": "2018-06-05",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-30",
        "num_contributors": 455,
        "num_pull": 9370,
        "num_issues": 13292,
        "num_opening_issue": 1663,
        "project_size(kB)": 556184,
        "num_stargazers": 18636,
        "num_watchers": 18636,
        "num_forks": 4221,
        "num_subscribers": 303,
        "SecurityPolicy_created_at": "2022-02-11 06:57:43",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "d00d8b9fee09d4459e09ef4e3ef903ab3a1a06fb",
                "url": "https://github.com/mlflow/mlflow/commit/d00d8b9fee09d4459e09ef4e3ef903ab3a1a06fb",
                "date": "2023-10-31 02:18:06"
            },
            {
                "commit_id": "062aa18bd3c6c734447efd79eb55d030ec68d9c4",
                "url": "https://github.com/mlflow/mlflow/commit/062aa18bd3c6c734447efd79eb55d030ec68d9c4",
                "date": "2023-03-24 06:11:19"
            },
            {
                "commit_id": "2201d3ca729e60cf8addf45f1abe4f5d2db2cae2",
                "url": "https://github.com/mlflow/mlflow/commit/2201d3ca729e60cf8addf45f1abe4f5d2db2cae2",
                "date": "2023-03-24 06:04:49"
            },
            {
                "commit_id": "01252f1270ddcb63bd92c07f161d218a8f380a0b",
                "url": "https://github.com/mlflow/mlflow/commit/01252f1270ddcb63bd92c07f161d218a8f380a0b",
                "date": "2022-12-01 04:35:15"
            },
            {
                "commit_id": "2c373dd9aeabb1d81920aa9abc4f148e51a03768",
                "url": "https://github.com/mlflow/mlflow/commit/2c373dd9aeabb1d81920aa9abc4f148e51a03768",
                "date": "2022-11-02 15:14:00"
            },
            {
                "commit_id": "a49d7b3a4292980f15cc840408d825fec1a2423b",
                "url": "https://github.com/mlflow/mlflow/commit/a49d7b3a4292980f15cc840408d825fec1a2423b",
                "date": "2022-04-20 07:35:01"
            },
            {
                "commit_id": "1723d932311e7ef982ae2590d24ae8699370ed78",
                "url": "https://github.com/mlflow/mlflow/commit/1723d932311e7ef982ae2590d24ae8699370ed78",
                "date": "2022-02-11 06:57:43"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email_issue",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "httpie/cli",
        "project_url": "https://github.com/httpie/cli",
        "SSF": {
            "date": "2024-10-29T21:50:36+07:00",
            "repo": {
                "name": "github.com/httpie/cli",
                "commit": "50e1564600eaca3ff99ffd7a7f707f564da3af48"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 4.6,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'master'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 3,
                    "reason": "5 out of 14 merged PRs checked by a CI test -- score normalized to 3",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 3,
                    "reason": "Found 9/26 approved changesets -- score normalized to 3",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: httpie contributor org/company found, fal-ai contributor org/company found, 3DprintFIT contributor org/company found, fedora-python contributor org/company found, nodesecurity contributor org/company found, jupyterlab contributor org/company found, python-organizers contributor org/company found, reizio contributor org/company found, fsspec contributor org/company found, adobe contributor org/company found, pyvec contributor org/company found, devassistant contributor org/company found, pytest-dev contributor org/company found, code4rena contributor org/company found, python contributor org/company found, cvut contributor org/company found, admesh contributor org/company found, sclorg contributor org/company found, red hat fit ctu contributor org/company found, hapijs contributor org/company found, conda-forge contributor org/company found, jazzband contributor org/company found, pyldap contributor org/company found, betamaxpy contributor org/company found, LinuxDays contributor org/company found, slic3r contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 26 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: BSD 3-Clause \"New\" or \"Revised\" License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 1,
                    "reason": "1 commit(s) and 1 issue activity found in the last 90 days -- score normalized to 1",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/benchmark.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/benchmark.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/benchmark.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/benchmark.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/benchmark.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/benchmark.yml:50: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/benchmark.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/code-style.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/code-style.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/code-style.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/code-style.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/content.yml:10: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/content.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/content.yml:11: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/content.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/content.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/content.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/coverage.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/coverage.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/coverage.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/coverage.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docs-check-markdown.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/docs-check-markdown.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/docs-check-markdown.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/docs-check-markdown.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-brew.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-brew.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-brew.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-brew.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-choco.yml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-choco.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-linux-standalone.yml:23: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-linux-standalone.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-linux-standalone.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-linux-standalone.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-linux-standalone.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-linux-standalone.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-linux-standalone.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-linux-standalone.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-linux-standalone.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-linux-standalone.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-linux-standalone.yml:60: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-linux-standalone.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-linux-standalone.yml:70: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-linux-standalone.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-pypi.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-pypi.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-pypi.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-pypi.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/release-snap.yml:29: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-snap.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-snap.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-snap.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release-snap.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/release-snap.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/stale.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/stale.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test-package-linux-snap.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/test-package-linux-snap.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/test-package-linux-snap.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/test-package-linux-snap.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test-package-mac-brew.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/test-package-mac-brew.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/tests.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/httpie/cli/tests.yml/master?enable=pin",
                        "Warn: containerImage not pinned by hash: extras/packaging/linux/Dockerfile:3: pin your Docker image by updating ubuntu:18.04 to ubuntu:18.04@sha256:152dc042452c496007f07ca9127571cb9c29697f42acbfad72324b2bb2e43c98",
                        "Warn: pipCommand not pinned by hash: extras/packaging/linux/Dockerfile:26",
                        "Warn: pipCommand not pinned by hash: extras/packaging/linux/Dockerfile:27",
                        "Warn: pipCommand not pinned by hash: extras/packaging/linux/Dockerfile:28",
                        "Warn: pipCommand not pinned by hash: .github/workflows/benchmark.yml:24",
                        "Warn: pipCommand not pinned by hash: .github/workflows/docs-deploy.yml:21",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release-linux-standalone.yml:54",
                        "Info:   0 out of  26 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of  10 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   1 containerImage dependencies pinned",
                        "Info:   0 out of   6 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 14 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact 3.2.2 not signed: https://api.github.com/repos/httpie/cli/releases/103665121",
                        "Warn: release artifact 3.2.1 not signed: https://api.github.com/repos/httpie/cli/releases/66196395",
                        "Warn: release artifact 3.2.0 not signed: https://api.github.com/repos/httpie/cli/releases/66163753",
                        "Warn: release artifact 3.1.0 not signed: https://api.github.com/repos/httpie/cli/releases/61214710",
                        "Warn: release artifact 3.2.2 does not have provenance: https://api.github.com/repos/httpie/cli/releases/103665121",
                        "Warn: release artifact 3.2.1 does not have provenance: https://api.github.com/repos/httpie/cli/releases/66196395",
                        "Warn: release artifact 3.2.0 does not have provenance: https://api.github.com/repos/httpie/cli/releases/66163753",
                        "Warn: release artifact 3.1.0 does not have provenance: https://api.github.com/repos/httpie/cli/releases/61214710"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/code-style.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/content.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/coverage.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/docs-check-markdown.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/docs-deploy.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release-brew.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release-choco.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release-linux-standalone.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release-pypi.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/release-snap.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/test-package-linux-snap.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/test-package-mac-brew.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/tests.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/httpie/cli/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security policy\n\n## Reporting a vulnerability\n\nWhen you identify a vulnerability in HTTPie, please report it privately using one of the following channels:\n\n- Email to [`security@httpie.io`](mailto:security@httpie.io)\n- Report on [huntr.dev](https://huntr.dev/)\n\nIn addition to the description of the vulnerability, include the following information:\n\n- A short reproducer to verify it (it can be a small HTTP server, shell script, docker image, etc.)\n- Your deemed severity level of the vulnerability (`LOW`/`MEDIUM`/`HIGH`/`CRITICAL`)\n- [CWE](https://cwe.mitre.org/) ID, if available.\n",
        "project_all_labels": [
            "awaiting-response",
            "benchmark",
            "blocked by upstream",
            "bug",
            "cli",
            "deferred",
            "dependencies",
            "docs",
            "duplicate",
            "enhancement",
            "error-messages",
            "extensions",
            "good first issue",
            "help wanted",
            "invalid",
            "low-priority",
            "needs product design",
            "new",
            "not-a-bug",
            "packaging",
            "performance",
            "planned",
            "plugins",
            "project-structure",
            "question",
            "sessions",
            "stale",
            "testing",
            "website",
            "windows",
            "wontfix"
        ],
        "README_content": "<h2 align=\"center\">\n    <a href=\"https://httpie.io\" target=\"blank_\">\n        <img height=\"100\" alt=\"HTTPie\" src=\"https://raw.githubusercontent.com/httpie/cli/master/docs/httpie-logo.svg\" />\n    </a>\n    <br>\n    HTTPie CLI: human-friendly HTTP client for the API era\n</h2>\n\n<div align=\"center\">\n\n[![HTTPie for Desktop](https://img.shields.io/static/v1?label=HTTPie&message=Desktop&color=4B78E6)](https://httpie.io/product)\n[![](https://img.shields.io/static/v1?label=HTTPie&message=Web%20%26%20Mobile&color=73DC8C)](https://httpie.io/app)\n[![](https://img.shields.io/static/v1?label=HTTPie&message=CLI&color=FA9BFA)](https://httpie.io/cli)\n[![Twitter](https://img.shields.io/twitter/follow/httpie?style=flat&color=%234B78E6&logoColor=%234B78E6)](https://twitter.com/httpie)\n[![Chat](https://img.shields.io/discord/725351238698270761?style=flat&label=Chat%20on%20Discord&color=%23FA9BFA)](https://httpie.io/discord)\n\n</div>\n\n\n<div align=\"center\">\n\n[![Docs](https://img.shields.io/badge/stable%20docs-httpie.io%2Fdocs%2Fcli-brightgreen?style=flat&color=%2373DC8C&label=Docs)](https://httpie.org/docs/cli)\n[![Latest version](https://img.shields.io/pypi/v/httpie.svg?style=flat&label=Latest&color=%234B78E6&logo=&logoColor=white)](https://pypi.python.org/pypi/httpie)\n[![Build](https://img.shields.io/github/actions/workflow/status/httpie/cli/tests.yml?branch=master&color=%23FA9BFA&label=Build)](https://github.com/httpie/cli/actions)\n[![Coverage](https://img.shields.io/codecov/c/github/httpie/cli?style=flat&label=Coverage&color=%2373DC8C)](https://codecov.io/gh/httpie/cli)\n[![PyPi downloads](https://img.shields.io/pepy/dt/httpie?style=flat&label=Downloads%20from%20PyPi%20only&color=4B78E6)](https://www.pepy.tech/projects/httpie)\n\n</div>\n\nHTTPie (pronounced _aitch-tee-tee-pie_) is a command-line HTTP client.\nIts goal is to make CLI interaction with web services as human-friendly as possible.\nHTTPie is designed for testing, debugging, and generally interacting with APIs & HTTP servers.\nThe `http` & `https` commands allow for creating and sending arbitrary HTTP requests.\nThey use simple and natural syntax and provide formatted and colorized output.\n\n<div align=\"center\">\n\n<img src=\"https://raw.githubusercontent.com/httpie/cli/master/docs/httpie-animation.gif\" alt=\"HTTPie in action\" width=\"100%\"/>\n\n\n</div>\n\n\n\n\n## We lost 54k GitHub stars\n\nPlease note we recently accidentally made this repo private for a moment, and GitHub deleted our community that took a decade to build. Read the full story here: https://httpie.io/blog/stardust\n\n![](docs/stardust.png)\n\n\n## Getting started\n\n- [Installation instructions ](https://httpie.io/docs#installation)\n- [Full documentation ](https://httpie.io/docs)\n\n## Features\n\n- Expressive and intuitive syntax\n- Formatted and colorized terminal output\n- Built-in JSON support\n- Forms and file uploads\n- HTTPS, proxies, and authentication\n- Arbitrary request data\n- Custom headers\n- Persistent sessions\n- `wget`-like downloads\n\n[See all features ](https://httpie.io/docs)\n\n## Examples\n\nHello World:\n\n```bash\nhttps httpie.io/hello\n```\n\nCustom [HTTP method](https://httpie.io/docs#http-method), [HTTP headers](https://httpie.io/docs#http-headers) and [JSON](https://httpie.io/docs#json) data:\n\n```bash\nhttp PUT pie.dev/put X-API-Token:123 name=John\n```\n\nBuild and print a request without sending it using [offline mode](https://httpie.io/docs/cli/offline-mode):\n\n```bash\nhttp --offline pie.dev/post hello=offline\n```\n\nUse [GitHub API](https://developer.github.com/v3/issues/comments/#create-a-comment) to post a comment on an [Issue](https://github.com/httpie/cli/issues/83) with [authentication](https://httpie.io/docs#authentication):\n\n```bash\nhttp -a USERNAME POST https://api.github.com/repos/httpie/cli/issues/83/comments body='HTTPie is awesome! :heart:'\n```\n\n[See more examples ](https://httpie.io/docs#examples)\n\n## Community & support\n\n- Visit the [HTTPie website](https://httpie.io) for full documentation and useful links.\n- Join our [Discord server](https://httpie.io/discord) is to ask questions, discuss features, and for general API chat.\n- Tweet at [@httpie](https://twitter.com/httpie) on Twitter.\n- Use [StackOverflow](https://stackoverflow.com/questions/tagged/httpie) to ask questions and include a `httpie` tag.\n- Create [GitHub Issues](https://github.com/httpie/cli/issues) for bug reports and feature requests.\n- Subscribe to the [HTTPie newsletter](https://httpie.io) for occasional updates.\n\n## Contributing\n\nHave a look through existing [Issues](https://github.com/httpie/cli/issues) and [Pull Requests](https://github.com/httpie/cli/pulls) that you could help with. If you'd like to request a feature or report a bug, please [create a GitHub Issue](https://github.com/httpie/cli/issues) using one of the templates provided.\n\n[See contribution guide ](https://github.com/httpie/cli/blob/master/CONTRIBUTING.md)\n",
        "num_commits": 1787,
        "project_age_days": 4630,
        "project_created_at": "2012-02-25",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-28",
        "num_contributors": 149,
        "num_pull": 615,
        "num_issues": 1491,
        "num_opening_issue": 182,
        "project_size(kB)": 6898,
        "num_stargazers": 33780,
        "num_watchers": 33780,
        "num_forks": 3676,
        "num_subscribers": 85,
        "SecurityPolicy_created_at": "2022-03-07 20:29:48",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "59d9e928f8a6de4bd78e9e11adbabf9de9207d45",
                "url": "https://github.com/httpie/cli/commit/59d9e928f8a6de4bd78e9e11adbabf9de9207d45",
                "date": "2022-03-07 20:29:48"
            },
            {
                "commit_id": "0a873172c95404b43387c1a4302eecc1cdb8379e",
                "url": "https://github.com/httpie/cli/commit/0a873172c95404b43387c1a4302eecc1cdb8379e",
                "date": "2022-03-07 20:29:48"
            },
            {
                "commit_id": "395914fb4d439ce5220a44af231d3e16bf3fe18d",
                "url": "https://github.com/httpie/cli/commit/395914fb4d439ce5220a44af231d3e16bf3fe18d",
                "date": "2022-03-07 20:29:48"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email_external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "mirahezebots/mirahezebots",
        "project_url": "https://github.com/mirahezebots/mirahezebots",
        "SSF": {
            "date": "2024-10-30T00:40:44+07:00",
            "repo": {
                "name": "github.com/mirahezebots/mirahezebots",
                "commit": "ba3264385501a421882c5cb2461ae2f14b51035e"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 4.9,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'dev'",
                        "Info: 'force pushes' disabled on branch 'dev'",
                        "Warn: branch 'dev' does not require approvers",
                        "Warn: codeowners review is not required on branch 'dev'",
                        "Info: status check found to merge onto on branch 'dev'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "0 out of 27 merged PRs checked by a CI test -- score normalized to 0",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 0/3 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: wiki-ai contributor org/company found, Test-Wiki contributor org/company found, FOSSBots contributor org/company found, sysadmin @wikitideorg contributor org/company found, hackforla contributor org/company found, jackson street capital contributor org/company found, MirahezeBots contributor org/company found, miraheze / @wikimedia contributor org/company found, Wikiopen contributor org/company found, volunteer/freelance developer contributor org/company found, miraheze contributor org/company found, bitbot-irc contributor org/company found, quirc-bot contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 13 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": [
                        "Warn: Repository is archived."
                    ],
                    "score": 0,
                    "reason": "project is archived",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/FOSSBots/MirahezeBots/codeql-analysis.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:44: update your workflow using https://app.stepsecurity.io/secureworkflow/FOSSBots/MirahezeBots/codeql-analysis.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/FOSSBots/MirahezeBots/codeql-analysis.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:51: update your workflow using https://app.stepsecurity.io/secureworkflow/FOSSBots/MirahezeBots/codeql-analysis.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:62: update your workflow using https://app.stepsecurity.io/secureworkflow/FOSSBots/MirahezeBots/codeql-analysis.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:76: update your workflow using https://app.stepsecurity.io/secureworkflow/FOSSBots/MirahezeBots/codeql-analysis.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/dependabot-merge.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/FOSSBots/MirahezeBots/dependabot-merge.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/workflow.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/FOSSBots/MirahezeBots/workflow.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/workflow.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/FOSSBots/MirahezeBots/workflow.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/workflow.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/FOSSBots/MirahezeBots/workflow.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/workflow.yml:53: update your workflow using https://app.stepsecurity.io/secureworkflow/FOSSBots/MirahezeBots/workflow.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/workflow.yml:56: update your workflow using https://app.stepsecurity.io/secureworkflow/FOSSBots/MirahezeBots/workflow.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/workflow.yml:58: update your workflow using https://app.stepsecurity.io/secureworkflow/FOSSBots/MirahezeBots/workflow.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/workflow.yml:69: update your workflow using https://app.stepsecurity.io/secureworkflow/FOSSBots/MirahezeBots/workflow.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/workflow.yml:77: update your workflow using https://app.stepsecurity.io/secureworkflow/FOSSBots/MirahezeBots/workflow.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/workflow.yml:80: update your workflow using https://app.stepsecurity.io/secureworkflow/FOSSBots/MirahezeBots/workflow.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/workflow.yml:84: update your workflow using https://app.stepsecurity.io/secureworkflow/FOSSBots/MirahezeBots/workflow.yml/dev?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/workflow.yml:26",
                        "Warn: pipCommand not pinned by hash: .github/workflows/workflow.yml:27",
                        "Warn: pipCommand not pinned by hash: .github/workflows/workflow.yml:41",
                        "Warn: pipCommand not pinned by hash: .github/workflows/workflow.yml:63",
                        "Warn: pipCommand not pinned by hash: .github/workflows/workflow.yml:64",
                        "Info:   0 out of  10 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   7 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   5 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Warn: 0 commits out of 27 are checked with a SAST tool"
                    ],
                    "score": 7,
                    "reason": "SAST tool detected but not run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/codeql-analysis.yml:1",
                        "Warn: topLevel 'contents' permission set to 'write': .github/workflows/dependabot-merge.yml:6",
                        "Warn: no topLevel permission defined: .github/workflows/workflow.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-34jh-p97f-mpxf",
                        "Warn: Project is vulnerable to: GHSA-g4mx-q9vg-27p4 / PYSEC-2023-212",
                        "Warn: Project is vulnerable to: GHSA-v845-jxx5-vc9f / PYSEC-2023-192"
                    ],
                    "score": 7,
                    "reason": "3 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/mirahezebots/mirahezebots/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nWe currently support with security releases: the lastest PyPi version on the Release branch, and the Dev branch when running sopel 7.1.2 - 8.0 on python 3.8+.\n\n\n## Reporting a Vulnerability\n\n\nTo report a Security Vulnerability or issue, we ask that you please email any applicable information to: staff[at]fossbots.org.\n\nPlease note that by doing this you agree to disclose your email address, and/or any information provided in the email header.\n\nAt a minimum, we ask that you provide, context to the finding of the vulnerability/issue, steps to recreate the vulnerability/issue, and if you have a potiental solution.\n\nPlease do note every effort will be done to respect your privacy, however, please do note the following:\n\nBy using this project or contacting us, you agree that your details can be used in accordance with our Privacy Policy (https://fossbots.org/privacy.html).\n",
        "project_all_labels": [
            "bug",
            "code-style",
            "dependencies",
            "duplicate",
            "enhancement",
            "fix",
            "help wanted",
            "invalid",
            "merge when green",
            "python",
            "question",
            "regression",
            "Sonarcloud",
            "wontfix"
        ],
        "README_content": "# MirahezeBots\n\nMirahezeBots is an IRC bot mainly used by [Miraheze](https://meta.miraheze.org)\n([#miraheze on Libera.Chat](http://web.libera.chat)).\n\nIt is simple and easy to customize.\nMirahezeBot uses [Sopel](https://sopel.chat).\n\nTo use this bot, simply type install 'MirahezeBot-Plugins' from PyPi and then run 'sopel configure --plugins'\n\nTo make use of the beta branch, clone the repo and check the 'dev' branch out and use pip's \"install .\" function to install it. You can then use 'sopel configure --plugins' as normal.\n\n\nPlease note that in line with our security policy, we can only support Sopel 7.1.2 - 8.0 installations running Python 3.8+.\n\n[Source Github](http://github.com/sopel-irc/sopel)\n\n[More info](https://fossbots.org)\n\n[Documentation](https://fossbots.org/documentation.html)\n",
        "num_commits": 1751,
        "project_age_days": 2650,
        "project_created_at": "2017-07-28",
        "latest_updated_at": "2024-08-18",
        "latest_pushed_at": "2023-03-14",
        "num_contributors": 19,
        "num_pull": 823,
        "num_issues": 823,
        "num_opening_issue": 0,
        "project_size(kB)": 14973,
        "num_stargazers": 11,
        "num_watchers": 11,
        "num_forks": 11,
        "num_subscribers": 9,
        "SecurityPolicy_created_at": "2019-10-04 18:29:26",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "b8f32d0b66236acb368ee8130829feeee04ec8f2",
                "url": "https://github.com/FOSSBots/MirahezeBots/commit/b8f32d0b66236acb368ee8130829feeee04ec8f2",
                "date": "2022-05-12 20:09:00"
            },
            {
                "commit_id": "4a1020d50f6ae4f4fc3fe2d8f7be33f89dc6a38b",
                "url": "https://github.com/FOSSBots/MirahezeBots/commit/4a1020d50f6ae4f4fc3fe2d8f7be33f89dc6a38b",
                "date": "2022-02-23 16:13:03"
            },
            {
                "commit_id": "7a18f01e39388e0053c26cfc58153f9566cb3106",
                "url": "https://github.com/FOSSBots/MirahezeBots/commit/7a18f01e39388e0053c26cfc58153f9566cb3106",
                "date": "2022-01-06 16:26:56"
            },
            {
                "commit_id": "5af1def7b3f1f4c566fe6f8021f3b168d7ab79ce",
                "url": "https://github.com/FOSSBots/MirahezeBots/commit/5af1def7b3f1f4c566fe6f8021f3b168d7ab79ce",
                "date": "2021-07-13 16:52:17"
            },
            {
                "commit_id": "4286f3081bf8ef9e92e0268a46321dfde39d9467",
                "url": "https://github.com/FOSSBots/MirahezeBots/commit/4286f3081bf8ef9e92e0268a46321dfde39d9467",
                "date": "2021-06-23 18:33:15"
            },
            {
                "commit_id": "076856cfddba98dcccff464e3367eec3f667a4ec",
                "url": "https://github.com/FOSSBots/MirahezeBots/commit/076856cfddba98dcccff464e3367eec3f667a4ec",
                "date": "2020-11-29 00:22:40"
            },
            {
                "commit_id": "c56ecf3a7303e7739cf7f53b37fa5898c1628267",
                "url": "https://github.com/FOSSBots/MirahezeBots/commit/c56ecf3a7303e7739cf7f53b37fa5898c1628267",
                "date": "2020-08-03 12:48:22"
            },
            {
                "commit_id": "3d9fb92aa40ee207e83c454590e129461e2ad6b0",
                "url": "https://github.com/FOSSBots/MirahezeBots/commit/3d9fb92aa40ee207e83c454590e129461e2ad6b0",
                "date": "2020-07-27 21:42:18"
            },
            {
                "commit_id": "294c6fcb2cade492f0635d3aeedc7599304d7ae7",
                "url": "https://github.com/FOSSBots/MirahezeBots/commit/294c6fcb2cade492f0635d3aeedc7599304d7ae7",
                "date": "2020-07-13 16:56:08"
            },
            {
                "commit_id": "1f96b7206d94c3e060e6672e1c40c8d0cfdd3469",
                "url": "https://github.com/FOSSBots/MirahezeBots/commit/1f96b7206d94c3e060e6672e1c40c8d0cfdd3469",
                "date": "2020-06-26 09:50:00"
            },
            {
                "commit_id": "d858b7c4586cfe739a82fc422083f69a9f54aed7",
                "url": "https://github.com/FOSSBots/MirahezeBots/commit/d858b7c4586cfe739a82fc422083f69a9f54aed7",
                "date": "2020-06-18 06:36:50"
            },
            {
                "commit_id": "dc316e64ba16278e9b7da69c105c4f9a3490071d",
                "url": "https://github.com/FOSSBots/MirahezeBots/commit/dc316e64ba16278e9b7da69c105c4f9a3490071d",
                "date": "2020-06-02 16:13:28"
            },
            {
                "commit_id": "b41785e0356252ab066ddd482f4a82c528ef9adb",
                "url": "https://github.com/FOSSBots/MirahezeBots/commit/b41785e0356252ab066ddd482f4a82c528ef9adb",
                "date": "2020-05-27 13:05:43"
            },
            {
                "commit_id": "515253b8dc68b7f0f5412d02a408a6704abd543f",
                "url": "https://github.com/FOSSBots/MirahezeBots/commit/515253b8dc68b7f0f5412d02a408a6704abd543f",
                "date": "2019-10-05 19:30:14"
            },
            {
                "commit_id": "3e6354cc008a0a2fe7f764ba77e9fb58becdb681",
                "url": "https://github.com/FOSSBots/MirahezeBots/commit/3e6354cc008a0a2fe7f764ba77e9fb58becdb681",
                "date": "2019-10-04 18:32:56"
            },
            {
                "commit_id": "cac7ddbf2f16e646d0261c455895b98205a0e593",
                "url": "https://github.com/FOSSBots/MirahezeBots/commit/cac7ddbf2f16e646d0261c455895b98205a0e593",
                "date": "2019-10-04 18:29:26"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "freetakteam/freetakserver",
        "project_url": "https://github.com/freetakteam/freetakserver",
        "SSF": {
            "date": "2024-10-29T23:43:01+07:00",
            "repo": {
                "name": "github.com/freetakteam/freetakserver",
                "commit": "19fcc6126f84682d8130823a9ff1b756064aaa3b"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.0,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'master'",
                        "Warn: branch protection not enabled for branch 'Android'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 8,
                    "reason": "6 out of 7 merged PRs checked by a CI test -- score normalized to 8",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 2,
                    "reason": "Found 4/18 approved changesets -- score normalized to 2",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: kinetic compute services contributor org/company found, FreeTAKTeam contributor org/company found, clustermod contributor org/company found, apeiros contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 4 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: :0"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: Eclipse Public License 2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "8 commit(s) and 4 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/docker.yml:14"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/Upload-Python-Package-To-Dev.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/Upload-Python-Package-To-Dev.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/Upload-Python-Package-To-Dev.yml:26: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/Upload-Python-Package-To-Dev.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:59: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:72: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/containerize-on-tag.yml:23: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/containerize-on-tag.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/containerize-on-tag.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/containerize-on-tag.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/containerize-on-tag.yml:47: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/containerize-on-tag.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/containerize-on-tag.yml:49: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/containerize-on-tag.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/containerize-on-tag.yml:69: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/containerize-on-tag.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/docker.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/docker.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pub-server-rebuild.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/pub-server-rebuild.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-python-package.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/publish-python-package.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-python-package.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/publish-python-package.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-dev-publish.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/python-dev-publish.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-dev-publish.yml:23: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/python-dev-publish.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-dev-publish.yml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/python-dev-publish.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/python-dev-publish.yml:46: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/python-dev-publish.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-test.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/python-test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-test.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/python-test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-test.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/python-test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-test.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/python-test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/simple_dev_upload.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/simple_dev_upload.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/simple_dev_upload.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/simple_dev_upload.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/simple_dev_upload.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/simple_dev_upload.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/simple_dev_upload.yml:44: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/simple_dev_upload.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wemake.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/wemake.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/wemake.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/FreeTAKTeam/FreeTakServer/wemake.yml/master?enable=pin",
                        "Warn: containerImage not pinned by hash: Dockerfile:1: pin your Docker image by updating python:3.11 to python:3.11@sha256:70f1eb2927a8ef72840254b17024d3a8aa8c3c9715a625d426a2861b5899bc62",
                        "Warn: containerImage not pinned by hash: FreeTAKServer/components/extended/mission/Dockerfile:1: pin your Docker image by updating python:3.6-alpine to python:3.6-alpine@sha256:579978dec4602646fe1262f02b96371779bfb0294e92c91392707fa999c0c989",
                        "Warn: containerImage not pinned by hash: gitDigitalPy.Dockerfile:1: pin your Docker image by updating python:3.11 to python:3.11@sha256:70f1eb2927a8ef72840254b17024d3a8aa8c3c9715a625d426a2861b5899bc62",
                        "Warn: pipCommand not pinned by hash: Dockerfile:20",
                        "Warn: pipCommand not pinned by hash: Dockerfile:20",
                        "Warn: pipCommand not pinned by hash: Dockerfile:20",
                        "Warn: pipCommand not pinned by hash: Dockerfile:21",
                        "Warn: pipCommand not pinned by hash: FreeTAKServer/components/extended/mission/Dockerfile:8",
                        "Warn: pipCommand not pinned by hash: gitDigitalPy.Dockerfile:17",
                        "Warn: pipCommand not pinned by hash: gitDigitalPy.Dockerfile:23",
                        "Warn: pipCommand not pinned by hash: gitDigitalPy.Dockerfile:24",
                        "Warn: pipCommand not pinned by hash: .github/workflows/Upload-Python-Package-To-Dev.yml:31",
                        "Warn: pipCommand not pinned by hash: .github/workflows/Upload-Python-Package-To-Dev.yml:32",
                        "Warn: pipCommand not pinned by hash: .github/workflows/containerize-on-tag.yml:30",
                        "Warn: pipCommand not pinned by hash: .github/workflows/containerize-on-tag.yml:31",
                        "Warn: pipCommand not pinned by hash: .github/workflows/containerize-on-tag.yml:32",
                        "Warn: pipCommand not pinned by hash: .github/workflows/containerize-on-tag.yml:54",
                        "Warn: pipCommand not pinned by hash: .github/workflows/containerize-on-tag.yml:55",
                        "Warn: pipCommand not pinned by hash: .github/workflows/containerize-on-tag.yml:56",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish-python-package.yml:22",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish-python-package.yml:23",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python-dev-publish.yml:28",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python-dev-publish.yml:29",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python-test.yml:22",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python-test.yml:23",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python-test.yml:24",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python-test.yml:46",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python-test.yml:47",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python-test.yml:48",
                        "Warn: pipCommand not pinned by hash: .github/workflows/simple_dev_upload.yml:25",
                        "Warn: pipCommand not pinned by hash: .github/workflows/simple_dev_upload.yml:26",
                        "Info:   0 out of  23 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   6 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   3 containerImage dependencies pinned",
                        "Info:   0 out of  28 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Warn: 17 commits out of 19 are checked with a SAST tool"
                    ],
                    "score": 9,
                    "reason": "SAST tool detected but not run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Warn: no linked content found",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 4,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql.yml:28",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql.yml:29",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/containerize-on-tag.yml:66",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/Upload-Python-Package-To-Dev.yml:16",
                        "Warn: no topLevel permission defined: .github/workflows/codeql.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/containerize-on-tag.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/docker.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/pub-server-rebuild.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish-python-package.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/python-dev-publish.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/python-test.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/simple_dev_upload.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/wemake.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-cx63-2mw6-8hw5",
                        "Warn: Project is vulnerable to: GHSA-r9hx-vwmv-q579 / PYSEC-2022-43012"
                    ],
                    "score": 8,
                    "reason": "2 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/freetakteam/freetakserver/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nFTS is currently supporting those versions with security updates.\n\n| Version | Supported          |\n| ------- | ------------------ |\n| >1.8.x  | :x:                |\n| 1.9.x   | :white_check_mark: |\n| < 2.X   | :white_check_mark: |\n\n## Reporting a Vulnerability\n\nplease report a vulnerability as an issue, our team will evaluate it and address in the proper time\n",
        "project_all_labels": [
            "bug_Fatal",
            "bug_minor",
            "bug_Normal",
            "Configuration",
            "dependencies",
            "documentation",
            "duplicate",
            "enhancement",
            "help wanted",
            "Priority",
            "question",
            "Roadmap",
            "To do",
            "todo",
            "wontfix"
        ],
        "README_content": "# FreeTAKServer [![Downloads](https://pepy.tech/badge/freetakserver)](https://pepy.tech/project/freetakserver) ![PyPI](https://img.shields.io/pypi/v/FreeTAKServer) ![GitHub release (latest by date)](https://img.shields.io/github/v/release/FreeTAKTeam/FreeTakServer)\n\n<img src=\"https://user-images.githubusercontent.com/60719165/226138056-a2b1076c-fd4c-4488-b330-55e57f9ecc78.png\" alt=\"the Parrot is not dead\" width=\"300\" height=\"300\">\n\n\nWelcome to the FreeTakServer (FTS) git repository.\n\nFTS is a Python3 implementation of a TAK Server for devices like [ATAK](https://play.google.com/store/apps/details?id=com.atakmap.app.civ), [WinTAK](https://1drv.ms/u/s!AtMVrrXVTu4YgSanKtSHIslxfRu5?e=ftVio7), and ITAK, it is cross-platform and runs from a multi node installation on AWS down to the Android edition.\nIt's free and open source (released under the [Eclipse Public License](https://www.eclipse.org/legal/epl-2.0/)).\n\n- [Use Cases](#use-cases)\n- [Documentation](#documentation)\n- [Requirements](#requirements)\n- [Community](#community)\n- [Project Status](#project-status)\n  - [Public instance](#public-instance)\n  - [Tell us what you think](#tell-us-what-you-think)\n- [Project Structure](#project-structure)\n- [Architecture](#architecture)\n- [Donate](#donate)\n- [Open Source Notes](#open-source-notes)\n\n![FTS UI 1.8](https://user-images.githubusercontent.com/60719165/118400921-0731e180-b63a-11eb-976e-c38ee052a013.png)\n\n## Use Cases\n\nFTS allows you to connect ATAK clients to share geo information, to chat with all the connected clients, exchange files and more.\nIt intends to support all the major use cases of the original TAK server.\n\n- Web administration\n- Federation Service (Connecting two or more FTS instances)\n- Data Package upload, share with all connected users and retrieval\n- Image transfer and storage\n- COT recording in a database\n- Execution of common task list (_using the ExCheck plugin for WinTAK; ATAK plugin only available to users with takmaps.com access_)\n- SSL Encryption\n- KML generation\n- Command Line Interface\n- [Extensive REST API](https://freetakteam.github.io/FreeTAKServer-User-Docs/API/REST_API_Doc/) for integrations and extensions\n![some use cases](https://user-images.githubusercontent.com/60719165/193834333-ea041722-e3ea-46f9-9eb6-7417c19807ea.png)\n\n## Documentation\n\nFor documentation on installation and usage visit our [FreeTAKServer Documentation page](https://freetakteam.github.io/FreeTAKServer-User-Docs/)\n\n## Requirements\n\n- Python 3.11\n- Dependencies:\n  - `flask`\n  - `lxml`\n  - `pathlib`\n  - `tabulate`\n  - `sqlalchemy`\n  - `setuptools`\n  - `Flask-SQLAlchemy`\n\n## Community\n\nIf you have any issues don't hesitate to [bring it up](https://github.com/FreeTAKTeam/FreeTakServer/issues), as FreeTAKServer is in continuous development.\nTo discuss with the ATAK community you may use:\n\n- The [official FreeTakServer Discord](https://discord.gg/VSukyY5wfD)\n- The [public ATAK Discord Server](https://discordapp.com/invite/XEPyhHA)\n- The [subreddit](https://www.reddit.com/r/ATAK/)\n\n## Project Status\n\nThis code is currently in _Production Stage_.\nCheck out our roadmap [@FreeTakServer#25](https://github.com/FreeTAKTeam/FreeTakServer/issues/25) to see what is planned\nAlso subscribe to this feed to be automatically informed about PIP new versions:\n<https://pypi.org/rss/project/freetakserver/releases.xml>\n\n### Public instance\n\nWe support a public instance of FTS.\nthe IP address is TCP: `137.184.101.250:8087`\n\n- download the configuration [here](https://drive.google.com/file/d/1IK1LfPN13EWikHaMyOuDDwIerNGz-Wli/view?usp=sharing)\n- use the Import manager in ATAK to import the configuration\n- [more details](https://freetakteam.github.io/FreeTAKServer-User-Docs/Usage/Connecting_ATAK/)\n\n### Tell us what you think\n\nTo discuss with the developer team:\n\n- Join the FreeTakServer Discord\n  <https://discord.gg/VSukyY5wfD>\n\n## Project Structure\n\n- [FreeTakServer](./FreeTAKServer/)\n  - **Controllers**: Contains FTS business Logic\n  - **Models**: Contains all the FTS object model\n  - **Views**: contains the access to FTS\n\n## Architecture\n\nTAKFreeServer uses a MVC pattern, the concept of a [COT (Cursor On Target)](https://freetakteam.github.io/FreeTAKServer-User-Docs/About/architecture/cot_domain/) is described in a set of Domain classes, generated from the UML model using a Model Driven Architecture approach.\n\n## Donate\n\nThe FTS team is working daily on the development of an open and free solution. We plan to do more than simply replicate the functionalities of the legacy TAK server, our road map includes integration with open source systems like LORA's Meshtastic, porting it to Android, having an open API, and much more.\n\nWe are doing it for free because we believe that donating personal time to a cause is an endeavour that is worthy per-se, However, we are also spending our own time and money to:\n\n- Maintain a Public server and a test server\n- Invest in different technologies for R&D\n\nIf you feel that FTS is useful to you and you can donate in those challenging times please consider contributing here:\n[DONATE](https://www.paypal.com/cgi-bin/webscr?cmd=_donations&business=brothercorvo%40gmail.com&item_name=FreeTAKServer+R%26D&currency_code=CAD&source=url)\n\nYou can also support the project by buying one of our [t-shirts](http://tee.pub/lic/elARpZYCmaw).\n\n**_NOTE_**:\n\n> Not a big fan of Paypal, but that is the easiest way I found for an initial attempt. We may go to some more ethical system in future.\n> Finally you can help the project by spamming FTS information, starring our repositories in github and Pip and upvoting us.\n\n[![Star History Chart](https://api.star-history.com/svg?repos=FreeTAKTeam/FreeTakServer,tkuester/taky,TAK-Product-Center/Server&type=Date)](https://star-history.com/#FreeTAKTeam/FreeTakServer&tkuester/taky&TAK-Product-Center/Server&Date)\n\n## Open Source Notes\n\nFTS was made possible by the following Open Source projects.\nWe'd like to thank the following individuals and organizations for providing crucial support and making FTS possible.\n\n- [flask](https://flask.palletsprojects.com/en/2.0.x/)\n- [lxml](https://lxml.de/)\n- [pathlib](https://pathlib.readthedocs.io/en/pep428/)\n- [tabulate](https://pypi.org/project/tabulate/)\n- [sqlalchemy](https://www.sqlalchemy.org/)\n- [setuptools](https://pypi.org/project/setuptools/)\n- [eventlet](https://eventlet.net/)\n- [random_word](https://pypi.org/project/Random-Word/)\n- [Pip](https://pypi.org/project/pip/)\n- [Bootstrap4](https://getbootstrap.com/)\n- [pyopenssl](https://pypi.org/project/pyOpenSSL/)\n- [Flask Dashboard Black by AppSeed](https://github.com/app-generator/flask-black-dashboard)\n",
        "num_commits": 1917,
        "project_age_days": 1728,
        "project_created_at": "2020-02-05",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 36,
        "num_pull": 190,
        "num_issues": 703,
        "num_opening_issue": 143,
        "project_size(kB)": 19105,
        "num_stargazers": 674,
        "num_watchers": 674,
        "num_forks": 170,
        "num_subscribers": 60,
        "SecurityPolicy_created_at": "2023-01-06 21:50:36",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "25a25737c9e60546a38603776002cf17961312eb",
                "url": "https://github.com/FreeTAKTeam/FreeTakServer/commit/25a25737c9e60546a38603776002cf17961312eb",
                "date": "2024-02-17 16:03:19"
            },
            {
                "commit_id": "e61aa8ce3f0c167245f43f598eaf6b5ef2cd05b7",
                "url": "https://github.com/FreeTAKTeam/FreeTakServer/commit/e61aa8ce3f0c167245f43f598eaf6b5ef2cd05b7",
                "date": "2023-01-06 21:50:36"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "issue",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "vinitkumar/json2xml",
        "project_url": "https://github.com/vinitkumar/json2xml",
        "SSF": {
            "date": "2024-10-29T22:30:45+07:00",
            "repo": {
                "name": "github.com/vinitkumar/json2xml",
                "commit": "d72b955ebdbe8fc86f42102abcb5661b4a74a48e"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.6,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: codeowners review is required - but no codeowners file found in repo",
                        "Warn: no status checks found to merge onto branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 6,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "15 out of 15 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 1/25 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: django-cms contributor org/company found, socialschools b.v. contributor org/company found, ciena contributor org/company found, gotchacode contributor org/company found, SocialSchools contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 5 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: :0"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "19 commit(s) and 1 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/publish-to-live-pypi.yml:9"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/codeql.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:35: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/lint.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/lint.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/lint.yml:43: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/lint.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/lint.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/lint.yml:17: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/lint.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-to-live-pypi.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/publish-to-live-pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-to-live-pypi.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/publish-to-live-pypi.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-to-live-pypi.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/publish-to-live-pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-to-test-pypi.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/publish-to-test-pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish-to-test-pypi.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/publish-to-test-pypi.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish-to-test-pypi.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/publish-to-test-pypi.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pythonpackage.yml:33: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/pythonpackage.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pythonpackage.yml:35: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/pythonpackage.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pythonpackage.yml:48: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/pythonpackage.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pythonpackage.yml:53: update your workflow using https://app.stepsecurity.io/secureworkflow/vinitkumar/json2xml/pythonpackage.yml/master?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint.yml:22",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint.yml:23",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint.yml:42",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish-to-live-pypi.yml:21",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish-to-test-pypi.yml:22",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pythonpackage.yml:41",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pythonpackage.yml:42",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pythonpackage.yml:43",
                        "Info:   0 out of  14 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   5 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   8 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: all commits (15) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql.yml:17",
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql.yml:16",
                        "Warn: no topLevel permission defined: .github/workflows/codeql.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/lint.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish-to-live-pypi.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish-to-test-pypi.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/pythonpackage.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: PYSEC-2023-117",
                        "Warn: Project is vulnerable to: GHSA-3f84-rpwh-47g6",
                        "Warn: Project is vulnerable to: GHSA-9298-4cf8-g4wj"
                    ],
                    "score": 7,
                    "reason": "3 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/vinitkumar/json2xml/contents/SECURITY.md",
        "SecurityPolicy_content": "## Security contact information\n\nTo report a security vulnerability, please use the\n[Tidelift security contact](https://tidelift.com/security).\nTidelift will coordinate the fix and disclosure.\n",
        "project_all_labels": [
            "bug",
            "can't reproduce",
            "dependencies",
            "duplicate",
            "enhancement",
            "fixed",
            "future",
            "invalid",
            "need more info",
            "open for contribution",
            "question",
            "wontfix"
        ],
        "README_content": "========\njson2xml\n========\n\n.. image:: https://badge.fury.io/py/json2xml.svg\n.. image:: https://static.pepy.tech/personalized-badge/json2xml?period=total&units=international_system&left_color=blue&right_color=orange&left_text=Downloads\n        :target: https://pepy.tech/project/json2xml\n\n.. image:: https://github.com/vinitkumar/json2xml/actions/workflows/pythonpackage.yml/badge.svg\n.. image:: https://img.shields.io/pypi/pyversions/json2xml.svg\n.. image:: https://readthedocs.org/projects/json2xml/badge/?version=latest\n        :target: https://json2xml.readthedocs.io/en/latest/?badge=latest\n        :alt: Documentation Status\n.. image:: https://codecov.io/gh/vinitkumar/json2xml/branch/master/graph/badge.svg?token=Yt2h55eTL2\n      :target: https://codecov.io/gh/vinitkumar/json2xml\n\njson2xml is a Python library that allows you to convert JSON data into XML format. It's simple, efficient, and easy to use.\n\nDocumentation: https://json2xml.readthedocs.io.\n\nThe library was initially dependent on the `dict2xml` project, but it has now been integrated into json2xml itself. This has led to cleaner code, the addition of types and tests, and overall improved performance.\n\nFeatures\n^^^^^^^^\n\njson2xml supports the following features:\n\n* Conversion from a `json` string to XML\n* Conversion from a `json` file to XML\n* Conversion from an API that emits `json` data to XML\n\nUsage\n^^^^^\n\nYou can use the json2xml library in the following ways:\n\n\n.. code-block:: python\n\n    from json2xml import json2xml\n    from json2xml.utils import readfromurl, readfromstring, readfromjson\n\n    # Convert JSON data from a URL to XML\n    data = readfromurl(\"https://api.publicapis.org/entries\")\n    print(json2xml.Json2xml(data).to_xml())\n\n    # Convert a JSON string to XML\n    data = readfromstring(\n        '{\"login\":\"mojombo\",\"id\":1,\"avatar_url\":\"https://avatars0.githubusercontent.com/u/1?v=4\"}'\n    )\n    print(json2xml.Json2xml(data).to_xml())\n\n    # Convert a JSON file to XML\n    data = readfromjson(\"examples/licht.json\")\n    print(json2xml.Json2xml(data).to_xml())\n\n\nCustom Wrappers and Indentation\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nBy default, a wrapper `all` and pretty `True` is set. However, you can easily change this in your code like this:\n\n.. code-block:: python\n\n    from json2xml import json2xml\n    from json2xml.utils import readfromurl, readfromstring, readfromjson\n\n    data = readfromstring(\n        '{\"login\":\"mojombo\",\"id\":1,\"avatar_url\":\"https://avatars0.githubusercontent.com/u/1?v=4\"}'\n    )\n    print(json2xml.Json2xml(data, wrapper=\"all\", pretty=True).to_xml())\n\n\nOutputs this:\n\n.. code-block:: xml\n\n    <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n    <all>\n      <login type=\"str\">mojombo</login>\n      <id type=\"int\">1</id>\n      <avatar_url type=\"str\">https://avatars0.githubusercontent.com/u/1?v=4</avatar_url>\n    </all>\n\nOmit List item\n^^^^^^^^^^^^^^\n\nAssume the following json input\n\n.. code-block:: json\n\n    {\n      \"my_items\": [\n        { \"my_item\": { \"id\": 1 } },\n        { \"my_item\": { \"id\": 2 } }\n      ],\n      \"my_str_items\": [\"a\", \"b\"]\n    }\n\nBy default, items in an array are wrapped in <item></item>.\n\nDefault output:\n\n.. code-block:: xml\n\n    <?xml version=\"1.0\" ?>\n    <all>\n      <my_items type=\"list\">\n        <item type=\"dict\">\n          <my_item type=\"dict\">\n            <id type=\"int\">1</id>\n          </my_item>\n        </item>\n        <item type=\"dict\">\n          <my_item type=\"dict\">\n            <id type=\"int\">2</id>\n          </my_item>\n        </item>\n      </my_items>\n      <my_str_items type=\"list\">\n        <item type=\"str\">a</item>\n        <item type=\"str\">b</item>\n      </my_str_items>\n      <empty type=\"list\"/>\n    </all>\n\nHowever, you can change this behavior using the item_wrap property like this:\n\n.. code-block:: python\n\n    from json2xml import json2xml\n    from json2xml.utils import readfromurl, readfromstring, readfromjson\n\n    data = readfromstring('{\"my_items\":[{\"my_item\":{\"id\":1} },{\"my_item\":{\"id\":2} }],\"my_str_items\":[\"a\",\"b\"]}')\n    print(json2xml.Json2xml(data, item_wrap=False).to_xml())\n\nOutputs this:\n\n.. code-block:: xml\n\n    <?xml version=\"1.0\" ?>\n    <all>\n      <my_items type=\"list\">\n        <my_item type=\"dict\">\n          <id type=\"int\">1</id>\n        </my_item>\n        <my_item type=\"dict\">\n          <id type=\"int\">2</id>\n        </my_item>\n      </my_items>\n      <my_str_items type=\"str\">a</my_str_items>\n      <my_str_items type=\"str\">b</my_str_items>\n    </all>\n\nOptional Attribute Type Support\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nYou can also specify if the output XML needs to have type specified or not. Here is the usage:\n\n .. code-block:: python\n\n    from json2xml import json2xml\n    from json2xml.utils import readfromurl, readfromstring, readfromjson\n\n    data = readfromstring(\n        '{\"login\":\"mojombo\",\"id\":1,\"avatar_url\":\"https://avatars0.githubusercontent.com/u/1?v=4\"}'\n    )\n    print(json2xml.Json2xml(data, wrapper=\"all\", pretty=True, attr_type=False).to_xml())\n\n\nOutputs this:\n\n.. code-block:: xml\n\n    <?xml version=\"1.0\" ?>\n    <all>\n      <login>mojombo</login>\n      <id>1</id>\n      <avatar_url>https://avatars0.githubusercontent.com/u/1?v=4</avatar_url>\n    </all>\n\n\nThe methods are simple and easy to use and there are also checks inside of code to exit cleanly\nin case any of the input(file, string or API URL) returns invalid JSON.\n\nHow to run tests\n^^^^^^^^^^^^^^^^\n\nThis is provided by pytest, which is straight forward.\n\n .. code-block:: console\n\n    virtualenv venv -p $(which python3.9)\n    pip install -r requirements-dev.txt\n    python setup.py install\n    pytest -vv\n\n\nHelp and Support to maintain this project\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n- You can sponsor my work for this plugin here: https://github.com/sponsors/vinitkumar/\n\n",
        "num_commits": 382,
        "project_age_days": 4133,
        "project_created_at": "2013-07-06",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 12,
        "num_pull": 149,
        "num_issues": 220,
        "num_opening_issue": 7,
        "project_size(kB)": 984,
        "num_stargazers": 98,
        "num_watchers": 98,
        "num_forks": 32,
        "num_subscribers": 2,
        "SecurityPolicy_created_at": "2023-01-06 08:01:38",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "b339a22696b6284229ecef0eff39a8581c4290e8",
                "url": "https://github.com/vinitkumar/json2xml/commit/b339a22696b6284229ecef0eff39a8581c4290e8",
                "date": "2023-01-06 08:01:38"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "includesecurity/safeurl-python",
        "project_url": "https://github.com/includesecurity/safeurl-python",
        "SSF": {
            "date": "2024-10-29T23:59:19+07:00",
            "repo": {
                "name": "github.com/includesecurity/safeurl-python",
                "commit": "1656c92e7580423e961ce13a348cc2a640ab62ac"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 3.8,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'main'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "0 out of 4 merged PRs checked by a CI test -- score normalized to 0",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 5,
                    "reason": "Found 4/8 approved changesets -- score normalized to 5",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "project has 0 contributing companies or organizations -- score normalized to 0",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no workflows found",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": [
                        "Warn: Repository is archived."
                    ],
                    "score": 0,
                    "reason": "project is archived",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no dependencies found",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 15 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "No tokens found",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/includesecurity/safeurl-python/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Reporting a Security Concern\nPlease do not report security vulnerabilities through public GitHub issues.\n\nInstead, report security vulnerabilities to **[security@includesecurity.com](mailto:security@includesecurity.com)**. You should receive a response from us within 48 hours. If the issue is confirmed, we will release a patch as soon as possible.\n\n## Past Reports\nThank you to [dir0x](https://github.com/dir0x) for reporting a vulnerability that could allow an attacker to bypass a domain whitelist in certain circumstances, fixed in [this commit](https://github.com/IncludeSecurity/safeurl-python/commit/42dd0c8e5fc84e17e1d3578d18aaea169eece474).\n",
        "project_all_labels": [
            "bug",
            "duplicate",
            "enhancement",
            "help wanted",
            "invalid",
            "question",
            "wontfix"
        ],
        "README_content": "# SafeURL for Python\r\n\r\n**Note: The SafeURL libraries are no longer maintained and we recommend considering other SSRF mitigation approaches alongside application-layer SSRF protection libraries. See our [2023 blog post](https://blog.includesecurity.com/2023/03/mitigating-ssrf-in-2023/) for more details.**\r\n\r\n### Ported by [@nicolasrod](https://github.com/nicolasrod) and docs by [@momopranto](https://github.com/momopranto)\r\n\r\n## Overview\r\nSafeURL is a library that aids developers in protecting against a class of vulnerabilities known as [Server Side Request Forgery (SSRF)](http://www.acunetix.com/blog/articles/server-side-request-forgery-vulnerability/). It does this by validating each part of the URL against a configurable white or black list before making an HTTP request. SafeURL is open-source and licensed under MIT.\r\n\r\nNote that for mitigating SSRF vulnerabilities, we first recommend routing outbound requests from your infrastructure through a proxy such as [Smokescreen](https://github.com/stripe/smokescreen). Alternately, ensure that all services which can make outbound requests to potentially user-controlled URLs are firewalled from talking to other internal hosts. Application-layer defences such as this library should only be used if those options are not practical. Please see [our blog post](https://blog.includesecurity.com/2023/03/mitigating-ssrf-in-2023/) for further information.\r\n\r\n## Installation\r\nClone this repository and import it into your project.\r\n\r\n## Implementation\r\nSafeURL serves as a replacement wrapper for [PyCurl](http://pycurl.io/) in Python.\r\n\r\n```python\r\ntry:\r\n  #User controlled input\r\n  url = request.args['url']\r\n  su = safeurl.SafeURL()\r\n  #Execute using SafeURL\r\n  res = su.execute(url)\r\nexcept:\r\n  print \"Unexpected error:\", sys.exc_info()\r\n  #URL wasn't safe\r\n```\r\n\r\n## Configuration\r\nOptions such as white and black lists can be modified. For example:\r\n\r\n```python\r\ntry:\r\n    su = safeurl.SafeURL()\r\n    #Create an options object\r\n    opt = safeurl.Options()\r\n    opt.clearList(\"whitelist\")\r\n    opt.clearList(\"blacklist\")\r\n    #Allow requests to specific domains\r\n    opt.setList(\"whitelist\", [\"google.com\", \"youtube.com\"], \"domain\")\r\n    #Restrict urls with the ftp scheme\r\n    opt.setList(\"blacklist\",[\"ftp\"],\"scheme\")\r\n\r\n    su.setOptions(opt)\r\n    res = su.execute(\"http://www.youtube.com\")\r\nexcept:\r\n    print \"Unexpected error:\", sys.exc_info()\r\n```\r\n",
        "num_commits": 19,
        "project_age_days": 2993,
        "project_created_at": "2016-08-19",
        "latest_updated_at": "2024-08-29",
        "latest_pushed_at": "2024-08-29",
        "num_contributors": 4,
        "num_pull": 4,
        "num_issues": 6,
        "num_opening_issue": 1,
        "project_size(kB)": 19,
        "num_stargazers": 11,
        "num_watchers": 11,
        "num_forks": 4,
        "num_subscribers": 0,
        "SecurityPolicy_created_at": "2023-01-26 18:27:16",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "eca8740182cbcd951c98101d892c443019418196",
                "url": "https://github.com/IncludeSecurity/safeurl-python/commit/eca8740182cbcd951c98101d892c443019418196",
                "date": "2023-01-26 18:27:16"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism",
            "History of vulnerability"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "home-assistant/core",
        "project_url": "https://github.com/home-assistant/core",
        "SSF": {
            "date": "2024-10-29T20:02:08+07:00",
            "repo": {
                "name": "github.com/home-assistant/core",
                "commit": "f194a689ccaec56cc4234fd8de6dc50c34334fa0"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 7.2,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'dev'",
                        "Info: 'allow deletion' disabled on branch 'rc'",
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'dev'",
                        "Info: 'force pushes' disabled on branch 'rc'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: required approving review count is 1 on branch 'dev'",
                        "Warn: required approving review count is 1 on branch 'rc'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: codeowners review is not required on branch 'dev'",
                        "Warn: codeowners review is not required on branch 'rc'",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Info: status check found to merge onto on branch 'dev'",
                        "Warn: no status checks found to merge onto branch 'rc'",
                        "Warn: no status checks found to merge onto branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'dev'",
                        "Info: PRs are required in order to make changes on branch 'rc'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 6,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 9,
                    "reason": "29 out of 30 merged PRs checked by a CI test -- score normalized to 9",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: aws contributor org/company found, tibber contributor org/company found, affolter-engineering contributor org/company found, Bluetooth-Devices contributor org/company found, home-assistant @hassio-addons contributor org/company found, PyCQA contributor org/company found, aio-libs contributor org/company found, ratgdo contributor org/company found, ovdingen contributor org/company found, pylint-dev contributor org/company found, improv-wifi contributor org/company found, news corp contributor org/company found, UpCloudLtd contributor org/company found, home-assistant @nabucasa contributor org/company found, shenv contributor org/company found, cleverreach contributor org/company found, home-assistant-libs contributor org/company found, home-assistant-ecosystem contributor org/company found, home-assistant contributor org/company found, python-kasa contributor org/company found, pyenphase contributor org/company found, OpenHomeFoundation contributor org/company found, nabucasa contributor org/company found, libwww-perl contributor org/company found, rpm-software-management contributor org/company found, esphome contributor org/company found, python-zeroconf contributor org/company found, uilibs contributor org/company found, SINTEFMedtek contributor org/company found, upcloudltd contributor org/company found, NabuCasa contributor org/company found, CpanelInc contributor org/company found, ESPHome-RATGDO contributor org/company found, NixOS contributor org/company found, nabucasa lekkerkerker software development contributor org/company found, hacs contributor org/company found, hassio-addons contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 37 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.md:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE.md:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 13 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/builder.yml:487"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:93: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:97: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:108: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:119: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:178: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:193: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:200: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:245: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:259: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:266: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:282: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:285: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:292: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:301: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:324: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:327: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:333: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:340: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:454: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:457: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:462: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:30: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:35: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/builder.yml:50: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/builder.yml:72: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/builder.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1296: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1299: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1305: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1357: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1364: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:553: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:556: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:562: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:714: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:717: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:723: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:838: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:841: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:847: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:859: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1245: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1247: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:1252: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:469: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:472: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:485: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:494: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:624: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:627: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:633: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:645: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:902: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:905: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:911: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:924: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:960: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:967: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:280: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:282: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:289: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:298: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:320: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:322: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:329: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:338: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:360: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:362: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:369: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:378: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:450: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:455: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1022: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1025: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1031: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1086: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1094: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:96: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:114: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:129: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:586: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:589: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:595: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:667: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:670: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:676: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:759: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:762: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:775: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:783: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:234: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:237: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:243: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:259: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1150: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1153: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1159: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1215: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1223: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1383: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci.yaml:1385: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/ci.yaml:1390: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/ci.yaml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:24: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/codeql.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:27: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/codeql.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql.yml:32: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/codeql.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/lock.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/lock.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/stale.yml:20: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/stale.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/stale.yml:60: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/stale.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/stale.yml:90: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/stale.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/translations.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/translations.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/translations.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/translations.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:35: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:39: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/wheels.yml:54: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:82: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:90: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:102: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:119: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:122: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:127: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/wheels.yml:138: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:163: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:166: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:171: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/wheels.yml:176: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/wheels.yml:211: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/wheels.yml:226: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/wheels.yml:240: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/wheels.yml:254: update your workflow using https://app.stepsecurity.io/secureworkflow/home-assistant/core/wheels.yml/dev?enable=pin",
                        "Warn: containerImage not pinned by hash: Dockerfile:5",
                        "Warn: containerImage not pinned by hash: Dockerfile.dev:1: pin your Docker image by updating mcr.microsoft.com/devcontainers/python:1-3.12 to mcr.microsoft.com/devcontainers/python:1-3.12@sha256:6df2043e0cc9f73751c605aa101aafdd74b7b1cc52b7510b729f085e21ade8cd",
                        "Warn: containerImage not pinned by hash: script/hassfest/docker/Dockerfile:4: pin your Docker image by updating python:3.12-alpine to python:3.12-alpine@sha256:38e179a0f0436c97ecc76bcd378d7293ab3ee79e4b8c440fdc7113670cb6e204",
                        "Warn: pipCommand not pinned by hash: Dockerfile:15",
                        "Warn: pipCommand not pinned by hash: Dockerfile.dev:39",
                        "Warn: pipCommand not pinned by hash: script/setup:29",
                        "Warn: pipCommand not pinned by hash: .github/workflows/builder.yml:476",
                        "Warn: pipCommand not pinned by hash: .github/workflows/builder.yml:129",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yaml:528",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci.yaml:255",
                        "Warn: pipCommand not pinned by hash: .github/workflows/wheels.yml:49",
                        "Info:   2 out of 105 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   4 out of  31 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   3 containerImage dependencies pinned",
                        "Info:   0 out of   8 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 7,
                    "reason": "SAST tool detected but not run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/home-assistant/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/home-assistant/.github/SECURITY.md:1",
                        "Warn: One or no descriptive hints of disclosure, vulnerability, and/or timelines in security policy",
                        "Info: Found text in security policy: github.com/home-assistant/.github/SECURITY.md:1"
                    ],
                    "score": 9,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/builder.yml:315",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/builder.yml:491",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/builder.yml:84",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/builder.yml:215",
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql.yml:18",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql.yml:19",
                        "Warn: no topLevel permission defined: .github/workflows/builder.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/ci.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/codeql.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/lock.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/stale.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/translations.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/wheels.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": [
                        "Warn: Project is vulnerable to: GHSA-248v-346w-9cwc",
                        "Warn: Project is vulnerable to: GHSA-43fp-rhv2-5gv8 / PYSEC-2022-42986",
                        "Warn: Project is vulnerable to: GHSA-xqr8-7jwr-rhp7 / PYSEC-2023-135"
                    ],
                    "score": 7,
                    "reason": "3 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/home-assistant/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\nInformation on Home Assistant's security policies and guidelines\ncan be found on our website:\n\n<https://www.home-assistant.io/security>\n",
        "project_all_labels": [
            "ai-review",
            "almost-done",
            "async",
            "auth",
            "awaiting-frontend",
            "blocking event loop",
            "bluetooth-range-interference",
            "board/raspberrypi",
            "breaking-change",
            "bug",
            "bugfix",
            "by-code-owner",
            "by-core-dev",
            "cherry-picked",
            "ci-full-run",
            "ci-keep-cache",
            "cla-error",
            "cla-needed",
            "cla-recheck",
            "cla-signed",
            "cleanup",
            "climate",
            "code-owner-approved",
            "code-quality",
            "component",
            "config error",
            "config-flow",
            "core",
            "cpu",
            "custom component",
            "database: mariadb",
            "database: mysql",
            "database: postgresql",
            "database: sqlite3",
            "dependency",
            "dependency-bump",
            "deprecation",
            "docker",
            "docs-missing",
            "documentation",
            "duplicate",
            "easy-fix",
            "energy",
            "enhancement",
            "feature-request",
            "flapping-test",
            "For Paulus",
            "frontend",
            "github_actions",
            "good first issue",
            "Hacktoberfest",
            "hacktoberfest-accepted",
            "hardware",
            "has parent issue",
            "has-tests",
            "help-wanted",
            "http",
            "import-deadlock",
            "in progress",
            "integration: __init__",
            "integration: .translations",
            "integration: 1_domintell",
            "integration: 2_domintell",
            "integration: 2n_entrycom",
            "integration: 3_day_blinds",
            "integration: abode",
            "integration: acaia",
            "integration: accuweather",
            "integration: acer_projector",
            "integration: acmeda",
            "integration: acomax",
            "integration: action",
            "integration: actiontec",
            "integration: adaptive_lighting",
            "integration: adax",
            "integration: adguard",
            "integration: ads",
            "integration: advantage_air",
            "integration: aemet",
            "integration: aep_ohio",
            "integration: aep_texas",
            "integration: aepohio",
            "integration: aeptexas",
            "integration: aftership",
            "integration: afvalwijzer",
            "integration: agent_dvr",
            "integration: ai_speaker",
            "integration: aidot",
            "integration: air_pollutants",
            "integration: air_quality",
            "integration: aircube",
            "integration: airgradient",
            "integration: airly",
            "integration: airnow",
            "integration: airq",
            "integration: airscape",
            "integration: airthings",
            "integration: airthings_ble",
            "integration: airtouch4",
            "integration: airtouch5",
            "integration: airvisual",
            "integration: airvisual_pro",
            "integration: airzone",
            "integration: airzone_cloud",
            "integration: ais_tracker",
            "integration: aladdin_connect",
            "integration: aladdin_genie",
            "integration: alarm_clock",
            "integration: alarm_control_panel",
            "integration: alarmdecoder",
            "integration: alarmdotcom",
            "integration: alert",
            "integration: alex_test",
            "integration: alexa",
            "integration: alexa_media",
            "integration: alfa",
            "integration: alfawise",
            "integration: alidns",
            "integration: allpowers_ble",
            "integration: almond",
            "integration: alpha_vantage",
            "integration: alphaess",
            "integration: amazon_polly",
            "integration: amazon_rekognition",
            "integration: ambee",
            "integration: amberelectric",
            "integration: ambiclimate",
            "integration: ambient_network",
            "integration: ambient_station",
            "integration: amcrest",
            "integration: ampio",
            "integration: analog_output",
            "integration: analytics",
            "integration: analytics_insights",
            "integration: android",
            "integration: android_battery",
            "integration: android_ip_webcam",
            "integration: androidtv",
            "integration: androidtv_remote",
            "integration: anel_pwrctrl",
            "integration: anglian_water",
            "integration: anomaly",
            "integration: anova",
            "integration: anova_cooker",
            "integration: anova_sous_vide",
            "integration: anthemav",
            "integration: anthropic",
            "integration: anwb_energie",
            "integration: aosmith",
            "integration: apache_kafka",
            "integration: apcupsd",
            "integration: api",
            "integration: api_streams",
            "integration: apiai",
            "integration: apns",
            "integration: appalachianpower",
            "integration: appartme",
            "integration: apple_tv",
            "integration: application_credentials",
            "integration: apprise",
            "integration: aprilaire",
            "integration: aprs",
            "integration: aps",
            "integration: apsystems",
            "integration: aqara",
            "integration: aquacell",
            "integration: aqualogic",
            "integration: aquostv",
            "integration: aqvify",
            "integration: aranet",
            "integration: aranet4",
            "integration: arcam_fmj",
            "integration: arcticspa",
            "integration: arduino",
            "integration: arest",
            "integration: arlo",
            "integration: arris_tg2492lg",
            "integration: artsound",
            "integration: aruba",
            "integration: aruba_instant",
            "integration: aruba_instant_on",
            "integration: arve",
            "integration: arwn",
            "integration: aseko_pool_live",
            "integration: assist_pipeline",
            "integration: assist_satellite",
            "integration: asterisk_ami",
            "integration: asterisk_cdr",
            "integration: asterisk_mbox",
            "integration: asus_router",
            "integration: asuswrt",
            "integration: asyncua",
            "integration: atag",
            "integration: aten_pe",
            "integration: atlona_juno",
            "integration: atome",
            "integration: attribute_as_sensor",
            "integration: attribute_sensor",
            "integration: attributes",
            "integration: audiconnect",
            "integration: august",
            "integration: aurora",
            "integration: aurora_abb_powerone",
            "integration: aussie_broadband",
            "integration: autarco",
            "integration: auth",
            "integration: auth_api",
            "integration: automate",
            "integration: automatic",
            "integration: automation",
            "integration: avea",
            "integration: avion",
            "integration: avocent_dpdu",
            "integration: avreceiver",
            "integration: avri",
            "integration: awair",
            "integration: awair_local",
            "integration: awattar",
            "integration: aws",
            "integration: aws_data",
            "integration: aws_lambda",
            "integration: aws_sns",
            "integration: aws_sqs",
            "integration: axion_dmx",
            "integration: axis",
            "integration: azure_cloud",
            "integration: azure_data_explorer",
            "integration: azure_devops",
            "integration: azure_event_hub",
            "integration: azure_maps_travel_time",
            "integration: azure_openai_conversation",
            "integration: azure_service_bus",
            "integration: azure_servicebus",
            "integration: azure_vm",
            "integration: azuredns",
            "integration: backup",
            "integration: baf",
            "integration: baidu",
            "integration: balboa",
            "integration: ban",
            "integration: bang_olufsen",
            "integration: bangolufsen",
            "integration: barry",
            "integration: battery_sim",
            "integration: bayesian",
            "integration: bbb_gpio",
            "integration: bbox",
            "integration: becker",
            "integration: bedrock_agent",
            "integration: beewi_smartclim",
            "integration: bemfa",
            "integration: benq_projector",
            "integration: bh1750",
            "integration: binance",
            "integration: binary_max_sensor",
            "integration: binary_sensor",
            "integration: binary_sensor_as_x",
            "integration: bitcoin",
            "integration: bittrex",
            "integration: bitvavo",
            "integration: bizkaibus",
            "integration: bkk",
            "integration: blackbird",
            "integration: blastbot_cloud",
            "integration: blebox",
            "integration: blink",
            "integration: blinksticklight",
            "integration: blinkt",
            "integration: blnet",
            "integration: blockchain",
            "integration: bloomsky",
            "integration: blue_current",
            "integration: bluecurrent",
            "integration: bluemaestro",
            "integration: blueprint",
            "integration: bluesound",
            "integration: bluetooth",
            "integration: bluetooth_le_tracker",
            "integration: bluetooth_tracker",
            "integration: bme280",
            "integration: bme280spi",
            "integration: bme680",
            "integration: bmp280",
            "integration: bmw_connected_drive",
            "integration: bom",
            "integration: bomradarcam",
            "integration: bomradarloop",
            "integration: bond",
            "integration: bosch_shc",
            "integration: bouncie",
            "integration: braviatv",
            "integration: brightsky",
            "integration: bring",
            "integration: broadcast",
            "integration: broadlink",
            "integration: broadlinkcustom",
            "integration: broadlinkRM3",
            "integration: brother",
            "integration: brottsplatskartan",
            "integration: browan",
            "integration: browser",
            "integration: brunt",
            "integration: bryant_evolution",
            "integration: bsblan",
            "integration: bt_home_hub_5",
            "integration: bt_smarthub",
            "integration: bthome",
            "integration: bthome_ble",
            "integration: buienradar",
            "integration: bunq",
            "integration: button",
            "integration: bzutech",
            "integration: c_by_ge",
            "integration: c_Elta",
            "integration: caldav",
            "integration: calendar",
            "integration: cambridge_audio",
            "integration: cambridgeaudio",
            "integration: came_domotic",
            "integration: camect",
            "integration: camera",
            "integration: canada_hydrometric",
            "integration: canary",
            "integration: carson",
            "integration: casatunes",
            "integration: cast",
            "integration: ccm15",
            "integration: cert_expiry",
            "integration: chacon_dio",
            "integration: channels",
            "integration: charge_place_scotland",
            "integration: circuit",
            "integration: cisco_ios",
            "integration: cisco_mobility_express",
            "integration: cisco_webex",
            "integration: cisco_webex_teams",
            "integration: ciscospark",
            "integration: citybikes",
            "integration: citybus",
            "integration: clarifai",
            "integration: clarifai_general",
            "integration: classificationbox",
            "integration: clementine",
            "integration: clickatell",
            "integration: clicksend",
            "integration: clicksend_tts",
            "integration: clicksendaudio",
            "integration: clicksendtts",
            "integration: climacell",
            "integration: climate",
            "integration: climate_scheduler",
            "integration: climaveneta_ilife",
            "integration: climaveneta_imxw",
            "integration: cloud",
            "integration: cloud_api",
            "integration: cloudflare",
            "integration: cmus",
            "integration: co2mini",
            "integration: co2signal",
            "integration: coautilities",
            "integration: coinbase",
            "integration: coinmarketcap",
            "integration: color_extractor",
            "integration: colorthief",
            "integration: combined_energy",
            "integration: combined_energy_api",
            "integration: comed_hourly_pricing",
            "integration: comelit",
            "integration: comexio",
            "integration: comfoair",
            "integration: comfoconnect",
            "integration: command_line",
            "integration: compensation",
            "integration: concord232",
            "integration: coned",
            "integration: config",
            "integration: config_entry_example",
            "integration: configurator",
            "integration: connectedcars",
            "integration: connector",
            "integration: contact_energy_nz",
            "integration: contec_controllers",
            "integration: control4",
            "integration: conversation",
            "integration: coolmaster",
            "integration: coolmaster_serial",
            "integration: core",
            "integration: coronavirus",
            "integration: counter",
            "integration: cover",
            "integration: cppm_tracker",
            "integration: cpuspeed",
            "integration: crestron",
            "integration: cribl",
            "integration: crimereports",
            "integration: crownstone",
            "integration: csv",
            "integration: cups",
            "integration: currencylayer",
            "integration: custom_card",
            "integration: customize",
            "integration: cybro",
            "integration: dahua",
            "integration: daikin",
            "integration: daikin_madoka",
            "integration: daily_min_max",
            "integration: danfoss_air",
            "integration: darksky",
            "integration: data_source",
            "integration: datadog",
            "integration: date",
            "integration: date_countdown",
            "integration: date_reminder",
            "integration: datetime",
            "integration: ddns_ovh",
            "integration: ddwrt",
            "integration: deako",
            "integration: debugpy",
            "integration: deconz",
            "integration: decora",
            "integration: decora_ble",
            "integration: decora_wifi",
            "integration: default_config",
            "integration: delegate_media_player",
            "integration: delijn",
            "integration: deluge",
            "integration: demo",
            "integration: denon",
            "integration: denonavr",
            "integration: depict",
            "integration: derivative",
            "integration: deutsche_bahn",
            "integration: developer_credentials",
            "integration: devialet",
            "integration: device",
            "integration: device_automation",
            "integration: device_sun_light_trigger",
            "integration: device_tracker",
            "integration: devolo_home_control",
            "integration: devolo_home_network",
            "integration: dewpoint",
            "integration: dexcom",
            "integration: dgarage",
            "integration: dhcp",
            "integration: dht",
            "integration: diagnostics",
            "integration: dialogflow",
            "integration: digital_ocean",
            "integration: digitalloggers",
            "integration: dio_chacon",
            "integration: directv",
            "integration: dirigera",
            "integration: discal",
            "integration: discogs",
            "integration: discord",
            "integration: discovergy",
            "integration: discovery",
            "integration: dispatcher",
            "integration: dlib_face_detect",
            "integration: dlib_face_identify",
            "integration: dlink",
            "integration: dlna_dmr",
            "integration: dlna_dms",
            "integration: dnsip",
            "integration: domain_expiry",
            "integration: domika",
            "integration: dominionenergy",
            "integration: dominos",
            "integration: doods",
            "integration: doorbird",
            "integration: dormakaba_dkey",
            "integration: dovado",
            "integration: downloader",
            "integration: dpi4relay",
            "integration: dremel_3d_printer",
            "integration: dreo",
            "integration: drone_mobile",
            "integration: drop",
            "integration: drop_connect",
            "integration: dsmr",
            "integration: dsmr_reader",
            "integration: dte_energy_bridge",
            "integration: dublin_bus_transport",
            "integration: duckdns",
            "integration: duke_energy",
            "integration: dunehd",
            "integration: duotecno",
            "integration: duquesne_light",
            "integration: duwi",
            "integration: dwd_warnapp",
            "integration: dwd_weather_warnings",
            "integration: dweet",
            "integration: dynalite",
            "integration: dyson",
            "integration: dyson_local",
            "integration: e3dc_modbus",
            "integration: eafm",
            "integration: easee",
            "integration: eastron",
            "integration: easyenergy",
            "integration: ebox",
            "integration: ebus",
            "integration: ebusd",
            "integration: ecoal_boiler",
            "integration: ecobee",
            "integration: ecodevices",
            "integration: ecoforest",
            "integration: econet",
            "integration: ecoplug",
            "integration: ecovacs",
            "integration: ecowitt",
            "integration: ecowitt_weather",
            "integration: eddystone_temperature",
            "integration: edilkamin",
            "integration: edimax",
            "integration: edl21",
            "integration: edp_redy",
            "integration: ee_brightbox",
            "integration: efergy",
            "integration: efesto",
            "integration: egardia",
            "integration: egps",
            "integration: eheimdigital",
            "integration: eight_sleep",
            "integration: elan",
            "integration: electraac",
            "integration: electrasmart",
            "integration: electric_kiwi",
            "integration: elevenlabs",
            "integration: elevenlabstts",
            "integration: elgato",
            "integration: eliqonline",
            "integration: elkm1",
            "integration: elmax",
            "integration: elmo_alarm",
            "integration: elro_connects",
            "integration: elv",
            "integration: elv_usb_wde",
            "integration: elvia",
            "integration: emby",
            "integration: emoncms",
            "integration: emoncms_history",
            "integration: emonitor",
            "integration: emulated_hue",
            "integration: emulated_kasa",
            "integration: emulated_roku",
            "integration: enasolar",
            "integration: energenie",
            "integration: energie_vanons",
            "integration: energy",
            "integration: energyid",
            "integration: energyzero",
            "integration: enertalk",
            "integration: enigma",
            "integration: enigma2",
            "integration: enmax",
            "integration: enocean",
            "integration: enphase_envoy",
            "integration: entur_public_transport",
            "integration: environment_canada",
            "integration: envirophat",
            "integration: envisalink",
            "integration: ephember",
            "integration: epic_games_store",
            "integration: epion",
            "integration: eps",
            "integration: epson",
            "integration: epsonprinter",
            "integration: epsonworkforce",
            "integration: epsonworkforceprinter",
            "integration: eq3btsmart",
            "integration: escea",
            "integration: esera_onewire",
            "integration: esphome",
            "integration: essent",
            "integration: etherrain",
            "integration: etherscan",
            "integration: eufy",
            "integration: eufy_security",
            "integration: eufylife_ble",
            "integration: event",
            "integration: everlights",
            "integration: evil_genius_labs",
            "integration: evohome",
            "integration: evse_wifi",
            "integration: eyeonwater",
            "integration: ezbeq",
            "integration: ezviz",
            "integration: ezviz_cloud",
            "integration: faa_delays",
            "integration: faadelays",
            "integration: facebook",
            "integration: facebox",
            "integration: facebox_face_detect",
            "integration: fail2ban",
            "integration: familyhub",
            "integration: fan",
            "integration: fastdotcom",
            "integration: fatek",
            "integration: fedex",
            "integration: feedreader",
            "integration: ferienapidotde",
            "integration: fever_smart",
            "integration: ffmpeg",
            "integration: ffmpeg_motion",
            "integration: ffmpeg_noise",
            "integration: fhz",
            "integration: fibaro",
            "integration: fido",
            "integration: file",
            "integration: file_upload",
            "integration: filesize",
            "integration: filter",
            "integration: fing",
            "integration: fints",
            "integration: fire_tv",
            "integration: fireservicerota",
            "integration: firetv",
            "integration: firmata",
            "integration: fitbit",
            "integration: fivem",
            "integration: fixer",
            "integration: fjaraskupan",
            "integration: flaktgroup",
            "integration: flashforge",
            "integration: fleetgo",
            "integration: flexit",
            "integration: flexit_bacnet",
            "integration: flexmeasures",
            "integration: flexpool",
            "integration: flic",
            "integration: flick_electric",
            "integration: flickelectric",
            "integration: flipr",
            "integration: flo",
            "integration: flock",
            "integration: flukso",
            "integration: flume",
            "integration: flunearyou",
            "integration: fluss",
            "integration: flux",
            "integration: flux_led",
            "integration: fmi",
            "integration: folder",
            "integration: folder_watcher",
            "integration: foobar",
            "integration: foobot",
            "integration: fordpass",
            "integration: forecast_solar",
            "integration: forked_daapd",
            "integration: formula_one",
            "integration: fortigate",
            "integration: fortinet_fortios",
            "integration: fortios",
            "integration: foscam",
            "integration: foursquare",
            "integration: fpl",
            "integration: frank_energie",
            "integration: free_mobile",
            "integration: freebox",
            "integration: freedns",
            "integration: freedompro",
            "integration: frigidaire",
            "integration: fritz",
            "integration: fritzbox",
            "integration: fritzbox_callmonitor",
            "integration: fritzbox_netmonitor",
            "integration: fronius",
            "integration: frontend",
            "integration: frontier_silicon",
            "integration: fs20",
            "integration: fujitsu_anywair",
            "integration: fujitsu_fglair",
            "integration: fujitsu_hvac",
            "integration: fully_kiosk",
            "integration: fullykiosk",
            "integration: futurenow",
            "integration: fuzzy",
            "integration: fyta",
            "integration: gandi_livedns",
            "integration: garadget",
            "integration: garages_amsterdam",
            "integration: gardena",
            "integration: gardena_bluetooth",
            "integration: garmin_connect",
            "integration: gc100",
            "integration: gdacs",
            "integration: ge_home",
            "integration: gearbest",
            "integration: geizhals",
            "integration: generic",
            "integration: generic_hygrostat",
            "integration: generic_thermostat",
            "integration: geniushub",
            "integration: geo_json_events",
            "integration: geo_location",
            "integration: geo_rss_events",
            "integration: geocaching",
            "integration: geofency",
            "integration: geonetnz_quakes",
            "integration: geonetnz_volcano",
            "integration: gios",
            "integration: github",
            "integration: gitlab_ci",
            "integration: gitter",
            "integration: glances",
            "integration: glinet",
            "integration: gntp",
            "integration: go2rtc",
            "integration: goalfeed",
            "integration: goalzero",
            "integration: gocr",
            "integration: godice",
            "integration: goe_charger",
            "integration: gogogate2",
            "integration: goodwe",
            "integration: google",
            "integration: google_assistant",
            "integration: google_assistant_sdk",
            "integration: google_calendar",
            "integration: google_cloud",
            "integration: google_domains",
            "integration: google_drive",
            "integration: google_generative_ai_conversation",
            "integration: google_home_alarm",
            "integration: google_mail",
            "integration: google_maps",
            "integration: google_photos",
            "integration: google_pubsub",
            "integration: google_reverse_geocode",
            "integration: google_sdm",
            "integration: google_sheets",
            "integration: google_stackdriver",
            "integration: google_tasks",
            "integration: google_translate",
            "integration: google_travel_time",
            "integration: google_travel_time_llm_api",
            "integration: google_wifi",
            "integration: googleactions",
            "integration: googlehome",
            "integration: gotify",
            "integration: govee",
            "integration: govee_api",
            "integration: govee_ble",
            "integration: govee_light_api",
            "integration: govee_light_local",
            "integration: gpm",
            "integration: gpmdp",
            "integration: gpsd",
            "integration: gpslogger",
            "integration: gpstracker",
            "integration: graphite",
            "integration: gree",
            "integration: greeneye_monitor",
            "integration: greenwave",
            "integration: griddy",
            "integration: group",
            "integration: group_state",
            "integration: grouped_light",
            "integration: growatt",
            "integration: growatt_rs232",
            "integration: growatt_server",
            "integration: gstreamer",
            "integration: gtfs",
            "integration: gtt",
            "integration: guardian",
            "integration: ha_alerts",
            "integration: habitica",
            "integration: habo",
            "integration: hadockermon",
            "integration: hafas",
            "integration: Haiku",
            "integration: halohome",
            "integration: hangouts",
            "integration: hardkernel",
            "integration: hardware",
            "integration: harman_kardon_avr",
            "integration: harmony",
            "integration: hasl",
            "integration: hassbian",
            "integration: hassio",
            "integration: hassmpris",
            "integration: hatchrest",
            "integration: hausbus",
            "integration: haveibeenpwned",
            "integration: hddtemp",
            "integration: hdmi_cec",
            "integration: heatilator",
            "integration: heatmiser",
            "integration: heatnglo",
            "integration: heatzy",
            "integration: hegel",
            "integration: helpers",
            "integration: heos",
            "integration: here_travel_time",
            "integration: here_weather",
            "integration: hifiberry",
            "integration: hikvision",
            "integration: hikvisioncam",
            "integration: hipchat",
            "integration: hisense_aehw4a1",
            "integration: history",
            "integration: history_average",
            "integration: history_graph",
            "integration: history_stats",
            "integration: history_values",
            "integration: hitron_coda",
            "integration: hive",
            "integration: hiwifi",
            "integration: hko",
            "integration: hlk_sw16",
            "integration: hm3301",
            "integration: holiday",
            "integration: home_connect",
            "integration: home_panel",
            "integration: home_plus_control",
            "integration: homeassistant",
            "integration: homeassistant_alerts",
            "integration: homeassistant_analytics",
            "integration: homeassistant_connect_zbt1",
            "integration: homeassistant_green",
            "integration: homeassistant_hardware",
            "integration: homeassistant_sky_connect",
            "integration: homeassistant_solar_trest_se",
            "integration: homeassistant_yellow",
            "integration: homebound",
            "integration: homecom",
            "integration: homeconnect",
            "integration: homekit",
            "integration: homekit_controller",
            "integration: homely",
            "integration: homematic",
            "integration: homematicip",
            "integration: homematicip_cloud",
            "integration: homepilot",
            "integration: homepluscontrol",
            "integration: homewizard",
            "integration: homewizard_climate",
            "integration: homewizard_energy",
            "integration: homeworks",
            "integration: honeygain",
            "integration: honeywell",
            "integration: hook",
            "integration: horizon",
            "integration: hp_ilo",
            "integration: hsl",
            "integration: html5",
            "integration: http",
            "integration: http_api",
            "integration: http_inline",
            "integration: http_plaintext",
            "integration: http_rgb",
            "integration: httplight",
            "integration: htu21d",
            "integration: huawei_hilink",
            "integration: huawei_lte",
            "integration: huawei_router",
            "integration: huawei_smart_logger",
            "integration: huawei_solar",
            "integration: hue",
            "integration: hue_api",
            "integration: hue_ble",
            "integration: hue_sensors",
            "integration: huisbaasje",
            "integration: humidifier",
            "integration: humidity",
            "integration: hunter_hydrawise",
            "integration: hunterdouglas_powerview",
            "integration: husqvarna_automower",
            "integration: husqvarna_automower_ble",
            "integration: huum",
            "integration: huumtest",
            "integration: hvv_departures",
            "integration: hwam",
            "integration: hydrawise",
            "integration: hydroquebec",
            "integration: hyperion",
            "integration: hyundai_kia_connect",
            "integration: i2c",
            "integration: ialarm",
            "integration: ialarm_xr",
            "integration: ialarmxr",
            "integration: iammeter",
            "integration: iaqstick",
            "integration: iaqualink",
            "integration: ibeacon",
            "integration: icloud",
            "integration: idasen_desk",
            "integration: ids_hyyp",
            "integration: idteck_prox",
            "integration: ifttt",
            "integration: igd",
            "integration: iglo",
            "integration: ign_sismologia",
            "integration: ihc",
            "integration: ihcdevice",
            "integration: iliad_italy",
            "integration: image",
            "integration: image_processing",
            "integration: image_upload",
            "integration: imap",
            "integration: imap_email_content",
            "integration: imazu_wall_pad",
            "integration: imgw_pib",
            "integration: improv_ble",
            "integration: incharge",
            "integration: incomfort",
            "integration: indianamichiganpower",
            "integration: inels",
            "integration: influxdb",
            "integration: influxdb_cloud",
            "integration: inkbird",
            "integration: input_boolean",
            "integration: input_box",
            "integration: input_button",
            "integration: input_datetime",
            "integration: input_number",
            "integration: input_schedule",
            "integration: input_select",
            "integration: input_slider",
            "integration: input_text",
            "integration: instapush",
            "integration: insteon",
            "integration: insteon_hub",
            "integration: insteon_local",
            "integration: insteon_plm",
            "integration: instructure",
            "integration: integration",
            "integration: intellidrive",
            "integration: intellifire",
            "integration: intent",
            "integration: intent_script",
            "integration: interval",
            "integration: intesishome",
            "integration: intouch",
            "integration: introduction",
            "integration: investec",
            "integration: ios",
            "integration: iot",
            "integration: iota",
            "integration: iotawatt",
            "integration: iotmeter",
            "integration: iotty",
            "integration: iperf3",
            "integration: ipma",
            "integration: ipp",
            "integration: iqvia",
            "integration: irc",
            "integration: irish_rail_transport",
            "integration: iron_os",
            "integration: isal",
            "integration: iskra",
            "integration: islamic_prayer_times",
            "integration: israel_rail",
            "integration: iss",
            "integration: issue117263",
            "integration: ista_ecotrend",
            "integration: isy994",
            "integration: itach",
            "integration: itunes",
            "integration: ituran",
            "integration: izone",
            "integration: jellyfin",
            "integration: jenkins",
            "integration: jewish_calendar",
            "integration: jewish_shabbath",
            "integration: jlrincontrol",
            "integration: joaoapps_join",
            "integration: json_attributes",
            "integration: juhe_stock",
            "integration: juicenet",
            "integration: just_nimbus",
            "integration: justnimbus",
            "integration: jvc_projector",
            "integration: jvc_projectors",
            "integration: kaiterra",
            "integration: kaleidescape",
            "integration: kankun",
            "integration: kat_bulgaria",
            "integration: kdeconnect",
            "integration: keba",
            "integration: keenetic_ndms2",
            "integration: kef",
            "integration: kegtron",
            "integration: kentuckypower",
            "integration: kermi",
            "integration: ketra",
            "integration: keyboard",
            "integration: keyboard_remote",
            "integration: keymitt_ble",
            "integration: kincony_hx",
            "integration: kindhome_solarbeaker",
            "integration: kira",
            "integration: kitchen_sink",
            "integration: kiwi",
            "integration: klyqa",
            "integration: kmtronic",
            "integration: knocki",
            "integration: knovvu",
            "integration: knx",
            "integration: kodi",
            "integration: komfovent",
            "integration: konnected",
            "integration: koogeek",
            "integration: kostal_piko",
            "integration: kostal_plenticore",
            "integration: kraken",
            "integration: krisinformation",
            "integration: krispol",
            "integration: kulersky",
            "integration: kumo",
            "integration: kwb",
            "integration: lacrosse",
            "integration: lacrosse_view",
            "integration: lamarzocco",
            "integration: lametric",
            "integration: landisgyr_heat_meter",
            "integration: landroid_cloud",
            "integration: lannouncer",
            "integration: lastfm",
            "integration: launch_library",
            "integration: laundrify",
            "integration: lawn_mower",
            "integration: lcn",
            "integration: ld2410_ble",
            "integration: leafspy",
            "integration: leaone",
            "integration: led_ble",
            "integration: ledsc",
            "integration: legrand_rflc",
            "integration: legrandinone",
            "integration: lektrico",
            "integration: leslies_pool",
            "integration: leviosa_shades",
            "integration: lg_netcast",
            "integration: lg_soundbar",
            "integration: lg_thinq",
            "integration: lgthinq",
            "integration: liberty",
            "integration: lidarr",
            "integration: life360",
            "integration: lifesos",
            "integration: lifetime_total",
            "integration: lifx",
            "integration: lifx_cloud",
            "integration: lifx_legacy",
            "integration: light",
            "integration: light_defaults",
            "integration: lightwave",
            "integration: lightwave_energy",
            "integration: limitlessled",
            "integration: limitlessled_rf",
            "integration: linear_garage_door",
            "integration: linknlink",
            "integration: linkplay",
            "integration: linksys_ap",
            "integration: linksys_smart",
            "integration: linky",
            "integration: linode",
            "integration: linux_battery",
            "integration: lirc",
            "integration: litejet",
            "integration: litterrobot",
            "integration: livebox",
            "integration: liveboxplaytv",
            "integration: livemasjid",
            "integration: livisi",
            "integration: ll_notify",
            "integration: llamalab_automate",
            "integration: llap",
            "integration: llm_tools",
            "integration: lm75",
            "integration: local",
            "integration: local_calendar",
            "integration: local_file",
            "integration: local_ip",
            "integration: local_todo",
            "integration: localip",
            "integration: location",
            "integration: locative",
            "integration: lock",
            "integration: lockitron",
            "integration: logbook",
            "integration: logentries",
            "integration: logger",
            "integration: logi_circle",
            "integration: london_air",
            "integration: london_underground",
            "integration: lookin",
            "integration: loopenergy",
            "integration: loqed",
            "integration: lorawan",
            "integration: lovelace",
            "integration: loxone",
            "integration: luci",
            "integration: luciwifi",
            "integration: luftdaten",
            "integration: lupusec",
            "integration: lutron",
            "integration: lutron_caseta",
            "integration: lutron_qse",
            "integration: luxor",
            "integration: luxtronik",
            "integration: luxtronik2",
            "integration: lviv_poweroff",
            "integration: lw12wifi",
            "integration: lyft",
            "integration: lyric",
            "integration: madeco",
            "integration: madvr",
            "integration: magichome",
            "integration: magicseaweed",
            "integration: maico",
            "integration: mailbox",
            "integration: mailgun",
            "integration: majestic",
            "integration: manual",
            "integration: manual_mqtt",
            "integration: map",
            "integration: marytts",
            "integration: mass",
            "integration: mastodon",
            "integration: matrix",
            "integration: matter",
            "integration: mawaqit",
            "integration: maxcube",
            "integration: maxcul",
            "integration: mazda",
            "integration: mcp23017",
            "integration: mealie",
            "integration: meater",
            "integration: medcom_ble",
            "integration: media_extractor",
            "integration: media_finder",
            "integration: media_helper",
            "integration: media_manager",
            "integration: media_player",
            "integration: media_source",
            "integration: mediaroom",
            "integration: melcloud",
            "integration: melissa",
            "integration: melnor",
            "integration: meppel_afvalkalender",
            "integration: meraki",
            "integration: mercedesme",
            "integration: mercury",
            "integration: message_bird",
            "integration: met",
            "integration: met_eireann",
            "integration: met_lightning",
            "integration: meteo_france",
            "integration: meteoalarm",
            "integration: meteoclimatic",
            "integration: meteoswiss",
            "integration: metlink",
            "integration: metoffice",
            "integration: mfi",
            "integration: mhtzn",
            "integration: mhz19",
            "integration: microBees",
            "integration: microbot_push",
            "integration: micropel",
            "integration: microsoft",
            "integration: microsoft_face",
            "integration: microsoft_face_detect",
            "integration: microsoft_face_identify",
            "integration: microsoft_graph",
            "integration: microsoft_speech",
            "integration: miflora",
            "integration: migardener",
            "integration: migration",
            "integration: mijnafvalwijzer",
            "integration: mijndomein_energie",
            "integration: mikrotik",
            "integration: mikrotik_bt5",
            "integration: mikrotik_firewall",
            "integration: mill",
            "integration: mill_local",
            "integration: min_max",
            "integration: minecraft_server",
            "integration: mini_connected",
            "integration: minio",
            "integration: mint_finance",
            "integration: mipow",
            "integration: miraie_ac",
            "integration: missile_launcher",
            "integration: mitemp_bt",
            "integration: mitsubishicontroller",
            "integration: mjpeg",
            "integration: moat",
            "integration: mobile_app",
            "integration: mobilevikings_pl",
            "integration: mochad",
            "integration: modbus",
            "integration: modbus_sunspec",
            "integration: models",
            "integration: modem_callerid",
            "integration: modern_forms",
            "integration: moehlenhoff_alpha2",
            "integration: mojio",
            "integration: mold_indicator",
            "integration: molohub",
            "integration: monarch_money",
            "integration: monarchmoney",
            "integration: monessen",
            "integration: monoprice",
            "integration: monzo",
            "integration: moon",
            "integration: moonraker",
            "integration: mopar",
            "integration: mopeka",
            "integration: motion_blinds",
            "integration: motionblinds_ble",
            "integration: motioneye",
            "integration: motionmount",
            "integration: mpchc",
            "integration: mpd",
            "integration: mqtt",
            "integration: mqtt_eventstream",
            "integration: mqtt_json",
            "integration: mqtt_room",
            "integration: mqtt_statestream",
            "integration: mqtt_template",
            "integration: msteams",
            "integration: mullvad",
            "integration: multicover",
            "integration: mutesync",
            "integration: mvglive",
            "integration: my",
            "integration: mychevy",
            "integration: mycroft",
            "integration: myfitnesspal",
            "integration: myicomfort",
            "integration: myio",
            "integration: myio_valet_mega",
            "integration: myq",
            "integration: mysensors",
            "integration: mystrom",
            "integration: mythicbeastsdns",
            "integration: myuplink",
            "integration: n26",
            "integration: nad",
            "integration: nad7050",
            "integration: nadtcp",
            "integration: nadtelnet",
            "integration: nam",
            "integration: namecheapdns",
            "integration: nanoleaf",
            "integration: nanoleaf_aurora",
            "integration: nasweb",
            "integration: natural_resources_wales",
            "integration: nea",
            "integration: neato",
            "integration: nederlandse_spoorwegen",
            "integration: neevo",
            "integration: nello",
            "integration: neptune_apex",
            "integration: ness_alarm",
            "integration: nest",
            "integration: netatmo",
            "integration: netatmo_public",
            "integration: netdata",
            "integration: netgear",
            "integration: netgear_lte",
            "integration: netio",
            "integration: netio_json",
            "integration: nettigo",
            "integration: netwave",
            "integration: network",
            "integration: neurio_energy",
            "integration: news",
            "integration: nexia",
            "integration: nextbus",
            "integration: nextcloud",
            "integration: nextdns",
            "integration: nfandroidtv",
            "integration: nhc2",
            "integration: nibe_heatpump",
            "integration: nibe_local",
            "integration: nice_go",
            "integration: nightscout",
            "integration: niko_home_control",
            "integration: nilu",
            "integration: nilu_air_quality",
            "integration: nina",
            "integration: nissan_leaf",
            "integration: niu",
            "integration: nmap_tracker",
            "integration: nmbs",
            "integration: no_ip",
            "integration: noaa_tides",
            "integration: noaaweather",
            "integration: nobo_hub",
            "integration: noonlight",
            "integration: nordpool",
            "integration: norway_air",
            "integration: notify",
            "integration: notify_events",
            "integration: notify_mqtt",
            "integration: notion",
            "integration: npi_gpio",
            "integration: nsw_fuel_station",
            "integration: nsw_rural_fire_service_feed",
            "integration: ntfy",
            "integration: nuheat",
            "integration: nuimo_controller",
            "integration: nuki",
            "integration: numato",
            "integration: number",
            "integration: numeric_float",
            "integration: numeric_integer",
            "integration: numeric_state",
            "integration: nut",
            "integration: nuvo",
            "integration: nws",
            "integration: nws_alerts",
            "integration: nx584",
            "integration: nyt_games",
            "integration: nzbget",
            "integration: oasa",
            "integration: oasa_telematics",
            "integration: obihai",
            "integration: octoprint",
            "integration: oem",
            "integration: ohmconnect",
            "integration: olarm_sensors",
            "integration: ollama",
            "integration: ollama_conversation",
            "integration: ombi",
            "integration: omie",
            "integration: omnilogic",
            "integration: onboarding",
            "integration: oncue",
            "integration: ondilo_ico",
            "integration: onetracker",
            "integration: onewire",
            "integration: onkyo",
            "integration: onkyo_serial",
            "integration: onvif",
            "integration: oocsi",
            "integration: ooler",
            "integration: open_ble_sensors",
            "integration: open_energy_view",
            "integration: open_meteo",
            "integration: openai_conversation",
            "integration: openalpr",
            "integration: openalpr_cloud",
            "integration: openalpr_local",
            "integration: opencv",
            "integration: openerz",
            "integration: openevse",
            "integration: openexchangerates",
            "integration: opengarage",
            "integration: openhardwaremonitor",
            "integration: openhome",
            "integration: openplantbook",
            "integration: openrgb",
            "integration: opensensemap",
            "integration: opensky",
            "integration: opensprinkler",
            "integration: opentherm_gw",
            "integration: opentherm_web",
            "integration: openuv",
            "integration: openweathermap",
            "integration: opnsense",
            "integration: opower",
            "integration: opple",
            "integration: opsgenie",
            "integration: optoma_projector",
            "integration: oralb",
            "integration: orange_funbox",
            "integration: orangepi_gpio",
            "integration: oru",
            "integration: oru_opower",
            "integration: orvibo",
            "integration: osc",
            "integration: osoenergy",
            "integration: osramlightify",
            "integration: otbr",
            "integration: otp",
            "integration: ourgroceries",
            "integration: outlook",
            "integration: overkiz",
            "integration: overseerr",
            "integration: ovo_energy",
            "integration: ovos",
            "integration: owfs",
            "integration: owlet",
            "integration: owntracks",
            "integration: owntracks_http",
            "integration: ozw",
            "integration: p1_monitor",
            "integration: p2pcam",
            "integration: palazzetti",
            "integration: paloalto",
            "integration: pan_tilt_phat",
            "integration: panasonic_bluray",
            "integration: panasonic_viera",
            "integration: pandora",
            "integration: panel_custom",
            "integration: panel_iframe",
            "integration: panel_proxy",
            "integration: particle",
            "integration: pax_ble",
            "integration: pca",
            "integration: pcal9535a",
            "integration: pcf8574",
            "integration: peco",
            "integration: pegel_online",
            "integration: pencom",
            "integration: permobil",
            "integration: persistent_notification",
            "integration: person",
            "integration: pglab",
            "integration: phicomm",
            "integration: philips_air_purifier",
            "integration: philips_airpurifier",
            "integration: philips_js",
            "integration: philips_js_v5",
            "integration: philipslight",
            "integration: phone_modem",
            "integration: phonetrack_oc",
            "integration: pi_hole",
            "integration: pi4ioe5v9xxxx",
            "integration: picnic",
            "integration: picotts",
            "integration: pid_controller",
            "integration: pid_thermostat",
            "integration: piglow",
            "integration: pilight",
            "integration: pinecil",
            "integration: ping",
            "integration: pioneer",
            "integration: piper",
            "integration: pjlink",
            "integration: pjm",
            "integration: plaato",
            "integration: planifneige",
            "integration: plant",
            "integration: plex",
            "integration: plexamp",
            "integration: plugwise",
            "integration: plugwise_stick",
            "integration: plum_lightpad",
            "integration: pocketcasts",
            "integration: point",
            "integration: pollen",
            "integration: pollen_benadryl",
            "integration: polling",
            "integration: poolsense",
            "integration: poolstation",
            "integration: portainer",
            "integration: portlandgeneral",
            "integration: postnl",
            "integration: powerplanner",
            "integration: powerwall",
            "integration: prezzibenzina",
            "integration: private_ble_device",
            "integration: profiler",
            "integration: progettihwsw",
            "integration: projector",
            "integration: proliphix",
            "integration: prometheus",
            "integration: prosegur",
            "integration: prowl",
            "integration: proximity",
            "integration: proxmox",
            "integration: proxmoxve",
            "integration: proxy",
            "integration: prusalink",
            "integration: ps4",
            "integration: pseg",
            "integration: psoklahoma",
            "integration: ptvsd",
            "integration: publibike",
            "integration: pulseaudio",
            "integration: pulseaudio_loopback",
            "integration: pure_energie",
            "integration: purge",
            "integration: purpleair",
            "integration: push",
            "integration: pushbullet",
            "integration: pushetta",
            "integration: pushover",
            "integration: pushsafer",
            "integration: pvoutput",
            "integration: pvpc_hourly_pricing",
            "integration: pvs6_proxy",
            "integration: pyload",
            "integration: pylontech_us",
            "integration: pynubank",
            "integration: pyscript",
            "integration: pytest",
            "integration: python_script",
            "integration: qbittorrent",
            "integration: qbus",
            "integration: qingping",
            "integration: qld_bushfire",
            "integration: qnap",
            "integration: qnap_qsw",
            "integration: qq",
            "integration: qr_generator",
            "integration: qrcode",
            "integration: quadrafire",
            "integration: quantum_gateway",
            "integration: quotable",
            "integration: qvr_pro",
            "integration: qvrpro",
            "integration: qwikswitch",
            "integration: rabbitair",
            "integration: rachio",
            "integration: radarr",
            "integration: radio_browser",
            "integration: radiotherm",
            "integration: rainbird",
            "integration: raincloud",
            "integration: rainforest_eagle",
            "integration: rainforest_raven",
            "integration: rainmachine",
            "integration: rako",
            "integration: random",
            "integration: range",
            "integration: rapt_ble",
            "integration: raspberry_pi",
            "integration: raspberrypi",
            "integration: raspihats",
            "integration: raspyrfm",
            "integration: raven_emu",
            "integration: rdw",
            "integration: recollect_waste",
            "integration: recorder",
            "integration: recovery_mode",
            "integration: recswitch",
            "integration: reddit",
            "integration: refoss",
            "integration: rehau",
            "integration: reisingerbridge",
            "integration: rejseplanen",
            "integration: remember_the_milk",
            "integration: remootio",
            "integration: remote",
            "integration: remote_homeassistant",
            "integration: remote_rpi_gpio",
            "integration: renault",
            "integration: renson",
            "integration: renson_endura_delta",
            "integration: reolink",
            "integration: repairs",
            "integration: repetier",
            "integration: resolution_center",
            "integration: rest",
            "integration: rest_command",
            "integration: rflink",
            "integration: rfxtrx",
            "integration: rhasspy",
            "integration: ridwell",
            "integration: ring",
            "integration: ripple",
            "integration: risco",
            "integration: ritassist",
            "integration: rituals_perfume_genie",
            "integration: rki_covid",
            "integration: RMmini3",
            "integration: rmvtransport",
            "integration: roborock",
            "integration: rocketchat",
            "integration: rointe",
            "integration: roku",
            "integration: romy",
            "integration: room_occupancy",
            "integration: roomba",
            "integration: roon",
            "integration: rotel",
            "integration: route53",
            "integration: rova",
            "integration: rpi_camera",
            "integration: rpi_fanshim",
            "integration: rpi_gpio",
            "integration: rpi_gpio_pwm",
            "integration: rpi_gpiozero",
            "integration: rpi_i2c_chips",
            "integration: rpi_i2c_expanders",
            "integration: rpi_i2c_ha_expanders",
            "integration: rpi_pfio",
            "integration: rpi_pfio2",
            "integration: rpi_power",
            "integration: rpi_rf",
            "integration: rpi_servo",
            "integration: rpi_spi_mcp",
            "integration: rrd",
            "integration: rss_feed_template",
            "integration: rtorrent",
            "integration: rtsp_to_webrtc",
            "integration: ruckus_unleashed",
            "integration: russound_rio",
            "integration: russound_rnet",
            "integration: ruter",
            "integration: ruuvi_gateway",
            "integration: ruuvitag_ble",
            "integration: rympro",
            "integration: ryobi_gdo",
            "integration: ryobiGDO",
            "integration: sabnzbd",
            "integration: safe_mode",
            "integration: saj",
            "integration: salt",
            "integration: salus",
            "integration: samsam",
            "integration: samsungtv",
            "integration: samsungtv_upnp",
            "integration: sanix",
            "integration: satel_integra",
            "integration: scene",
            "integration: schedule",
            "integration: scheduler",
            "integration: schlage",
            "integration: schluter",
            "integration: scl",
            "integration: scrape",
            "integration: screenlogic",
            "integration: script",
            "integration: scsgate",
            "integration: search",
            "integration: season",
            "integration: sector_alarm",
            "integration: securitas_direct",
            "integration: seitron",
            "integration: select",
            "integration: sems_portal",
            "integration: sendgrid",
            "integration: sense",
            "integration: sensehat",
            "integration: senseme",
            "integration: sensibo",
            "integration: sensirion_ble",
            "integration: sensirion_sht31_smart_gadget",
            "integration: sensor",
            "integration: sensorpro",
            "integration: sensorpush",
            "integration: sensorpush_cloud",
            "integration: sensoterra",
            "integration: sentry",
            "integration: senz",
            "integration: senziio",
            "integration: serial",
            "integration: serial_pm",
            "integration: server",
            "integration: sesame",
            "integration: seven_segments",
            "integration: seventeentrack",
            "integration: sfr_box",
            "integration: sharkiq",
            "integration: shell_command",
            "integration: shell_player",
            "integration: shelly",
            "integration: shelly_button_manager",
            "integration: shiftr",
            "integration: shodan",
            "integration: shopping_list",
            "integration: sht31",
            "integration: sia",
            "integration: sigfox",
            "integration: sighthound",
            "integration: signal_messenger",
            "integration: signal_messenger_jsonrpc",
            "integration: simplefin",
            "integration: simplepush",
            "integration: simplisafe",
            "integration: simulated",
            "integration: sinch",
            "integration: sinch_sms",
            "integration: sipcall",
            "integration: siren",
            "integration: sisyphus",
            "integration: sky_hub",
            "integration: sky_plus_hd",
            "integration: sky_remote",
            "integration: skybeacon",
            "integration: skybell",
            "integration: slack",
            "integration: sleepiq",
            "integration: slide",
            "integration: slimproto",
            "integration: slow_pwm",
            "integration: sma",
            "integration: sma_manager",
            "integration: smappee",
            "integration: smappee_official",
            "integration: smart_home",
            "integration: smart_meter_b_route",
            "integration: smart_meter_texas",
            "integration: smartenergy_awattar",
            "integration: smartenergy_goecharger",
            "integration: smartfox",
            "integration: smarthab",
            "integration: smartthings",
            "integration: smarttub",
            "integration: smarty",
            "integration: smhi",
            "integration: smlight",
            "integration: sms",
            "integration: smsapi",
            "integration: smscom",
            "integration: smtp",
            "integration: smud",
            "integration: snapcast",
            "integration: snips",
            "integration: snmp",
            "integration: snooz",
            "integration: sochain",
            "integration: socialblade",
            "integration: solar_frontier",
            "integration: solaredge",
            "integration: solaredge_local",
            "integration: solarlog",
            "integration: solax",
            "integration: solcast_solar",
            "integration: solvis_heating",
            "integration: soma",
            "integration: somfy",
            "integration: somfy_mylink",
            "integration: somfy_tahoma",
            "integration: sonarr",
            "integration: songpal",
            "integration: sonos",
            "integration: sony_projector",
            "integration: soundtouch",
            "integration: southern_company",
            "integration: spaceapi",
            "integration: spanet",
            "integration: spc",
            "integration: speedtest",
            "integration: speedtestdotnet",
            "integration: spider",
            "integration: splunk",
            "integration: spokestack",
            "integration: spokestack_wakeword",
            "integration: spotcrime",
            "integration: spotify",
            "integration: sql",
            "integration: squeezebox",
            "integration: squeezebox_player",
            "integration: srp_energy",
            "integration: ssdp",
            "integration: starline",
            "integration: starlingbank",
            "integration: starlink",
            "integration: starlink_dishy_stats",
            "integration: startca",
            "integration: state",
            "integration: state_schedule",
            "integration: static",
            "integration: statistics",
            "integration: statsd",
            "integration: steady_light",
            "integration: steady_switch",
            "integration: steam_online",
            "integration: steamist",
            "integration: stiebel_eltron",
            "integration: stihl_imow",
            "integration: stookalert",
            "integration: stookwijzer",
            "integration: strava",
            "integration: stream",
            "integration: streamlabswater",
            "integration: stride",
            "integration: stt",
            "integration: subaru",
            "integration: suez_water",
            "integration: suggestions",
            "integration: sum",
            "integration: sun",
            "integration: sungrow",
            "integration: sunsynk",
            "integration: sunsynkweb",
            "integration: sunweg",
            "integration: supervisord",
            "integration: supla",
            "integration: surepetcare",
            "integration: sutro",
            "integration: sveriges_radio",
            "integration: swepco",
            "integration: swidget",
            "integration: swiss_hydrological_data",
            "integration: swiss_public_transport",
            "integration: swisscom",
            "integration: switch",
            "integration: switch_as_x",
            "integration: switchbee",
            "integration: switchbot",
            "integration: switchbot_cloud",
            "integration: switchbot_meter",
            "integration: switcher_kis",
            "integration: switchgrid",
            "integration: switchmate",
            "integration: sws12500",
            "integration: symfonisk",
            "integration: syncthing",
            "integration: syncthru",
            "integration: synology",
            "integration: synology_chat",
            "integration: synology_dsm",
            "integration: synology_homemode",
            "integration: synology_srm",
            "integration: synologydsm",
            "integration: syslog",
            "integration: system_bridge",
            "integration: system_health",
            "integration: system_log",
            "integration: system_monitoring",
            "integration: systemair",
            "integration: systemair_savecair",
            "integration: systemmonitor",
            "integration: sytadin",
            "integration: ta_cmi",
            "integration: tado",
            "integration: tado_v1",
            "integration: tag",
            "integration: tahoma",
            "integration: tailscale",
            "integration: tailwind",
            "integration: tami4",
            "integration: tank_utility",
            "integration: tankerkoenig",
            "integration: tapsaff",
            "integration: tasmota",
            "integration: tasmota_irhvac",
            "integration: tautulli",
            "integration: tcp",
            "integration: tcpbulbs",
            "integration: technicolor",
            "integration: technove",
            "integration: ted",
            "integration: ted5000",
            "integration: ted6000",
            "integration: tedee",
            "integration: teksavvy",
            "integration: telegram",
            "integration: telegram_bot",
            "integration: telegram_client",
            "integration: telegram_poll",
            "integration: telegram_polling",
            "integration: telegram_webhooks",
            "integration: teleinfo",
            "integration: telekomunikace_2n",
            "integration: teletask",
            "integration: tellduslive",
            "integration: tellstick",
            "integration: telnet",
            "integration: temper",
            "integration: template",
            "integration: templated_automation",
            "integration: tensorflow",
            "integration: terncy",
            "integration: tesla",
            "integration: tesla_fleet",
            "integration: tesla_wall_connector",
            "integration: teslemetry",
            "integration: tessie",
            "integration: test",
            "integration: testing",
            "integration: testplatform",
            "integration: texecom",
            "integration: texecominterface",
            "integration: text",
            "integration: textfile",
            "integration: tfiac",
            "integration: tfl",
            "integration: thermobeacon",
            "integration: thermopro",
            "integration: thermoworks_smoke",
            "integration: thethingsnetwork",
            "integration: thethingsnetwork_data",
            "integration: thingbits",
            "integration: thingsmobile",
            "integration: thingspeak",
            "integration: thinkingcleaner",
            "integration: thomson",
            "integration: thread",
            "integration: threshold",
            "integration: tibber",
            "integration: ticktick",
            "integration: tikteck",
            "integration: tile",
            "integration: tilt_ble",
            "integration: time",
            "integration: time_date",
            "integration: timed_state_infer",
            "integration: timer",
            "integration: tis_control",
            "integration: tmb",
            "integration: tmdb",
            "integration: tod",
            "integration: todo",
            "integration: todo_local",
            "integration: todoist",
            "integration: tof",
            "integration: tolo",
            "integration: tolosauna",
            "integration: tomato",
            "integration: tomorrowio",
            "integration: toon",
            "integration: torque",
            "integration: toshiba",
            "integration: totalconnect",
            "integration: touchline",
            "integration: touchline_sl",
            "integration: tp_link_eap",
            "integration: tplink",
            "integration: tplink_deco",
            "integration: tplink_lte",
            "integration: tplink_omada",
            "integration: tplink_tapo",
            "integration: traccar",
            "integration: traccar_server",
            "integration: trace",
            "integration: trackr",
            "integration: tractive",
            "integration: tradfri",
            "integration: trafikverket_camera",
            "integration: trafikverket_ferry",
            "integration: trafikverket_train",
            "integration: trafikverket_weatherstation",
            "integration: transition",
            "integration: translations",
            "integration: transmission",
            "integration: transport_nsw",
            "integration: travel_time",
            "integration: travisci",
            "integration: trello",
            "integration: trend",
            "integration: trigger",
            "integration: triggercmd",
            "integration: tts",
            "integration: tts_homely",
            "integration: tube_state",
            "integration: turn_touch",
            "integration: tuya",
            "integration: tvoverlay",
            "integration: twcmanager",
            "integration: twentemilieu",
            "integration: twilio",
            "integration: twilio_call",
            "integration: twilio_sms",
            "integration: twinkly",
            "integration: twitch",
            "integration: twitter",
            "integration: ubee",
            "integration: uber",
            "integration: ubus",
            "integration: ue_radio",
            "integration: ue_smart_radio",
            "integration: uk_transport",
            "integration: ukraine_alarm",
            "integration: ultraloq",
            "integration: ultrasync",
            "integration: unifi",
            "integration: unifi_direct",
            "integration: unifi_video",
            "integration: unifiled",
            "integration: unifiprotect",
            "integration: universal",
            "integration: unmanic",
            "integration: upb",
            "integration: upc_connect",
            "integration: upcloud",
            "integration: update",
            "integration: updater",
            "integration: upnp",
            "integration: ups",
            "integration: uptime",
            "integration: uptime_kuma",
            "integration: uptimerobot",
            "integration: urlwatch",
            "integration: usb",
            "integration: uscis",
            "integration: usgs_earthquakes_feed",
            "integration: usps",
            "integration: util",
            "integration: utility_cost",
            "integration: utility_meter",
            "integration: uvc",
            "integration: v2c",
            "integration: vacuum",
            "integration: vaillant",
            "integration: validator",
            "integration: vallox",
            "integration: valve",
            "integration: variables",
            "integration: varta_storage",
            "integration: vartastorage",
            "integration: vasttrafik",
            "integration: vconnex",
            "integration: velbus",
            "integration: velo",
            "integration: velux",
            "integration: vemmio",
            "integration: venstar",
            "integration: vera",
            "integration: verisure",
            "integration: vermont_castings",
            "integration: versasense",
            "integration: version",
            "integration: version_control",
            "integration: vestaboard",
            "integration: vesync",
            "integration: vevor_heater",
            "integration: viaggiatreno",
            "integration: viam",
            "integration: viaris",
            "integration: vicare",
            "integration: victron_ble",
            "integration: vilfo",
            "integration: virtual_thermostat",
            "integration: vivotek",
            "integration: vizio",
            "integration: viziosoundbar",
            "integration: vlc",
            "integration: vlc_telnet",
            "integration: vlc-telnet",
            "integration: vodafone_station",
            "integration: voice_assistant",
            "integration: voicerss",
            "integration: voip",
            "integration: volkswagencarnet",
            "integration: volkszaehler",
            "integration: volumio",
            "integration: volvooncall",
            "integration: vorwerk",
            "integration: vrtnws",
            "integration: vulcan",
            "integration: vultr",
            "integration: w800rf32",
            "integration: wake",
            "integration: wake_on_lan",
            "integration: wake_word",
            "integration: walkingpad",
            "integration: wallallcamera",
            "integration: wallallsensor",
            "integration: wallalltts",
            "integration: wallbox",
            "integration: waqi",
            "integration: warmup4ie",
            "integration: watchdog_file_watcher",
            "integration: watchyourlan",
            "integration: water_heater",
            "integration: waterfurnace",
            "integration: waterkotte_heatpump",
            "integration: watson_iot",
            "integration: watson_tts",
            "integration: watts_vision",
            "integration: watttime",
            "integration: waze_travel_time",
            "integration: weather",
            "integration: weatherflow",
            "integration: weatherflow_cloud",
            "integration: weatherkit",
            "integration: weback_cloud",
            "integration: webdav",
            "integration: webhook",
            "integration: webhooks",
            "integration: webmin",
            "integration: webostv",
            "integration: webrtc",
            "integration: websocket_api",
            "integration: weconnect",
            "integration: weenect",
            "integration: weheat",
            "integration: weightedaverage",
            "integration: wemo",
            "integration: wevolor",
            "integration: whirlpool",
            "integration: whisper",
            "integration: whois",
            "integration: wiffi",
            "integration: wilight",
            "integration: wink",
            "integration: wireguard",
            "integration: wirelesstag",
            "integration: wiser",
            "integration: withings",
            "integration: wittiot",
            "integration: wiz",
            "integration: wiz_light",
            "integration: wled",
            "integration: wmspro",
            "integration: wolflink",
            "integration: workalendar",
            "integration: workday",
            "integration: worldclock",
            "integration: worldtidesinfo",
            "integration: worx-landroid",
            "integration: worxlandroid",
            "integration: ws66i",
            "integration: ws980wifi",
            "integration: wsdot",
            "integration: wulu",
            "integration: wunderground",
            "integration: wunderlist",
            "integration: wwlln",
            "integration: wyoming",
            "integration: x10",
            "integration: xbee",
            "integration: xbox",
            "integration: xbox_live",
            "integration: xcel",
            "integration: xeoma",
            "integration: xfinity",
            "integration: xiaofang",
            "integration: xiaomi",
            "integration: xiaomi_aqara",
            "integration: xiaomi_ble",
            "integration: xiaomi_ir",
            "integration: xiaomi_miio",
            "integration: xiaomi_philipslight",
            "integration: xiaomi_plug",
            "integration: xiaomi_tv",
            "integration: xiaomi_vacuum",
            "integration: xknx",
            "integration: xmpp",
            "integration: xs1",
            "integration: yahoo_finance",
            "integration: yale",
            "integration: yale_home",
            "integration: yale_smart_alarm",
            "integration: yalexs_ble",
            "integration: yamaha",
            "integration: yamaha_musiccast",
            "integration: yandex",
            "integration: yandex_transport",
            "integration: yandextts",
            "integration: yardian",
            "integration: yeelight",
            "integration: yeelightsunflower",
            "integration: yeelock",
            "integration: yessssms",
            "integration: yi",
            "integration: yolink",
            "integration: youless",
            "integration: youtube",
            "integration: yr",
            "integration: yweather",
            "integration: zabbix",
            "integration: zabbix_evt_sensors",
            "integration: zamg",
            "integration: zcs_azzurro_inverter",
            "integration: zengge",
            "integration: zengge-wifi",
            "integration: zeroconf",
            "integration: zerproc",
            "integration: zestimate",
            "integration: zeversolar",
            "integration: zeversolar_local",
            "integration: zha",
            "integration: zhong_hong",
            "integration: zigate",
            "integration: zigbee",
            "integration: ziggo_mediabox_xl",
            "integration: ziggo_next",
            "integration: zimi",
            "integration: zimi_test",
            "integration: zodiac",
            "integration: zondergas",
            "integration: zone",
            "integration: zoneminder",
            "integration: zoom",
            "integration: ztm",
            "integration: zwave",
            "integration: zwave_js",
            "integration: zwave_me",
            "integration: zwave_mqtt",
            "integration: zyxelnas",
            "integration: zyxelt50",
            "invalid",
            "master/slave",
            "memory-leak",
            "merging-to-master",
            "merging-to-rc",
            "needs followup review",
            "needs-more-information",
            "network_issue",
            "new-feature",
            "new-integration",
            "new-platform",
            "nginx",
            "no-stale",
            "non-thread-safe operation",
            "noteworthy",
            "outdated-version",
            "parent-merged",
            "platform",
            "problem in config",
            "problem in custom component",
            "problem in database",
            "problem in dependency",
            "problem in device",
            "problem in platform",
            "project-code_style",
            "python",
            "Quality Scale: gold",
            "Quality Scale: internal",
            "Quality Scale: No score",
            "Quality Scale: platinum",
            "Quality Scale: silver",
            "question",
            "Ready for review",
            "regression",
            "reliable-startup",
            "remove-platform",
            "requirement",
            "reverted",
            "rfc",
            "second-opinion-wanted",
            "sensor-tracking",
            "small-pr",
            "smash",
            "spam",
            "stale",
            "supervised",
            "templates",
            "Testing required",
            "to do",
            "translations",
            "under investigation",
            "unittest.TestCase",
            "unsupported",
            "via-github",
            "voluptuous",
            "waiting-for-diagnostics",
            "waiting-for-reply",
            "waiting-for-upstream",
            "windows",
            "wontfix",
            "workaround available",
            "WTH",
            "zwave-certification"
        ],
        "README_content": "Home Assistant |Chat Status|\n=================================================================================\n\nOpen source home automation that puts local control and privacy first. Powered by a worldwide community of tinkerers and DIY enthusiasts. Perfect to run on a Raspberry Pi or a local server.\n\nCheck out `home-assistant.io <https://home-assistant.io>`__ for `a\ndemo <https://demo.home-assistant.io>`__, `installation instructions <https://home-assistant.io/getting-started/>`__,\n`tutorials <https://home-assistant.io/getting-started/automation/>`__ and `documentation <https://home-assistant.io/docs/>`__.\n\nThis is a project of the `Open Home Foundation <https://www.openhomefoundation.org/>`__.\n\n|screenshot-states|\n\nFeatured integrations\n---------------------\n\n|screenshot-integrations|\n\nThe system is built using a modular approach so support for other devices or actions can be implemented easily. See also the `section on architecture <https://developers.home-assistant.io/docs/architecture_index/>`__ and the `section on creating your own\ncomponents <https://developers.home-assistant.io/docs/creating_component_index/>`__.\n\nIf you run into issues while using Home Assistant or during development\nof a component, check the `Home Assistant help section <https://home-assistant.io/help/>`__ of our website for further help and information.\n\n.. |Chat Status| image:: https://img.shields.io/discord/330944238910963714.svg\n   :target: https://www.home-assistant.io/join-chat/\n.. |screenshot-states| image:: https://raw.githubusercontent.com/home-assistant/core/dev/.github/assets/screenshot-states.png\n   :target: https://demo.home-assistant.io\n.. |screenshot-integrations| image:: https://raw.githubusercontent.com/home-assistant/core/dev/.github/assets/screenshot-integrations.png\n   :target: https://home-assistant.io/integrations/\n",
        "num_commits": 85030,
        "project_age_days": 4060,
        "project_created_at": "2013-09-17",
        "latest_updated_at": "2024-10-30",
        "latest_pushed_at": "2024-10-30",
        "num_contributors": 410,
        "num_pull": 75446,
        "num_issues": 128704,
        "num_opening_issue": 2781,
        "project_size(kB)": 663184,
        "num_stargazers": 73043,
        "num_watchers": 73043,
        "num_forks": 30555,
        "num_subscribers": 1337,
        "SecurityPolicy_created_at": "2023-10-19 07:51:35",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "2f1e2efc5ae11bbaee8ee2f6733cfe6627836718",
                "url": "https://github.com/home-assistant/.github/commit/2f1e2efc5ae11bbaee8ee2f6733cfe6627836718",
                "date": "2023-10-19 18:07:09"
            },
            {
                "commit_id": "11aa4f465e4e103f8456b9816da9ea68cf0b248f",
                "url": "https://github.com/home-assistant/.github/commit/11aa4f465e4e103f8456b9816da9ea68cf0b248f",
                "date": "2023-10-19 07:51:35"
            }
        ],
        "project_security_labels": [
            "integration: asterisk_mbox",
            "integration: eufy_security",
            "integration: asterisk_cdr",
            "integration: asterisk_ami"
        ],
        "security_issues": [
            {
                "url": "https://github.com/home-assistant/core/pull/123180",
                "title": "Remove deprecated asterisk_cdr integration",
                "labels": [
                    "core",
                    "breaking-change",
                    "remove-platform",
                    "cla-signed",
                    "small-pr",
                    "integration: asterisk_cdr",
                    "Quality Scale: No score"
                ],
                "user": "joostlek",
                "issue_author_association": "MEMBER",
                "number": 123180,
                "id": 2448190299,
                "state": "closed",
                "project_created_at": "2024-08-05T10:24:11Z",
                "closed_at": "2024-08-05T12:43:39Z",
                "body": "<!--\r\n  You are amazing! Thanks for contributing to our project!\r\n  Please, DO NOT DELETE ANY TEXT from this template! (unless instructed).\r\n-->\r\n## Breaking change\r\n<!--\r\n  If your PR contains a breaking change for existing users, it is important\r\n  to tell them what breaks, how to make it work again and why we did this.\r\n  This piece of text is published with the release notes, so it helps if you\r\n  write it towards our users, not us.\r\n  Note: Remove this section if this PR is NOT a breaking change.\r\n-->\r\nAsterisk_mbox has been deprecated in 2024.3.0 and has been removed\r\n\r\n## Proposed change\r\n<!--\r\n  Describe the big picture of your changes here to communicate to the\r\n  maintainers why we should accept this pull request. If it fixes a bug\r\n  or resolves a feature request, be sure to link to that issue in the\r\n  additional information section.\r\n-->\r\nRemove deprecated asterisk_cdr integration\r\n\r\n## Type of change\r\n<!--\r\n  What type of change does your PR introduce to Home Assistant?\r\n  NOTE: Please, check only 1! box!\r\n  If your PR requires multiple boxes to be checked, you'll most likely need to\r\n  split it into multiple PRs. This makes things easier and faster to code review.\r\n-->\r\n\r\n- [ ] Dependency upgrade\r\n- [ ] Bugfix (non-breaking change which fixes an issue)\r\n- [ ] New integration (thank you!)\r\n- [ ] New feature (which adds functionality to an existing integration)\r\n- [ ] Deprecation (breaking change to happen in the future)\r\n- [x] Breaking change (fix/feature causing existing functionality to break)\r\n- [ ] Code quality improvements to existing code or addition of tests\r\n\r\n## Additional information\r\n<!--\r\n  Details are important, and help maintainers processing your PR.\r\n  Please be sure to fill out additional details, if applicable.\r\n-->\r\n\r\n- This PR fixes or closes issue: fixes #\r\n- This PR is related to issue: \r\n- Link to documentation pull request: \r\n\r\n## Checklist\r\n<!--\r\n  Put an `x` in the boxes that apply. You can also fill these out after\r\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\r\n  We're here to help! This is simply a reminder of what we are going to look\r\n  for before merging your code.\r\n-->\r\n\r\n- [ ] The code change is tested and works locally.\r\n- [x] Local tests pass. **Your PR cannot be merged unless tests pass**\r\n- [x] There is no commented out code in this PR.\r\n- [x] I have followed the [development checklist][dev-checklist]\r\n- [x] I have followed the [perfect PR recommendations][perfect-pr]\r\n- [x] The code has been formatted using Ruff (`ruff format homeassistant tests`)\r\n- [ ] Tests have been added to verify that the new code works.\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n\r\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n\r\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \r\n      Updated and included derived files by running: `python3 -m script.hassfest`.\r\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \r\n      Updated by running `python3 -m script.gen_requirements_all`.\r\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\r\n\r\n<!--\r\n  This project is very active and we have a high turnover of pull requests.\r\n\r\n  Unfortunately, the number of incoming pull requests is higher than what our\r\n  reviewers can review and merge so there is a long backlog of pull requests\r\n  waiting for review. You can help here!\r\n  \r\n  By reviewing another pull request, you will help raise the code quality of\r\n  that pull request and the final review will be faster. This way the general\r\n  pace of pull request reviews will go up and your wait time will go down.\r\n  \r\n  When picking a pull request to review, try to choose one that hasn't yet\r\n  been reviewed.\r\n\r\n  Thanks for helping out!\r\n-->\r\n\r\nTo help with the load of incoming pull requests:\r\n\r\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\r\n\r\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\r\n\r\n<!--\r\n  Thank you for contributing <3\r\n\r\n  Below, some useful links you could explore:\r\n-->\r\n[dev-checklist]: https://developers.home-assistant.io/docs/development_checklist/\r\n[manifest-docs]: https://developers.home-assistant.io/docs/creating_integration_manifest/\r\n[quality-scale]: https://developers.home-assistant.io/docs/integration_quality_scale_index/\r\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\r\n[perfect-pr]: https://developers.home-assistant.io/docs/review-process/#creating-the-perfect-pr\r\n",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/123180",
                    "merged_at": "2024-08-05T12:43:39Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/123174",
                "title": "Remove deprecated asterisk_mbox integration",
                "labels": [
                    "breaking-change",
                    "remove-platform",
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "small-pr",
                    "Quality Scale: No score"
                ],
                "user": "joostlek",
                "issue_author_association": "MEMBER",
                "number": 123174,
                "id": 2448042707,
                "state": "closed",
                "project_created_at": "2024-08-05T09:17:26Z",
                "closed_at": "2024-08-05T13:28:50Z",
                "body": "<!--\r\n  You are amazing! Thanks for contributing to our project!\r\n  Please, DO NOT DELETE ANY TEXT from this template! (unless instructed).\r\n-->\r\n## Breaking change\r\n<!--\r\n  If your PR contains a breaking change for existing users, it is important\r\n  to tell them what breaks, how to make it work again and why we did this.\r\n  This piece of text is published with the release notes, so it helps if you\r\n  write it towards our users, not us.\r\n  Note: Remove this section if this PR is NOT a breaking change.\r\n-->\r\nAsterisk_mbox has been deprecated in 2024.3.0 and has been removed.\r\n\r\n## Proposed change\r\n<!--\r\n  Describe the big picture of your changes here to communicate to the\r\n  maintainers why we should accept this pull request. If it fixes a bug\r\n  or resolves a feature request, be sure to link to that issue in the\r\n  additional information section.\r\n-->\r\nRemove deprecated asterisk_mbox integration\r\n\r\n## Type of change\r\n<!--\r\n  What type of change does your PR introduce to Home Assistant?\r\n  NOTE: Please, check only 1! box!\r\n  If your PR requires multiple boxes to be checked, you'll most likely need to\r\n  split it into multiple PRs. This makes things easier and faster to code review.\r\n-->\r\n\r\n- [ ] Dependency upgrade\r\n- [ ] Bugfix (non-breaking change which fixes an issue)\r\n- [ ] New integration (thank you!)\r\n- [ ] New feature (which adds functionality to an existing integration)\r\n- [ ] Deprecation (breaking change to happen in the future)\r\n- [x] Breaking change (fix/feature causing existing functionality to break)\r\n- [ ] Code quality improvements to existing code or addition of tests\r\n\r\n## Additional information\r\n<!--\r\n  Details are important, and help maintainers processing your PR.\r\n  Please be sure to fill out additional details, if applicable.\r\n-->\r\n\r\n- This PR fixes or closes issue: fixes #\r\n- This PR is related to issue: \r\n- Link to documentation pull request: https://github.com/home-assistant/home-assistant.io/pull/34131\r\n\r\n## Checklist\r\n<!--\r\n  Put an `x` in the boxes that apply. You can also fill these out after\r\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\r\n  We're here to help! This is simply a reminder of what we are going to look\r\n  for before merging your code.\r\n-->\r\n\r\n- [x] The code change is tested and works locally.\r\n- [x] Local tests pass. **Your PR cannot be merged unless tests pass**\r\n- [x] There is no commented out code in this PR.\r\n- [x] I have followed the [development checklist][dev-checklist]\r\n- [x] I have followed the [perfect PR recommendations][perfect-pr]\r\n- [x] The code has been formatted using Ruff (`ruff format homeassistant tests`)\r\n- [ ] Tests have been added to verify that the new code works.\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n\r\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n\r\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \r\n      Updated and included derived files by running: `python3 -m script.hassfest`.\r\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \r\n      Updated by running `python3 -m script.gen_requirements_all`.\r\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\r\n\r\n<!--\r\n  This project is very active and we have a high turnover of pull requests.\r\n\r\n  Unfortunately, the number of incoming pull requests is higher than what our\r\n  reviewers can review and merge so there is a long backlog of pull requests\r\n  waiting for review. You can help here!\r\n  \r\n  By reviewing another pull request, you will help raise the code quality of\r\n  that pull request and the final review will be faster. This way the general\r\n  pace of pull request reviews will go up and your wait time will go down.\r\n  \r\n  When picking a pull request to review, try to choose one that hasn't yet\r\n  been reviewed.\r\n\r\n  Thanks for helping out!\r\n-->\r\n\r\nTo help with the load of incoming pull requests:\r\n\r\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\r\n\r\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\r\n\r\n<!--\r\n  Thank you for contributing <3\r\n\r\n  Below, some useful links you could explore:\r\n-->\r\n[dev-checklist]: https://developers.home-assistant.io/docs/development_checklist/\r\n[manifest-docs]: https://developers.home-assistant.io/docs/creating_integration_manifest/\r\n[quality-scale]: https://developers.home-assistant.io/docs/integration_quality_scale_index/\r\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\r\n[perfect-pr]: https://developers.home-assistant.io/docs/review-process/#creating-the-perfect-pr\r\n",
                "comments": [
                    {
                        "body": "<!-- ReviewDrafterComment -->\nPlease take a look at the requested changes, and use the **Ready for review** button when you are done, thanks :+1:\n\n[_Learn more about our pull request process._](https://developers.home-assistant.io/docs/review-process#prs-are-being-drafted-when-changes-are-needed)\n",
                        "user": "home-assistant[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-08-05T09:57:05Z",
                        "url": "https://github.com/home-assistant/core/pull/123174#issuecomment-2268675505"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/123174",
                    "merged_at": "2024-08-05T13:28:50Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/110930",
                "title": "Deprecate mailbox platform",
                "labels": [
                    "core",
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "integration: mailbox",
                    "integration: asterisk_cdr",
                    "deprecation",
                    "Quality Scale: No score",
                    "Quality Scale: internal"
                ],
                "user": "edenhaus",
                "issue_author_association": "CONTRIBUTOR",
                "number": 110930,
                "id": 2141845395,
                "state": "closed",
                "project_created_at": "2024-02-19T08:55:08Z",
                "closed_at": "2024-02-27T12:50:02Z",
                "body": "<!--\r\n  You are amazing! Thanks for contributing to our project!\r\n  Please, DO NOT DELETE ANY TEXT from this template! (unless instructed).\r\n-->\r\n## Breaking change\r\n<!--\r\n  If your PR contains a breaking change for existing users, it is important\r\n  to tell them what breaks, how to make it work again and why we did this.\r\n  This piece of text is published with the release notes, so it helps if you\r\n  write it towards our users, not us.\r\n  Note: Remove this section if this PR is NOT a breaking change.\r\n-->\r\nDeprecate the mailbox integration platform and the asterisk integrations, as they only implement the mailbox platform.\r\n\r\nWe deprecate the mailbox integration because the mailbox platform is used only by the asterisk integrations, where asterix_cdr has 0 active installations and asterisk_mbox only 25. By removing the mailbox platform we can also remove the custom mailbox panel from the frontend.\r\n\r\n## Proposed change\r\n<!--\r\n  Describe the big picture of your changes here to communicate to the\r\n  maintainers why we should accept this pull request. If it fixes a bug\r\n  or resolves a feature request, be sure to link to that issue in the\r\n  additional information section.\r\n-->\r\nWe deprecate the mailbox integration because the mailbox platform is used only by the asterisk integrations, where asterix_cdr has 0 active installations and asterisk_mbox only 25. By removing the mailbox platform we can also remove the custom mailbox panel from the frontend.\r\n\r\n## Type of change\r\n<!--\r\n  What type of change does your PR introduce to Home Assistant?\r\n  NOTE: Please, check only 1! box!\r\n  If your PR requires multiple boxes to be checked, you'll most likely need to\r\n  split it into multiple PRs. This makes things easier and faster to code review.\r\n-->\r\n\r\n- [ ] Dependency upgrade\r\n- [ ] Bugfix (non-breaking change which fixes an issue)\r\n- [ ] New integration (thank you!)\r\n- [ ] New feature (which adds functionality to an existing integration)\r\n- [x] Deprecation (breaking change to happen in the future)\r\n- [ ] Breaking change (fix/feature causing existing functionality to break)\r\n- [ ] Code quality improvements to existing code or addition of tests\r\n\r\n## Additional information\r\n<!--\r\n  Details are important, and help maintainers processing your PR.\r\n  Please be sure to fill out additional details, if applicable.\r\n-->\r\n\r\n- This PR fixes or closes issue: fixes #\r\n- This PR is related to issue: \r\n- Link to documentation pull request: https://github.com/home-assistant/home-assistant.io/pull/31632\r\n\r\n## Checklist\r\n<!--\r\n  Put an `x` in the boxes that apply. You can also fill these out after\r\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\r\n  We're here to help! This is simply a reminder of what we are going to look\r\n  for before merging your code.\r\n-->\r\n\r\n- [ ] The code change is tested and works locally.\r\n- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**\r\n- [ ] There is no commented out code in this PR.\r\n- [ ] I have followed the [development checklist][dev-checklist]\r\n- [ ] I have followed the [perfect PR recommendations][perfect-pr]\r\n- [ ] The code has been formatted using Ruff (`ruff format homeassistant tests`)\r\n- [ ] Tests have been added to verify that the new code works.\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n\r\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n\r\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \r\n      Updated and included derived files by running: `python3 -m script.hassfest`.\r\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \r\n      Updated by running `python3 -m script.gen_requirements_all`.\r\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\r\n- [ ] Untested files have been added to `.coveragerc`.\r\n\r\n<!--\r\n  This project is very active and we have a high turnover of pull requests.\r\n\r\n  Unfortunately, the number of incoming pull requests is higher than what our\r\n  reviewers can review and merge so there is a long backlog of pull requests\r\n  waiting for review. You can help here!\r\n  \r\n  By reviewing another pull request, you will help raise the code quality of\r\n  that pull request and the final review will be faster. This way the general\r\n  pace of pull request reviews will go up and your wait time will go down.\r\n  \r\n  When picking a pull request to review, try to choose one that hasn't yet\r\n  been reviewed.\r\n\r\n  Thanks for helping out!\r\n-->\r\n\r\nTo help with the load of incoming pull requests:\r\n\r\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\r\n\r\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\r\n\r\n<!--\r\n  Thank you for contributing <3\r\n\r\n  Below, some useful links you could explore:\r\n-->\r\n[dev-checklist]: https://developers.home-assistant.io/docs/development_checklist/\r\n[manifest-docs]: https://developers.home-assistant.io/docs/creating_integration_manifest/\r\n[quality-scale]: https://developers.home-assistant.io/docs/integration_quality_scale_index/\r\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\r\n[perfect-pr]: https://developers.home-assistant.io/docs/review-process/#creating-the-perfect-pr\r\n",
                "comments": [
                    {
                        "body": "I think we should add some context in the PR description why we remove the mailbox integration.",
                        "user": "MartinHjelmare",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-19T13:46:44Z",
                        "url": "https://github.com/home-assistant/core/pull/110930#issuecomment-1952488580"
                    },
                    {
                        "body": "<!-- ReviewDrafterComment -->\nPlease take a look at the requested changes, and use the **Ready for review** button when you are done, thanks :+1:\n\n[_Learn more about our pull request process._](https://developers.home-assistant.io/docs/review-process#prs-are-being-drafted-when-changes-are-needed)\n",
                        "user": "home-assistant[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-27T07:28:58Z",
                        "url": "https://github.com/home-assistant/core/pull/110930#issuecomment-1965940309"
                    },
                    {
                        "body": "CI / Run tests Python 3.11 (7) (pull_request) :\r\n`FAILED tests/components/switcher_kis/test_init.py::test_update_fail - AssertionError: assert 'unavailable' != 'unavailable'` is unrelated",
                        "user": "edenhaus",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-27T12:49:31Z",
                        "url": "https://github.com/home-assistant/core/pull/110930#issuecomment-1966474507"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/110930",
                    "merged_at": "2024-02-27T12:50:02Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/106841",
                "title": "Enable strict typing for asterisk_cdr + asterisk_mbox",
                "labels": [
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "integration: asterisk_cdr",
                    "code-quality",
                    "Quality Scale: No score"
                ],
                "user": "cdce8p",
                "issue_author_association": "MEMBER",
                "number": 106841,
                "id": 2061723033,
                "state": "closed",
                "project_created_at": "2024-01-01T19:09:00Z",
                "closed_at": "2024-01-01T19:45:16Z",
                "body": "## Proposed change\r\nImprove annotations and enable strict typing.\r\n\r\n## Type of change\r\n<!--\r\n  What type of change does your PR introduce to Home Assistant?\r\n  NOTE: Please, check only 1! box!\r\n  If your PR requires multiple boxes to be checked, you'll most likely need to\r\n  split it into multiple PRs. This makes things easier and faster to code review.\r\n-->\r\n\r\n- [ ] Dependency upgrade\r\n- [ ] Bugfix (non-breaking change which fixes an issue)\r\n- [ ] New integration (thank you!)\r\n- [ ] New feature (which adds functionality to an existing integration)\r\n- [ ] Deprecation (breaking change to happen in the future)\r\n- [ ] Breaking change (fix/feature causing existing functionality to break)\r\n- [x] Code quality improvements to existing code or addition of tests\r\n\r\n## Additional information\r\n<!--\r\n  Details are important, and help maintainers processing your PR.\r\n  Please be sure to fill out additional details, if applicable.\r\n-->\r\n\r\n- This PR fixes or closes issue: fixes #\r\n- This PR is related to issue: \r\n- Link to documentation pull request: \r\n\r\n## Checklist\r\n<!--\r\n  Put an `x` in the boxes that apply. You can also fill these out after\r\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\r\n  We're here to help! This is simply a reminder of what we are going to look\r\n  for before merging your code.\r\n-->\r\n\r\n- [ ] The code change is tested and works locally.\r\n- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**\r\n- [ ] There is no commented out code in this PR.\r\n- [ ] I have followed the [development checklist][dev-checklist]\r\n- [ ] I have followed the [perfect PR recommendations][perfect-pr]\r\n- [ ] The code has been formatted using Ruff (`ruff format homeassistant tests`)\r\n- [ ] Tests have been added to verify that the new code works.\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n\r\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n\r\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \r\n      Updated and included derived files by running: `python3 -m script.hassfest`.\r\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \r\n      Updated by running `python3 -m script.gen_requirements_all`.\r\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\r\n- [ ] Untested files have been added to `.coveragerc`.\r\n\r\n<!--\r\n  This project is very active and we have a high turnover of pull requests.\r\n\r\n  Unfortunately, the number of incoming pull requests is higher than what our\r\n  reviewers can review and merge so there is a long backlog of pull requests\r\n  waiting for review. You can help here!\r\n  \r\n  By reviewing another pull request, you will help raise the code quality of\r\n  that pull request and the final review will be faster. This way the general\r\n  pace of pull request reviews will go up and your wait time will go down.\r\n  \r\n  When picking a pull request to review, try to choose one that hasn't yet\r\n  been reviewed.\r\n\r\n  Thanks for helping out!\r\n-->\r\n\r\nTo help with the load of incoming pull requests:\r\n\r\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\r\n\r\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\r\n\r\n<!--\r\n  Thank you for contributing <3\r\n\r\n  Below, some useful links you could explore:\r\n-->\r\n[dev-checklist]: https://developers.home-assistant.io/docs/development_checklist/\r\n[manifest-docs]: https://developers.home-assistant.io/docs/creating_integration_manifest/\r\n[quality-scale]: https://developers.home-assistant.io/docs/integration_quality_scale_index/\r\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\r\n[perfect-pr]: https://developers.home-assistant.io/docs/review-process/#creating-the-perfect-pr\r\n",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/106841",
                    "merged_at": "2024-01-01T19:45:16Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/78353",
                "title": "Improve type hints in mailbox",
                "labels": [
                    "core",
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "integration: mailbox",
                    "code-quality",
                    "smash"
                ],
                "user": "epenet",
                "issue_author_association": "CONTRIBUTOR",
                "number": 78353,
                "id": 1371070276,
                "state": "closed",
                "project_created_at": "2022-09-13T08:34:46Z",
                "closed_at": "2022-09-13T19:55:50Z",
                "body": "## Proposed change\n<!--\n  Describe the big picture of your changes here to communicate to the\n  maintainers why we should accept this pull request. If it fixes a bug\n  or resolves a feature request, be sure to link to that issue in the\n  additional information section.\n-->\nImprove type hints in mailbox\n\n## Type of change\n<!--\n  What type of change does your PR introduce to Home Assistant?\n  NOTE: Please, check only 1! box!\n  If your PR requires multiple boxes to be checked, you'll most likely need to\n  split it into multiple PRs. This makes things easier and faster to code review.\n-->\n\n- [ ] Dependency upgrade\n- [ ] Bugfix (non-breaking change which fixes an issue)\n- [ ] New integration (thank you!)\n- [ ] New feature (which adds functionality to an existing integration)\n- [ ] Deprecation (breaking change to happen in the future)\n- [ ] Breaking change (fix/feature causing existing functionality to break)\n- [x] Code quality improvements to existing code or addition of tests\n\n## Additional information\n<!--\n  Details are important, and help maintainers processing your PR.\n  Please be sure to fill out additional details, if applicable.\n-->\n\n- This PR fixes or closes issue: fixes #\n- This PR is related to issue: \n- Link to documentation pull request: \n\n## Checklist\n<!--\n  Put an `x` in the boxes that apply. You can also fill these out after\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\n  We're here to help! This is simply a reminder of what we are going to look\n  for before merging your code.\n-->\n\n- [ ] The code change is tested and works locally.\n- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**\n- [ ] There is no commented out code in this PR.\n- [ ] I have followed the [development checklist][dev-checklist]\n- [ ] The code has been formatted using Black (`black --fast homeassistant tests`)\n- [ ] Tests have been added to verify that the new code works.\n\nIf user exposed functionality or configuration variables are added/changed:\n\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\n\nIf the code communicates with devices, web services, or third-party tools:\n\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \n      Updated and included derived files by running: `python3 -m script.hassfest`.\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \n      Updated by running `python3 -m script.gen_requirements_all`.\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\n- [ ] Untested files have been added to `.coveragerc`.\n\nThe integration reached or maintains the following [Integration Quality Scale][quality-scale]:\n<!--\n  The Integration Quality Scale scores an integration on the code quality\n  and user experience. Each level of the quality scale consists of a list\n  of requirements. We highly recommend getting your integration scored!\n-->\n\n- [ ] No score or internal\n- [ ]  Silver\n- [ ]  Gold\n- [ ]  Platinum\n\n<!--\n  This project is very active and we have a high turnover of pull requests.\n\n  Unfortunately, the number of incoming pull requests is higher than what our\n  reviewers can review and merge so there is a long backlog of pull requests\n  waiting for review. You can help here!\n  \n  By reviewing another pull request, you will help raise the code quality of\n  that pull request and the final review will be faster. This way the general\n  pace of pull request reviews will go up and your wait time will go down.\n  \n  When picking a pull request to review, try to choose one that hasn't yet\n  been reviewed.\n\n  Thanks for helping out!\n-->\n\nTo help with the load of incoming pull requests:\n\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\n\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\n\n<!--\n  Thank you for contributing <3\n\n  Below, some useful links you could explore:\n-->\n[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html\n[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html\n[quality-scale]: https://developers.home-assistant.io/docs/en/next/integration_quality_scale_index.html\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\n",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/78353",
                    "merged_at": "2022-09-13T19:55:50Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/64051",
                "title": "Adjust mailbox type hints",
                "labels": [
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "small-pr",
                    "integration: asterisk_cdr",
                    "code-quality"
                ],
                "user": "epenet",
                "issue_author_association": "CONTRIBUTOR",
                "number": 64051,
                "id": 1101752085,
                "state": "closed",
                "project_created_at": "2022-01-13T13:42:33Z",
                "closed_at": "2022-01-13T13:53:39Z",
                "body": "## Proposed change\r\n<!--\r\n  Describe the big picture of your changes here to communicate to the\r\n  maintainers why we should accept this pull request. If it fixes a bug\r\n  or resolves a feature request, be sure to link to that issue in the\r\n  additional information section.\r\n-->\r\nFollow-up to #64029\r\ncc @frenck \r\n\r\n## Type of change\r\n<!--\r\n  What type of change does your PR introduce to Home Assistant?\r\n  NOTE: Please, check only 1! box!\r\n  If your PR requires multiple boxes to be checked, you'll most likely need to\r\n  split it into multiple PRs. This makes things easier and faster to code review.\r\n-->\r\n\r\n- [ ] Dependency upgrade\r\n- [ ] Bugfix (non-breaking change which fixes an issue)\r\n- [ ] New integration (thank you!)\r\n- [ ] New feature (which adds functionality to an existing integration)\r\n- [ ] Breaking change (fix/feature causing existing functionality to break)\r\n- [x] Code quality improvements to existing code or addition of tests\r\n\r\n## Additional information\r\n<!--\r\n  Details are important, and help maintainers processing your PR.\r\n  Please be sure to fill out additional details, if applicable.\r\n-->\r\n\r\n- This PR fixes or closes issue: fixes #\r\n- This PR is related to issue: \r\n- Link to documentation pull request: \r\n\r\n## Checklist\r\n<!--\r\n  Put an `x` in the boxes that apply. You can also fill these out after\r\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\r\n  We're here to help! This is simply a reminder of what we are going to look\r\n  for before merging your code.\r\n-->\r\n\r\n- [ ] The code change is tested and works locally.\r\n- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**\r\n- [ ] There is no commented out code in this PR.\r\n- [ ] I have followed the [development checklist][dev-checklist]\r\n- [ ] The code has been formatted using Black (`black --fast homeassistant tests`)\r\n- [ ] Tests have been added to verify that the new code works.\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n\r\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n\r\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \r\n      Updated and included derived files by running: `python3 -m script.hassfest`.\r\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \r\n      Updated by running `python3 -m script.gen_requirements_all`.\r\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\r\n- [ ] Untested files have been added to `.coveragerc`.\r\n\r\nThe integration reached or maintains the following [Integration Quality Scale][quality-scale]:\r\n<!--\r\n  The Integration Quality Scale scores an integration on the code quality\r\n  and user experience. Each level of the quality scale consists of a list\r\n  of requirements. We highly recommend getting your integration scored!\r\n-->\r\n\r\n- [ ] No score or internal\r\n- [ ]  Silver\r\n- [ ]  Gold\r\n- [ ]  Platinum\r\n\r\n<!--\r\n  This project is very active and we have a high turnover of pull requests.\r\n\r\n  Unfortunately, the number of incoming pull requests is higher than what our\r\n  reviewers can review and merge so there is a long backlog of pull requests\r\n  waiting for review. You can help here!\r\n  \r\n  By reviewing another pull request, you will help raise the code quality of\r\n  that pull request and the final review will be faster. This way the general\r\n  pace of pull request reviews will go up and your wait time will go down.\r\n  \r\n  When picking a pull request to review, try to choose one that hasn't yet\r\n  been reviewed.\r\n\r\n  Thanks for helping out!\r\n-->\r\n\r\nTo help with the load of incoming pull requests:\r\n\r\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\r\n\r\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\r\n\r\n<!--\r\n  Thank you for contributing <3\r\n\r\n  Below, some useful links you could explore:\r\n-->\r\n[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html\r\n[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html\r\n[quality-scale]: https://developers.home-assistant.io/docs/en/next/integration_quality_scale_index.html\r\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\r\n",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/64051",
                    "merged_at": "2022-01-13T13:53:39Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/63975",
                "title": "Add setup type hints to mailboxes",
                "labels": [
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "small-pr",
                    "integration: asterisk_cdr",
                    "code-quality",
                    "smash"
                ],
                "user": "epenet",
                "issue_author_association": "CONTRIBUTOR",
                "number": 63975,
                "id": 1100334223,
                "state": "closed",
                "project_created_at": "2022-01-12T13:20:05Z",
                "closed_at": "2022-01-12T13:25:37Z",
                "body": "## Proposed change\r\n<!--\r\n  Describe the big picture of your changes here to communicate to the\r\n  maintainers why we should accept this pull request. If it fixes a bug\r\n  or resolves a feature request, be sure to link to that issue in the\r\n  additional information section.\r\n-->\r\nI recently discoverd async_get_handler/get_handler in mailbox platform.\r\nThis PR is 100% pure type hint\r\n\r\n## Type of change\r\n<!--\r\n  What type of change does your PR introduce to Home Assistant?\r\n  NOTE: Please, check only 1! box!\r\n  If your PR requires multiple boxes to be checked, you'll most likely need to\r\n  split it into multiple PRs. This makes things easier and faster to code review.\r\n-->\r\n\r\n- [ ] Dependency upgrade\r\n- [ ] Bugfix (non-breaking change which fixes an issue)\r\n- [ ] New integration (thank you!)\r\n- [ ] New feature (which adds functionality to an existing integration)\r\n- [ ] Breaking change (fix/feature causing existing functionality to break)\r\n- [x] Code quality improvements to existing code or addition of tests\r\n\r\n## Additional information\r\n<!--\r\n  Details are important, and help maintainers processing your PR.\r\n  Please be sure to fill out additional details, if applicable.\r\n-->\r\n\r\n- This PR fixes or closes issue: fixes #\r\n- This PR is related to issue: \r\n- Link to documentation pull request: \r\n\r\n## Checklist\r\n<!--\r\n  Put an `x` in the boxes that apply. You can also fill these out after\r\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\r\n  We're here to help! This is simply a reminder of what we are going to look\r\n  for before merging your code.\r\n-->\r\n\r\n- [ ] The code change is tested and works locally.\r\n- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**\r\n- [ ] There is no commented out code in this PR.\r\n- [ ] I have followed the [development checklist][dev-checklist]\r\n- [ ] The code has been formatted using Black (`black --fast homeassistant tests`)\r\n- [ ] Tests have been added to verify that the new code works.\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n\r\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n\r\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \r\n      Updated and included derived files by running: `python3 -m script.hassfest`.\r\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \r\n      Updated by running `python3 -m script.gen_requirements_all`.\r\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\r\n- [ ] Untested files have been added to `.coveragerc`.\r\n\r\nThe integration reached or maintains the following [Integration Quality Scale][quality-scale]:\r\n<!--\r\n  The Integration Quality Scale scores an integration on the code quality\r\n  and user experience. Each level of the quality scale consists of a list\r\n  of requirements. We highly recommend getting your integration scored!\r\n-->\r\n\r\n- [ ] No score or internal\r\n- [ ]  Silver\r\n- [ ]  Gold\r\n- [ ]  Platinum\r\n\r\n<!--\r\n  This project is very active and we have a high turnover of pull requests.\r\n\r\n  Unfortunately, the number of incoming pull requests is higher than what our\r\n  reviewers can review and merge so there is a long backlog of pull requests\r\n  waiting for review. You can help here!\r\n  \r\n  By reviewing another pull request, you will help raise the code quality of\r\n  that pull request and the final review will be faster. This way the general\r\n  pace of pull request reviews will go up and your wait time will go down.\r\n  \r\n  When picking a pull request to review, try to choose one that hasn't yet\r\n  been reviewed.\r\n\r\n  Thanks for helping out!\r\n-->\r\n\r\nTo help with the load of incoming pull requests:\r\n\r\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\r\n\r\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\r\n\r\n<!--\r\n  Thank you for contributing <3\r\n\r\n  Below, some useful links you could explore:\r\n-->\r\n[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html\r\n[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html\r\n[quality-scale]: https://developers.home-assistant.io/docs/en/next/integration_quality_scale_index.html\r\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\r\n",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/63975",
                    "merged_at": "2022-01-12T13:25:37Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/63424",
                "title": "Add setup type hints [a]",
                "labels": [
                    "core",
                    "cla-signed",
                    "integration: api",
                    "integration: asterisk_mbox",
                    "integration: anel_pwrctrl",
                    "integration: alpha_vantage",
                    "integration: arest",
                    "code-quality",
                    "integration: airtouch4",
                    "smash"
                ],
                "user": "epenet",
                "issue_author_association": "CONTRIBUTOR",
                "number": 63424,
                "id": 1094061162,
                "state": "closed",
                "project_created_at": "2022-01-05T07:30:54Z",
                "closed_at": "2022-01-05T13:15:58Z",
                "body": "## Proposed change\r\n<!--\r\n  Describe the big picture of your changes here to communicate to the\r\n  maintainers why we should accept this pull request. If it fixes a bug\r\n  or resolves a feature request, be sure to link to that issue in the\r\n  additional information section.\r\n-->\r\nAs follow-up to #63098, add more setup type hints.\r\n\r\nThese components needed a few tweaks to pass mypy.\r\n\r\n## Type of change\r\n<!--\r\n  What type of change does your PR introduce to Home Assistant?\r\n  NOTE: Please, check only 1! box!\r\n  If your PR requires multiple boxes to be checked, you'll most likely need to\r\n  split it into multiple PRs. This makes things easier and faster to code review.\r\n-->\r\n\r\n- [ ] Dependency upgrade\r\n- [ ] Bugfix (non-breaking change which fixes an issue)\r\n- [ ] New integration (thank you!)\r\n- [ ] New feature (which adds functionality to an existing integration)\r\n- [ ] Breaking change (fix/feature causing existing functionality to break)\r\n- [x] Code quality improvements to existing code or addition of tests\r\n\r\n## Additional information\r\n<!--\r\n  Details are important, and help maintainers processing your PR.\r\n  Please be sure to fill out additional details, if applicable.\r\n-->\r\n\r\n- This PR fixes or closes issue: fixes #\r\n- This PR is related to issue: \r\n- Link to documentation pull request: \r\n\r\n## Checklist\r\n<!--\r\n  Put an `x` in the boxes that apply. You can also fill these out after\r\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\r\n  We're here to help! This is simply a reminder of what we are going to look\r\n  for before merging your code.\r\n-->\r\n\r\n- [ ] The code change is tested and works locally.\r\n- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**\r\n- [ ] There is no commented out code in this PR.\r\n- [ ] I have followed the [development checklist][dev-checklist]\r\n- [ ] The code has been formatted using Black (`black --fast homeassistant tests`)\r\n- [ ] Tests have been added to verify that the new code works.\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n\r\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n\r\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \r\n      Updated and included derived files by running: `python3 -m script.hassfest`.\r\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \r\n      Updated by running `python3 -m script.gen_requirements_all`.\r\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\r\n- [ ] Untested files have been added to `.coveragerc`.\r\n\r\nThe integration reached or maintains the following [Integration Quality Scale][quality-scale]:\r\n<!--\r\n  The Integration Quality Scale scores an integration on the code quality\r\n  and user experience. Each level of the quality scale consists of a list\r\n  of requirements. We highly recommend getting your integration scored!\r\n-->\r\n\r\n- [ ] No score or internal\r\n- [ ]  Silver\r\n- [ ]  Gold\r\n- [ ]  Platinum\r\n\r\n<!--\r\n  This project is very active and we have a high turnover of pull requests.\r\n\r\n  Unfortunately, the number of incoming pull requests is higher than what our\r\n  reviewers can review and merge so there is a long backlog of pull requests\r\n  waiting for review. You can help here!\r\n  \r\n  By reviewing another pull request, you will help raise the code quality of\r\n  that pull request and the final review will be faster. This way the general\r\n  pace of pull request reviews will go up and your wait time will go down.\r\n  \r\n  When picking a pull request to review, try to choose one that hasn't yet\r\n  been reviewed.\r\n\r\n  Thanks for helping out!\r\n-->\r\n\r\nTo help with the load of incoming pull requests:\r\n\r\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\r\n\r\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\r\n\r\n<!--\r\n  Thank you for contributing <3\r\n\r\n  Below, some useful links you could explore:\r\n-->\r\n[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html\r\n[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html\r\n[quality-scale]: https://developers.home-assistant.io/docs/en/next/integration_quality_scale_index.html\r\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\r\n",
                "comments": [
                    {
                        "body": "Hey there @fabaff, mind taking a look at this pull request as it has been labeled with an integration (`arest`) you are listed as a [code owner](https://github.com/home-assistant/core/blob/dev/CODEOWNERS#L81) for? Thanks!\n<sub><sup>(message by CodeOwnersMention)</sup></sub>",
                        "user": "probot-home-assistant[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-01-05T07:31:04Z",
                        "url": "https://github.com/home-assistant/core/pull/63424#issuecomment-1005445639"
                    },
                    {
                        "body": "Hey there @fabaff, mind taking a look at this pull request as it has been labeled with an integration (`alpha_vantage`) you are listed as a [code owner](https://github.com/home-assistant/core/blob/dev/CODEOWNERS#L54) for? Thanks!\n<sub><sup>(message by CodeOwnersMention)</sup></sub>",
                        "user": "probot-home-assistant[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-01-05T07:31:06Z",
                        "url": "https://github.com/home-assistant/core/pull/63424#issuecomment-1005445658"
                    },
                    {
                        "body": "Hey there @lonepurplewolf, mind taking a look at this pull request as it has been labeled with an integration (`airtouch4`) you are listed as a [code owner](https://github.com/home-assistant/core/blob/dev/CODEOWNERS#L44) for? Thanks!\n<sub><sup>(message by CodeOwnersMention)</sup></sub>",
                        "user": "probot-home-assistant[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-01-05T07:31:07Z",
                        "url": "https://github.com/home-assistant/core/pull/63424#issuecomment-1005445663"
                    },
                    {
                        "body": "Hey there @home-assistant/core, mind taking a look at this pull request as it has been labeled with an integration (`api`) you are listed as a [code owner](https://github.com/home-assistant/core/blob/dev/CODEOWNERS#L70) for? Thanks!\n<sub><sup>(message by CodeOwnersMention)</sup></sub>",
                        "user": "probot-home-assistant[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2022-01-05T07:31:07Z",
                        "url": "https://github.com/home-assistant/core/pull/63424#issuecomment-1005445668"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/63424",
                    "merged_at": "2022-01-05T13:15:58Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/issues/49363",
                "title": "I have an issue playing a stream from an API \"Rest Coomand\"",
                "labels": [
                    "stale",
                    "integration: eufy_security"
                ],
                "user": "hamdanfadi",
                "issue_author_association": "NONE",
                "number": 49363,
                "id": 860546280,
                "state": "closed",
                "project_created_at": "2021-04-18T00:57:21Z",
                "closed_at": "2021-07-24T13:07:07Z",
                "body": "### The problem\r\nI'm trying to stream a camera using Rest API \r\nI'm getting an error in my log: \r\nError opening stream No Stream\r\n12:49:17 PM  (ERROR) Stream - message first occurred at 12:45:54 PM and shows up 7 times\r\n\r\nWhen I inspect the page I have found this issue:\r\nhttp://hass:8123/api/hls/fc285d4d2ae1787ea84c30736e2ada4e2a1b72869348d2784205d88427b2718f/master_playlist.m3u8\r\n\r\nCan you please hep how to resolve it?\r\n\r\nThis issue only happened after version -2021.4.x\r\n\r\nCheers,\r\n\r\n### What is version of Home Assistant Core has the issue?\r\n\r\ncore-2021.4.5\r\n\r\n### What was the last working version of Home Assistant Core?\r\n\r\ncore-2021.4.5\r\n\r\n### What type of installation are you running?\r\n\r\nHome Assistant OS\r\n\r\n### Integration causing the issue\r\n\r\nNo idea\r\n\r\n### Link to integration documentation on our website\r\n\r\n_No response_\r\n\r\n### Example YAML snippet\r\n\r\n```yaml\r\nrest_command:\r\n  eufy_start_stream:\r\n    url: \"http://192.168.88.86:8087/toggle/eufy-security.0.T8010N13203000F1.cameras.T8113N13203004DC.start_stream\"\r\n  eufy_stop_stream:\r\n    url: \"http://192.168.88.86:8087/toggle/eufy-security.0.T8010N13203000F1.cameras.T8113N13203004DC.stop_stream\"\r\n#------\r\n```\r\n\r\n\r\n### Anything in the logs that might be useful for us?\r\n\r\n_No response_\r\n\r\n### Additional information\r\n\r\n_No response_",
                "comments": [
                    {
                        "body": "> When I inspect the page I have found this issue:\r\n\r\nWhat issue ? You just posted a URL, but that does not say much.\r\n\r\nAlso how can the broken version and the last version where it worked be the same ? Please double check your issue info.",
                        "user": "spacegaier",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2021-04-18T12:21:59Z",
                        "url": "https://github.com/home-assistant/core/issues/49363#issuecomment-821983243"
                    },
                    {
                        "body": "[eufy_security documentation](https://www.home-assistant.io/integrations/eufy_security)\n[eufy_security source](https://github.com/home-assistant/core/tree/dev/homeassistant/components/eufy_security)\n<sub><sup>(message by IssueLinks)</sup></sub>",
                        "user": "probot-home-assistant[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-04-18T12:22:52Z",
                        "url": "https://github.com/home-assistant/core/issues/49363#issuecomment-821983348"
                    },
                    {
                        "body": "There hasn't been any activity on this issue recently. Due to the high number of incoming GitHub notifications, we have to clean some of the old issues, as many of them have already been resolved with the latest updates.\nPlease make sure to update to the latest Home Assistant version and check if that solves the issue. Let us know if that works for you by adding a comment \nThis issue has now been marked as stale and will be closed if no further activity occurs. Thank you for your contributions.",
                        "user": "github-actions[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2021-07-17T13:06:55Z",
                        "url": "https://github.com/home-assistant/core/issues/49363#issuecomment-881896186"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/home-assistant/core/pull/28443",
                "title": "Add support for Eufy Security cameras/doorbells",
                "labels": [
                    "cla-signed",
                    "docs-missing",
                    "new-integration",
                    "integration: eufy_security"
                ],
                "user": "bachya",
                "issue_author_association": "CONTRIBUTOR",
                "number": 28443,
                "id": 516230581,
                "state": "closed",
                "project_created_at": "2019-11-01T16:54:05Z",
                "closed_at": "2020-01-21T20:31:01Z",
                "body": "## Description:\r\n\r\nThis PR adds support for Eufy Security devices (cameras and doorbells). This integration is separate from the `eufy` integration.\r\n\r\n**Related issue (if applicable):** N/A\r\n\r\n**Pull request with documentation for [home-assistant.io](https://github.com/home-assistant/home-assistant.io) (if applicable):** TBD\r\n\r\n## Example entry for `configuration.yaml` (if applicable):\r\n```yaml\r\neufy_security:\r\n  username: !secret eufy_security_email\r\n  password: !secret eufy_security_password\r\n```\r\n\r\n## Checklist:\r\n  - [ ] The code change is tested and works locally.\r\n  - [ ] Local tests pass with `tox`. **Your PR cannot be merged unless tests pass**\r\n  - [ ] There is no commented out code in this PR.\r\n  - [ ] I have followed the [development checklist][dev-checklist]\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n  - [ ] Documentation added/updated in [home-assistant.io](https://github.com/home-assistant/home-assistant.io)\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n  - [ ] [_The manifest file_][manifest-docs] has all fields filled out correctly. Update and include derived files by running `python3 -m script.hassfest`.\r\n  - [ ] New or updated dependencies have been added to `requirements_all.txt` by running `python3 -m script.gen_requirements_all`.\r\n  - [ ] Untested files have been added to `.coveragerc`.\r\n\r\nIf the code does not interact with devices:\r\n  - [ ] Tests have been added to verify that the new code works.\r\n\r\n[dev-checklist]: https://developers.home-assistant.io/docs/en/development_checklist.html\r\n[manifest-docs]: https://developers.home-assistant.io/docs/en/creating_integration_manifest.html\r\n",
                "comments": [
                    {
                        "body": "There is a ways to go before this is ready  even then, based on what we're seeing, it may be better served as a custom component. Going to close for now.",
                        "user": "bachya",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2020-01-21T20:31:00Z",
                        "url": "https://github.com/home-assistant/core/pull/28443#issuecomment-576867251"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/28443",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/27807",
                "title": "Move imports in asterisk_mbox component",
                "labels": [
                    "Hacktoberfest",
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "small-pr"
                ],
                "user": "Bouni",
                "issue_author_association": "CONTRIBUTOR",
                "number": 27807,
                "id": 508526603,
                "state": "closed",
                "project_created_at": "2019-10-17T14:45:12Z",
                "closed_at": "2019-10-18T00:08:59Z",
                "body": "## Breaking Change:\r\n\r\nNone\r\n\r\n## Description:\r\n\r\nMoved import from function to top-level as requested in #27284\r\n\r\n## Checklist:\r\n\r\n- [ ] The code change is tested and works locally.\r\n- [x] Local tests pass with tox. Your PR cannot be merged unless tests pass\r\n- [x] There is no commented out code in this PR.\r\n- [x] I have followed the development checklist\r\n\r\nNote: imports sorted using [isort](https://pypi.org/project/isort/)",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/27807",
                    "merged_at": "2019-10-18T00:08:59Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/16940",
                "title": "0.79.0",
                "labels": [
                    "core",
                    "merging-to-master",
                    "integration: alexa",
                    "integration: spc",
                    "integration: asterisk_mbox",
                    "integration: apple_tv",
                    "integration: auth"
                ],
                "user": "balloob",
                "issue_author_association": "MEMBER",
                "number": 16940,
                "id": 364892189,
                "state": "closed",
                "project_created_at": "2018-09-28T13:36:46Z",
                "closed_at": "2018-09-28T14:51:25Z",
                "body": "## New Platforms\r\n\r\n- Add Huawei LTE router platform, device tracker, and sensor ([@scop] - [#16498]) ([device_tracker docs]) ([huawei_lte docs]) ([sensor.huawei_lte docs]) (new-platform)\r\n- New EDP re:dy component ([@abmantis] - [#16426]) ([edp_redy docs]) ([sensor.edp_redy docs]) ([switch.edp_redy docs]) (new-platform)\r\n- Jewish calendar sensor ([@tsvi] - [#16393]) ([sensor.jewish_calendar docs]) (new-platform)\r\n- Added support for Starling Bank ([@Dullage] - [#16522]) ([sensor.starlingbank docs]) (new-platform)\r\n- Add Call Data Log platform. Mailboxes no longer require media ([@PhracturedBlue] - [#16579]) ([asterisk_mbox docs]) ([mailbox docs]) ([mailbox.asterisk_cdr docs]) ([mailbox.asterisk_mbox docs]) (new-platform)\r\n- Add Logi Circle component, camera and sensor platform ([@evanjd] - [#16540]) ([logi_circle docs]) ([camera.logi_circle docs]) ([sensor.logi_circle docs]) (new-platform)\r\n- deCONZ cover support ([@Kane610] - [#16759]) ([cover docs]) ([deconz docs]) ([cover.deconz docs]) (new-platform)\r\n- GeoJSON platform ([@exxamalte] - [#16610]) ([geo_location docs]) (new-platform)\r\n- Add linky sensor ([@tiste] - [#16468]) ([sensor.linky docs]) (new-platform)\r\n\r\n## Breaking Changes\r\n\r\n- Netdata configuration change: Allows multiple elements per group. Specify the `data_group` as part of the sensor description. See docs for details. ([@reefab] - [#16656]) ([sensor.netdata docs]) (breaking change)\r\n- The Dyson sensor Air Quality Index is now named AQI following Dyson's mobile app ([@glpatcern] - [#14550]) ([sensor.dyson docs]) (breaking change)\r\n\r\n## Beta Fixes\r\n\r\n- Don't warn but info when on dev mode ([@balloob] - [#16831]) ([updater docs]) (beta fix)\r\n- Bump zm-py to 0.0.3 ([@rohankapoorcom] - [#16835]) ([zoneminder docs]) (beta fix)\r\n- Support old tradfri config format ([@balloob] - [#16841]) ([tradfri docs]) (beta fix)\r\n- Allow MQTT discovery ([@balloob] - [#16842]) ([mqtt docs]) (beta fix)\r\n- Add unique ID and device info to Nest camera ([@balloob] - [#16846]) ([camera.nest docs]) (beta fix)\r\n- Device Registry Support for iOS Sensors ([@cgarwood] - [#16862]) ([sensor.ios docs]) (beta fix)\r\n- Fix MQTT discovery ([@balloob] - [#16864]) ([mqtt docs]) (beta fix)\r\n- Make ring sync again ([@balloob] - [#16866]) ([camera.ring docs]) (beta fix)\r\n- Add unique_id to Nest Sensors ([@cgarwood] - [#16869]) ([binary_sensor.nest docs]) ([sensor.nest docs]) (beta fix)\r\n- Prevent discovered Tradfri while already configured ([@balloob] - [#16891]) ([tradfri docs]) (beta fix)\r\n- Handle exception handling websocket command ([@balloob] - [#16927]) ([websocket_api docs]) (beta fix)\r\n\r\n## All changes\r\n\r\n- Upgrade wakeonlan to 1.1.6 ([@fabaff] - [#16512]) ([wake_on_lan docs]) ([media_player.panasonic_viera docs]) ([media_player.samsungtv docs]) ([switch.wake_on_lan docs])\r\n- Make the Qnap sensor more resilient if server is not reachable ([@mrosseel] - [#16445]) ([sensor.qnap docs])\r\n- Update PyRMVtransport version ([@cgtobi] - [#16547]) ([sensor.rmvtransport docs])\r\n- Isort preparations ([@scop] - [#16555]) ([apple_tv docs]) ([geo_location docs]) ([google_assistant docs]) ([rachio docs]) ([media_player.cast docs]) ([media_player.webostv docs])\r\n- Store notifications in component. Add ws endpoint for fetching. ([@jeradM] - [#16503]) ([http docs]) ([persistent_notification docs])\r\n- Fixes an OpenUV bug with the scan interval ([@bachya] - [#16570]) ([openuv docs])\r\n- Bump pyeconet ([@w1ll1am23] - [#16571]) ([climate.econet docs])\r\n- yr: use async syntax ([@Danielhiversen] - [#16563]) ([sensor.yr docs])\r\n- Notifications for Android TV: Add fontsize and sending images ([@danielperna84] - [#16565]) ([notify docs])\r\n- Upgrade pytest to 3.8.0 and pytest-timeout to 1.3.2 ([@scop] - [#16489])\r\n- Refactor zha/async_device_initialized(). ([@Adminiuga] - [#16485]) ([zha docs])\r\n- Update fan.zha platform. ([@Adminiuga] - [#16551]) ([fan.zha docs])\r\n- Hangouts help \"page\" and little bugfix ([@hobbypunk90] - [#16464]) ([hangouts docs])\r\n- Konnected component feature updates ([@heythisisnate] - [#16479]) ([konnected docs])\r\n- Add config entry to iOS ([@balloob] - [#16580]) ([ios docs]) ([notify docs])\r\n- Switchmate ([@Danielhiversen] - [#16395]) ([switch.switchmate docs])\r\n- Update pyhomematic to 0.1.48 ([@danielperna84] - [#16588]) ([homematic docs])\r\n- Add configure_reporting() method to zha component ([@Adminiuga] - [#16487]) ([zha docs]) ([binary_sensor.zha docs]) ([sensor.zha docs])\r\n- Allow only_cache parameter in zha.safe_read() ([@Adminiuga] - [#16553]) ([zha docs])\r\n- Update tibber lib version ([@Danielhiversen] - [#16590]) ([sensor.tibber docs])\r\n- xiaomi lib 0.10.0 ([@Danielhiversen] - [#16591]) ([xiaomi_aqara docs])\r\n- Support for the Quirky Nimbus ([@w1ll1am23] - [#16520]) ([wink docs]) ([climate.wink docs])\r\n- Multiple tag managers for Wireless Sensor Tags. ([@sergeymaysak] - [#16353]) ([wirelesstag docs]) ([binary_sensor.wirelesstag docs]) ([sensor.wirelesstag docs]) ([switch.wirelesstag docs])\r\n- Add Huawei LTE router platform, device tracker, and sensor ([@scop] - [#16498]) ([device_tracker docs]) ([huawei_lte docs]) ([sensor.huawei_lte docs]) (new-platform)\r\n- Changing z-wave brightness calculation to respect 0x01 and 0x02 byte values ([@Harvtronix] - [#16420]) ([light.zwave docs])\r\n- Add myself to CODEOWNERS for upcloud ([@scop] - [#16599])\r\n- Add websocket list APIs for the registries ([@balloob] - [#16597]) ([config docs])\r\n- MQTT config entry ([@balloob] - [#16594]) ([hangouts docs]) ([homematicip_cloud docs]) ([mqtt docs])\r\n- Upgrade python-twitch-client to 0.6.0 ([@fabaff] - [#16602]) ([sensor.twitch docs])\r\n- Improve precision of timer ticks ([@amelchio] - [#16598])\r\n- Switch components.sensor.zha to await syntax. ([@Adminiuga] - [#16619]) ([sensor.zha docs])\r\n- Adding support for RTDSContactSensor and RTDSMotionSensor in Tahoma  (RTS Alarms sensors and contacts for Somfy Protexiom alarms) ([@christopheBfr] - [#16609]) ([tahoma docs]) ([sensor.tahoma docs])\r\n- fix bug where momentary switch with activation low does not reset ([@heythisisnate] - [#16603]) ([switch.konnected docs])\r\n- Extracting zoneminder to a new library ([@rohankapoorcom] - [#16527]) ([zoneminder docs]) ([camera.zoneminder docs])\r\n- Add @rohankapoorcom to CODEOWNERS for the zoneminder platform ([@rohankapoorcom] - [#16627])\r\n- Small huawei_lte improvements ([@scop] - [#16626]) ([huawei_lte docs]) ([sensor.huawei_lte docs])\r\n- Upgrade pwmled to 1.3.0 ([@soldag] - [#16624]) ([light.rpi_gpio_pwm docs])\r\n- Clean up MjpegCamera by removing unnused hass object in __init__ ([@rohankapoorcom] - [#16628]) ([camera.axis docs]) ([camera.mjpeg docs]) ([camera.zoneminder docs])\r\n- Update developer doc links to developers.home-assistant.io ([@scop] - [#16622]) ([websocket_api docs])\r\n- Add valid_window=1 to TOTP verify ([@awarecan] - [#16625])\r\n- Add new devices to HomematicIP Cloud ([@mxworm] - [#16636]) ([binary_sensor.homematicip_cloud docs]) ([sensor.homematicip_cloud docs])\r\n- New EDP re:dy component ([@abmantis] - [#16426]) ([edp_redy docs]) ([sensor.edp_redy docs]) ([switch.edp_redy docs]) (new-platform)\r\n- Upgrade Switchmate lib ([@Danielhiversen] - [#16637]) ([switch.switchmate docs])\r\n- Update pyhomematic to 0.1.49 ([@danielperna84] - [#16649]) ([homematic docs])\r\n- Upgrade holidays to 0.9.7 ([@fabaff] - [#16651]) ([binary_sensor.workday docs])\r\n- Fix link to docs ([@fabaff] - [#16652]) ([vacuum.ecovacs docs])\r\n- Log raw result of configure_reporting() command. ([@Adminiuga] - [#16655]) ([zha docs])\r\n- Rework timer delays ([@amelchio] - [#16650])\r\n- Add config entries to connection class ([@balloob] - [#16618])\r\n- Add zha device entity ([@damarco] - [#14579]) ([zha docs])\r\n- Clean up device update, add via-hub ([@balloob] - [#16659])\r\n- Jewish calendar sensor ([@tsvi] - [#16393]) ([sensor.jewish_calendar docs]) (new-platform)\r\n- Fixes an AirVisual bug where response data is missing ([@bachya] - [#16673]) ([sensor.airvisual docs])\r\n- Suppress traceback and log error ([@fabaff] - [#16669]) ([sensor.scrape docs])\r\n- Fix Ecovacs vacuums showing \"None\" for name ([@OverloadUT] - [#16654]) ([ecovacs docs]) ([vacuum.ecovacs docs])\r\n- Upgrade paho-mqtt to 1.4.0 ([@fabaff] - [#16688]) ([mqtt docs]) ([shiftr docs])\r\n- Streamline log messages ([@gwww] - [#16243])\r\n- Added velbus counter sensors, updated to py-velbus 2.0.20 ([@Cereal2nd] - [#16683]) ([velbus docs]) ([sensor.velbus docs])\r\n- Added support for Starling Bank ([@Dullage] - [#16522]) ([sensor.starlingbank docs]) (new-platform)\r\n- Netdata configuration change: Allows multiple elements per group ([@reefab] - [#16656]) ([sensor.netdata docs]) (breaking change)\r\n- Upgrade mypy to 0.630 ([@scop] - [#16674])\r\n- Use one regex for Hass.io URL check ([@pvizeli] - [#16710]) ([hassio docs])\r\n- Remove usage of \"run_until_complete\" ([@smurfix] - [#16617])\r\n- More isort preparations ([@scop] - [#16633])\r\n- Use posargs in tox lint env ([@scop] - [#16646])\r\n- Make pylint report non-LF linefeeds per the style guidelines ([@scop] - [#16601])\r\n- Config flow tradfri ([@balloob] - [#16665])\r\n- MyQ Open State Fix ([@geekofweek] - [#16681]) ([cover.myq docs])\r\n- Save disabled_by in entity registry ([@cgarwood] - [#16699])\r\n- Upgrading librouteros version ([@kunago] - [#16718]) ([device_tracker docs])\r\n- Add unique_id to mqtt_json light ([@nikolaykasyanov] - [#16721])\r\n- On-demand update of swiss public transport sensor ([@vikramgorla] - [#16723]) ([sensor.swiss_public_transport docs])\r\n- Upgrade youtube_dl to 2018.09.18 ([@fabaff] - [#16729]) ([media_extractor docs])\r\n- Met.no weather platform ([@Danielhiversen] - [#16582])\r\n- Upgrade keyring to 15.1.0 ([@fabaff] - [#16734])\r\n- Avoid calling yr update every second for a minute ones every hour ([@Danielhiversen] - [#16731]) ([sensor.yr docs])\r\n- Upgrade shodan to 1.10.2 ([@fabaff] - [#16736]) ([sensor.shodan docs])\r\n- Add subscription info endpoint ([@balloob] - [#16727]) ([cloud docs]) ([websocket_api docs])\r\n- Small cleanup for slack ([@pvizeli] - [#16743]) ([notify docs])\r\n- light.zha: Catch exceptions for all commands. ([@Adminiuga] - [#16752]) ([light.zha docs])\r\n- Changed save_on_change to default to False ([@zoe1337] - [#16744]) ([light.yeelight docs])\r\n- Add option to disable specific integrations ([@balloob] - [#16757]) ([alexa docs]) ([cloud docs]) ([google_assistant docs])\r\n- Use pysonos for Sonos media player ([@amelchio] - [#16753]) ([sonos docs]) ([media_player.sonos docs])\r\n- deCONZ add via_hub attribute for device registry ([@Kane610] - [#16760]) ([binary_sensor.deconz docs]) ([light.deconz docs]) ([sensor.deconz docs]) ([switch.deconz docs])\r\n- Upgrade pysonos to 0.0.2 ([@amelchio] - [#16761])\r\n- Fix faulty color temp crashing google ([@balloob] - [#16758]) ([google_assistant docs])\r\n- Add Call Data Log platform. Mailboxes no longer require media ([@PhracturedBlue] - [#16579]) ([asterisk_mbox docs]) ([mailbox docs]) ([mailbox.asterisk_cdr docs]) ([mailbox.asterisk_mbox docs]) (new-platform)\r\n- Implement support for complex templates in script delays ([@rohankapoorcom] - [#16442])\r\n- Add Logi Circle component, camera and sensor platform ([@evanjd] - [#16540]) ([logi_circle docs]) ([camera.logi_circle docs]) ([sensor.logi_circle docs]) (new-platform)\r\n- Zha switch schedule update state ([@Adminiuga] - [#16621]) ([switch.zha docs])\r\n- Add Carbon Monoxide HomeKit Sensor ([@cdce8p] - [#16664]) ([homekit docs])\r\n- Add unique_id to mqtt camera ([@bieniu] - [#16569]) ([camera.mqtt docs])\r\n- Add tradfri device info ([@balloob] - [#16768])\r\n- Make rest sensor and binary sensor more efficient ([@exxamalte] - [#14484]) ([binary_sensor.rest docs]) ([sensor.rest docs])\r\n- Refactored units and icons for the Dyson sensors ([@glpatcern] - [#14550]) ([sensor.dyson docs]) (breaking change)\r\n- Add confirmation to Cast/Sonos/iOS config entries ([@balloob] - [#16769])\r\n- deCONZ cover support ([@Kane610] - [#16759]) ([cover docs]) ([deconz docs]) ([cover.deconz docs]) (new-platform)\r\n- GeoJSON platform ([@exxamalte] - [#16610]) ([geo_location docs]) (new-platform)\r\n- Upgrade restrictedpython to 4.0b5 ([@fabaff] - [#16779]) ([python_script docs])\r\n- Upgrade bimmer_connected to 0.5.2 ([@gerard33] - [#16780]) ([bmw_connected_drive docs])\r\n- Fix Windows loop ([@balloob] - [#16737])\r\n- Fix return to base logic for neato ([@dshokouhi] - [#16776]) ([vacuum.neato docs])\r\n- Update Tibber lib ([@Danielhiversen] - [#16795])\r\n- Bump pybotvac to 0.0.10 ([@dshokouhi] - [#16799]) ([neato docs])\r\n- Bump zm-py up to 0.0.2 ([@rohankapoorcom] - [#16800]) ([zoneminder docs])\r\n- Bump sucks (Ecovacs) lib to 0.9.3 ([@OverloadUT] - [#16803]) ([ecovacs docs]) ([vacuum.ecovacs docs])\r\n- Upgrade zeroconf to 0.21.3 ([@tadly] - [#16789])\r\n- Add Tuya cover state ([@huangyupeng] - [#16709]) ([cover.tuya docs])\r\n- Add configurable host for bbox routers ([@isonet] - [#16778])\r\n- Set botvac state when offline ([@dshokouhi] - [#16805]) ([vacuum.neato docs])\r\n- Handle netgear_lte connection errors ([@amelchio] - [#16806]) ([netgear_lte docs]) ([notify docs]) ([sensor.netgear_lte docs])\r\n- Improve opentherm_gw state detection ([@mvn23] - [#16809]) ([climate.opentherm_gw docs])\r\n- Rework chromecast fix ([@awarecan] - [#16804]) ([media_player.cast docs])\r\n- Add linky sensor ([@tiste] - [#16468]) ([sensor.linky docs]) (new-platform)\r\n- Use pyspcwebgw for SPC component ([@mbrrg] - [#16214]) ([spc docs]) ([alarm_control_panel.spc docs]) ([binary_sensor.spc docs])\r\n- Remove discovered MQTT Switch device when discovery topic is cleared ([@emontnemery] - [#16605]) ([mqtt docs]) ([switch.mqtt docs])\r\n- Allow split component definitions in packages ([@thomasloven] - [#16177])\r\n- Add Notify MFA module ([@awarecan] - [#16314])\r\n- Broadlink service name ([@Danielhiversen] - [#16345]) ([switch.broadlink docs])\r\n- Add Python 3.7 classifier ([@scop] - [#16645])\r\n- Allow soundtouch to play https content too ([@robin13] - [#16713]) ([media_player.soundtouch docs])\r\n- Fix some unhandled exceptions due to missing null checks ([@OverloadUT] - [#16812]) ([cover.isy994 docs]) ([light.isy994 docs])\r\n- Don't warn but info when on dev mode ([@balloob] - [#16831]) ([updater docs]) (beta fix)\r\n- Bump zm-py to 0.0.3 ([@rohankapoorcom] - [#16835]) ([zoneminder docs]) (beta fix)\r\n- Support old tradfri config format ([@balloob] - [#16841]) ([tradfri docs]) (beta fix)\r\n- Allow MQTT discovery ([@balloob] - [#16842]) ([mqtt docs]) (beta fix)\r\n- Add unique ID and device info to Nest camera ([@balloob] - [#16846]) ([camera.nest docs]) (beta fix)\r\n- Device Registry Support for iOS Sensors ([@cgarwood] - [#16862]) ([sensor.ios docs]) (beta fix)\r\n- Fix MQTT discovery ([@balloob] - [#16864]) ([mqtt docs]) (beta fix)\r\n- Make ring sync again ([@balloob] - [#16866]) ([camera.ring docs]) (beta fix)\r\n- Add unique_id to Nest Sensors ([@cgarwood] - [#16869]) ([binary_sensor.nest docs]) ([sensor.nest docs]) (beta fix)\r\n- Prevent discovered Tradfri while already configured ([@balloob] - [#16891]) ([tradfri docs]) (beta fix)\r\n- Handle exception handling websocket command ([@balloob] - [#16927]) ([websocket_api docs]) (beta fix)\r\n\r\n[#14484]: https://github.com/home-assistant/home-assistant/pull/14484\r\n[#14550]: https://github.com/home-assistant/home-assistant/pull/14550\r\n[#14579]: https://github.com/home-assistant/home-assistant/pull/14579\r\n[#16177]: https://github.com/home-assistant/home-assistant/pull/16177\r\n[#16214]: https://github.com/home-assistant/home-assistant/pull/16214\r\n[#16243]: https://github.com/home-assistant/home-assistant/pull/16243\r\n[#16314]: https://github.com/home-assistant/home-assistant/pull/16314\r\n[#16345]: https://github.com/home-assistant/home-assistant/pull/16345\r\n[#16353]: https://github.com/home-assistant/home-assistant/pull/16353\r\n[#16393]: https://github.com/home-assistant/home-assistant/pull/16393\r\n[#16395]: https://github.com/home-assistant/home-assistant/pull/16395\r\n[#16420]: https://github.com/home-assistant/home-assistant/pull/16420\r\n[#16426]: https://github.com/home-assistant/home-assistant/pull/16426\r\n[#16442]: https://github.com/home-assistant/home-assistant/pull/16442\r\n[#16445]: https://github.com/home-assistant/home-assistant/pull/16445\r\n[#16464]: https://github.com/home-assistant/home-assistant/pull/16464\r\n[#16468]: https://github.com/home-assistant/home-assistant/pull/16468\r\n[#16479]: https://github.com/home-assistant/home-assistant/pull/16479\r\n[#16485]: https://github.com/home-assistant/home-assistant/pull/16485\r\n[#16487]: https://github.com/home-assistant/home-assistant/pull/16487\r\n[#16489]: https://github.com/home-assistant/home-assistant/pull/16489\r\n[#16498]: https://github.com/home-assistant/home-assistant/pull/16498\r\n[#16503]: https://github.com/home-assistant/home-assistant/pull/16503\r\n[#16512]: https://github.com/home-assistant/home-assistant/pull/16512\r\n[#16520]: https://github.com/home-assistant/home-assistant/pull/16520\r\n[#16522]: https://github.com/home-assistant/home-assistant/pull/16522\r\n[#16527]: https://github.com/home-assistant/home-assistant/pull/16527\r\n[#16540]: https://github.com/home-assistant/home-assistant/pull/16540\r\n[#16547]: https://github.com/home-assistant/home-assistant/pull/16547\r\n[#16551]: https://github.com/home-assistant/home-assistant/pull/16551\r\n[#16553]: https://github.com/home-assistant/home-assistant/pull/16553\r\n[#16555]: https://github.com/home-assistant/home-assistant/pull/16555\r\n[#16563]: https://github.com/home-assistant/home-assistant/pull/16563\r\n[#16565]: https://github.com/home-assistant/home-assistant/pull/16565\r\n[#16569]: https://github.com/home-assistant/home-assistant/pull/16569\r\n[#16570]: https://github.com/home-assistant/home-assistant/pull/16570\r\n[#16571]: https://github.com/home-assistant/home-assistant/pull/16571\r\n[#16579]: https://github.com/home-assistant/home-assistant/pull/16579\r\n[#16580]: https://github.com/home-assistant/home-assistant/pull/16580\r\n[#16582]: https://github.com/home-assistant/home-assistant/pull/16582\r\n[#16588]: https://github.com/home-assistant/home-assistant/pull/16588\r\n[#16590]: https://github.com/home-assistant/home-assistant/pull/16590\r\n[#16591]: https://github.com/home-assistant/home-assistant/pull/16591\r\n[#16594]: https://github.com/home-assistant/home-assistant/pull/16594\r\n[#16597]: https://github.com/home-assistant/home-assistant/pull/16597\r\n[#16598]: https://github.com/home-assistant/home-assistant/pull/16598\r\n[#16599]: https://github.com/home-assistant/home-assistant/pull/16599\r\n[#16601]: https://github.com/home-assistant/home-assistant/pull/16601\r\n[#16602]: https://github.com/home-assistant/home-assistant/pull/16602\r\n[#16603]: https://github.com/home-assistant/home-assistant/pull/16603\r\n[#16605]: https://github.com/home-assistant/home-assistant/pull/16605\r\n[#16609]: https://github.com/home-assistant/home-assistant/pull/16609\r\n[#16610]: https://github.com/home-assistant/home-assistant/pull/16610\r\n[#16617]: https://github.com/home-assistant/home-assistant/pull/16617\r\n[#16618]: https://github.com/home-assistant/home-assistant/pull/16618\r\n[#16619]: https://github.com/home-assistant/home-assistant/pull/16619\r\n[#16621]: https://github.com/home-assistant/home-assistant/pull/16621\r\n[#16622]: https://github.com/home-assistant/home-assistant/pull/16622\r\n[#16624]: https://github.com/home-assistant/home-assistant/pull/16624\r\n[#16625]: https://github.com/home-assistant/home-assistant/pull/16625\r\n[#16626]: https://github.com/home-assistant/home-assistant/pull/16626\r\n[#16627]: https://github.com/home-assistant/home-assistant/pull/16627\r\n[#16628]: https://github.com/home-assistant/home-assistant/pull/16628\r\n[#16633]: https://github.com/home-assistant/home-assistant/pull/16633\r\n[#16636]: https://github.com/home-assistant/home-assistant/pull/16636\r\n[#16637]: https://github.com/home-assistant/home-assistant/pull/16637\r\n[#16645]: https://github.com/home-assistant/home-assistant/pull/16645\r\n[#16646]: https://github.com/home-assistant/home-assistant/pull/16646\r\n[#16649]: https://github.com/home-assistant/home-assistant/pull/16649\r\n[#16650]: https://github.com/home-assistant/home-assistant/pull/16650\r\n[#16651]: https://github.com/home-assistant/home-assistant/pull/16651\r\n[#16652]: https://github.com/home-assistant/home-assistant/pull/16652\r\n[#16654]: https://github.com/home-assistant/home-assistant/pull/16654\r\n[#16655]: https://github.com/home-assistant/home-assistant/pull/16655\r\n[#16656]: https://github.com/home-assistant/home-assistant/pull/16656\r\n[#16659]: https://github.com/home-assistant/home-assistant/pull/16659\r\n[#16664]: https://github.com/home-assistant/home-assistant/pull/16664\r\n[#16665]: https://github.com/home-assistant/home-assistant/pull/16665\r\n[#16669]: https://github.com/home-assistant/home-assistant/pull/16669\r\n[#16673]: https://github.com/home-assistant/home-assistant/pull/16673\r\n[#16674]: https://github.com/home-assistant/home-assistant/pull/16674\r\n[#16681]: https://github.com/home-assistant/home-assistant/pull/16681\r\n[#16683]: https://github.com/home-assistant/home-assistant/pull/16683\r\n[#16688]: https://github.com/home-assistant/home-assistant/pull/16688\r\n[#16699]: https://github.com/home-assistant/home-assistant/pull/16699\r\n[#16709]: https://github.com/home-assistant/home-assistant/pull/16709\r\n[#16710]: https://github.com/home-assistant/home-assistant/pull/16710\r\n[#16713]: https://github.com/home-assistant/home-assistant/pull/16713\r\n[#16718]: https://github.com/home-assistant/home-assistant/pull/16718\r\n[#16721]: https://github.com/home-assistant/home-assistant/pull/16721\r\n[#16723]: https://github.com/home-assistant/home-assistant/pull/16723\r\n[#16727]: https://github.com/home-assistant/home-assistant/pull/16727\r\n[#16729]: https://github.com/home-assistant/home-assistant/pull/16729\r\n[#16731]: https://github.com/home-assistant/home-assistant/pull/16731\r\n[#16734]: https://github.com/home-assistant/home-assistant/pull/16734\r\n[#16736]: https://github.com/home-assistant/home-assistant/pull/16736\r\n[#16737]: https://github.com/home-assistant/home-assistant/pull/16737\r\n[#16743]: https://github.com/home-assistant/home-assistant/pull/16743\r\n[#16744]: https://github.com/home-assistant/home-assistant/pull/16744\r\n[#16752]: https://github.com/home-assistant/home-assistant/pull/16752\r\n[#16753]: https://github.com/home-assistant/home-assistant/pull/16753\r\n[#16757]: https://github.com/home-assistant/home-assistant/pull/16757\r\n[#16758]: https://github.com/home-assistant/home-assistant/pull/16758\r\n[#16759]: https://github.com/home-assistant/home-assistant/pull/16759\r\n[#16760]: https://github.com/home-assistant/home-assistant/pull/16760\r\n[#16761]: https://github.com/home-assistant/home-assistant/pull/16761\r\n[#16768]: https://github.com/home-assistant/home-assistant/pull/16768\r\n[#16769]: https://github.com/home-assistant/home-assistant/pull/16769\r\n[#16776]: https://github.com/home-assistant/home-assistant/pull/16776\r\n[#16778]: https://github.com/home-assistant/home-assistant/pull/16778\r\n[#16779]: https://github.com/home-assistant/home-assistant/pull/16779\r\n[#16780]: https://github.com/home-assistant/home-assistant/pull/16780\r\n[#16789]: https://github.com/home-assistant/home-assistant/pull/16789\r\n[#16795]: https://github.com/home-assistant/home-assistant/pull/16795\r\n[#16799]: https://github.com/home-assistant/home-assistant/pull/16799\r\n[#16800]: https://github.com/home-assistant/home-assistant/pull/16800\r\n[#16803]: https://github.com/home-assistant/home-assistant/pull/16803\r\n[#16804]: https://github.com/home-assistant/home-assistant/pull/16804\r\n[#16805]: https://github.com/home-assistant/home-assistant/pull/16805\r\n[#16806]: https://github.com/home-assistant/home-assistant/pull/16806\r\n[#16809]: https://github.com/home-assistant/home-assistant/pull/16809\r\n[#16812]: https://github.com/home-assistant/home-assistant/pull/16812\r\n[#16831]: https://github.com/home-assistant/home-assistant/pull/16831\r\n[#16835]: https://github.com/home-assistant/home-assistant/pull/16835\r\n[#16841]: https://github.com/home-assistant/home-assistant/pull/16841\r\n[#16842]: https://github.com/home-assistant/home-assistant/pull/16842\r\n[#16846]: https://github.com/home-assistant/home-assistant/pull/16846\r\n[#16862]: https://github.com/home-assistant/home-assistant/pull/16862\r\n[#16864]: https://github.com/home-assistant/home-assistant/pull/16864\r\n[#16866]: https://github.com/home-assistant/home-assistant/pull/16866\r\n[#16869]: https://github.com/home-assistant/home-assistant/pull/16869\r\n[#16891]: https://github.com/home-assistant/home-assistant/pull/16891\r\n[#16927]: https://github.com/home-assistant/home-assistant/pull/16927\r\n[@Adminiuga]: https://github.com/Adminiuga\r\n[@Cereal2nd]: https://github.com/Cereal2nd\r\n[@Danielhiversen]: https://github.com/Danielhiversen\r\n[@Dullage]: https://github.com/Dullage\r\n[@Harvtronix]: https://github.com/Harvtronix\r\n[@Kane610]: https://github.com/Kane610\r\n[@OverloadUT]: https://github.com/OverloadUT\r\n[@PhracturedBlue]: https://github.com/PhracturedBlue\r\n[@abmantis]: https://github.com/abmantis\r\n[@amelchio]: https://github.com/amelchio\r\n[@awarecan]: https://github.com/awarecan\r\n[@bachya]: https://github.com/bachya\r\n[@balloob]: https://github.com/balloob\r\n[@bieniu]: https://github.com/bieniu\r\n[@cdce8p]: https://github.com/cdce8p\r\n[@cgarwood]: https://github.com/cgarwood\r\n[@cgtobi]: https://github.com/cgtobi\r\n[@christopheBfr]: https://github.com/christopheBfr\r\n[@damarco]: https://github.com/damarco\r\n[@danielperna84]: https://github.com/danielperna84\r\n[@dshokouhi]: https://github.com/dshokouhi\r\n[@emontnemery]: https://github.com/emontnemery\r\n[@evanjd]: https://github.com/evanjd\r\n[@exxamalte]: https://github.com/exxamalte\r\n[@fabaff]: https://github.com/fabaff\r\n[@geekofweek]: https://github.com/geekofweek\r\n[@gerard33]: https://github.com/gerard33\r\n[@glpatcern]: https://github.com/glpatcern\r\n[@gwww]: https://github.com/gwww\r\n[@heythisisnate]: https://github.com/heythisisnate\r\n[@hobbypunk90]: https://github.com/hobbypunk90\r\n[@huangyupeng]: https://github.com/huangyupeng\r\n[@isonet]: https://github.com/isonet\r\n[@jeradM]: https://github.com/jeradM\r\n[@kunago]: https://github.com/kunago\r\n[@mbrrg]: https://github.com/mbrrg\r\n[@mrosseel]: https://github.com/mrosseel\r\n[@mvn23]: https://github.com/mvn23\r\n[@mxworm]: https://github.com/mxworm\r\n[@nikolaykasyanov]: https://github.com/nikolaykasyanov\r\n[@pvizeli]: https://github.com/pvizeli\r\n[@reefab]: https://github.com/reefab\r\n[@robin13]: https://github.com/robin13\r\n[@rohankapoorcom]: https://github.com/rohankapoorcom\r\n[@scop]: https://github.com/scop\r\n[@sergeymaysak]: https://github.com/sergeymaysak\r\n[@smurfix]: https://github.com/smurfix\r\n[@soldag]: https://github.com/soldag\r\n[@tadly]: https://github.com/tadly\r\n[@thomasloven]: https://github.com/thomasloven\r\n[@tiste]: https://github.com/tiste\r\n[@tsvi]: https://github.com/tsvi\r\n[@vikramgorla]: https://github.com/vikramgorla\r\n[@w1ll1am23]: https://github.com/w1ll1am23\r\n[@zoe1337]: https://github.com/zoe1337\r\n[alarm_control_panel.spc docs]: https://www.home-assistant.io/components/alarm_control_panel.spc/\r\n[alexa docs]: https://www.home-assistant.io/components/alexa/\r\n[apple_tv docs]: https://www.home-assistant.io/components/apple_tv/\r\n[asterisk_mbox docs]: https://www.home-assistant.io/components/asterisk_mbox/\r\n[binary_sensor.deconz docs]: https://www.home-assistant.io/components/binary_sensor.deconz/\r\n[binary_sensor.homematicip_cloud docs]: https://www.home-assistant.io/components/binary_sensor.homematicip_cloud/\r\n[binary_sensor.nest docs]: https://www.home-assistant.io/components/binary_sensor.nest/\r\n[binary_sensor.rest docs]: https://www.home-assistant.io/components/binary_sensor.rest/\r\n[binary_sensor.spc docs]: https://www.home-assistant.io/components/binary_sensor.spc/\r\n[binary_sensor.wirelesstag docs]: https://www.home-assistant.io/components/binary_sensor.wirelesstag/\r\n[binary_sensor.workday docs]: https://www.home-assistant.io/components/binary_sensor.workday/\r\n[binary_sensor.zha docs]: https://www.home-assistant.io/components/binary_sensor.zha/\r\n[bmw_connected_drive docs]: https://www.home-assistant.io/components/bmw_connected_drive/\r\n[camera.axis docs]: https://www.home-assistant.io/components/camera.axis/\r\n[camera.logi_circle docs]: https://www.home-assistant.io/components/camera.logi_circle/\r\n[camera.mjpeg docs]: https://www.home-assistant.io/components/camera.mjpeg/\r\n[camera.mqtt docs]: https://www.home-assistant.io/components/camera.mqtt/\r\n[camera.nest docs]: https://www.home-assistant.io/components/camera.nest/\r\n[camera.ring docs]: https://www.home-assistant.io/components/camera.ring/\r\n[camera.zoneminder docs]: https://www.home-assistant.io/components/camera.zoneminder/\r\n[climate.econet docs]: https://www.home-assistant.io/components/climate.econet/\r\n[climate.opentherm_gw docs]: https://www.home-assistant.io/components/climate.opentherm_gw/\r\n[climate.wink docs]: https://www.home-assistant.io/components/climate.wink/\r\n[cloud docs]: https://www.home-assistant.io/components/cloud/\r\n[config docs]: https://www.home-assistant.io/components/config/\r\n[cover docs]: https://www.home-assistant.io/components/cover/\r\n[cover.deconz docs]: https://www.home-assistant.io/components/cover.deconz/\r\n[cover.isy994 docs]: https://www.home-assistant.io/components/cover.isy994/\r\n[cover.myq docs]: https://www.home-assistant.io/components/cover.myq/\r\n[cover.tuya docs]: https://www.home-assistant.io/components/cover.tuya/\r\n[deconz docs]: https://www.home-assistant.io/components/deconz/\r\n[device_tracker docs]: https://www.home-assistant.io/components/device_tracker/\r\n[ecovacs docs]: https://www.home-assistant.io/components/ecovacs/\r\n[edp_redy docs]: https://www.home-assistant.io/components/edp_redy/\r\n[fan.zha docs]: https://www.home-assistant.io/components/fan.zha/\r\n[geo_location docs]: https://www.home-assistant.io/components/geo_location/\r\n[google_assistant docs]: https://www.home-assistant.io/components/google_assistant/\r\n[hangouts docs]: https://www.home-assistant.io/components/hangouts/\r\n[hassio docs]: https://www.home-assistant.io/components/hassio/\r\n[homekit docs]: https://www.home-assistant.io/components/homekit/\r\n[homematic docs]: https://www.home-assistant.io/components/homematic/\r\n[homematicip_cloud docs]: https://www.home-assistant.io/components/homematicip_cloud/\r\n[http docs]: https://www.home-assistant.io/components/http/\r\n[huawei_lte docs]: https://www.home-assistant.io/components/huawei_lte/\r\n[ios docs]: https://www.home-assistant.io/components/ios/\r\n[konnected docs]: https://www.home-assistant.io/components/konnected/\r\n[light.deconz docs]: https://www.home-assistant.io/components/light.deconz/\r\n[light.isy994 docs]: https://www.home-assistant.io/components/light.isy994/\r\n[light.rpi_gpio_pwm docs]: https://www.home-assistant.io/components/light.rpi_gpio_pwm/\r\n[light.yeelight docs]: https://www.home-assistant.io/components/light.yeelight/\r\n[light.zha docs]: https://www.home-assistant.io/components/light.zha/\r\n[light.zwave docs]: https://www.home-assistant.io/components/light.zwave/\r\n[logi_circle docs]: https://www.home-assistant.io/components/logi_circle/\r\n[mailbox docs]: https://www.home-assistant.io/components/mailbox/\r\n[mailbox.asterisk_cdr docs]: https://www.home-assistant.io/components/mailbox.asterisk_cdr/\r\n[mailbox.asterisk_mbox docs]: https://www.home-assistant.io/components/mailbox.asterisk_mbox/\r\n[media_extractor docs]: https://www.home-assistant.io/components/media_extractor/\r\n[media_player.cast docs]: https://www.home-assistant.io/components/media_player.cast/\r\n[media_player.panasonic_viera docs]: https://www.home-assistant.io/components/media_player.panasonic_viera/\r\n[media_player.samsungtv docs]: https://www.home-assistant.io/components/media_player.samsungtv/\r\n[media_player.sonos docs]: https://www.home-assistant.io/components/media_player.sonos/\r\n[media_player.soundtouch docs]: https://www.home-assistant.io/components/media_player.soundtouch/\r\n[media_player.webostv docs]: https://www.home-assistant.io/components/media_player.webostv/\r\n[mqtt docs]: https://www.home-assistant.io/components/mqtt/\r\n[neato docs]: https://www.home-assistant.io/components/neato/\r\n[netgear_lte docs]: https://www.home-assistant.io/components/netgear_lte/\r\n[notify docs]: https://www.home-assistant.io/components/notify/\r\n[openuv docs]: https://www.home-assistant.io/components/openuv/\r\n[persistent_notification docs]: https://www.home-assistant.io/components/persistent_notification/\r\n[python_script docs]: https://www.home-assistant.io/components/python_script/\r\n[rachio docs]: https://www.home-assistant.io/components/rachio/\r\n[sensor.airvisual docs]: https://www.home-assistant.io/components/sensor.airvisual/\r\n[sensor.deconz docs]: https://www.home-assistant.io/components/sensor.deconz/\r\n[sensor.dyson docs]: https://www.home-assistant.io/components/sensor.dyson/\r\n[sensor.edp_redy docs]: https://www.home-assistant.io/components/sensor.edp_redy/\r\n[sensor.homematicip_cloud docs]: https://www.home-assistant.io/components/sensor.homematicip_cloud/\r\n[sensor.huawei_lte docs]: https://www.home-assistant.io/components/sensor.huawei_lte/\r\n[sensor.ios docs]: https://www.home-assistant.io/components/sensor.ios/\r\n[sensor.jewish_calendar docs]: https://www.home-assistant.io/components/sensor.jewish_calendar/\r\n[sensor.linky docs]: https://www.home-assistant.io/components/sensor.linky/\r\n[sensor.logi_circle docs]: https://www.home-assistant.io/components/sensor.logi_circle/\r\n[sensor.nest docs]: https://www.home-assistant.io/components/sensor.nest/\r\n[sensor.netdata docs]: https://www.home-assistant.io/components/sensor.netdata/\r\n[sensor.netgear_lte docs]: https://www.home-assistant.io/components/sensor.netgear_lte/\r\n[sensor.qnap docs]: https://www.home-assistant.io/components/sensor.qnap/\r\n[sensor.rest docs]: https://www.home-assistant.io/components/sensor.rest/\r\n[sensor.rmvtransport docs]: https://www.home-assistant.io/components/sensor.rmvtransport/\r\n[sensor.scrape docs]: https://www.home-assistant.io/components/sensor.scrape/\r\n[sensor.shodan docs]: https://www.home-assistant.io/components/sensor.shodan/\r\n[sensor.starlingbank docs]: https://www.home-assistant.io/components/sensor.starlingbank/\r\n[sensor.swiss_public_transport docs]: https://www.home-assistant.io/components/sensor.swiss_public_transport/\r\n[sensor.tahoma docs]: https://www.home-assistant.io/components/sensor.tahoma/\r\n[sensor.tibber docs]: https://www.home-assistant.io/components/sensor.tibber/\r\n[sensor.twitch docs]: https://www.home-assistant.io/components/sensor.twitch/\r\n[sensor.velbus docs]: https://www.home-assistant.io/components/sensor.velbus/\r\n[sensor.wirelesstag docs]: https://www.home-assistant.io/components/sensor.wirelesstag/\r\n[sensor.yr docs]: https://www.home-assistant.io/components/sensor.yr/\r\n[sensor.zha docs]: https://www.home-assistant.io/components/sensor.zha/\r\n[shiftr docs]: https://www.home-assistant.io/components/shiftr/\r\n[sonos docs]: https://www.home-assistant.io/components/sonos/\r\n[spc docs]: https://www.home-assistant.io/components/spc/\r\n[switch.broadlink docs]: https://www.home-assistant.io/components/switch.broadlink/\r\n[switch.deconz docs]: https://www.home-assistant.io/components/switch.deconz/\r\n[switch.edp_redy docs]: https://www.home-assistant.io/components/switch.edp_redy/\r\n[switch.konnected docs]: https://www.home-assistant.io/components/switch.konnected/\r\n[switch.mqtt docs]: https://www.home-assistant.io/components/switch.mqtt/\r\n[switch.switchmate docs]: https://www.home-assistant.io/components/switch.switchmate/\r\n[switch.wake_on_lan docs]: https://www.home-assistant.io/components/switch.wake_on_lan/\r\n[switch.wirelesstag docs]: https://www.home-assistant.io/components/switch.wirelesstag/\r\n[switch.zha docs]: https://www.home-assistant.io/components/switch.zha/\r\n[tahoma docs]: https://www.home-assistant.io/components/tahoma/\r\n[tradfri docs]: https://www.home-assistant.io/components/tradfri/\r\n[updater docs]: https://www.home-assistant.io/components/updater/\r\n[vacuum.ecovacs docs]: https://www.home-assistant.io/components/vacuum.ecovacs/\r\n[vacuum.neato docs]: https://www.home-assistant.io/components/vacuum.neato/\r\n[velbus docs]: https://www.home-assistant.io/components/velbus/\r\n[wake_on_lan docs]: https://www.home-assistant.io/components/wake_on_lan/\r\n[websocket_api docs]: https://www.home-assistant.io/components/websocket_api/\r\n[wink docs]: https://www.home-assistant.io/components/wink/\r\n[wirelesstag docs]: https://www.home-assistant.io/components/wirelesstag/\r\n[xiaomi_aqara docs]: https://www.home-assistant.io/components/xiaomi_aqara/\r\n[zha docs]: https://www.home-assistant.io/components/zha/\r\n[zoneminder docs]: https://www.home-assistant.io/components/zoneminder/",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/16940",
                    "merged_at": "2018-09-28T14:51:25Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/16579",
                "title": "Add Call Data Log platform.  Mailboxes no longer require media",
                "labels": [
                    "new-platform",
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "integration: mailbox",
                    "integration: asterisk_cdr"
                ],
                "user": "PhracturedBlue",
                "issue_author_association": "CONTRIBUTOR",
                "number": 16579,
                "id": 359469068,
                "state": "closed",
                "project_created_at": "2018-09-12T13:00:06Z",
                "closed_at": "2018-09-21T09:55:12Z",
                "body": "## Description:\r\nThis patch adds the asterisk_cdr mailbox platform to view call activity.  It also makes it possible to dynamically create mailbox platforms (needed in case CDR isn't supplied by the server).  Additionally, mailboxes without media are now supported, as are read-only messages, making the mailbox platform more generic.  Lastly all asycio.coroutines have been migrated to async/await.\r\nThis pull request requires a matching frontend change\r\n\r\n**Pull request in [home-assistant.github.io](https://github.com/home-assistant/home-assistant.github.io) with documentation (if applicable): https://github.com/home-assistant/home-assistant.io/pull/6264**\r\n**Pull request in [home-assistant-polymer](https://github.com/home-assistant/home-assistant-polymer) for frontend updates: https://github.com/home-assistant/home-assistant-polymer/pull/1660**\r\n\r\n## Checklist:\r\n  - [x] The code change is tested and works locally.\r\n  - [x] Local tests pass with `tox`. **Your PR cannot be merged unless tests pass**\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n  - [x] Documentation added/updated in [home-assistant.github.io](https://github.com/home-assistant/home-assistant.github.io)\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n  - [x] New files were added to `.coveragerc`.\r\n\r\n",
                "comments": [
                    {
                        "body": "Thanks, should be better now",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2018-09-17T12:16:52Z",
                        "url": "https://github.com/home-assistant/core/pull/16579#issuecomment-421990893"
                    },
                    {
                        "body": "@MartinHjelmare Thanks for the review.  Moving those async calls to sync uncovered a real race condition.  Is there any way to detect async calls made from the wrong thread to help prevent these types of errors?\r\n\r\nI believe I have resolved all of your concerns.\r\n",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2018-09-17T21:42:53Z",
                        "url": "https://github.com/home-assistant/core/pull/16579#issuecomment-422181722"
                    },
                    {
                        "body": "Not sure how to debug that.\r\n\r\nMaybe by timing callbacks?\r\n\r\nhttps://pymotw.com/3/asyncio/debugging.html",
                        "user": "MartinHjelmare",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2018-09-17T22:33:19Z",
                        "url": "https://github.com/home-assistant/core/pull/16579#issuecomment-422193635"
                    },
                    {
                        "body": "> Not sure how to debug that.\r\n> \r\n> Maybe by timing callbacks?\r\n> \r\n> https://pymotw.com/3/asyncio/debugging.html\r\n\r\nSorry, I wasn't clear.  I meant that changing to using the sync versions uncovered a timing race which I have already fixed.  I was just wondering in general about checkers to help find these types of issues before I submit patches",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2018-09-18T00:53:03Z",
                        "url": "https://github.com/home-assistant/core/pull/16579#issuecomment-422217548"
                    },
                    {
                        "body": "Yes, that was what I was answering.",
                        "user": "MartinHjelmare",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2018-09-18T02:39:34Z",
                        "url": "https://github.com/home-assistant/core/pull/16579#issuecomment-422234672"
                    },
                    {
                        "body": "Thanks, hopefully I've addressed your concerns now.  Please let me know if you see anything else",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2018-09-18T13:55:23Z",
                        "url": "https://github.com/home-assistant/core/pull/16579#issuecomment-422402724"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/16579",
                    "merged_at": "2018-09-21T09:55:12Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/16425",
                "title": "[WIP] Add Asterisk component",
                "labels": [
                    "new-platform",
                    "cla-signed",
                    "docs-missing",
                    "integration: asterisk_ami"
                ],
                "user": "girlpunk",
                "issue_author_association": "CONTRIBUTOR",
                "number": 16425,
                "id": 356995047,
                "state": "closed",
                "project_created_at": "2018-09-04T22:13:21Z",
                "closed_at": "2019-02-06T01:06:30Z",
                "body": "## Description:\r\nNew component for intigrations with Asterisk-based phone systems using the Asterisk Management Interface (AMI). Very much a WIP, but I would appreciate a quick review to make sure what's done so far looks ok.\r\n\r\n**Pull request in [home-assistant.github.io](https://github.com/home-assistant/home-assistant.github.io) with documentation (if applicable):** TBC\r\n\r\n## Example entry for `configuration.yaml` (if applicable):\r\n```yaml\r\nasterisk_ami:\r\n  host: localhost\r\n  username: admin\r\n  password: correcthorsebatterystaple\r\n  mailboxes:\r\n  - 100@default\r\n```\r\n\r\n## Checklist:\r\n  - [X] The code change is tested and works locally.\r\n  - [ ] Local tests pass with `tox`. **Your PR cannot be merged unless tests pass**\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n  - [ ] Documentation added/updated in [home-assistant.github.io](https://github.com/home-assistant/home-assistant.github.io)\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n  - [X] New dependencies have been added to the `REQUIREMENTS` variable ([example][ex-requir]).\r\n  - [X] New dependencies are only imported inside functions that use them ([example][ex-import]).\r\n  - [ ] New or updated dependencies have been added to `requirements_all.txt` by running `script/gen_requirements_all.py`.\r\n  - [ ] New files were added to `.coveragerc`.\r\n\r\nIf the code does not interact with devices:\r\n  - [ ] Tests have been added to verify that the new code works.\r\n\r\n[ex-requir]: https://github.com/home-assistant/home-assistant/blob/dev/homeassistant/components/keyboard.py#L14\r\n[ex-import]: https://github.com/home-assistant/home-assistant/blob/dev/homeassistant/components/keyboard.py#L54\r\n",
                "comments": [
                    {
                        "body": "This PR seems to have gone stale. Closing it.",
                        "user": "balloob",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2019-02-06T01:06:30Z",
                        "url": "https://github.com/home-assistant/core/pull/16425#issuecomment-460866231"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/16425",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/16296",
                "title": "Use asterisk_mbox 0.5.0 client",
                "labels": [
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "small-pr"
                ],
                "user": "PhracturedBlue",
                "issue_author_association": "CONTRIBUTOR",
                "number": 16296,
                "id": 355591208,
                "state": "closed",
                "project_created_at": "2018-08-30T13:41:48Z",
                "closed_at": "2018-08-30T16:44:38Z",
                "body": "## Description:\r\nThe 0.5 server has many bug fixes, but is incompatible with the 0.4.0 client despite the end-facing API being the same.  We need to move to the 0.5.0 client in order to be able to communicate with the 0.5 server.\r\n## Checklist:\r\n  - [x] The code change is tested and works locally.\r\n  - [x] Local tests pass with `tox`. **Your PR cannot be merged unless tests pass**\r\n",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/16296",
                    "merged_at": "2018-08-30T16:44:38Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/11774",
                "title": "Update header and make it less verbose",
                "labels": [
                    "cla-signed",
                    "integration: asterisk_mbox"
                ],
                "user": "fabaff",
                "issue_author_association": "MEMBER",
                "number": 11774,
                "id": 289783902,
                "state": "closed",
                "project_created_at": "2018-01-18T21:36:12Z",
                "closed_at": "2018-01-18T22:04:19Z",
                "body": "## Description:\r\n- Update header\r\n- Make it less verbose\r\n- Update ordering\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n  - [x] Local tests with `tox` run successfully. **Your PR cannot be merged unless tests pass**\r\n\r\n",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/11774",
                    "merged_at": "2018-01-18T22:04:19Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/11043",
                "title": "Add Asterisk Call Data Record to mailboxes component",
                "labels": [
                    "component",
                    "platform",
                    "requirement",
                    "new-platform",
                    "cla-signed",
                    "integration: demo",
                    "integration: asterisk_mbox",
                    "integration: mailbox",
                    "integration: asterisk_cdr"
                ],
                "user": "PhracturedBlue",
                "issue_author_association": "CONTRIBUTOR",
                "number": 11043,
                "id": 280678946,
                "state": "closed",
                "project_created_at": "2017-12-09T04:40:47Z",
                "closed_at": "2018-04-17T11:00:34Z",
                "body": "## Description:\r\nThis adds the ability to see the call-history from Asterisk as a mailbox component.  There is an associated frontend change as well to allow viewing each mailbox component on its own tab.\r\n\r\nThe frontend pull request is here: https://github.com/home-assistant/home-assistant-polymer/pull/719\r\n\r\n**Pull request in [home-assistant.github.io](https://github.com/home-assistant/home-assistant.github.io) with documentation (if applicable):** home-assistant/home-assistant.github.io#4173\r\n\r\n## Checklist:\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n  - [x] Documentation added/updated in [home-assistant.github.io](https://github.com/home-assistant/home-assistant.github.io)\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n  - [x] Local tests with `tox` run successfully. **Your PR cannot be merged unless tests pass**\r\n  - [x] New dependencies have been added to the `REQUIREMENTS` variable ([example][ex-requir]).\r\n  - [x] New dependencies are only imported inside functions that use them ([example][ex-import]).\r\n  - [x] New dependencies have been added to `requirements_all.txt` by running `script/gen_requirements_all.py`.\r\n  - [x] New files were added to `.coveragerc`.\r\n\r\n",
                "comments": [
                    {
                        "body": "I still struggle with the sync/async usage.\r\nHere is what I'm trying to do:\r\n\r\n`AsteriskData.handle_data()` is called by an independent thread from the `asterisk_mbox` module.  It should send signals to handle data (I believe these should be sent with `dispatcher_send` since they come from outside the event-loop).\r\n\r\nThe signals should be picked up from inside the event-loop and processed there.  My understanding is that these signal handlers (`_request_messages`, `_request_cdr` and `_discover_platform`) are executed asynchronously, and so should use async_* functions internally.\r\n\r\nI am not sure when the `@callback` decorator is appropriate or not.  The `handle_data` function is a callback handler, but is only called from an external thread and not within the event-loop.  Should it have the decorator?  The `_request_*` and `_discover_platform` functions are called by the signal handler within the event-loop. Should these have the decorator?",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2017-12-11T00:07:10Z",
                        "url": "https://github.com/home-assistant/core/pull/11043#issuecomment-350593397"
                    },
                    {
                        "body": "Address comments and look how I do change the code and reopen after all is addressed",
                        "user": "pvizeli",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2018-04-17T11:00:34Z",
                        "url": "https://github.com/home-assistant/core/pull/11043#issuecomment-381948954"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/11043",
                    "merged_at": null
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/8233",
                "title": "Add Initial Mailbox panel and sensor",
                "labels": [
                    "component",
                    "platform",
                    "requirement",
                    "new-platform",
                    "cla-signed",
                    "integration: asterisk_mbox"
                ],
                "user": "PhracturedBlue",
                "issue_author_association": "CONTRIBUTOR",
                "number": 8233,
                "id": 239179489,
                "state": "closed",
                "project_created_at": "2017-06-28T14:18:37Z",
                "closed_at": "2017-08-06T18:19:48Z",
                "body": "## Description:\r\nThis is a new panel and sensor that adds an interface to and Asterisk voice-mailbox\r\n\r\nThe panel allows viewing messages, reading a speech-to-text translation of the messages, listening to the messages, and deleting messages\r\n\r\nThe sensor shows how many messages are in the mailbox\r\n\r\n**Note**\r\nWhile the functionality is all in place, I am not fluent in working with asyncio.  I think I've fixed most of the data handlers now.\r\nI believe the MP3 handler should now properly load asynchronously\r\n\r\nI would really appreciate any code review, especially on the async aspects.\r\n\r\n**Pull request in [home-assistant.github.io](https://github.com/home-assistant/home-assistant.github.io) with documentation (if applicable):** home-assistant/home-assistant.github.io#2908\r\n\r\n**Pull request in [github.com/home-assistant/home-assistant-polymer) with frontend code change:** https://github.com/home-assistant/home-assistant-polymer/pull/319\r\n\r\n## Example entry for `configuration.yaml` (if applicable):\r\n```yaml\r\nasterisk_mbox:\r\n    password: This is my password\r\n    host: localhost\r\n    port: 12345\r\n```\r\n\r\n## Checklist:\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n  - [x] Documentation added/updated in [home-assistant.github.io](https://github.com/home-assistant/home-assistant.github.io)\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n  - [x] Local tests with `tox` run successfully. **Your PR cannot be merged unless tests pass**\r\n  - [x] New dependencies have been added to the `REQUIREMENTS` variable ([example][ex-requir]).\r\n  - [x] New dependencies are only imported inside functions that use them ([example][ex-import]).\r\n  - [x] New dependencies have been added to `requirements_all.txt` by running `script/gen_requirements_all.py`.\r\n  - [x] New files were added to `.coveragerc`.\r\n\r\nIf the code does not interact with devices:\r\n  - [x] Local tests with `tox` run successfully. **Your PR cannot be merged unless tests pass**\r\n  - [x] Tests have been added to verify that the new code works.\r\n",
                "comments": [
                    {
                        "body": "I think I have addressed most of your concerns, but I do not understand this one:\r\n> set depencencies to http component\r\n\r\nCan you clarify your request please?",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2017-06-29T02:48:41Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-311847557"
                    },
                    {
                        "body": "He means that you should add `DEPENDENCIES = ['http']` so that the HTTP component is loaded before your component in initialized. (otherwise you can't register your view)",
                        "user": "balloob",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-07-01T00:02:46Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-312396642"
                    },
                    {
                        "body": "I have completed all of the development now, have completed the frontend impelementation and documentation, so I'm moving this out of WIP.  I will of course still appreciate any feedback.",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2017-07-01T03:03:13Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-312406532"
                    },
                    {
                        "body": "I had a thought...Should I convert this into a generic 'mailbox' component?  The panel could easily be made a bit more generic and provide a list of any messages not just voicemail).",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2017-07-01T12:15:27Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-312428944"
                    },
                    {
                        "body": "Sorry for the delay responding to this PR. We've been busy wrapping up Hass.io.\r\n\r\nI like the idea of making it into a generic mailbox component. That makes it easier to justify shipping a panel to all our users. I do think that mailbox might not be the best name, maybe voicemail ? ",
                        "user": "balloob",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-07-24T15:45:08Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-317464921"
                    },
                    {
                        "body": "I'll start work on the requested changes.  I called it 'mailbox' because there is very little inherent to voicemail in the panel (pretty much just the icon).  It could just as easily be email or twitter or list of camera photos, or whatever.  I thought that would make it more likely someone would devise an alternate backend.",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2017-07-25T02:45:53Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-317612818"
                    },
                    {
                        "body": "Okay, we can leave it as mailbox. ",
                        "user": "balloob",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-07-26T03:44:31Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-317938959"
                    },
                    {
                        "body": "I have refactored the code now.  I would appreciate it if you could re-review to make sure the new structure is acceptable.  In the mean time, I am going to try to develop a demo component and then some tests for it.",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2017-07-27T02:19:31Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-318239308"
                    },
                    {
                        "body": "I reworked the mailbox to separate the entity from the platform object and removed the sensor.  I am not precisely sure if this is more aligned with what you were looking for though.",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2017-07-30T16:29:39Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-318912824"
                    },
                    {
                        "body": "Yes, the current architecture is great. ",
                        "user": "balloob",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-08-02T06:09:19Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-319577221"
                    },
                    {
                        "body": "One thing I wasn't sure about was whether I was allowed to use a '@property' tag on the platform object.  the 'media_type' value is static (per platform) and it seemed excessive to use an coroutine to retrieve it.  I had only seen '@prperty' on entities though, so I wasn't sure it is ok.",
                        "user": "PhracturedBlue",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2017-08-03T15:17:34Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-320000528"
                    },
                    {
                        "body": "Yeah, properties are fine . If it's static it doesn't even have to be a property per se. Just this could work too:\r\n\r\n```python\r\nclass Bla:\r\n  media_type = 'something'\r\n```",
                        "user": "balloob",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-08-06T18:08:47Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-320522702"
                    },
                    {
                        "body": "    Awesome, great work!",
                        "user": "balloob",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2017-08-06T18:19:59Z",
                        "url": "https://github.com/home-assistant/core/pull/8233#issuecomment-320523297"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/8233",
                    "merged_at": "2017-08-06T18:19:48Z"
                }
            }
        ],
        "SecurityPolicy_reporting_mechanism": "advisory",
        "num_security_issues_after_policy": 4,
        "num_security_issue_and_pull": 18,
        "security_issues_created_after_policy": [
            {
                "url": "https://github.com/home-assistant/core/pull/123180",
                "title": "Remove deprecated asterisk_cdr integration",
                "labels": [
                    "core",
                    "breaking-change",
                    "remove-platform",
                    "cla-signed",
                    "small-pr",
                    "integration: asterisk_cdr",
                    "Quality Scale: No score"
                ],
                "user": "joostlek",
                "issue_author_association": "MEMBER",
                "number": 123180,
                "id": 2448190299,
                "state": "closed",
                "project_created_at": "2024-08-05T10:24:11Z",
                "closed_at": "2024-08-05T12:43:39Z",
                "body": "<!--\r\n  You are amazing! Thanks for contributing to our project!\r\n  Please, DO NOT DELETE ANY TEXT from this template! (unless instructed).\r\n-->\r\n## Breaking change\r\n<!--\r\n  If your PR contains a breaking change for existing users, it is important\r\n  to tell them what breaks, how to make it work again and why we did this.\r\n  This piece of text is published with the release notes, so it helps if you\r\n  write it towards our users, not us.\r\n  Note: Remove this section if this PR is NOT a breaking change.\r\n-->\r\nAsterisk_mbox has been deprecated in 2024.3.0 and has been removed\r\n\r\n## Proposed change\r\n<!--\r\n  Describe the big picture of your changes here to communicate to the\r\n  maintainers why we should accept this pull request. If it fixes a bug\r\n  or resolves a feature request, be sure to link to that issue in the\r\n  additional information section.\r\n-->\r\nRemove deprecated asterisk_cdr integration\r\n\r\n## Type of change\r\n<!--\r\n  What type of change does your PR introduce to Home Assistant?\r\n  NOTE: Please, check only 1! box!\r\n  If your PR requires multiple boxes to be checked, you'll most likely need to\r\n  split it into multiple PRs. This makes things easier and faster to code review.\r\n-->\r\n\r\n- [ ] Dependency upgrade\r\n- [ ] Bugfix (non-breaking change which fixes an issue)\r\n- [ ] New integration (thank you!)\r\n- [ ] New feature (which adds functionality to an existing integration)\r\n- [ ] Deprecation (breaking change to happen in the future)\r\n- [x] Breaking change (fix/feature causing existing functionality to break)\r\n- [ ] Code quality improvements to existing code or addition of tests\r\n\r\n## Additional information\r\n<!--\r\n  Details are important, and help maintainers processing your PR.\r\n  Please be sure to fill out additional details, if applicable.\r\n-->\r\n\r\n- This PR fixes or closes issue: fixes #\r\n- This PR is related to issue: \r\n- Link to documentation pull request: \r\n\r\n## Checklist\r\n<!--\r\n  Put an `x` in the boxes that apply. You can also fill these out after\r\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\r\n  We're here to help! This is simply a reminder of what we are going to look\r\n  for before merging your code.\r\n-->\r\n\r\n- [ ] The code change is tested and works locally.\r\n- [x] Local tests pass. **Your PR cannot be merged unless tests pass**\r\n- [x] There is no commented out code in this PR.\r\n- [x] I have followed the [development checklist][dev-checklist]\r\n- [x] I have followed the [perfect PR recommendations][perfect-pr]\r\n- [x] The code has been formatted using Ruff (`ruff format homeassistant tests`)\r\n- [ ] Tests have been added to verify that the new code works.\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n\r\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n\r\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \r\n      Updated and included derived files by running: `python3 -m script.hassfest`.\r\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \r\n      Updated by running `python3 -m script.gen_requirements_all`.\r\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\r\n\r\n<!--\r\n  This project is very active and we have a high turnover of pull requests.\r\n\r\n  Unfortunately, the number of incoming pull requests is higher than what our\r\n  reviewers can review and merge so there is a long backlog of pull requests\r\n  waiting for review. You can help here!\r\n  \r\n  By reviewing another pull request, you will help raise the code quality of\r\n  that pull request and the final review will be faster. This way the general\r\n  pace of pull request reviews will go up and your wait time will go down.\r\n  \r\n  When picking a pull request to review, try to choose one that hasn't yet\r\n  been reviewed.\r\n\r\n  Thanks for helping out!\r\n-->\r\n\r\nTo help with the load of incoming pull requests:\r\n\r\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\r\n\r\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\r\n\r\n<!--\r\n  Thank you for contributing <3\r\n\r\n  Below, some useful links you could explore:\r\n-->\r\n[dev-checklist]: https://developers.home-assistant.io/docs/development_checklist/\r\n[manifest-docs]: https://developers.home-assistant.io/docs/creating_integration_manifest/\r\n[quality-scale]: https://developers.home-assistant.io/docs/integration_quality_scale_index/\r\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\r\n[perfect-pr]: https://developers.home-assistant.io/docs/review-process/#creating-the-perfect-pr\r\n",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/123180",
                    "merged_at": "2024-08-05T12:43:39Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/123174",
                "title": "Remove deprecated asterisk_mbox integration",
                "labels": [
                    "breaking-change",
                    "remove-platform",
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "small-pr",
                    "Quality Scale: No score"
                ],
                "user": "joostlek",
                "issue_author_association": "MEMBER",
                "number": 123174,
                "id": 2448042707,
                "state": "closed",
                "project_created_at": "2024-08-05T09:17:26Z",
                "closed_at": "2024-08-05T13:28:50Z",
                "body": "<!--\r\n  You are amazing! Thanks for contributing to our project!\r\n  Please, DO NOT DELETE ANY TEXT from this template! (unless instructed).\r\n-->\r\n## Breaking change\r\n<!--\r\n  If your PR contains a breaking change for existing users, it is important\r\n  to tell them what breaks, how to make it work again and why we did this.\r\n  This piece of text is published with the release notes, so it helps if you\r\n  write it towards our users, not us.\r\n  Note: Remove this section if this PR is NOT a breaking change.\r\n-->\r\nAsterisk_mbox has been deprecated in 2024.3.0 and has been removed.\r\n\r\n## Proposed change\r\n<!--\r\n  Describe the big picture of your changes here to communicate to the\r\n  maintainers why we should accept this pull request. If it fixes a bug\r\n  or resolves a feature request, be sure to link to that issue in the\r\n  additional information section.\r\n-->\r\nRemove deprecated asterisk_mbox integration\r\n\r\n## Type of change\r\n<!--\r\n  What type of change does your PR introduce to Home Assistant?\r\n  NOTE: Please, check only 1! box!\r\n  If your PR requires multiple boxes to be checked, you'll most likely need to\r\n  split it into multiple PRs. This makes things easier and faster to code review.\r\n-->\r\n\r\n- [ ] Dependency upgrade\r\n- [ ] Bugfix (non-breaking change which fixes an issue)\r\n- [ ] New integration (thank you!)\r\n- [ ] New feature (which adds functionality to an existing integration)\r\n- [ ] Deprecation (breaking change to happen in the future)\r\n- [x] Breaking change (fix/feature causing existing functionality to break)\r\n- [ ] Code quality improvements to existing code or addition of tests\r\n\r\n## Additional information\r\n<!--\r\n  Details are important, and help maintainers processing your PR.\r\n  Please be sure to fill out additional details, if applicable.\r\n-->\r\n\r\n- This PR fixes or closes issue: fixes #\r\n- This PR is related to issue: \r\n- Link to documentation pull request: https://github.com/home-assistant/home-assistant.io/pull/34131\r\n\r\n## Checklist\r\n<!--\r\n  Put an `x` in the boxes that apply. You can also fill these out after\r\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\r\n  We're here to help! This is simply a reminder of what we are going to look\r\n  for before merging your code.\r\n-->\r\n\r\n- [x] The code change is tested and works locally.\r\n- [x] Local tests pass. **Your PR cannot be merged unless tests pass**\r\n- [x] There is no commented out code in this PR.\r\n- [x] I have followed the [development checklist][dev-checklist]\r\n- [x] I have followed the [perfect PR recommendations][perfect-pr]\r\n- [x] The code has been formatted using Ruff (`ruff format homeassistant tests`)\r\n- [ ] Tests have been added to verify that the new code works.\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n\r\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n\r\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \r\n      Updated and included derived files by running: `python3 -m script.hassfest`.\r\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \r\n      Updated by running `python3 -m script.gen_requirements_all`.\r\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\r\n\r\n<!--\r\n  This project is very active and we have a high turnover of pull requests.\r\n\r\n  Unfortunately, the number of incoming pull requests is higher than what our\r\n  reviewers can review and merge so there is a long backlog of pull requests\r\n  waiting for review. You can help here!\r\n  \r\n  By reviewing another pull request, you will help raise the code quality of\r\n  that pull request and the final review will be faster. This way the general\r\n  pace of pull request reviews will go up and your wait time will go down.\r\n  \r\n  When picking a pull request to review, try to choose one that hasn't yet\r\n  been reviewed.\r\n\r\n  Thanks for helping out!\r\n-->\r\n\r\nTo help with the load of incoming pull requests:\r\n\r\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\r\n\r\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\r\n\r\n<!--\r\n  Thank you for contributing <3\r\n\r\n  Below, some useful links you could explore:\r\n-->\r\n[dev-checklist]: https://developers.home-assistant.io/docs/development_checklist/\r\n[manifest-docs]: https://developers.home-assistant.io/docs/creating_integration_manifest/\r\n[quality-scale]: https://developers.home-assistant.io/docs/integration_quality_scale_index/\r\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\r\n[perfect-pr]: https://developers.home-assistant.io/docs/review-process/#creating-the-perfect-pr\r\n",
                "comments": [
                    {
                        "body": "<!-- ReviewDrafterComment -->\nPlease take a look at the requested changes, and use the **Ready for review** button when you are done, thanks :+1:\n\n[_Learn more about our pull request process._](https://developers.home-assistant.io/docs/review-process#prs-are-being-drafted-when-changes-are-needed)\n",
                        "user": "home-assistant[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-08-05T09:57:05Z",
                        "url": "https://github.com/home-assistant/core/pull/123174#issuecomment-2268675505"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/123174",
                    "merged_at": "2024-08-05T13:28:50Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/110930",
                "title": "Deprecate mailbox platform",
                "labels": [
                    "core",
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "integration: mailbox",
                    "integration: asterisk_cdr",
                    "deprecation",
                    "Quality Scale: No score",
                    "Quality Scale: internal"
                ],
                "user": "edenhaus",
                "issue_author_association": "CONTRIBUTOR",
                "number": 110930,
                "id": 2141845395,
                "state": "closed",
                "project_created_at": "2024-02-19T08:55:08Z",
                "closed_at": "2024-02-27T12:50:02Z",
                "body": "<!--\r\n  You are amazing! Thanks for contributing to our project!\r\n  Please, DO NOT DELETE ANY TEXT from this template! (unless instructed).\r\n-->\r\n## Breaking change\r\n<!--\r\n  If your PR contains a breaking change for existing users, it is important\r\n  to tell them what breaks, how to make it work again and why we did this.\r\n  This piece of text is published with the release notes, so it helps if you\r\n  write it towards our users, not us.\r\n  Note: Remove this section if this PR is NOT a breaking change.\r\n-->\r\nDeprecate the mailbox integration platform and the asterisk integrations, as they only implement the mailbox platform.\r\n\r\nWe deprecate the mailbox integration because the mailbox platform is used only by the asterisk integrations, where asterix_cdr has 0 active installations and asterisk_mbox only 25. By removing the mailbox platform we can also remove the custom mailbox panel from the frontend.\r\n\r\n## Proposed change\r\n<!--\r\n  Describe the big picture of your changes here to communicate to the\r\n  maintainers why we should accept this pull request. If it fixes a bug\r\n  or resolves a feature request, be sure to link to that issue in the\r\n  additional information section.\r\n-->\r\nWe deprecate the mailbox integration because the mailbox platform is used only by the asterisk integrations, where asterix_cdr has 0 active installations and asterisk_mbox only 25. By removing the mailbox platform we can also remove the custom mailbox panel from the frontend.\r\n\r\n## Type of change\r\n<!--\r\n  What type of change does your PR introduce to Home Assistant?\r\n  NOTE: Please, check only 1! box!\r\n  If your PR requires multiple boxes to be checked, you'll most likely need to\r\n  split it into multiple PRs. This makes things easier and faster to code review.\r\n-->\r\n\r\n- [ ] Dependency upgrade\r\n- [ ] Bugfix (non-breaking change which fixes an issue)\r\n- [ ] New integration (thank you!)\r\n- [ ] New feature (which adds functionality to an existing integration)\r\n- [x] Deprecation (breaking change to happen in the future)\r\n- [ ] Breaking change (fix/feature causing existing functionality to break)\r\n- [ ] Code quality improvements to existing code or addition of tests\r\n\r\n## Additional information\r\n<!--\r\n  Details are important, and help maintainers processing your PR.\r\n  Please be sure to fill out additional details, if applicable.\r\n-->\r\n\r\n- This PR fixes or closes issue: fixes #\r\n- This PR is related to issue: \r\n- Link to documentation pull request: https://github.com/home-assistant/home-assistant.io/pull/31632\r\n\r\n## Checklist\r\n<!--\r\n  Put an `x` in the boxes that apply. You can also fill these out after\r\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\r\n  We're here to help! This is simply a reminder of what we are going to look\r\n  for before merging your code.\r\n-->\r\n\r\n- [ ] The code change is tested and works locally.\r\n- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**\r\n- [ ] There is no commented out code in this PR.\r\n- [ ] I have followed the [development checklist][dev-checklist]\r\n- [ ] I have followed the [perfect PR recommendations][perfect-pr]\r\n- [ ] The code has been formatted using Ruff (`ruff format homeassistant tests`)\r\n- [ ] Tests have been added to verify that the new code works.\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n\r\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n\r\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \r\n      Updated and included derived files by running: `python3 -m script.hassfest`.\r\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \r\n      Updated by running `python3 -m script.gen_requirements_all`.\r\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\r\n- [ ] Untested files have been added to `.coveragerc`.\r\n\r\n<!--\r\n  This project is very active and we have a high turnover of pull requests.\r\n\r\n  Unfortunately, the number of incoming pull requests is higher than what our\r\n  reviewers can review and merge so there is a long backlog of pull requests\r\n  waiting for review. You can help here!\r\n  \r\n  By reviewing another pull request, you will help raise the code quality of\r\n  that pull request and the final review will be faster. This way the general\r\n  pace of pull request reviews will go up and your wait time will go down.\r\n  \r\n  When picking a pull request to review, try to choose one that hasn't yet\r\n  been reviewed.\r\n\r\n  Thanks for helping out!\r\n-->\r\n\r\nTo help with the load of incoming pull requests:\r\n\r\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\r\n\r\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\r\n\r\n<!--\r\n  Thank you for contributing <3\r\n\r\n  Below, some useful links you could explore:\r\n-->\r\n[dev-checklist]: https://developers.home-assistant.io/docs/development_checklist/\r\n[manifest-docs]: https://developers.home-assistant.io/docs/creating_integration_manifest/\r\n[quality-scale]: https://developers.home-assistant.io/docs/integration_quality_scale_index/\r\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\r\n[perfect-pr]: https://developers.home-assistant.io/docs/review-process/#creating-the-perfect-pr\r\n",
                "comments": [
                    {
                        "body": "I think we should add some context in the PR description why we remove the mailbox integration.",
                        "user": "MartinHjelmare",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2024-02-19T13:46:44Z",
                        "url": "https://github.com/home-assistant/core/pull/110930#issuecomment-1952488580"
                    },
                    {
                        "body": "<!-- ReviewDrafterComment -->\nPlease take a look at the requested changes, and use the **Ready for review** button when you are done, thanks :+1:\n\n[_Learn more about our pull request process._](https://developers.home-assistant.io/docs/review-process#prs-are-being-drafted-when-changes-are-needed)\n",
                        "user": "home-assistant[bot]",
                        "issue_author_association": "NONE",
                        "project_created_at": "2024-02-27T07:28:58Z",
                        "url": "https://github.com/home-assistant/core/pull/110930#issuecomment-1965940309"
                    },
                    {
                        "body": "CI / Run tests Python 3.11 (7) (pull_request) :\r\n`FAILED tests/components/switcher_kis/test_init.py::test_update_fail - AssertionError: assert 'unavailable' != 'unavailable'` is unrelated",
                        "user": "edenhaus",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2024-02-27T12:49:31Z",
                        "url": "https://github.com/home-assistant/core/pull/110930#issuecomment-1966474507"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/110930",
                    "merged_at": "2024-02-27T12:50:02Z"
                }
            },
            {
                "url": "https://github.com/home-assistant/core/pull/106841",
                "title": "Enable strict typing for asterisk_cdr + asterisk_mbox",
                "labels": [
                    "cla-signed",
                    "integration: asterisk_mbox",
                    "integration: asterisk_cdr",
                    "code-quality",
                    "Quality Scale: No score"
                ],
                "user": "cdce8p",
                "issue_author_association": "MEMBER",
                "number": 106841,
                "id": 2061723033,
                "state": "closed",
                "project_created_at": "2024-01-01T19:09:00Z",
                "closed_at": "2024-01-01T19:45:16Z",
                "body": "## Proposed change\r\nImprove annotations and enable strict typing.\r\n\r\n## Type of change\r\n<!--\r\n  What type of change does your PR introduce to Home Assistant?\r\n  NOTE: Please, check only 1! box!\r\n  If your PR requires multiple boxes to be checked, you'll most likely need to\r\n  split it into multiple PRs. This makes things easier and faster to code review.\r\n-->\r\n\r\n- [ ] Dependency upgrade\r\n- [ ] Bugfix (non-breaking change which fixes an issue)\r\n- [ ] New integration (thank you!)\r\n- [ ] New feature (which adds functionality to an existing integration)\r\n- [ ] Deprecation (breaking change to happen in the future)\r\n- [ ] Breaking change (fix/feature causing existing functionality to break)\r\n- [x] Code quality improvements to existing code or addition of tests\r\n\r\n## Additional information\r\n<!--\r\n  Details are important, and help maintainers processing your PR.\r\n  Please be sure to fill out additional details, if applicable.\r\n-->\r\n\r\n- This PR fixes or closes issue: fixes #\r\n- This PR is related to issue: \r\n- Link to documentation pull request: \r\n\r\n## Checklist\r\n<!--\r\n  Put an `x` in the boxes that apply. You can also fill these out after\r\n  creating the PR. If you're unsure about any of them, don't hesitate to ask.\r\n  We're here to help! This is simply a reminder of what we are going to look\r\n  for before merging your code.\r\n-->\r\n\r\n- [ ] The code change is tested and works locally.\r\n- [ ] Local tests pass. **Your PR cannot be merged unless tests pass**\r\n- [ ] There is no commented out code in this PR.\r\n- [ ] I have followed the [development checklist][dev-checklist]\r\n- [ ] I have followed the [perfect PR recommendations][perfect-pr]\r\n- [ ] The code has been formatted using Ruff (`ruff format homeassistant tests`)\r\n- [ ] Tests have been added to verify that the new code works.\r\n\r\nIf user exposed functionality or configuration variables are added/changed:\r\n\r\n- [ ] Documentation added/updated for [www.home-assistant.io][docs-repository]\r\n\r\nIf the code communicates with devices, web services, or third-party tools:\r\n\r\n- [ ] The [manifest file][manifest-docs] has all fields filled out correctly.  \r\n      Updated and included derived files by running: `python3 -m script.hassfest`.\r\n- [ ] New or updated dependencies have been added to `requirements_all.txt`.  \r\n      Updated by running `python3 -m script.gen_requirements_all`.\r\n- [ ] For the updated dependencies - a link to the changelog, or at minimum a diff between library versions is added to the PR description.\r\n- [ ] Untested files have been added to `.coveragerc`.\r\n\r\n<!--\r\n  This project is very active and we have a high turnover of pull requests.\r\n\r\n  Unfortunately, the number of incoming pull requests is higher than what our\r\n  reviewers can review and merge so there is a long backlog of pull requests\r\n  waiting for review. You can help here!\r\n  \r\n  By reviewing another pull request, you will help raise the code quality of\r\n  that pull request and the final review will be faster. This way the general\r\n  pace of pull request reviews will go up and your wait time will go down.\r\n  \r\n  When picking a pull request to review, try to choose one that hasn't yet\r\n  been reviewed.\r\n\r\n  Thanks for helping out!\r\n-->\r\n\r\nTo help with the load of incoming pull requests:\r\n\r\n- [ ] I have reviewed two other [open pull requests][prs] in this repository.\r\n\r\n[prs]: https://github.com/home-assistant/core/pulls?q=is%3Aopen+is%3Apr+-author%3A%40me+-draft%3Atrue+-label%3Awaiting-for-upstream+sort%3Acreated-desc+review%3Anone+-status%3Afailure\r\n\r\n<!--\r\n  Thank you for contributing <3\r\n\r\n  Below, some useful links you could explore:\r\n-->\r\n[dev-checklist]: https://developers.home-assistant.io/docs/development_checklist/\r\n[manifest-docs]: https://developers.home-assistant.io/docs/creating_integration_manifest/\r\n[quality-scale]: https://developers.home-assistant.io/docs/integration_quality_scale_index/\r\n[docs-repository]: https://github.com/home-assistant/home-assistant.io\r\n[perfect-pr]: https://developers.home-assistant.io/docs/review-process/#creating-the-perfect-pr\r\n",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/home-assistant/core/pulls/106841",
                    "merged_at": "2024-01-01T19:45:16Z"
                }
            }
        ],
        "SecurityPolicy_content_category": [
            "Generic policy"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 4,
        "has_generic_policy": false
    },
    {
        "project_name": "pywbem/pywbem",
        "project_url": "https://github.com/pywbem/pywbem",
        "SSF": {
            "date": "2024-10-29T19:45:05+07:00",
            "repo": {
                "name": "github.com/pywbem/pywbem",
                "commit": "f55b499a96f0b57ff6e7f30f2819bc31c92898c7"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 4.8,
            "checks": [
                {
                    "details": [
                        "Warn: binary detected: dist/pywbem-0.3/pywbem-0.3.win32.exe:1",
                        "Warn: binary detected: dist/pywbem-0.4/pywbem-0.4.win32.exe:1",
                        "Warn: binary detected: dist/pywbem-0.5/pywbem-0.5.win32.exe:1",
                        "Warn: binary detected: dist/pywbem-0.6/pywbem-0.6.win32.exe:1"
                    ],
                    "score": 6,
                    "reason": "binaries present in source code",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: branch 'master' does not require approvers",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Info: status check found to merge onto on branch 'master'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 9,
                    "reason": "28 out of 29 merged PRs checked by a CI test -- score normalized to 9",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 4,
                    "reason": "Found 13/29 approved changesets -- score normalized to 4",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: libstorage contributor org/company found, open-iscsi contributor org/company found, cmpi-wg contributor org/company found, zhmcclient contributor org/company found, inova development contributor org/company found, red hat contributor org/company found, SNIA contributor org/company found, storaged-project contributor org/company found, lvmteam contributor org/company found, kubernetes contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 10 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": [
                        "Warn: script injection with untrusted input ' github.head_ref ': .github/workflows/test.yml:34"
                    ],
                    "score": 0,
                    "reason": "dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: PyUp: .pyup.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.txt:0",
                        "Info: FSF or OSI recognized license: GNU Lesser General Public License v2.1: LICENSE.txt:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "16 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/test.yml:153",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/test.yml:176",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/test.yml:183",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/test.yml:189",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/test.yml:195",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/test.yml:202",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/test.yml:208",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/test.yml:215",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/test.yml:219",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/test.yml:225",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/test.yml:231",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/test.yml:237",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/test.yml:243",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/test.yml:249",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/test.yml:255",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/test.yml:262",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/test.yml:270",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/test.yml:280",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/test.yml:286",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/test.yml:292",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/test.yml:298",
                        "Info: Possibly incomplete results: error parsing job operating system: .github/workflows/test.yml:305",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/pywbem/pywbem/publish.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:45: update your workflow using https://app.stepsecurity.io/secureworkflow/pywbem/pywbem/publish.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:61: update your workflow using https://app.stepsecurity.io/secureworkflow/pywbem/pywbem/publish.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:70: update your workflow using https://app.stepsecurity.io/secureworkflow/pywbem/pywbem/publish.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:99: update your workflow using https://app.stepsecurity.io/secureworkflow/pywbem/pywbem/publish.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:123: update your workflow using https://app.stepsecurity.io/secureworkflow/pywbem/pywbem/publish.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:127: update your workflow using https://app.stepsecurity.io/secureworkflow/pywbem/pywbem/publish.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish.yml:149: update your workflow using https://app.stepsecurity.io/secureworkflow/pywbem/pywbem/publish.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish.yml:157: update your workflow using https://app.stepsecurity.io/secureworkflow/pywbem/pywbem/publish.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish.yml:165: update your workflow using https://app.stepsecurity.io/secureworkflow/pywbem/pywbem/publish.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:180: update your workflow using https://app.stepsecurity.io/secureworkflow/pywbem/pywbem/publish.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:139: update your workflow using https://app.stepsecurity.io/secureworkflow/pywbem/pywbem/test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:161: update your workflow using https://app.stepsecurity.io/secureworkflow/pywbem/pywbem/test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:168: update your workflow using https://app.stepsecurity.io/secureworkflow/pywbem/pywbem/test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/test.yml:173: update your workflow using https://app.stepsecurity.io/secureworkflow/pywbem/pywbem/test.yml/master?enable=pin",
                        "Warn: pipCommand not pinned by hash: pywbem_os_setup.sh:163",
                        "Warn: pipCommand not pinned by hash: tools/jnb:24",
                        "Warn: pipCommand not pinned by hash: tools/jnb:25",
                        "Warn: pipCommand not pinned by hash: tools/pycmp_0.7.0.sh:39",
                        "Warn: pipCommand not pinned by hash: .github/workflows/test.yml:319",
                        "Info:   0 out of  12 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   3 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   5 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/notify.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/test.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/pywbem/pywbem/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\nThis project supports its released versions as follows:\n\n- The [latest released version on Pypi](https://pypi.org/project/pywbem/)\n  gets fixes, including security fixes.\n- Earlier versions are not fixed anymore.\n\n## Reporting a Vulnerability\n\nPlease report vulnerabilities via the\n[Security Advisories](https://github.com/pywbem/pywbem/security/advisories)\npage of this project. This ensures that they are passed on to the maintainers\nprivately.\n\nDo not report them as issues or pull requests, since that would reveal the\nvulnerability before the maintainers have a chance to fix it. Note that even\nwith a pull request that fixes the vulnerability perfectly, it is revealed\npublicly before a new version of the package can be released to Pypi.\n",
        "project_all_labels": [
            "area: code",
            "area: devenv",
            "area: docs",
            "area: setup",
            "area: test",
            "dependencies",
            "discussion needed",
            "help wanted",
            "investigation needed",
            "keep branch",
            "priority",
            "question",
            "rebase needed",
            "release definition",
            "release: mandatory",
            "release: optional",
            "release: user generated",
            "resolution: duplicate",
            "resolution: elsewhere",
            "resolution: fixed",
            "resolution: invalid",
            "resolution: no issue",
            "resolution: partly fixed",
            "resolution: wont fix",
            "resolution: workaround",
            "review needed",
            "rollback done",
            "rollback needed",
            "test needed",
            "type: bug",
            "type: cleanup",
            "type: DMTF issue",
            "type: enhancement",
            "type: standards compliance",
            "under work",
            "update needed",
            "waiting"
        ],
        "README_content": "# Pywbem - A WBEM client and related utilities, written in pure Python\n\n[![Version on Pypi](https://img.shields.io/pypi/v/pywbem.svg)](https://pypi.python.org/pypi/pywbem/)\n[![Test status (master)](https://github.com/pywbem/pywbem/actions/workflows/test.yml/badge.svg?branch=master)](https://github.com/pywbem/pywbem/actions/workflows/test.yml?query=branch%3Amaster)\n[![Docs status (master)](https://readthedocs.org/projects/pywbem/badge/?version=latest)](https://readthedocs.org/projects/pywbem/builds/)\n[![Test coverage (master)](https://coveralls.io/repos/github/pywbem/pywbem/badge.svg?branch=master)](https://coveralls.io/github/pywbem/pywbem?branch=master)\n[![Supported Python](https://img.shields.io/pypi/pyversions/pywbem.svg?color=brightgreen)](https://pypi.python.org/pypi/pywbem/)\n\n# Overview\n\nPywbem is a WBEM client and WBEM indication listener and provides\nrelated WBEM client-side functionality. It is written in pure Python and\nruns on Python 3.\n\nWBEM is a standardized approach for systems management defined by the\n[DMTF](https://www.dmtf.org) that is used in the industry for a wide\nvariety of systems management tasks. See [WBEM\nStandards](https://www.dmtf.org/standards/wbem) for more information. An\nimportant use of this approach is the\n[SMI-S](https://www.snia.org/tech_activities/standards/curr_standards/smi)\nstandard defined by [SNIA](https://www.snia.org) for managing storage.\n\n# Functionality\n\nThe major components of pywbem are shown in this diagram:\n\n![pywbem components](images/pywbemcomponents.png)\n\nThe green components all have Python APIs for use by user applications.\nThe yellow components are command line utilities. The blue components\nare not part of the pywbem or pywbemtools packages.\n\nThe pywbem components all run on the client side and communicate with a\nremote WBEM server using the standard CIM operations over HTTP (CIM-XML)\nprotocol defined by the DMTF.\n\nPywbem provides the following Python APIs:\n\n- [WBEM Client Library](https://pywbem.readthedocs.io/en/latest/client.html) -\n  An API that supports issuing WBEM operations to a WBEM server, using the CIM\n  operations over HTTP (CIM-XML) protocol defined by the DMTF.\n- [WBEM Server Library](https://pywbem.readthedocs.io/en/latest/server.html) -\n  An API that encapsulates selected functionality of a WBEM server for use by a\n  WBEM client application, such as determining the Interop namespace and other\n  basic information about the server, or the management profiles advertised by\n  the server.\n- [WBEM Indication Listener](https://pywbem.readthedocs.io/en/latest/indication.html) -\n  An API for creating and managing a thread-based WBEM listener that waits for\n  indications (i.e. event notifications) emitted by a WBEM server using the\n  CIM-XML protocol. The API supports registering callback functions that get\n  called when indications are received by the listener.\n- [WBEM Subscription Manager](https://pywbem.readthedocs.io/en/latest/subscription.html) -\n  An API for viewing and managing subscriptions for indications on a WBEM server.\n- [MOF Compiler](https://pywbem.readthedocs.io/en/latest/compiler.html) -\n  An API for compiling MOF files or strings into a CIM repository (e.g. on a\n  WBEM server), or for test-compiling MOF.\n- [Mock WBEM server](https://pywbem.readthedocs.io/en/latest/mockwbemserver.html) -\n  An API for setting up a mocked WBEM server that is used instead of a real WBEM\n  server. This allows setting up well-defined WBEM servers locally that can be\n  used for example for prototyping or testing user applications.\n\nPywbem provides this command line utility:\n\n- [mof_compiler](https://pywbem.readthedocs.io/en/latest/utilities.html#mof-compiler) -\n  A MOF compiler that takes MOF files as input and compiles them into a CIM\n  repository (e.g. on a WBEM server).\n\nThe related [pywbemtools project](https://github.com/pywbem/pywbemtools)\nprovides the following command line utilities:\n\n- [pywbemcli](https://pywbemtools.readthedocs.io/en/latest/pywbemcli) -\n  A client-side command line interface for a WBEM server, supporting a command\n  line mode and an interactive (repl) mode.\n- [pywbemlistener](https://pywbemtools.readthedocs.io/en/latest/pywbemlistener) -\n  A command that runs and manages WBEM indication listeners that can receive\n  indications from a WBEM server.\n\n# Installation\n\nTo install the latest released version of pywbem into your active Python\nenvironment:\n\n``` bash\n$ pip install pywbem\n```\n\nThis will also install any prerequisite Python packages.\n\nStarting with version 1.0.0, pywbem has no OS-level prerequisite packages.\n\nOn newer versions of some operating systems(ex. Ubuntu 23.04, Debian 12)\npywbem will only install into a virtual environment. This is by design\nto avoid conflicts between OS distributed python packages and other user\ninstalled packages and is documented in\n[Python PEP 668](https://peps.python.org/pep-0668/). See the pywbem documentation\n[Troubleshooting section](https://pywbem.readthedocs.io/en/latest/appendix.html#troubleshooting)\nfor more information if an \\\"Externally-managed-environment\\\" error\noccurs during installation.\n\nFor more details and alternative ways to install, see the\n[Installation section](https://pywbem.readthedocs.io/en/latest/intro.html#installation)\nin the pywbem documentation.\n\n# Documentation\n\n- [Documentation](https://pywbem.readthedocs.io/en/latest/) -\n  Concepts, tutorials, Python API, command line tools, and developer\n  documentation.\n- [Tutorial](https://pywbem.readthedocs.io/en/latest/tutorial.html) -\n  The tutorials in the documentation are provided as Jupyter notebooks\n  and provide working examples of pywbem API usage.\n- [Change log](https://pywbem.readthedocs.io/en/latest/changes.html) -\n  Detailed change history in the documentation.\n- [Presentations](https://pywbem.github.io/pywbem/documentation.html) -\n  status, concepts, and implementation of pywbem.\n\n# Quick Start\n\nThe following simple example script lists the namespaces and the Interop\nnamespace in a particular WBEM server:\n\n``` python\n#!/usr/bin/env python\n\nimport pywbem\n\nserver_url = 'http://localhost'\nuser = 'fred'\npassword = 'blah'\n\nconn = pywbem.WBEMConnection(server_url, (user, password))\n\nserver = pywbem.WBEMServer(conn)\n\nprint(f\"Interop namespace:\\n  {server.interop_ns}\")\n\nprint(\"All namespaces:\")\nfor ns in server.namespaces:\n    print(f\"  {ns}\")\n```\n\n# Project Planning\n\nFor each upcoming release, the bugs and feature requests that are planned to be\naddressed in that release are listed in the\n[issue tracker](https://github.com/pywbem/pywbem/issues) with an according\nmilestone set that identifies the target release. The due date on the milestone\ndefinition is the planned release date. There is usually also an issue that\nsets out the major goals for an upcoming release.\n\n# Planned Next Release\n\nFix versions of pywbem are released as needed.\n\nThe next planned feature version(s) of pywbem can be found by listing the\n[release definition issues](https://github.com/pywbem/pywbem/issues?q=is%3Aissue+is%3Aopen+label%3A%22release+definition%22).\n\n# Contributing\n\nFor information on how to contribute to pywbem, see the\n[Contributing section](https://pywbem.readthedocs.io/en/latest/development.html#contributing)\nin the pywbem documentation.\n\n# License\n\nPywbem is provided under the\n[GNU Lesser General Public License (LGPL) version 2.1](https://raw.githubusercontent.com/pywbem/pywbem/master/LICENSE.txt),\nor (at your option) any later version.\n",
        "num_commits": 2984,
        "project_age_days": 3311,
        "project_created_at": "2015-10-06",
        "latest_updated_at": "2024-10-28",
        "latest_pushed_at": "2024-10-28",
        "num_contributors": 8,
        "num_pull": 2112,
        "num_issues": 3238,
        "num_opening_issue": 18,
        "project_size(kB)": 45877,
        "num_stargazers": 41,
        "num_watchers": 41,
        "num_forks": 26,
        "num_subscribers": 6,
        "SecurityPolicy_created_at": "2023-06-01 07:22:15",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "f77d85c64ac2af1d0dab2b446ec514d9f11b4fcd",
                "url": "https://github.com/pywbem/pywbem/commit/f77d85c64ac2af1d0dab2b446ec514d9f11b4fcd",
                "date": "2023-06-01 07:22:15"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "advisory",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "pylons/waitress",
        "project_url": "https://github.com/pylons/waitress",
        "SSF": {
            "date": "2024-10-29T23:04:59+07:00",
            "repo": {
                "name": "github.com/pylons/waitress",
                "commit": "ae949bb428e50cf04152db56460f31c1e6d3a2a9"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.8,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Warn: branch 'main' does not require approvers",
                        "Warn: codeowners review is not required on branch 'main'",
                        "Warn: no status checks found to merge onto branch 'main'"
                    ],
                    "score": 3,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 8,
                    "reason": "5 out of 6 merged PRs checked by a CI test -- score normalized to 8",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 1/17 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: usingnamespace contributor org/company found, ptahproject contributor org/company found, pyramid-collective contributor org/company found, clinical ink contributor org/company found, dabapps contributor org/company found, BrumCodeJo contributor org/company found, mongodb contributor org/company found, theasylum contributor org/company found, Supervisor contributor org/company found, repoze contributor org/company found, agendaless consulting contributor org/company found, codeinn contributor org/company found, rhodecode contributor org/company found, CampFireManager contributor org/company found, dafizilla contributor org/company found, Pylons contributor org/company found, Shoobx contributor org/company found, knop-project contributor org/company found, zopefoundation contributor org/company found, colossaldynamics contributor org/company found, workday contributor org/company found, buildout contributor org/company found, collective contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 23 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.txt:0",
                        "Warn: project license file does not contain an FSF or OSI license."
                    ],
                    "score": 9,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "9 commit(s) and 3 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:80: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/waitress/ci-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:82: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/waitress/ci-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:100: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/waitress/ci-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:102: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/waitress/ci-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:113: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/waitress/ci-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:115: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/waitress/ci-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:125: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/waitress/ci-tests.yml/main?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/ci-tests.yml:127: update your workflow using https://app.stepsecurity.io/secureworkflow/Pylons/waitress/ci-tests.yml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci-tests.yml:132",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci-tests.yml:87",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci-tests.yml:108",
                        "Warn: pipCommand not pinned by hash: .github/workflows/ci-tests.yml:120",
                        "Info:   0 out of   8 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   4 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 19 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/Pylons/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/Pylons/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/Pylons/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/Pylons/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/ci-tests.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/Pylons/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\nTo report security issues with projects under the Pylons Project, send email to: pylons-project-security@googlegroups.com.\nIf we determine that your report may be a security issue with the project, we may contact you for further information.\nWe volunteers ask that you delay public disclosure of your report for at least ninety (90) days from the date you report it to us.\nThis will allow sufficient time for us to process your report and coordinate disclosure with you.\n\nOnce verified and fixed, the following steps will be taken.\n\n-   We will use GitHub's Security Advisory tool to report the issue.\n-   GitHub will review our Security Advisory report for compliance with Common Vulnerabilities and Exposures (CVE) rules.\n    If it is compliant, they will submit it to the MITRE Corporation to generate a [CVE](https://www.cve.org/).\n    This in turn submits the CVE to the [National Vulnerability Database (NVD)](https://nvd.nist.gov/vuln/search).\n    GitHub notifies us of their decision.\n-   Assuming it is compliant, we then publish our Security Advisory on GitHub, which triggers the next steps.\n-   GitHub will publish the CVE to the CVE List.\n-   GitHub will broadcast our Security Advisory via the [GitHub Advisory Database](https://github.com/advisories).\n-   GitHub will send [security alerts](https://docs.github.com/en/code-security/supply-chain-security/managing-vulnerabilities-in-your-projects-dependencies/about-alerts-for-vulnerable-dependencies) to all repositories that use our package (and have opted into security alerts).\n    This includes Dependabot alerts.\n-   We will make a bug-fix release.\n-   We will send an announcement through our usual channels, including those listed on the Pylons Project website's [Contact](https://pylonsproject.org/about-contact.html) page.\n-   We will provide credit to the reporter or researcher in the vulnerability notice.\n",
        "project_all_labels": [
            "bug",
            "dependencies",
            "docs",
            "enhancement",
            "sprintable"
        ],
        "README_content": "Waitress\n========\n\n.. image:: https://img.shields.io/pypi/v/waitress.svg\n    :target: https://pypi.org/project/waitress/\n    :alt: latest version of waitress on PyPI\n\n.. image:: https://github.com/Pylons/waitress/actions/workflows/ci-tests.yml/badge.svg\n    :target: https://github.com/Pylons/waitress/actions/workflows/ci-tests.yml\n\n.. image:: https://readthedocs.org/projects/waitress/badge/?version=stable\n        :target: https://docs.pylonsproject.org/projects/waitress/en/stable/\n        :alt: main Documentation Status\n\nWaitress is a production-quality pure-Python WSGI server with very acceptable\nperformance. It has no dependencies except ones which live in the Python\nstandard library. It runs on CPython on Unix and Windows under Python 3.9+. It\nis also known to run on PyPy 3 (version 3.9 compatible python and above) on\nUNIX. It supports HTTP/1.0 and HTTP/1.1.\n\nFor more information, see the \"docs\" directory of the Waitress package or visit\nhttps://docs.pylonsproject.org/projects/waitress/en/latest/\n",
        "num_commits": 1036,
        "project_age_days": 4700,
        "project_created_at": "2011-12-17",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-29",
        "num_contributors": 50,
        "num_pull": 206,
        "num_issues": 445,
        "num_opening_issue": 19,
        "project_size(kB)": 1778,
        "num_stargazers": 1442,
        "num_watchers": 1442,
        "num_forks": 165,
        "num_subscribers": 38,
        "SecurityPolicy_created_at": "2022-03-13 08:20:20",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "ab14abef44c69ff35e9b9cc58379a8c97c71eaf8",
                "url": "https://github.com/Pylons/.github/commit/ab14abef44c69ff35e9b9cc58379a8c97c71eaf8",
                "date": "2022-03-17 01:20:43"
            },
            {
                "commit_id": "a066e581a373c17e7a9ce58b215b2308272c940e",
                "url": "https://github.com/Pylons/.github/commit/a066e581a373c17e7a9ce58b215b2308272c940e",
                "date": "2022-03-16 05:35:12"
            },
            {
                "commit_id": "ce347b2da70eae5aad5c99c563e7835df4addb31",
                "url": "https://github.com/Pylons/.github/commit/ce347b2da70eae5aad5c99c563e7835df4addb31",
                "date": "2022-03-13 08:20:20"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": false
    },
    {
        "project_name": "ikus060/rdiffweb",
        "project_url": "https://github.com/ikus060/rdiffweb",
        "SSF": {
            "date": "2024-10-29T22:16:06+07:00",
            "repo": {
                "name": "github.com/ikus060/rdiffweb",
                "commit": "a96f583797b65a8f68d3780c1ed470c7989a56dc"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 3.5,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'master'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no pull request found",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 2,
                    "reason": "badge detected: InProgress",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "Found 0/30 approved changesets -- score normalized to 0",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: ikus software contributor org/company found, "
                    ],
                    "score": 3,
                    "reason": "project has 1 contributing companies or organizations -- score normalized to 3",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no workflows found",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Warn: no dependency update tool configurations found"
                    ],
                    "score": 0,
                    "reason": "no update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: GNU General Public License v3.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 2,
                    "reason": "3 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 2",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: containerImage not pinned by hash: Dockerfile:2",
                        "Warn: containerImage not pinned by hash: Dockerfile:24",
                        "Warn: pipCommand not pinned by hash: Dockerfile:20-22",
                        "Warn: pipCommand not pinned by hash: Dockerfile:25-29",
                        "Info:   0 out of   2 containerImage dependencies pinned",
                        "Info:   0 out of   2 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: no pull requests merged into dev branch"
                    ],
                    "score": 0,
                    "reason": "no SAST tool detected",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "No tokens found",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/ikus060/rdiffweb/contents/SECURITY.md",
        "SecurityPolicy_content": "# Reporting a Vulnerability\n\nIf you discover a security vulnerability in Rdiffweb please disclose it via [our huntr page](https://huntr.dev/repos/ikus060/rdiffweb). Bounty eligibility, CVE assignment, response times and past reports are all there.\n\nYou may alos contact-us directly by email `info@ikus-soft.com`\n\nThank you for improving the security of Rdiffweb.\n",
        "project_all_labels": [
            "bug",
            "cosmetic",
            "duplicate",
            "enhancement",
            "invalid",
            "question",
            "task",
            "wontfix"
        ],
        "README_content": "![Rdiffweb Banner](https://gitlab.com/ikus-soft/rdiffweb/-/raw/master/doc/_static/banner.png)\n\n<p align=\"center\">\n<strong>\n<a href=\"https://www.rdiffweb.org\">website</a>\n <a href=\"https://www.ikus-soft.com/archive/rdiffweb/doc/latest/html/\">docs</a>\n <a href=\"https://groups.google.com/d/forum/rdiffweb\">community</a>\n <a href=\"https://rdiffweb-demo.ikus-soft.com/\">demo</a>\n</strong>\n</p>\n\n<p align=\"center\">\n<a href=\"LICENSE\"><img alt=\"License\" src=\"https://img.shields.io/github/license/ikus060/rdiffweb\"></a>\n<a href=\"https://gitlab.com/ikus-soft/rdiffweb/pipelines\"><img alt=\"Build\" src=\"https://gitlab.com/ikus-soft/rdiffweb/badges/master/pipeline.svg\"></a>\n<a href=\"https://sonar.ikus-soft.com/dashboard?id=rdiffweb\"><img alt=\"Quality Gate Minarca Client\" src=\"https://sonar.ikus-soft.com/api/project_badges/measure?project=rdiffweb&metric=alert_status\"></a>\n<a href=\"https://sonar.ikus-soft.com/dashboard?id=rdiffweb\"><img alt=\"Coverage\" src=\"https://sonar.ikus-soft.com/api/project_badges/measure?project=rdiffweb&metric=coverage\"></a>\n<a href=\"https://bestpractices.coreinfrastructure.org/projects/6583\"><img src=\"https://bestpractices.coreinfrastructure.org/projects/6583/badge\"></a>\n</p>\n\n<h1 align=\"center\">\nWelcome to Rdiffweb\n</h1>\n\nRdiffweb is a web application that allows you to view repositories generated\nby [rdiff-backup](https://rdiff-backup.net/). The purpose of this\napplication is to ease the management of backups and quickly restore your data\nwith a rich and powerful web interface.\n\nRdiffweb is written in Python and is released as open source project under the\nGNU GENERAL PUBLIC LICENSE (GPL). All source code and documentation are\nCopyright Rdiffweb contributors.\n\nRdiffweb is actively developed by [IKUS Soft](https://www.ikus-soft.com/)\nsince November 2014.\n\nThe Rdiffweb source code is hosted on [Gitlab](https://gitlab.com/ikus-soft/rdiffweb)\nand mirrored to [Github](https://github.com/ikus060/rdiffweb).\n\nThe Rdiffweb website is <https://rdiffweb.org/>.\n\n## Features\n\nWith its rich web interface Rdiffweb provide a notable list of features:\n\n* Browse your backup\n* Restore single file or multiple files as an archived\n* Users authentication via local database and LDAP\n* Users authorization\n* Email notification when backup is not successful\n* Configurable repository encoding\n* Configurable retention period\n* Backup statistics visualization using graphs\n* SSH Keys management\n* Disk quota visualization\n* File and folder deletion\n\n## Demo\n\nIf you quickly want to check how Rdiffweb is behaving, you may try our demo server hosted on:\n\n[https://rdiffweb-demo.ikus-soft.com/](https://rdiffweb-demo.ikus-soft.com/)\n\nUse the following credential to login:\n\n* Username: admin\n* Password: admin123\n\n## Installation & Docker usage\n\nFor detailed installation steps, read the [Installation documentation](https://www.ikus-soft.com/archive/rdiffweb/doc/latest/html/installation.html).\n\n## Current Build Status\n\n[![Build Status](https://gitlab.com/ikus-soft/rdiffweb/badges/master/pipeline.svg)](https://gitlab.com/ikus-soft/rdiffweb/pipelines)\n\n## Download\n\nYou should read the [Documentation](https://www.ikus-soft.com/archive/rdiffweb/doc/latest/html/index.html) to properly install Rdiffweb in your environment.\n\n**Docker**\n\n    docker pull ikus060/rdiffweb\n\n**Debian**\n\n    apt install lsb-release\n    curl -L https://www.ikus-soft.com/archive/rdiffweb/public.key | gpg --dearmor > /usr/share/keyrings/rdiffweb-keyring.gpg\n    echo \"deb [arch=amd64 signed-by=/usr/share/keyrings/rdiffweb-keyring.gpg] https://nexus.ikus-soft.com/repository/apt-release-$(lsb_release -sc)/ $(lsb_release -sc) main\" > /etc/apt/sources.list.d/rdiffweb.list\n    apt update\n    apt install rdiffweb\n\n**Pypi**\n\n    pip install rdiffweb\n\n## Newsletter\n\nSubscribing to our newsletter is an effective way to stay up-to-date on the latest news about Rdiffweb.\nBy signing up for, you will receive regular updates and notifications about new features, updates, and releases related to Rdiffweb.\n\n[Rdiffweb Newsletter](https://rdiffweb.org/contactus).\n\n## Google Group\n\nJoin our growing community to get answers to your technical questions.\n\nRdiffweb users should use the [Rdiffweb Google Group](https://groups.google.com/forum/#!forum/rdiffweb).\n\n## Documentation\n\nWant to know more about Rdiffweb and learn it thoroughly? Read our complete documentation.\n\n[Rdiffweb Documentation](https://www.ikus-soft.com/archive/rdiffweb/doc/latest/html/).\n\n## Bug Reports\n\nBug reports should be reported on the Rdiffweb Gitlab at <https://gitlab.com/ikus-soft/rdiffweb/-/issues>\n\n## Professional support\n\nProfessional support for Rdiffweb is available by [contacting IKUS Soft](https://rdiffweb.org/contactus).\n\n## Support Us Through Github Sponsorship\n\nWe are passionate about developing and maintaining this open-source project to make it better with each update. Your support can help us continue our efforts and enhance the project for the entire community. By becoming a Github Sponsor, you directly contribute to the project's sustainability and growth.\n\n[Becoming a Sponsor](https://github.com/sponsors/ikus060)\n\n# Changelog\n\n## 2.9.2 (2024-07-03)\n\n* Use default language to send notification if user doesn't have a \"Preferred Language\" #306\n\n## 2.9.1 (2024-06-11)\n\n* Add \"Preferred Language\" to Admin view to allow administrator to update the value\n* Improve DockerImage by removing cache files\n* Upgrade rdiff-backup to v2.2.6 in DockerFile\n\n## 2.9.0 (2024-04-22)\n\n* Add API entry point to create and list access token\n* Add access token scope #298\n* Add user's quota to Rdiffweb API #299\n* Change Debian and Ubuntu version numbering\n* Drop support for Debian Buster\n\n## 2.8.9 (2023-02-19)\n\n* Fix display of page settings for user with role \"user\"\n\n## 2.8.8 (2023-01-08)\n\n* Fix usage of `session-idle-timeout` in config file #296\n\n## 2.8.7 (2024-01-04)\n\n* Adjust the session idle and absolute timeouts to 10 and 30 minutes, respectively.\n* Fix date calculation when generating report in January #295\n\n## 2.8.6 (2023-11-24)\n\n* Fix broken URL to <https://ikus-soft.com>\n* Fix \"Remember me\" check box to allow cliking on label to ease usability #293\n* Fix translation of backup status in email report #291\n* Adding German translation file - credit to [Michael Nitzsche](https://github.com/einzelfabrik)\n\n## 2.8.5 (2023-10-10)\n\n* Fix reported version in Debian package #289\n* Add support for WTForms v3.1.0\n* Add last backup date to email notification\n\n## 2.8.4 (2023-09-29)\n\n* Add ratelimit to Access Token, SSH Keys and User creation [CVE-2023-5289](https://nvd.nist.gov/vuln/detail/CVE-2023-5289)\n\n## 2.8.3 (2023-08-22)\n\n* Drop support of Ubuntu Kinetic\n\n## 2.8.2 (2023-08-22)\n\n* Add Ubuntu Mantic Support\n* Use Multi-Step to build Docker image\n* Update layout of file statistics to display a single day\n* Stop sending notification for ignored days #284\n* Handle warning exit code 2 return by rdiff-backup version 2.2\n\n## 2.8.1 (2023-08-01)\n\n* Pin version of selenium to v4.10\n\n## 2.8.0 (2023-07-31)\n\n* Log detailed error message when restore command failed to help debugging\n* Update interface used to manage users to be more user friendly #237\n* Disable Disk Quota in users view when quota command is not configured #237\n* Hide LDAP label in users view when LDAP is not configured #237\n* Allow administrator to change user's reporting preferences\n* Add support for Ubuntu Lunar\n* Add support for SQLAlchemy v2.0 for forward compatibility\n* When reaching 100% disk usage, show quota in red to improve visibility\n* Send notification when user's quota reach 90% #46\n* Add ratelimit to \"send me a status report\" to avoid email flooding #272 - credit to [Nehal Pillai](https://www.linkedin.com/in/nehal-pillai-02a854172)\n* Fix creation of access token with expiration time #277\n* Allow user to disable notification for selected day of week #278\n* Add detailed file statistics to show created, modified and deleted files #103\n* Trim spaces on verification code to improve usability #279\n* Determine default username when user get redirected to login page #283\n* Sort repository by dates in administration view #282\n* Document how to configure fail2ban to improve server hardening\n* Document how to configure certbot for automatic SSL certificate generation\n* Update installation steps to include `arch=amd64`\n* Update french translation\n\n## 2.7.1 (2023-04-27)\n\n* Fix encoding problem with older Outlook 2007 client #273\n\n## 2.7.0 (2023-04-20)\n\n* Support Python 3.11\n* Provide a Monthly, Weekly or Daily repport for user #71\n* Fix MFA verification code email's subjet #270\n* Add translation for footer not in email layout\n* Send email to administrator when a new version is available #266\n* Improve automatic testing\n\n## 2.6.1 (2023-03-22)\n\n* Refused to start if `rdiff-backup` executable is not found #267\n\n## 2.6.0 (2023-03-15)\n\n* Review the application layout to use Fluid container to use all the space available on the screen\n* Rename status view to Dashboard\n* Display more useful data in Dashboard view: Backups per days, Oldest backup, Storage Usage, Average duration, Least Active, Most active\n* Fix deletion confirmation of repositories within subdirectory #250\n* Properly clean-up plain text email from HTML tags\n* Send notification for inactive backup based on statistics\n* Send notification using a new template following the web interface branding\n* Send notification to user when repository get added or removed\n* Send all notification to an optional \"catch-all\" email address configured using `--email-catch-all` option #258\n* Redistribute logos in PNG format for better compatibility\n* Disable error page logs for 4xx errors\n* Add username and IP address to logs only for HTTP Request\n* Fix LDAP integration to support non-list attributes - credit to [Shane Robinson](https://gitlab.com/shanesq)\n* Add support of multiple required-group for LDAP integration\n* Improve System Logs view to identify \"User Activity\", \"Threats\" and \"User Login\"\n* Fix display of \"* minutes ago\" #264\n* Add `default-lang` option to configure default language #263\n* Allow user to select a preferred language #263\n* Use user's preferred language when sending notifications #263\n\n## 2.5.8 (2023-02-19)\n\n* Support Setuptools v66 for compatibility with Debian Bookworm\n* Fix execution of rdiffweb remove-older job to clean-up repository history #262\n\n## 2.5.7 (2023-01-27)\n\n* Enforce SQLAlchemy version between 1.2 or 1.4\n\n## 2.5.6 (2023-01-11)\n\n* Fixed display of Hamburger menu on mobiles (minarca#192)\n* Change wording for interupted backup\n\n## 2.5.5 (2022-12-23)\n\n* Fix loading of Charts in Status page\n* Ensure Gmail and other mail client doesn't create hyperlink automatically for any nodification sent by Rdiffweb to avoid phishing - credit to [Nehal Pillai](https://www.linkedin.com/in/nehal-pillai-02a854172)\n* Sent email notification to user when a new SSH Key get added - credit to [Nehal Pillai](https://www.linkedin.com/in/nehal-pillai-02a854172)\n* Ratelimit \"Resend code to my email\" in Two-Factor Authentication view - credit to [Nehal Pillai](https://www.linkedin.com/in/nehal-pillai-02a854172)\n* Username are not case-insensitive - credits to [raiders0786](https://www.linkedin.com/in/chirag-agrawal-770488144/)\n* Make sure that all ssh keys are unique, regardless of the user - credit to [Nehal Pillai](https://www.linkedin.com/in/nehal-pillai-02a854172)\n* Disable translation caching\n\nBreaking changes:\n\n* Username with different cases (e.g.: admin vs Ammin) are not supported. If your database contains such username make sure to remove them before upgrading otherwise Rdiffweb will not start.\n\n## 2.5.4 (2022-12-19)\n\n* Discard `X-Forwarded-Host` headers credit to [Anishka Shukla](https://github.com/anishkashukla)\n* Create proper symbolic link of `chartkick.js` on Ubuntu Jammy to fix loading of Charts in web interface\n* Add CSRF verification on `/logout` credits to [reza.duty](https://rezaduty.me)\n\n## 2.5.3 (2022-12-05)\n\n* Add support for WTForms v3 to support Debian Bookworm\n* Fix strange behavior in access token management #247\n\n## 2.5.2 (2022-11-28)\n\n* Block repository access when user_root directory is empty or relative path [CVE-2022-4314](https://nvd.nist.gov/vuln/detail/CVE-2022-4314) credit to [neverjunior](https://github.com/neverjunior)\n* Replace admin password only when `--admin-password` option is provided #246\n* Invalidate browser cache for `logo`, `headerlogo` and `favicon` on restart #245\n\n## 2.5.1 (2022-11-11)\n\n* Add support for Ubuntu Kinetic #240\n* Disable filesize for deleted files to improve page loading #241\n\n## 2.5.0 (2022-11-09)\n\nThis next release focus on two-factor-authentication as a measure to increase security of user's account.\n\n* Store User's session information into database\n* Update ldap plugin to load additional attributes from LDAP server\n* Improve `/status` page error handling when `session_statistics` cannot be read\n* Add support for Ubuntu Jammy\n* Upgrade from Bootstrap v3 to v4 #204\n* Replace Fontello by Font-Awesome v4\n* Use CSS variables `var()` to customize themes using `--branding-X` options #239\n* Remove usage of Jquery.validate\n* Replace custom timsort by jquery DataTables #205\n* Add Active Session managements #203\n  * Active session should be visible in user's profiles\n  * Active session may be revoked by user\n  * Active session should be visible in administration view\n  * Action session may be revoke by administrator\n  * Show number of active users within the last 24 hours in dashboard\n* Handle migration of older Rdiffweb database by adding the missing `repos.Encoding`, `repos.keepdays` and `users.role` columns #185\n* Replace deprecated references of `disutils.spawn.find_executable()` by `shutil.which()` #208\n* Add two-factor authentication with email verification #201\n* Generate a new session on login and 2FA #220\n* Enforce permission on /etc/rdiffweb configuration folder\n* Enforce validation on fullname, username and email\n* Limit incorrect attempts to change the user's password to prevent brute force attacks #225 [CVE-2022-3273](https://nvd.nist.gov/vuln/detail/CVE-2022-3273) credit to [Nehal Pillai](https://www.linkedin.com/in/nehal-pillai-02a854172)\n* Enforce password policy new password cannot be set as new password [CVE-2022-3376](https://nvd.nist.gov/vuln/detail/CVE-2022-3376) credit to [Nehal Pillai](https://www.linkedin.com/in/nehal-pillai-02a854172)\n* Enforce better rate limit on login, mfa, password change and API [CVE-2022-3439](https://nvd.nist.gov/vuln/detail/CVE-2022-3439) [CVE-2022-3456](https://nvd.nist.gov/vuln/detail/CVE-2022-3456) credit to [Nehal Pillai](https://www.linkedin.com/in/nehal-pillai-02a854172)\n* Enforce 'Origin' validation [CVE-2022-3457](https://nvd.nist.gov/vuln/detail/CVE-2022-3457) credit to [Nithissh12](Nithissh12)\n* Define idle and absolute session timeout with agressive default to protect usage on public computer [CVE-2022-3327](https://nvd.nist.gov/vuln/detail/CVE-2022-3327) credit to [Nehal Pillai](https://www.linkedin.com/in/nehal-pillai-02a854172)\n* Send email notification when enabling or disabling MFA [CVE-2022-3363](https://nvd.nist.gov/vuln/detail/CVE-2022-3363) credit to [Nehal Pillai](https://www.linkedin.com/in/nehal-pillai-02a854172)\n* Use Argon2id to store password hash #231\n* Fixed plugin priorities to ensure that jobs are scheduled at each startup #232\n* Revoke previous user's sessions on password change [CVE-2022-3362](https://nvd.nist.gov/vuln/detail/CVE-2022-3362) credit to [Nehal Pillai](https://www.linkedin.com/in/nehal-pillai-02a854172)\n\nBreaking changes:\n\n* Drop Ubuntu Hirsute & Impish (End-of-life)\n* `session-dir` is deprecated and should be replace by `rate-limit-dir`. User's session are stored in database.\n* previous `.css` customization are not barkward compatible. Make usage of the `--branding-X` options.\n\n**Thanks to [Nehal Pillai](https://www.linkedin.com/in/nehal-pillai-02a854172) with whom I collaborate to improve the security of this project.**\n\n## 2.4.10 (2022-10-03)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Mitigate path traversal vulnerability [CVE-2022-3389](https://nvd.nist.gov/vuln/detail/CVE-2022-3389) credit to [Hoang Van Hiep](https://www.linkedin.com/in/hiephv2410/)\n\n## 2.4.9 (2022-09-28)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Add `Cache-Control` and other security headers [CVE-2022-3292](https://nvd.nist.gov/vuln/detail/CVE-2022-3292) credit to [Nehal Pillai](https://www.linkedin.com/in/nehal-pillai-02a854172)\n* Enforce password policy using `password-score` based on [zxcvbn](https://github.com/dropbox/zxcvbn) [CVE-2022-3326](https://nvd.nist.gov/vuln/detail/CVE-2022-3326) credit to [Nehal Pillai](https://www.linkedin.com/in/nehal-pillai-02a854172)\n\n## 2.4.8 (2022-09-26)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Clean-up invalid path on error page\n* Limit username field length [CVE-2022-3290](https://nvd.nist.gov/vuln/detail/CVE-2022-3290) credit to [Nehal Pillai](https://www.linkedin.com/in/nehal-pillai-02a854172)\n* Limit user's email field length [CVE-2022-3272](https://nvd.nist.gov/vuln/detail/CVE-2022-3272) credit to [Nehal Pillai](https://www.linkedin.com/in/nehal-pillai-02a854172)\n* Limit user's root directory field length [CVE-2022-3295](https://nvd.nist.gov/vuln/detail/CVE-2022-3295) credit to [Nehal Pillai](https://www.linkedin.com/in/nehal-pillai-02a854172)\n* Limit SSH Key title field length [CVE-2022-3298](https://nvd.nist.gov/vuln/detail/CVE-2022-3298) credit to [Nehal Pillai](https://www.linkedin.com/in/nehal-pillai-02a854172)\n\n## 2.4.7 (2002-09-21)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Generate a new session on login and 2FA #220 [CVE-2022-3269](https://nvd.nist.gov/vuln/detail/CVE-2022-3269) credit to [Ambadi MP](https://www.linkedin.com/in/ambadi-m-p-16a95217b/)\n* Mitigate CSRF on user's settings #221 [CVE-2022-3274](https://nvd.nist.gov/vuln/detail/CVE-2022-3274) credit to [irfansayyed](https://github.com/irfansayyed-github)\n\n## 2.4.6 (2022-09-20)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Support MarkupSafe<3 for Debian bookworm\n* Mitigate CSRF on user's notification settings #216 [CVE-2022-3233](https://nvd.nist.gov/vuln/detail/CVE-2022-3233) credit to [Ambadi MP](https://www.linkedin.com/in/ambadi-m-p-16a95217b/)\n* Mitigate CSRF on repository settings #217 [CVE-2022-3267](https://nvd.nist.gov/vuln/detail/CVE-2022-3267) credit to [irfansayyed](https://github.com/irfansayyed-github)\n* Use 'Secure' Attribute with Sensitive Cookie in HTTPS Session on HTTP Error #218 [CVE-2022-3174](https://nvd.nist.gov/vuln/detail/CVE-2022-3174) credit to [Chuu](https://github.com/uonghoangminhchau)\n\n## 2.4.5 (2002-09-16)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Mitigate CSRF on repository deletion and user deletion [CVE-2022-3232](https://nvd.nist.gov/vuln/detail/CVE-2022-3232) #214 #215 credit to [Ambadi MP](https://www.linkedin.com/in/ambadi-m-p-16a95217b/)\n\n## 2.4.4 (2002-09-15)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Use `X-Real-IP` to identify client IP address to mitigate Brute-Force attack #213\n\n## 2.4.3 (2022-09-14)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Mitigate CSRF in profile's SSH Keys [CVE-2022-3221](https://nvd.nist.gov/vuln/detail/CVE-2022-3221) #212 credit to [Ambadi MP](https://www.linkedin.com/in/ambadi-m-p-16a95217b/)\n\n## 2.4.2 (2022-09-12)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Use 'Secure' Attribute with Sensitive Cookie in HTTPS Session. [CVE-2022-3174](https://nvd.nist.gov/vuln/detail/CVE-2022-3174) #209 credit to [Chuu](https://github.com/uonghoangminhchau)\n* Avoid leakage of the stack trace in the default error page. [CVE-2022-3175](https://nvd.nist.gov/vuln/detail/CVE-2022-3175) #210 credit to [Chuu](https://github.com/uonghoangminhchau)\n* Enforce minimum and maximum password length [CVE-2022-3175](https://nvd.nist.gov/vuln/detail/CVE-2022-3179) #211 credit to [Chuu](https://github.com/uonghoangminhchau)\n\n## 2.4.1 (2022-09-08)\n\nThis releases include a security fix. If you are using an earlier version, you should upgrade to this release immediately.\n\n* Add Clickjacking Defense [CVE-2022-3167](https://nvd.nist.gov/vuln/detail/CVE-2022-3167) credit to [tharunavula](https://github.com/tharunavula)\n* Drop Ubuntu Hirsute & Impish (End-of-life)\n\n## 2.4.0 (2022-06-21)\n\nThis new release brings a lot of improvement since the last version, multiple bug fixes\nto make the application stable. A couple of new features to improve the overall\nusability and a new security feature to block a brute force attack.\n\n* Add RateLimit to login page and API to mitigate robots attacks #167\n* Send email notification only if `email-sender` option is defined to avoid raising exception in logs #176\n* Support file restore cancellation without leaving `rdiffweb-restore` process in `<defunct>` state #174\n* Replace `python-ldap` by `ldap3` a pure python implementation to avoid dependencies on `sasl` and `ldap` binaries #186\n* Reffactor core module to allow better extendability and reusability #183\n* Add support for Debian Bookworm #180\n* Add support for Ubuntu Impish #175\n* Add rdiff-backup version to administration view\n* Run unit test during Debian build package\n* Refresh repository list automatically when required #188 #189\n* Fix error 500 displayed in status page #191\n* Improve repository browsing speed by minimizing the number of I/O call #192\n* Publish Docker image directly to DockerHub #144\n* Add REST API to manage sshkeys\n\nBreaking changes:\n\n* Ldap Password changes is not supported anymore.\n* Ldap Check Shadow expire config is not supported anymore. It should be replace by a custom filter.\n* Drop CentOS 7 and CentOS 8 support\n\n## 2.3.9 (2022-01-05)\n\nMaintenance release to fix minor issues\n\n* Improve date parsing for `backup.log` to avoid printing exception in logs #170\n* Return HTTP error 403 for invalid symlink to avoid returning a misleading HTTP 500 Server Error #168\n* Show a user friendly error message when trying to create a new user with an existing username #169\n* Handle repository without last-backup date during the notification process to ensure notifications are sent #171\n* Replace CherryPy `storage_type` by `storage_class` to avoid warning in logs\n* Update code to avoid deprecation warning where applicable\n* Add Flake8 validation to improve code quality\n* Remove Ubuntu Groovy support\n\n## 2.3.8 (2021-12-01)\n\n* Push all artefacts to nexus server including binaries and documentation\n* Fix `Chart.js` loading on Debian bullseye #164\n* Update installation steps documentation\n* Improve LDAP authentication to lookup entire directory\n* Fix usage of `--ldap-add-user-default-userroot` to avoid error related to wrong encoding\n* Improve authentication mechanics\n* Avoid raising an HTTP error 500 when login form receive invalid payload\n* Mitigate open redirect vulnerability in login form\n\n## 2.3.7 (2021-10-21)\n\n* To avoid backward compatibility issue, revert CSRF Token validation\n* Mitigate CSRF vulnerability using cookies with `SameSite=Lax`\n* Mitigate CSRF vulnerability by validating the `Origin` header when a form is submited\n* Improve usage of WTForm for all form validation\n* Update installation stepd for debian #162\n* Build Ubuntu packages and publish them to our APT repo\n\n## 2.3.6 (2021-10-20)\n\n* Broken build\n\n## 2.3.5 (2021-10-18)\n\n* Mitigate CSRF vulnerability to user, ssh and repo management with CSRF Token\n\n## 2.3.4 (2021-09-20)\n\n* Skip email notification if `email-host` configuration is not provided #157\n* Skip email notification when the new attribute value has the same value #159\n* USE LDAP `mail` attribute when creating new user from LDAP directory #156\n\n## 2.3.3 (2021-09-10)\n\n* Provide a new theme `blue` to match IKUS Soft colors #158\n\n## 2.3.2 (2021-09-07)\n\n* Automatically update user's repository list based on user's home directory\n\n## 2.3.1 (2021-07-14)\n\n* Update default `session-dir` location to `/var/lib/rdiffweb/session` to avoid using `/var/run` #148\n\n## 2.3.0 (2021-07-06)\n\n* Improve timezone handling to display date with local timezone using javascript #143\n* Improve charts by replacing d3js by chartkick #122\n* Replace the status view by something meaningful with chartkick #122\n* Provide Docker image with Rdiffweb `docker pull ikus060/rdiffweb` #55\n* Fix file and folder sorting #143\n\n## 2.2.0 (2021-05-11)\n\n* Debian package:\n  * Add rdiff-backup as dependencies to comply with Debian packaging rules\n  * Multiple other fixed to control files\n  * Use debhelper-compat (= 13)\n  * Use debhelper-compat (= 13)\n  * Run test during packaging\n  * Create default folder `/var/run/rdiffweb/sessions` to store user session\n* Use ConfigArgPare for configuration to support configuration file, environment variables and arguments to configure rdiffweb #114\n* Fix cache in localization module\n* Add `ldap-add-default-role` and `ldap-add-default-userroot` option to define default value for role and user root when creating user from LDAP #125\n* Support PostgreSQL database by replacing our storage layer by SQLAlchemy #126\n* Fix to retrieve user quota only for valid user_root #135\n* Add option `disable-ssh-keys` to disable SSH Key management\n* Use absolute URL everywhere\n* Add support for `X-Forwarded-For`, `X-Forwarded-proto` and other reverse proxy header when generating absolute URL\n* Drop Debian Stretch support\n* Implement a new background scheduler using apscheduler #82\n* Use background job to send email notification to avoid blocking web page loading #47\n* Use background job to delete repository to avoid blocking web page loading #48\n* Allow deleting a specific file or folder from the history using `rdiff-backup-delete` #128\n* Improve support for `session-dir` #131\n* Add option `admin-password` to define administrator password for better security\n* Improve performance of repository browsing\n* Add a new view to display logs of a specific repository\n* Allow downloading the log\n* Define a default limit to graph statistics to make it display faster\n* Fix `get-quota-cmd` option to properly return a value\n\n## 2.1.0 (2021-01-15)\n\n* Debian package: Remove dh-systemd from Debian build dependencies (<https://bugs.debian.org/871312we>)\n* Improve Quota management:\n  * `QuotaSetCmd`, `QuotaGetCmd` and `QuotaUsedCmd` options could be used to customize how to set the quota for your environment.\n  * Display user's quota in User View\n  * Display user's quota in Admin View\n  * Allow admin to update user quota from Admin View when `QuotaSetCmd` is defined.\n  * Allow admin to define user quota using human readable value (e.g.: GiB, TiB, etc.)\n  * Improve logging around quota management\n* Improve robustness when service is starting\n* Improve robustness when repository has wrong permission defined (e.g.: when some files not readable)\n* Add user id in Admin view\n* Replace `UserObject(1)` by the actual username in log file to improve debugging\n\n## 2.0.0 (2020-12-04)\n\n* Re-implement logic to update repositories views to remove duplicates and avoid nesting repo. #107\n* Handle elapsed time of days in the graph. Thanks [Nathaniel van Diepen](https://github.com/Eeems) contributions.\n* Rebrand all link to ikus-soft.com\n* Update documentation to install rdiffweb\n* Remove obsolete minify dependency\n* Drop support for python2\n* Provide null translation if translation catalogues are not found\n* Pass a LANG environment variable to rdiff-backup restore process to fix encoding issue #112\n* Remove obsolete python shebang\n* Remove execution bit (+x) on python modules\n* Provide `--help` and `--version` on `rdiffweb` executable\n* Improve cherrypy version detection\n* Do not update translation files (.mo) during build\n\n## 1.5.0 (2020-06-24)\n\nThis minor release introduce official support of rdiffweb on Debian Bullseye. It also includes some usability improvements.\n\n* Change formatting of Last Backup date for \"Updated 3 weeks ago\" to ease the readability\n* Add support for Debian Bullseye\n* Add support for Python 3.8 (#104)\n* Add warning in the users list view when a root directory is invalid (#30)\n* Add options to control search depthness (#1)\n* Print a warning in the log when the \"DefaultTheme\" value is not valid (#90)\n\n## 1.4.0 (2020-05-20)\n\nThanks to our sponsor, this release introduce a feature to have better control over the user's permission by defining 3 different levels of privilege: Admin, Maintainer and User. This addition allows you to have better control on what your users can or can't do.\n\n* Fix single repository discovery when a user's home is a rdiff-backup repository\n* [SPONSORED] Add a new setting at the user level to define the user's role. Admin,\n   Maintainer and User. Admin are allowed to do everything. Maintainer are\n   allow to browse and delete repo. Users are only allowed to browse. #94\n* Add \"Powered by\" in the web interface footer #91\n* Display a nice error message when trying to delete admin user #93\n* Introduce usage of wtforms and flash in admin users for better form validation. #96 #97\n* Update French translation\n\n## 1.3.2 (2020-04-23)\n\nThis minor releases fixed issues found while testing release 1.3.0.\n\n* Fix lookup of executable rdiff-backup and rdiffweb-restore to search in current virtualenv first\n* Fix repository view when multiple repo path are conflicting\n* Fix logging of rdiffweb-restore subprocess\n\n## 1.3.1 (2020-04-10)\n\nThis minor release enforces security of the password stored in rdiffweb database to make use of a better encryption using SSHA.\nOnly new passwords will make use of the SSHA scheme.\n\n* Enforce password encryption by using SSHA scheme #88\n\n## 1.3.0 (2020-04-07)\n\nThis release focuses on improving the restore of big archives. The download should be much faster to start. Major enhancement was made to offload the processing outside the web server. And all of this is still compatible with rdiff-backup v1.2.8 and the latest v2.0.0.\n\n* Restore file and folder in a subprocess to make the download start faster\n* Fix encoding of archive on Python3.6 (CentOS 7) by using PAX format\n* Add support to restore files and folders using rdiff-backup2\n* Remove obsolete dependencies `pysqlite2`\n* Fix issue creating duplicate entries of repository in the database\n\n## 1.2.2 (2020-03-05)\n\nThis release provides little improvement to the v1.2.x including official support of rdiff-backup v2.0.0.\n\n* Enhance the repository to invite users to refresh the repository when the view is empty.\n* Support rdiff-backup v2.0.0\n* Deprecate support for cherrypy 4, 5, 6 and 7\n* Improve loading of repository data (cache status and entries)\n* Restore compatibility with SQLite 3.7 (CentOS7)\n\nKnown issues:\n\n* Filename encoding in tar.gz and zip file might not be accurate if you are running Python 3.6 (CentOS7)\n\n## 1.2.1 (2020-02-08)\n\nLittle bug fix following the previous release\n\n* Fix 404 error when trying to access other users repo as admin\n* Fix logging format for cherrypy logs to matches rdiffweb format\n* Add log rotation by default\n\n## 1.2.0 (2020-01-30)\n\nThis release focus on improving the database layers for better extendability to add more type of data and to support more databases backend like postgresql in the near future.\n\n* Add explicit testing for Debian Stretch & Buster\n* Change the persistence layers\n  * Minimize number of SQL queries\n  * Add object lazy loading\n  * Add object data caching\n* Fix bugs with SQLite <= 3.16 (Debian Stretch)\n\n## 1.1.0 (2019-10-31)\n\nThis release focus on improving the admin area and building the fundation for repository access control list (ACL).\n\n* Update documentation from PDSL web site\n* Improve the navigation bar layout\n* Update the login page headline\n* Update jinja2 version to allow 2.10.x\n* Show server log in admin area\n* Reduce code smell\n* Add System information in admin area\n* Validate credential using local database before LDAP\n* Reffactoring templates macros\n* Enhance user's view search bar\n* Change repository URL to username/repopath\n* Add System information in admin area\n* Improve testcases\n* Clean-up obsolete code\n* Fix issue with captital case encoding name\n* Fix compilation of less files\n* Fix google font import\n\n## 1.0.3 (2019-10-04)\n\n* Removing the auto update repos\n\n## 1.0.2 (2019-10-01)\n\n* Create \"admin\" user if missing\n* Update french translation\n\n## 1.0.1 (2019-09-22)\n\n* Update installation documentation\n* Fix removal of SSH Key\n* Return meaningful error to the user trying to add an existing SSH key\n\n## 1.0.0 (2019-09-11)\n\n* Make repository removal more robust\n* Improve performance of librdiff\n* Add new RESTful api\n* Return the right HTTP 401 or 402 error code for authentication\n* Fix bug introduce by upgrade to Jinja2 + python3\n* Store ssh keys in database and disk\n* Add support for theme (default, orange)\n* Remove deprecated profiling code\n* Add disk usage support / quota\n* Add support of cherrypy v18\n* Drop support of cherrypy v3.2.2\n* Add wsgi entry point\n* Replace the plugins architecture to ease implementation\n* Numerous bug fixes\n\n## 0.10.9 (2019-05-22)\n\n* Better error handling when error.log file are not valid gzip file\n",
        "num_commits": 1544,
        "project_age_days": 4390,
        "project_created_at": "2012-10-22",
        "latest_updated_at": "2024-10-24",
        "latest_pushed_at": "2024-10-25",
        "num_contributors": 7,
        "num_pull": 18,
        "num_issues": 18,
        "num_opening_issue": 1,
        "project_size(kB)": 25768,
        "num_stargazers": 122,
        "num_watchers": 122,
        "num_forks": 28,
        "num_subscribers": 17,
        "SecurityPolicy_created_at": "2021-09-20 11:56:06",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "c8d69ce2e46f6d9d2852d062e400934e32fe3ed1",
                "url": "https://github.com/ikus060/rdiffweb/commit/c8d69ce2e46f6d9d2852d062e400934e32fe3ed1",
                "date": "2022-09-14 15:40:22"
            },
            {
                "commit_id": "54c343c72c19ab1261b3ffdd2bb26d458c3f207c",
                "url": "https://github.com/ikus060/rdiffweb/commit/54c343c72c19ab1261b3ffdd2bb26d458c3f207c",
                "date": "2021-09-20 11:56:06"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "spotipy-dev/spotipy",
        "project_url": "https://github.com/spotipy-dev/spotipy",
        "SSF": {
            "date": "2024-10-30T00:15:44+07:00",
            "repo": {
                "name": "github.com/spotipy-dev/spotipy",
                "commit": "db3fb9a5eea6e7c48c716fa554d497a12a78b677"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.9,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Warn: required approving review count is 1 on branch 'master'",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Warn: no status checks found to merge onto branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 6,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 9,
                    "reason": "20 out of 21 merged PRs checked by a CI test -- score normalized to 9",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 8,
                    "reason": "Found 17/21 approved changesets -- score normalized to 8",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: mps-youtube contributor org/company found, spotipy-dev contributor org/company found, cycle148hki contributor org/company found, ultrajson contributor org/company found, endoflife-date contributor org/company found, cu-unofficial contributor org/company found, unitedstates contributor org/company found, python-twitter-tools contributor org/company found, spotify contributor org/company found, mirrorfm contributor org/company found, python contributor org/company found, python-pillow contributor org/company found, NaPoGenMo contributor org/company found, AdventOfVim contributor org/company found, echonest contributor org/company found, pytest-dev contributor org/company found, whyaretheflagsup contributor org/company found, WahKazoo contributor org/company found, deadsetbit contributor org/company found, ShazamScrobbler contributor org/company found, WormsSpeedrunning contributor org/company found, NaNoGenMo contributor org/company found, flake8-implicit-str-concat contributor org/company found, rust-lang-nursery contributor org/company found, termcolor contributor org/company found, musicleague @hashicorp contributor org/company found, openPMD contributor org/company found, jazzband contributor org/company found, citybikes contributor org/company found, nordsoftware contributor org/company found, resident-archive contributor org/company found, radiopy contributor org/company found, fatiando contributor org/company found, pylast contributor org/company found, mobbler contributor org/company found, python-humanize contributor org/company found, helsinki-python contributor org/company found, hashicorp contributor org/company found, rust-lang contributor org/company found, spotDL contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 40 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE.md:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE.md:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "1 commit(s) and 13 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/publish.yml:11"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/integration_tests.yml:14: update your workflow using https://app.stepsecurity.io/secureworkflow/spotipy-dev/spotipy/integration_tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/integration_tests.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/spotipy-dev/spotipy/integration_tests.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:16: update your workflow using https://app.stepsecurity.io/secureworkflow/spotipy-dev/spotipy/publish.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/spotipy-dev/spotipy/publish.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish.yml:37: update your workflow using https://app.stepsecurity.io/secureworkflow/spotipy-dev/spotipy/publish.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pull_request.yml:11: update your workflow using https://app.stepsecurity.io/secureworkflow/spotipy-dev/spotipy/pull_request.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pull_request.yml:12: update your workflow using https://app.stepsecurity.io/secureworkflow/spotipy-dev/spotipy/pull_request.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pythonapp.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/spotipy-dev/spotipy/pythonapp.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/pythonapp.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/spotipy-dev/spotipy/pythonapp.yml/master?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/integration_tests.yml:21",
                        "Warn: pipCommand not pinned by hash: .github/workflows/integration_tests.yml:22",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish.yml:23",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pythonapp.yml:20",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pythonapp.yml:21",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pythonapp.yml:24",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pythonapp.yml:25",
                        "Info:   0 out of   7 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   2 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   7 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 29 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: .github/SECURITY.md:1",
                        "Info: Found linked content: .github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: .github/SECURITY.md:1",
                        "Info: Found text in security policy: .github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/integration_tests.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/pull_request.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/pythonapp.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/spotipy-dev/spotipy/contents/.github/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Supported Versions\n\n| Version | Supported          |\n| ------- | ------------------ |\n| 2.x     | :white_check_mark: |\n| 1.x     | :x:                |\n\n## Reporting a Vulnerability\n\nReport via https://github.com/spotipy-dev/spotipy/security/advisories.\n\nGuidance: https://docs.github.com/en/code-security/security-advisories/guidance-on-reporting-and-writing/privately-reporting-a-security-vulnerability.\n",
        "project_all_labels": [
            "api-bug",
            "bug",
            "cannot-reproduce",
            "dependencies",
            "documentation",
            "duplicate",
            "enhancement",
            "external-ide",
            "hacktoberfest-accepted",
            "headless-mode",
            "implicit-grant-flow",
            "invalid",
            "missing-endpoint",
            "pr-welcome",
            "private-api",
            "question",
            "spotipy3",
            "wontfix"
        ],
        "README_content": "# Spotipy\n\n##### Spotipy is a lightweight Python library for the [Spotify Web API](https://developer.spotify.com/documentation/web-api). With Spotipy you get full access to all of the music data provided by the Spotify platform.\n\n![Integration tests](https://github.com/spotipy-dev/spotipy/actions/workflows/integration_tests.yml/badge.svg?branch=master) [![Documentation Status](https://readthedocs.org/projects/spotipy/badge/?version=master)](https://spotipy.readthedocs.io/en/latest/?badge=master) [![Discord server](https://img.shields.io/discord/1244611850700849183?style=flat&logo=discord&logoColor=7289DA&color=7289DA)](https://discord.gg/HP6xcPsTPJ)\n\n## Table of Contents\n\n- [Features](#features)\n- [Installation](#installation)\n- [Quick Start](#quick-start)\n- [Reporting Issues](#reporting-issues)\n- [Contributing](#contributing)\n\n## Features\n\nSpotipy supports all of the features of the Spotify Web API including access to all end points, and support for user authorization. For details on the capabilities you are encouraged to review the [Spotify Web API](https://developer.spotify.com/web-api/) documentation.\n\n## Installation\n\n```bash\npip install spotipy\n```\n\nalternatively, for Windows users \n\n```bash\npy -m pip install spotipy\n```\n\nor upgrade\n\n```bash\npip install spotipy --upgrade\n```\n\n## Quick Start\n\nA full set of examples can be found in the [online documentation](http://spotipy.readthedocs.org/) and in the [Spotipy examples directory](https://github.com/plamere/spotipy/tree/master/examples).\n\nTo get started, [install spotipy](#installation), create a new account or log in on https://developers.spotify.com/. Go to the [dashboard](https://developer.spotify.com/dashboard), create an app and add your new ID and SECRET (ID and SECRET can be found on an app setting) to your environment ([step-by-step video](https://www.youtube.com/watch?v=kaBVN8uP358)):\n\n### Example without user authentication\n\n```python\nimport spotipy\nfrom spotipy.oauth2 import SpotifyClientCredentials\n\nsp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=\"YOUR_APP_CLIENT_ID\",\n                                                           client_secret=\"YOUR_APP_CLIENT_SECRET\"))\n\nresults = sp.search(q='weezer', limit=20)\nfor idx, track in enumerate(results['tracks']['items']):\n    print(idx, track['name'])\n```\nExpected result:\n```\n0 Island In The Sun\n1 Say It Ain't So\n2 Buddy Holly\n.\n.\n.\n18 Troublemaker\n19 Feels Like Summer\n```\n\n\n### Example with user authentication\n\nA redirect URI must be added to your application at [My Dashboard](https://developer.spotify.com/dashboard/applications) to access user authenticated features.\n\n```python\nimport spotipy\nfrom spotipy.oauth2 import SpotifyOAuth\n\nsp = spotipy.Spotify(auth_manager=SpotifyOAuth(client_id=\"YOUR_APP_CLIENT_ID\",\n                                               client_secret=\"YOUR_APP_CLIENT_SECRET\",\n                                               redirect_uri=\"YOUR_APP_REDIRECT_URI\",\n                                               scope=\"user-library-read\"))\n\nresults = sp.current_user_saved_tracks()\nfor idx, item in enumerate(results['items']):\n    track = item['track']\n    print(idx, track['artists'][0]['name'], \"  \", track['name'])\n```\nExpected result will be the list of music that you liked. For example if you liked Red and Sunflower, the result will be:\n```\n0 Post Malone    Sunflower - Spider-Man: Into the Spider-Verse\n1 Taylor Swift    Red\n```\n\n\n## Reporting Issues\n\nFor common questions please check our [FAQ](FAQ.md).\n\nYou can ask questions about Spotipy on\n[Stack Overflow](http://stackoverflow.com/questions/ask).\nDont forget to add the *Spotipy* tag, and any other relevant tags as well, before posting.\n\nIf you have suggestions, bugs or other issues specific to this library,\nfile them [here](https://github.com/plamere/spotipy/issues).\nOr just send a pull request.\n\n## Contributing\n\nIf you are a developer with Python experience, and you would like to contribute to Spotipy, please be sure to follow the guidelines listed on documentation page\n\n> #### [Visit the guideline](https://spotipy.readthedocs.io/en/#contribute)\n",
        "num_commits": 690,
        "project_age_days": 3860,
        "project_created_at": "2014-04-05",
        "latest_updated_at": "2024-10-28",
        "latest_pushed_at": "2024-10-14",
        "num_contributors": 180,
        "num_pull": 475,
        "num_issues": 1161,
        "num_opening_issue": 83,
        "project_size(kB)": 1275,
        "num_stargazers": 5012,
        "num_watchers": 5012,
        "num_forks": 958,
        "num_subscribers": 79,
        "SecurityPolicy_created_at": "2023-01-07 08:26:17",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "f669966a7221a25051e84d8e9eb5933ac4772aa4",
                "url": "https://github.com/spotipy-dev/spotipy/commit/f669966a7221a25051e84d8e9eb5933ac4772aa4",
                "date": "2023-01-07 08:27:58"
            },
            {
                "commit_id": "0b9062726c079958afd5c641ed7175c5c83a7b66",
                "url": "https://github.com/spotipy-dev/spotipy/commit/0b9062726c079958afd5c641ed7175c5c83a7b66",
                "date": "2023-01-07 08:26:17"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "advisory",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Scope of practice",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "onnx/onnx",
        "project_url": "https://github.com/onnx/onnx",
        "SSF": {
            "date": "2024-10-29T20:08:22+07:00",
            "repo": {
                "name": "github.com/onnx/onnx",
                "commit": "9f4b58aad39bd1c73e719e959739a64f389243d6"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 8.1,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Info: 'allow deletion' disabled on branch 'main'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.17.0'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.16.2'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.16.1'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.16.0'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.15.0'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.14.1'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.14.0'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.13.1'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.13.0'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.12.0'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.11.0'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.10.2'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.10.1'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.10.0'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.9.0'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.8.1'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.8.0'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.7.0'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.6.0'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.5.0'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.4.1'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.4.0'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.2.3'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.2.2'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.2.1'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.1.2'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.0.1'",
                        "Info: 'allow deletion' disabled on branch 'rel-1.0'",
                        "Info: 'force pushes' disabled on branch 'main'",
                        "Info: 'force pushes' disabled on branch 'rel-1.17.0'",
                        "Info: 'force pushes' disabled on branch 'rel-1.16.2'",
                        "Info: 'force pushes' disabled on branch 'rel-1.16.1'",
                        "Info: 'force pushes' disabled on branch 'rel-1.16.0'",
                        "Info: 'force pushes' disabled on branch 'rel-1.15.0'",
                        "Info: 'force pushes' disabled on branch 'rel-1.14.1'",
                        "Info: 'force pushes' disabled on branch 'rel-1.14.0'",
                        "Info: 'force pushes' disabled on branch 'rel-1.13.1'",
                        "Info: 'force pushes' disabled on branch 'rel-1.13.0'",
                        "Info: 'force pushes' disabled on branch 'rel-1.12.0'",
                        "Info: 'force pushes' disabled on branch 'rel-1.11.0'",
                        "Info: 'force pushes' disabled on branch 'rel-1.10.2'",
                        "Info: 'force pushes' disabled on branch 'rel-1.10.1'",
                        "Info: 'force pushes' disabled on branch 'rel-1.10.0'",
                        "Info: 'force pushes' disabled on branch 'rel-1.9.0'",
                        "Info: 'force pushes' disabled on branch 'rel-1.8.1'",
                        "Info: 'force pushes' disabled on branch 'rel-1.8.0'",
                        "Info: 'force pushes' disabled on branch 'rel-1.7.0'",
                        "Info: 'force pushes' disabled on branch 'rel-1.6.0'",
                        "Info: 'force pushes' disabled on branch 'rel-1.5.0'",
                        "Info: 'force pushes' disabled on branch 'rel-1.4.1'",
                        "Info: 'force pushes' disabled on branch 'rel-1.4.0'",
                        "Info: 'force pushes' disabled on branch 'rel-1.2.3'",
                        "Info: 'force pushes' disabled on branch 'rel-1.2.2'",
                        "Info: 'force pushes' disabled on branch 'rel-1.2.1'",
                        "Info: 'force pushes' disabled on branch 'rel-1.1.2'",
                        "Info: 'force pushes' disabled on branch 'rel-1.0.1'",
                        "Info: 'force pushes' disabled on branch 'rel-1.0'",
                        "Warn: required approving review count is 1 on branch 'main'",
                        "Warn: required approving review count is 1 on branch 'rel-1.17.0'",
                        "Warn: required approving review count is 1 on branch 'rel-1.16.2'",
                        "Warn: required approving review count is 1 on branch 'rel-1.16.1'",
                        "Warn: required approving review count is 1 on branch 'rel-1.16.0'",
                        "Warn: required approving review count is 1 on branch 'rel-1.15.0'",
                        "Warn: required approving review count is 1 on branch 'rel-1.14.1'",
                        "Warn: required approving review count is 1 on branch 'rel-1.14.0'",
                        "Warn: required approving review count is 1 on branch 'rel-1.13.1'",
                        "Warn: required approving review count is 1 on branch 'rel-1.13.0'",
                        "Warn: required approving review count is 1 on branch 'rel-1.12.0'",
                        "Warn: required approving review count is 1 on branch 'rel-1.11.0'",
                        "Warn: required approving review count is 1 on branch 'rel-1.10.2'",
                        "Warn: required approving review count is 1 on branch 'rel-1.10.1'",
                        "Warn: required approving review count is 1 on branch 'rel-1.10.0'",
                        "Warn: required approving review count is 1 on branch 'rel-1.9.0'",
                        "Warn: required approving review count is 1 on branch 'rel-1.8.1'",
                        "Warn: required approving review count is 1 on branch 'rel-1.8.0'",
                        "Warn: required approving review count is 1 on branch 'rel-1.7.0'",
                        "Warn: required approving review count is 1 on branch 'rel-1.6.0'",
                        "Warn: required approving review count is 1 on branch 'rel-1.5.0'",
                        "Warn: required approving review count is 1 on branch 'rel-1.4.1'",
                        "Warn: required approving review count is 1 on branch 'rel-1.4.0'",
                        "Warn: required approving review count is 1 on branch 'rel-1.2.3'",
                        "Warn: required approving review count is 1 on branch 'rel-1.2.2'",
                        "Warn: required approving review count is 1 on branch 'rel-1.2.1'",
                        "Warn: required approving review count is 1 on branch 'rel-1.1.2'",
                        "Warn: required approving review count is 1 on branch 'rel-1.0.1'",
                        "Warn: required approving review count is 1 on branch 'rel-1.0'",
                        "Info: codeowner review is required on branch 'main'",
                        "Warn: codeowners review is not required on branch 'rel-1.17.0'",
                        "Warn: codeowners review is not required on branch 'rel-1.16.2'",
                        "Warn: codeowners review is not required on branch 'rel-1.16.1'",
                        "Warn: codeowners review is not required on branch 'rel-1.16.0'",
                        "Warn: codeowners review is not required on branch 'rel-1.15.0'",
                        "Warn: codeowners review is not required on branch 'rel-1.14.1'",
                        "Warn: codeowners review is not required on branch 'rel-1.14.0'",
                        "Warn: codeowners review is not required on branch 'rel-1.13.1'",
                        "Warn: codeowners review is not required on branch 'rel-1.13.0'",
                        "Warn: codeowners review is not required on branch 'rel-1.12.0'",
                        "Warn: codeowners review is not required on branch 'rel-1.11.0'",
                        "Warn: codeowners review is not required on branch 'rel-1.10.2'",
                        "Warn: codeowners review is not required on branch 'rel-1.10.1'",
                        "Warn: codeowners review is not required on branch 'rel-1.10.0'",
                        "Warn: codeowners review is not required on branch 'rel-1.9.0'",
                        "Warn: codeowners review is not required on branch 'rel-1.8.1'",
                        "Warn: codeowners review is not required on branch 'rel-1.8.0'",
                        "Warn: codeowners review is not required on branch 'rel-1.7.0'",
                        "Warn: codeowners review is not required on branch 'rel-1.6.0'",
                        "Warn: codeowners review is not required on branch 'rel-1.5.0'",
                        "Warn: codeowners review is not required on branch 'rel-1.4.1'",
                        "Warn: codeowners review is not required on branch 'rel-1.4.0'",
                        "Warn: codeowners review is not required on branch 'rel-1.2.3'",
                        "Warn: codeowners review is not required on branch 'rel-1.2.2'",
                        "Warn: codeowners review is not required on branch 'rel-1.2.1'",
                        "Warn: codeowners review is not required on branch 'rel-1.1.2'",
                        "Warn: codeowners review is not required on branch 'rel-1.0.1'",
                        "Warn: codeowners review is not required on branch 'rel-1.0'",
                        "Info: status check found to merge onto on branch 'main'",
                        "Info: status check found to merge onto on branch 'rel-1.17.0'",
                        "Info: status check found to merge onto on branch 'rel-1.16.2'",
                        "Info: status check found to merge onto on branch 'rel-1.16.1'",
                        "Info: status check found to merge onto on branch 'rel-1.16.0'",
                        "Info: status check found to merge onto on branch 'rel-1.15.0'",
                        "Info: status check found to merge onto on branch 'rel-1.14.1'",
                        "Info: status check found to merge onto on branch 'rel-1.14.0'",
                        "Info: status check found to merge onto on branch 'rel-1.13.1'",
                        "Info: status check found to merge onto on branch 'rel-1.13.0'",
                        "Info: status check found to merge onto on branch 'rel-1.12.0'",
                        "Info: status check found to merge onto on branch 'rel-1.11.0'",
                        "Info: status check found to merge onto on branch 'rel-1.10.2'",
                        "Info: status check found to merge onto on branch 'rel-1.10.1'",
                        "Info: status check found to merge onto on branch 'rel-1.10.0'",
                        "Info: status check found to merge onto on branch 'rel-1.9.0'",
                        "Info: status check found to merge onto on branch 'rel-1.8.1'",
                        "Info: status check found to merge onto on branch 'rel-1.8.0'",
                        "Info: status check found to merge onto on branch 'rel-1.7.0'",
                        "Info: status check found to merge onto on branch 'rel-1.6.0'",
                        "Info: status check found to merge onto on branch 'rel-1.5.0'",
                        "Info: status check found to merge onto on branch 'rel-1.4.1'",
                        "Info: status check found to merge onto on branch 'rel-1.4.0'",
                        "Info: status check found to merge onto on branch 'rel-1.2.3'",
                        "Info: status check found to merge onto on branch 'rel-1.2.2'",
                        "Info: status check found to merge onto on branch 'rel-1.2.1'",
                        "Info: status check found to merge onto on branch 'rel-1.1.2'",
                        "Info: status check found to merge onto on branch 'rel-1.0.1'",
                        "Info: status check found to merge onto on branch 'rel-1.0'",
                        "Info: PRs are required in order to make changes on branch 'main'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.17.0'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.16.2'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.16.1'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.16.0'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.15.0'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.14.1'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.14.0'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.13.1'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.13.0'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.12.0'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.11.0'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.10.2'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.10.1'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.10.0'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.9.0'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.8.1'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.8.0'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.7.0'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.6.0'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.5.0'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.4.1'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.4.0'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.2.3'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.2.2'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.2.1'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.1.2'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.0.1'",
                        "Info: PRs are required in order to make changes on branch 'rel-1.0'"
                    ],
                    "score": 8,
                    "reason": "branch protection is not maximal on development and all release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 out of 30 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 5,
                    "reason": "badge detected: Passing",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: pytorch contributor org/company found, ut austin contributor org/company found, Astera-org contributor org/company found, cryfs contributor org/company found, dotnet contributor org/company found, mrbgems contributor org/company found, microsoft research contributor org/company found, ScottyLabs contributor org/company found, ghc contributor org/company found, k9mail contributor org/company found, skywork ai contributor org/company found, PeachPy contributor org/company found, cupy contributor org/company found, sql-machine-learning contributor org/company found, barnowl contributor org/company found, nanyang technological university contributor org/company found, gsoc-cn contributor org/company found, cpprefjp contributor org/company found, microsoft contributor org/company found, openai contributor org/company found, amd contributor org/company found, onnx contributor org/company found, couler-proj contributor org/company found, ZhaobangChina contributor org/company found, facebook contributor org/company found, EasyRPG contributor org/company found, intelligent-machine-learning contributor org/company found, sipb contributor org/company found, open-keychain contributor org/company found, astera-org contributor org/company found, chainer contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 31 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 commit(s) and 5 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/create_release.yml:64"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/main.yml:177: update your workflow using https://app.stepsecurity.io/secureworkflow/onnx/onnx/main.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/pr_checks.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/onnx/onnx/pr_checks.yml/main?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/release_linux_x86_64.yml:36: update your workflow using https://app.stepsecurity.io/secureworkflow/onnx/onnx/release_linux_x86_64.yml/main?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/auto_update_doc.yml:33",
                        "Warn: pipCommand not pinned by hash: .github/workflows/auto_update_doc.yml:34",
                        "Warn: pipCommand not pinned by hash: .github/workflows/auto_update_doc.yml:37",
                        "Warn: pipCommand not pinned by hash: .github/workflows/codeql.yml:55",
                        "Warn: pipCommand not pinned by hash: .github/workflows/codeql.yml:74",
                        "Warn: pipCommand not pinned by hash: .github/workflows/codeql.yml:77",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint.yml:70",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint.yml:71",
                        "Warn: pipCommand not pinned by hash: .github/workflows/lint.yml:82",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:105",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:106",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:107",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:117",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:127",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:210",
                        "Warn: pipCommand not pinned by hash: .github/workflows/main.yml:225",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pages.yml:38",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pages.yml:39",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pages.yml:40",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pages.yml:49",
                        "Warn: pipCommand not pinned by hash: .github/workflows/pr_checks.yml:34",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release_linux_aarch64.yml:72",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release_linux_aarch64.yml:73",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release_linux_aarch64.yml:91",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release_linux_aarch64.yml:103",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release_linux_aarch64.yml:115",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release_linux_aarch64.yml:116",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release_linux_x86_64.yml:49",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release_linux_x86_64.yml:50",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release_linux_x86_64.yml:76",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release_linux_x86_64.yml:83",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release_linux_x86_64.yml:90",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release_linux_x86_64.yml:97",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release_linux_x86_64.yml:98",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release_mac.yml:136",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release_mac.yml:137",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release_mac.yml:45",
                        "Warn: pipCommand not pinned by hash: .github/workflows/release_mac.yml:46",
                        "Warn: pipCommand not pinned by hash: .github/workflows/weekly_mac_ci.yml:45",
                        "Warn: pipCommand not pinned by hash: .github/workflows/weekly_mac_ci.yml:46",
                        "Warn: pipCommand not pinned by hash: .github/workflows/weekly_mac_ci.yml:58",
                        "Info:  45 out of  45 GitHub-owned GitHubAction dependencies pinned",
                        "Info:  18 out of  21 third-party GitHubAction dependencies pinned",
                        "Info:   7 out of  48 pipCommand dependencies pinned"
                    ],
                    "score": 4,
                    "reason": "dependency not pinned by hash detected -- score normalized to 4",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: all commits (30) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: SECURITY.md:1",
                        "Info: Found linked content: SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: SECURITY.md:1",
                        "Info: Found text in security policy: SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/auto_update_doc.yml:18",
                        "Info: jobLevel 'actions' permission set to 'read': .github/workflows/codeql.yml:35",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/codeql.yml:36",
                        "Warn: jobLevel 'contents' permission set to 'write': .github/workflows/create_release.yml:75",
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/pr_checks.yml:24",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/auto_update_doc.yml:7",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/check_urls.yml:16",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/clang_tidy_review.yml:16",
                        "Warn: topLevel 'checks' permission set to 'write': .github/workflows/clang_tidy_review_post.yml:16",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/codeql.yml:24",
                        "Warn: no topLevel permission defined: .github/workflows/create_release.yml:1",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/dco_merge_group.yml:10",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/lint.yml:15",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/main.yml:18",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/pages.yml:16",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/pr_checks.yml:13",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/release_linux_aarch64.yml:15",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/release_linux_x86_64.yml:15",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/release_mac.yml:19",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/release_win.yml:15",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/reuse.yml:10",
                        "Info: topLevel permissions set to 'read-all': .github/workflows/scorecard.yml:22",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/stale.yml:17",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/weekly_mac_ci.yml:18",
                        "Info: topLevel 'contents' permission set to 'read': .github/workflows/win_no_exception_ci.yml:14"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/onnx/onnx/contents/SECURITY.md",
        "SecurityPolicy_content": "<!--\nCopyright (c) ONNX Project Contributors\n\nSPDX-License-Identifier: Apache-2.0\n-->\n\n# Security Policy\n\n## Reporting a Vulnerability\nIf you think you have found a security vulnerability, please send a report to onnx-security@lists.lfaidata.foundation. Please do not post security vulnerabilities on Slack.\n\nWe don't currently have a PGP key, unfortunately.\n\nAn ONNX committer will send you a response indicating the next steps in handling your report. After the initial reply to your report, the committer will keep you informed of the progress towards a fix and full announcement, and may ask for additional information or guidance.\n\nImportant: Please don't disclose the vulnerability before it has been fixed and announced, to protect our users.\n\n## Security announcements\nPlease subscribe to the [announcements mailing list](https://lists.lfaidata.foundation/g/onnx-announce), where we post notifications and remediation details for security vulnerabilities.\n",
        "project_all_labels": [
            "announce",
            "auto update doc",
            "better engineering",
            "better error message",
            "bug",
            "build",
            "CI pipelines",
            "code style",
            "compiler warning",
            "contributions welcome",
            "converters",
            "dependencies",
            "do not merge",
            "documentation",
            "enhancement",
            "github_actions",
            "good first issue",
            "inliner",
            "ir",
            "low priority",
            "more info needed",
            "no-issue-activity",
            "no-pr-activity",
            "onnx checker",
            "onnx hub",
            "onnx parser",
            "operator",
            "optimizer",
            "partial data propagation",
            "preprocessing",
            "python",
            "quantization",
            "question",
            "reference implementation",
            "release notes",
            "review needed: operators approvers",
            "run release CIs",
            "runtime",
            "schema",
            "shape inference",
            "spec",
            "spec clarification",
            "stale",
            "test",
            "test ONNX Model Zoo",
            "tracking",
            "training",
            "utility",
            "version converter",
            "vulnerability",
            "website content"
        ],
        "README_content": "<!--\nCopyright (c) ONNX Project Contributors\n\nSPDX-License-Identifier: Apache-2.0\n-->\n\n<p align=\"center\"><img width=\"40%\" src=\"https://github.com/onnx/onnx/raw/main/docs/onnx-horizontal-color.png\" /></p>\n\n[![PyPI - Version](https://img.shields.io/pypi/v/onnx.svg)](https://pypi.org/project/onnx)\n[![CI](https://github.com/onnx/onnx/actions/workflows/main.yml/badge.svg)](https://github.com/onnx/onnx/actions/workflows/main.yml)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/3313/badge)](https://bestpractices.coreinfrastructure.org/projects/3313)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/onnx/onnx/badge)](https://api.securityscorecards.dev/projects/github.com/onnx/onnx)\n[![REUSE compliant](https://api.reuse.software/badge/github.com/onnx/onnx)](https://api.reuse.software/info/github.com/onnx/onnx)\n[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)\n[![Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n\n[Open Neural Network Exchange (ONNX)](https://onnx.ai) is an open ecosystem that empowers AI developers\nto choose the right tools as their project evolves. ONNX provides an open source format for AI models, both deep learning and traditional ML. It defines an extensible computation graph model, as well as definitions of built-in operators and standard\ndata types. Currently we focus on the capabilities needed for inferencing (scoring).\n\nONNX is [widely supported](http://onnx.ai/supported-tools) and can be found in many frameworks, tools, and hardware. Enabling interoperability between different frameworks and streamlining the path from research to production helps increase the speed of innovation in the AI community. We invite the community to join us and further evolve ONNX.\n\n# Use ONNX\n\n* [Documentation of ONNX Python Package](https://onnx.ai/onnx/)\n* [Tutorials for creating ONNX models](https://github.com/onnx/tutorials)\n* [Pre-trained ONNX models](https://github.com/onnx/models)\n\n# Learn about the ONNX spec\n\n* [Overview](https://github.com/onnx/onnx/blob/main/docs/Overview.md)\n* [ONNX intermediate representation spec](https://github.com/onnx/onnx/blob/main/docs/IR.md)\n* [Versioning principles of the spec](https://github.com/onnx/onnx/blob/main/docs/Versioning.md)\n* [Operators documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md)\n* [Operators documentation](https://onnx.ai/onnx/operators/index.html) (latest release)\n* [Python API Overview](https://github.com/onnx/onnx/blob/main/docs/PythonAPIOverview.md)\n\n# Programming utilities for working with ONNX Graphs\n\n* [Shape and Type Inference](https://github.com/onnx/onnx/blob/main/docs/ShapeInference.md)\n* [Graph Optimization](https://github.com/onnx/optimizer)\n* [Opset Version Conversion](https://github.com/onnx/onnx/blob/main/docs/docsgen/source/api/version_converter.md)\n\n# Contribute\n\nONNX is a community project and the open governance model is described [here](https://github.com/onnx/onnx/blob/main/community/readme.md). We encourage you to join the effort and contribute feedback, ideas, and code. You can participate in the [Special Interest Groups](https://github.com/onnx/onnx/blob/main/community/sigs.md) and [Working Groups](https://github.com/onnx/onnx/blob/main/community/working-groups.md) to shape the future of ONNX.\n\nCheck out our [contribution guide](https://github.com/onnx/onnx/blob/main/CONTRIBUTING.md) to get started.\n\nIf you think some operator should be added to ONNX specification, please read\n[this document](https://github.com/onnx/onnx/blob/main/docs/AddNewOp.md).\n\n# Community meetings\n\nThe schedules of the regular meetings of the Steering Committee, the working groups and the SIGs can be found [here](https://onnx.ai/calendar)\n\nCommunity Meetups are held at least once a year. Content from previous community meetups are at:\n\n* 2020.04.09 <https://wiki.lfaidata.foundation/display/DL/LF+AI+Day+-ONNX+Community+Virtual+Meetup+-+Silicon+Valley+-+April+9>\n* 2020.10.14 <https://wiki.lfaidata.foundation/display/DL/LF+AI+Day+-+ONNX+Community+Workshop+-+October+14>\n* 2021.03.24 <https://wiki.lfaidata.foundation/pages/viewpage.action?pageId=35160391>\n* 2021.10.21 <https://wiki.lfaidata.foundation/pages/viewpage.action?pageId=46989689>\n* 2022.06.24 <https://wiki.lfaidata.foundation/display/DL/ONNX+Community+Day+-+June+24>\n* 2023.06.28 <https://wiki.lfaidata.foundation/display/DL/ONNX+Community+Day+2023+-+June+28>\n\n# Discuss\n\nWe encourage you to open [Issues](https://github.com/onnx/onnx/issues), or use [Slack](https://lfaifoundation.slack.com/) (If you have not joined yet, please use this [link](https://join.slack.com/t/lfaifoundation/shared_invite/zt-o65errpw-gMTbwNr7FnNbVXNVFkmyNA) to join the group) for more real-time discussion.\n\n# Follow Us\n\nStay up to date with the latest ONNX news. [[Facebook](https://www.facebook.com/onnxai/)] [[Twitter](https://twitter.com/onnxai)]\n\n# Roadmap\n\nA roadmap process takes place every year. More details can be found [here](https://github.com/onnx/steering-committee/tree/main/roadmap)\n\n# Installation\n\n## Official Python packages\n\nONNX released packages are published in PyPi.\n\n```sh\npip install onnx  # or pip install onnx[reference] for optional reference implementation dependencies\n```\n\n[ONNX weekly packages](https://pypi.org/project/onnx-weekly/) are published in PyPI to enable experimentation and early testing.\n\n## vcpkg packages\n\nONNX is in the maintenance list of [vcpkg](https://github.com/microsoft/vcpkg), you can easily use vcpkg to build and install it.\n\n```sh\ngit clone https://github.com/microsoft/vcpkg.git\ncd vcpkg\n./bootstrap-vcpkg.bat # For powershell\n./bootstrap-vcpkg.sh # For bash\n./vcpkg install onnx\n```\n\n## Conda packages\n\nA binary build of ONNX is available from [Conda](https://conda.io), in [conda-forge](https://conda-forge.org/):\n\n```sh\nconda install -c conda-forge onnx\n```\n\n## Build ONNX from Source\n\nBefore building from source uninstall any existing versions of ONNX `pip uninstall onnx`.\n\nC++17 or higher C++ compiler version is required to build ONNX from source. Still, users can specify their own `CMAKE_CXX_STANDARD` version for building ONNX.\n\nIf you don't have protobuf installed, ONNX will internally download and build protobuf for ONNX build.\n\nOr, you can manually install [protobuf C/C++ libraries and tools](https://github.com/protocolbuffers/protobuf) with specified version before proceeding forward. Then depending on how you installed protobuf, you need to set environment variable CMAKE_ARGS to \"-DONNX_USE_PROTOBUF_SHARED_LIBS=ON\" or \"-DONNX_USE_PROTOBUF_SHARED_LIBS=OFF\".  For example, you may need to run the following command:\n\nLinux:\n\n```sh\nexport CMAKE_ARGS=\"-DONNX_USE_PROTOBUF_SHARED_LIBS=ON\"\n```\n\nWindows:\n\n```bat\nset CMAKE_ARGS=\"-DONNX_USE_PROTOBUF_SHARED_LIBS=ON\"\n```\n\nThe ON/OFF depends on what kind of protobuf library you have. Shared libraries are files ending with \\*.dll/\\*.so/\\*.dylib. Static libraries are files ending with \\*.a/\\*.lib. This option depends on how you get your protobuf library and how it was built. And it is default OFF. You don't need to run the commands above if you'd prefer to use a static protobuf library.\n\n### Windows\n\nIf you are building ONNX from source, it is recommended that you also build Protobuf locally as a static library. The version distributed with conda-forge is a DLL, but ONNX expects it to be a static library. Building protobuf locally also lets you control the version of protobuf. The tested and recommended version is 3.21.12.\n\nThe instructions in this README assume you are using Visual Studio.  It is recommended that you run all the commands from a shell started from \"x64 Native Tools Command Prompt for VS 2019\" and keep the build system generator for cmake (e.g., cmake -G \"Visual Studio 16 2019\") consistent while building protobuf as well as ONNX.\n\nYou can get protobuf by running the following commands:\n\n```bat\ngit clone https://github.com/protocolbuffers/protobuf.git\ncd protobuf\ngit checkout v21.12\ncd cmake\ncmake -G \"Visual Studio 16 2019\" -A x64 -DCMAKE_INSTALL_PREFIX=<protobuf_install_dir> -Dprotobuf_MSVC_STATIC_RUNTIME=OFF -Dprotobuf_BUILD_SHARED_LIBS=OFF -Dprotobuf_BUILD_TESTS=OFF -Dprotobuf_BUILD_EXAMPLES=OFF .\nmsbuild protobuf.sln /m /p:Configuration=Release\nmsbuild INSTALL.vcxproj /p:Configuration=Release\n```\n\nThen it will be built as a static library and installed to <protobuf_install_dir>. Please add the bin directory(which contains protoc.exe) to your PATH.\n\n```bat\nset CMAKE_PREFIX_PATH=<protobuf_install_dir>;%CMAKE_PREFIX_PATH%\n```\n\nPlease note: if your protobuf_install_dir contains spaces, **do not** add quotation marks around it.\n\nAlternative: if you don't want to change your PATH, you can set ONNX_PROTOC_EXECUTABLE instead.\n\n```bat\nset CMAKE_ARGS=-DONNX_PROTOC_EXECUTABLE=<full_path_to_protoc.exe>\n```\n\nThen you can build ONNX as:\n\n```\ngit clone https://github.com/onnx/onnx.git\ncd onnx\ngit submodule update --init --recursive\n# prefer lite proto\nset CMAKE_ARGS=-DONNX_USE_LITE_PROTO=ON\npip install -e . -v\n```\n\n### Linux\n\nFirst, you need to install protobuf. The minimum Protobuf compiler (protoc) version required by ONNX is 3.6.1. Please note that old protoc versions might not work with `CMAKE_ARGS=-DONNX_USE_LITE_PROTO=ON`.\n\nUbuntu 20.04 (and newer) users may choose to install protobuf via\n\n```sh\napt-get install python3-pip python3-dev libprotobuf-dev protobuf-compiler\n```\n\nIn this case, it is required to add `-DONNX_USE_PROTOBUF_SHARED_LIBS=ON` to CMAKE_ARGS in the ONNX build step.\n\nA more general way is to build and install it from source. See the instructions below for more details.\n\n<details>\n  <summary> Installing Protobuf from source </summary>\n\n  Debian/Ubuntu:\n\n  ```sh\n    git clone https://github.com/protocolbuffers/protobuf.git\n    cd protobuf\n    git checkout v21.12\n    git submodule update --init --recursive\n    mkdir build_source && cd build_source\n    cmake ../cmake -Dprotobuf_BUILD_SHARED_LIBS=OFF -DCMAKE_INSTALL_PREFIX=/usr -DCMAKE_INSTALL_SYSCONFDIR=/etc -DCMAKE_POSITION_INDEPENDENT_CODE=ON -Dprotobuf_BUILD_TESTS=OFF -DCMAKE_BUILD_TYPE=Release\n    make -j$(nproc)\n    make install\n  ```\n\n  CentOS/RHEL/Fedora:\n\n  ```sh\n    git clone https://github.com/protocolbuffers/protobuf.git\n    cd protobuf\n    git checkout v21.12\n    git submodule update --init --recursive\n    mkdir build_source && cd build_source\n    cmake ../cmake  -DCMAKE_INSTALL_LIBDIR=lib64 -Dprotobuf_BUILD_SHARED_LIBS=OFF -DCMAKE_INSTALL_PREFIX=/usr -DCMAKE_INSTALL_SYSCONFDIR=/etc -DCMAKE_POSITION_INDEPENDENT_CODE=ON -Dprotobuf_BUILD_TESTS=OFF -DCMAKE_BUILD_TYPE=Release\n    make -j$(nproc)\n    make install\n  ```\n\n  Here \"-DCMAKE_POSITION_INDEPENDENT_CODE=ON\" is crucial. By default static libraries are built without \"-fPIC\" flag, they are not position independent code. But shared libraries must be position independent code. Python C/C++ extensions(like ONNX) are shared libraries. So if a static library was not built with \"-fPIC\", it can't be linked to such a shared library.\n\n  Once build is successful, update PATH to include protobuf paths.\n\n</details>\n\nThen you can build ONNX as:\n\n```sh\ngit clone https://github.com/onnx/onnx.git\ncd onnx\ngit submodule update --init --recursive\n# Optional: prefer lite proto\nexport CMAKE_ARGS=-DONNX_USE_LITE_PROTO=ON\npip install -e . -v\n```\n\n### Mac\n\n```sh\nexport NUM_CORES=`sysctl -n hw.ncpu`\nbrew update\nbrew install autoconf && brew install automake\nwget https://github.com/protocolbuffers/protobuf/releases/download/v21.12/protobuf-cpp-3.21.12.tar.gz\ntar -xvf protobuf-cpp-3.21.12.tar.gz\ncd protobuf-3.21.12\nmkdir build_source && cd build_source\ncmake ../cmake -Dprotobuf_BUILD_SHARED_LIBS=OFF -DCMAKE_POSITION_INDEPENDENT_CODE=ON -Dprotobuf_BUILD_TESTS=OFF -DCMAKE_BUILD_TYPE=Release\nmake -j${NUM_CORES}\nmake install\n```\n\nOnce build is successful, update PATH to include protobuf paths.\n\nThen you can build ONNX as:\n\n```sh\ngit clone --recursive https://github.com/onnx/onnx.git\ncd onnx\n# Optional: prefer lite proto\nset CMAKE_ARGS=-DONNX_USE_LITE_PROTO=ON\npip install -e . -v\n```\n\n## Verify Installation\n\nAfter installation, run\n\n```sh\npython -c \"import onnx\"\n```\n\nto verify it works.\n\n## Common Build Options\n\nFor full list refer to CMakeLists.txt\n\n### Environment variables\n\n* `USE_MSVC_STATIC_RUNTIME` should be 1 or 0, not ON or OFF. When set to 1 ONNX links statically to runtime library.\n**Default**: `USE_MSVC_STATIC_RUNTIME=0`\n\n* `DEBUG` should be 0 or 1. When set to 1 ONNX is built in debug mode. or debug versions of the dependencies, you need to open the [CMakeLists file](https://github.com/onnx/onnx/blob/main/CMakeLists.txt) and append a letter `d` at the end of the package name lines. For example, `NAMES protobuf-lite` would become `NAMES protobuf-lited`.\n**Default**: `Debug=0`\n\n### CMake variables\n\n* `ONNX_USE_PROTOBUF_SHARED_LIBS` should be `ON` or `OFF`.\n**Default**: `ONNX_USE_PROTOBUF_SHARED_LIBS=OFF USE_MSVC_STATIC_RUNTIME=0`\n`ONNX_USE_PROTOBUF_SHARED_LIBS` determines how ONNX links to protobuf libraries.\n  * When set to `ON` - ONNX will dynamically link to protobuf shared libs, PROTOBUF_USE_DLLS will be defined as described [here](https://github.com/protocolbuffers/protobuf/blob/main/cmake/README.md#dlls-vs-static-linking).\n  * When set to `OFF` - ONNX will link statically to protobuf.\n\n* `ONNX_USE_LITE_PROTO` should be `ON` or `OFF`. When set to `ON` ONNX uses lite protobuf instead of full protobuf.\n**Default**: `ONNX_USE_LITE_PROTO=OFF`\n\n* `ONNX_WERROR` should be `ON` or `OFF`. When set to `ON` warnings are treated as errors.\n**Default**: `ONNX_WERROR=OFF` in local builds, `ON` in CI and release pipelines.\n\n## Common Errors\n\n* Note: the `import onnx` command does not work from the source checkout directory; in this case you'll see `ModuleNotFoundError: No module named 'onnx.onnx_cpp2py_export'`. Change into another directory to fix this error.\n\n* If you run into any issues while building Protobuf as a static library, please ensure that shared Protobuf libraries, like libprotobuf, are not installed on your device or in the conda environment. If these shared libraries exist, either remove them to build Protobuf from source as a static library, or skip the Protobuf build from source to use the shared version directly.\n\n* If you run into any issues while building ONNX from source, and your error message reads, `Could not find pythonXX.lib`, ensure that you have consistent Python versions for common commands, such as `python` and `pip`. Clean all existing build files and rebuild ONNX again.\n\n# Testing\n\nONNX uses [pytest](https://docs.pytest.org) as test driver. In order to run tests, you will first need to install `pytest`:\n\n```sh\npip install pytest nbval\n```\n\nAfter installing pytest, use the following command to run tests.\n\n```sh\npytest\n```\n\n# Development\n\nCheck out the [contributor guide](https://github.com/onnx/onnx/blob/main/CONTRIBUTING.md) for instructions.\n\n# License\n\n[Apache License v2.0](LICENSE)\n\n# Code of Conduct\n\n[ONNX Open Source Code of Conduct](https://onnx.ai/codeofconduct.html)\n",
        "num_commits": 2885,
        "project_age_days": 2609,
        "project_created_at": "2017-09-07",
        "latest_updated_at": "2024-10-29",
        "latest_pushed_at": "2024-10-30",
        "num_contributors": 295,
        "num_pull": 3433,
        "num_issues": 6262,
        "num_opening_issue": 354,
        "project_size(kB)": 35233,
        "num_stargazers": 17846,
        "num_watchers": 17846,
        "num_forks": 3670,
        "num_subscribers": 437,
        "SecurityPolicy_created_at": "2020-11-25 16:59:54",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "013eb5ee7e775afca58f504709ebef29e72175d0",
                "url": "https://github.com/onnx/onnx/commit/013eb5ee7e775afca58f504709ebef29e72175d0",
                "date": "2024-05-04 14:53:19"
            },
            {
                "commit_id": "4af67b97a5b1ece676bc30d2f4d50b4cfd82f5e2",
                "url": "https://github.com/onnx/onnx/commit/4af67b97a5b1ece676bc30d2f4d50b4cfd82f5e2",
                "date": "2023-03-22 17:22:19"
            },
            {
                "commit_id": "bd2ff65b775580d21ab38cb655a04854c348ff49",
                "url": "https://github.com/onnx/onnx/commit/bd2ff65b775580d21ab38cb655a04854c348ff49",
                "date": "2021-01-07 22:16:14"
            },
            {
                "commit_id": "6fb8e67863af3118ce73829b99941c2d2c0baaa6",
                "url": "https://github.com/onnx/onnx/commit/6fb8e67863af3118ce73829b99941c2d2c0baaa6",
                "date": "2020-11-25 16:59:54"
            }
        ],
        "project_security_labels": [
            "vulnerability"
        ],
        "security_issues": [
            {
                "url": "https://github.com/onnx/onnx/pull/4544",
                "title": "Bump protobuf from 3.16.0 to 3.18.3",
                "labels": [
                    "run release CIs",
                    "dependencies",
                    "vulnerability"
                ],
                "user": "jcwchen",
                "issue_author_association": "MEMBER",
                "number": 4544,
                "id": 1385119286,
                "state": "closed",
                "project_created_at": "2022-09-25T18:22:08Z",
                "closed_at": "2022-10-20T17:18:02Z",
                "body": "### Description\r\nBump protobuf from 3.16.0 to 3.18.3 and the minimum supported Protobuf version is also bumped.\r\n\r\n### Motivation and Context\r\nMotivated by https://github.com/onnx/onnx/pull/4541, but this PR includes more necessary updates.",
                "comments": [
                    {
                        "body": "When this is ready, is it something that would be back ported to the current 1.12 onnx release or would it wait for some future release (ie 1.13)?",
                        "user": "cjvolzka",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-09-28T16:03:11Z",
                        "url": "https://github.com/onnx/onnx/pull/4544#issuecomment-1261128279"
                    },
                    {
                        "body": "> When this is ready, is it something that would be back ported to the current 1.12 onnx release or would it wait for some future release (ie 1.13)?\r\n\r\nGood question. ONNX 1.13 release will probably happen this Nov. or Dec so I would say it will only be included in future release instead of a patch release for current 1.12. However, for now I am even not sure whether this PR will be included in next 1.13 since this PR will upgrade ONNX's minimum supported version of Python Protobuf (3.12.2 -> 3.20.0). I will need more time to investigate whether it is OK for other ONNX related tools. May I understand your demand? (Is it also because of this issue ~https://github.com/onnx/onnx/security/dependabot/4~ [GHSA-8gq9-2x98-w8hf](https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-8gq9-2x98-w8hf)?) ",
                        "user": "jcwchen",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-09-28T16:15:17Z",
                        "url": "https://github.com/onnx/onnx/pull/4544#issuecomment-1261142929"
                    },
                    {
                        "body": "@jcwchen I can't seem to access the link you provided. It's related to https://github.com/onnx/onnx/issues/4545 which references https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-8gq9-2x98-w8hf. \r\n\r\nBasically anyone who pulls in onnx and runs a dependency scanner is going to trip up on this. For our case onnx-mlir -> onnx -> protobuf. ",
                        "user": "cjvolzka",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-09-30T01:02:37Z",
                        "url": "https://github.com/onnx/onnx/pull/4544#issuecomment-1262986119"
                    },
                    {
                        "body": "> @jcwchen I can't seem to access the link you provided. It's related to https://github.com/onnx/onnx/issues/4545 which references [GHSA-8gq9-2x98-w8hf](https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-8gq9-2x98-w8hf).\r\n\r\nYes, thank you for providing the valid reference and that is the one I was talking about. I think it's good to have, but let me announce it for a while and see whether anyone has a concern about the upgrade. I will let you know when the decision is made. Thank you for waiting.\r\n",
                        "user": "jcwchen",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-09-30T01:11:25Z",
                        "url": "https://github.com/onnx/onnx/pull/4544#issuecomment-1262990468"
                    },
                    {
                        "body": "@cjvolzka FYI ONNX has bumped its used Protobuf version from 3.16.0 to 3.18.3. Thanks for waiting.",
                        "user": "jcwchen",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-10-20T17:20:35Z",
                        "url": "https://github.com/onnx/onnx/pull/4544#issuecomment-1285899349"
                    },
                    {
                        "body": "@p-wysocki can we make sure that this PR will come in ONNX 1.13 release? Since it's merged, it appears that this will be the case, just wanting to make sure. Thanks.",
                        "user": "AlexandreEichenberger",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-10-20T18:25:42Z",
                        "url": "https://github.com/onnx/onnx/pull/4544#issuecomment-1285968844"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/onnx/onnx/pulls/4544",
                    "merged_at": "2022-10-20T17:18:02Z"
                }
            },
            {
                "url": "https://github.com/onnx/onnx/pull/4470",
                "title": "Use filesystem to load filename to prevent encoding issues on Windows",
                "labels": [
                    "run release CIs",
                    "vulnerability"
                ],
                "user": "jcwchen",
                "issue_author_association": "MEMBER",
                "number": 4470,
                "id": 1351042488,
                "state": "closed",
                "project_created_at": "2022-08-25T15:00:41Z",
                "closed_at": "2022-09-12T20:39:56Z",
                "body": "### Description\r\n- On Windows, use filesystem to load filename to prevent encoding issues (e.g., Chinese locale).\r\n- Extend existing path functions to accept std::wstring as well.\r\n- Add comments for requiring C++17 or higher for Windows.\r\n\r\n### Motivation and Context\r\nFollow-up work of https://github.com/onnx/onnx/pull/4400. Here is another security issue when loading external tensors on Windows:\r\nOn Linux, a path string is either encoded by Unicode(UTF-16), or a multiple byte encoding like GB18030/ISO-8859-1/, and usually it is not UTF-8.  As there are so many encodings, usually we need to convert the string to UTF-16 first and process it with wchar_t. Otherwise, when you search the char \\, you may accidently misclassify a half of a Chinese character to \\. (It can happen in other encodings too). On Linux, the same thing could happen too, but we could claim on Linux we dont support locales other than xxx.UTF-8. But for Windows, we need to handle other encodings. Using filesystem could be a solution.",
                "comments": [
                    {
                        "body": "cc @onnx/sig-archinfra-approvers, @snnn: this PR is ready for review. Thanks!",
                        "user": "jcwchen",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-08-26T16:34:13Z",
                        "url": "https://github.com/onnx/onnx/pull/4470#issuecomment-1228702754"
                    },
                    {
                        "body": "@snnn Thank you for the reviews. I think I should solve all of them. Please take another round of review. Meanwhile, I will try to validate this PR and https://github.com/onnx/onnx/pull/4400 in ORT and see whether there is any issue in advance.\r\n\r\ncc @postrational IIRC, you mentioned you are interested in this topic in our last operator-sig meeting. Feel free to review. Thank you!",
                        "user": "jcwchen",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-09-09T18:50:26Z",
                        "url": "https://github.com/onnx/onnx/pull/4470#issuecomment-1242347909"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/onnx/onnx/pulls/4470",
                    "merged_at": "2022-09-12T20:39:56Z"
                }
            },
            {
                "url": "https://github.com/onnx/onnx/pull/4413",
                "title": "Add comment to make sure vsnprintf usage is secure",
                "labels": [
                    "run release CIs",
                    "vulnerability"
                ],
                "user": "jcwchen",
                "issue_author_association": "MEMBER",
                "number": 4413,
                "id": 1329303303,
                "state": "closed",
                "project_created_at": "2022-08-05T00:24:47Z",
                "closed_at": "2022-08-11T02:50:26Z",
                "body": "**Description**\r\n~Add an assert to make sure the quantity is reasonable for vsnprintf.~ Add comments about why current vsnprintf is fine without vulnerability issue.\r\n\r\n**Motivation and Context**\r\nTo resolve potential vulnerability issue for vsnprintf: Potentially vulnerable format argument for printf style function. The printf type functions format argument does not appear to be hard-coded. Never place user data in the format argument as an attacker can influence a buffer overflow through the format string itself.\r\n",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/onnx/onnx/pulls/4413",
                    "merged_at": "2022-08-11T02:50:26Z"
                }
            },
            {
                "url": "https://github.com/onnx/onnx/pull/4400",
                "title": "Do not allow to read tensor's external_data outside the model directory",
                "labels": [
                    "run release CIs",
                    "utility",
                    "vulnerability"
                ],
                "user": "jnovikov",
                "issue_author_association": "CONTRIBUTOR",
                "number": 4400,
                "id": 1325018901,
                "state": "closed",
                "project_created_at": "2022-08-01T21:48:20Z",
                "closed_at": "2022-08-10T15:35:50Z",
                "body": "Signed-off-by: jnovikov <johnnovikov0@gmail.com>\r\n\r\nThis PR fixes the vulnerability that allows to read tensor_data outside the model directory.\r\n\r\nThe logic behind the PR is to first normalize the relative_path inside the tensor and then check that path has no '../' suffix.\r\nNormalization code is based on go-lang path.Clean() but simplified to work correctly with the relative_paths only. \r\nProvided tests should cover most of the cases.\r\n\r\nPlease note that 'optimal' solution would be to use boost::filesystem or c++17 filesystem to get the absolute path file and resolve possible symlink problems, but AFAIK the project target is C++11 and the boost is not used at the project. \r\n\r\nfixes #3991",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/onnx/onnx/pulls/4400",
                    "merged_at": "2022-08-10T15:35:50Z"
                }
            },
            {
                "url": "https://github.com/onnx/onnx/pull/4377",
                "title": "Use fully qualified pathname when loading DLL to prevent security vulnerability",
                "labels": [
                    "vulnerability"
                ],
                "user": "jcwchen",
                "issue_author_association": "MEMBER",
                "number": 4377,
                "id": 1317428934,
                "state": "closed",
                "project_created_at": "2022-07-25T22:07:43Z",
                "closed_at": "2022-08-04T14:33:56Z",
                "body": "**Description**\r\nTo prevent security vulnerability, we should use fully qualified pathname when loading DLL.\r\n\r\n**Motivation and Context**\r\nSecurity vulnerability: The LoadLibrary*() family of functions are used to dynamically load a DLL into your\r\nprogram. Most versions of the Windows operating system search the current directory first\r\nwhen attempting to load files. If you do not specify a fully qualified pathname when loading\r\na Windows dynamic load library (DLL), the loader will attempt to locate the library in the\r\ncurrent directory. If there is a malicious library located in the current directory, it will be\r\nloaded instead of the intended library.\r\n",
                "comments": [
                    {
                        "body": "Can an approved accept this PR as it is a potential vulnerability. Thanks",
                        "user": "AlexandreEichenberger",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-07-28T15:18:14Z",
                        "url": "https://github.com/onnx/onnx/pull/4377#issuecomment-1198298710"
                    },
                    {
                        "body": "cc @onnx/sig-archinfra-approvers PTAL. Thanks!",
                        "user": "jcwchen",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-07-28T15:20:12Z",
                        "url": "https://github.com/onnx/onnx/pull/4377#issuecomment-1198300992"
                    },
                    {
                        "body": "> LGTM, not sure if the default `LOAD_LIBRARY_SEARCH_DEFAULT_DIRS` is still needed as a fully qualified path is used. But maybe its used for something else... your call.\r\n\r\nThanks for catching this. `LOAD_WITH_ALTERED_SEARCH_PATH` seems more accurate for absolute path and so I will use it instead.",
                        "user": "jcwchen",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-07-28T15:56:16Z",
                        "url": "https://github.com/onnx/onnx/pull/4377#issuecomment-1198340445"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/onnx/onnx/pulls/4377",
                    "merged_at": "2022-08-04T14:33:56Z"
                }
            },
            {
                "url": "https://github.com/onnx/onnx/issues/3991",
                "title": "The onnx runtime allow to load the external_data from the file outside the folder",
                "labels": [
                    "enhancement",
                    "vulnerability"
                ],
                "user": "jnovikov",
                "issue_author_association": "CONTRIBUTOR",
                "number": 3991,
                "id": 1125277391,
                "state": "closed",
                "project_created_at": "2022-02-06T18:21:58Z",
                "closed_at": "2022-08-10T15:35:51Z",
                "body": "The external_data field of the tensor proto can have a path to the file which is outside the model current directory or user provided directory, for example \"../../../etc/passwd\". \r\n\r\nThere is no validation on this in this function: https://github.com/onnx/onnx/blob/96516aecd4c110b0ac57eba08ac236ebf7205728/onnx/checker.cc#L129\r\n\r\nThe python library have the _sanitize_path function which has some basic restrictions but it doesn't work when you use the default onnxruntime package to do the model execution.\r\n\r\nI can provide POC and create a patch by request. \r\n\r\n",
                "comments": [
                    {
                        "body": "@jnovikov please send a PR to fix this.",
                        "user": "garymm",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-02-23T19:31:08Z",
                        "url": "https://github.com/onnx/onnx/issues/3991#issuecomment-1049138014"
                    },
                    {
                        "body": "@garymm @jcwchen I've sent a PR to fix, pls review. ",
                        "user": "jnovikov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-08-02T01:26:05Z",
                        "url": "https://github.com/onnx/onnx/issues/3991#issuecomment-1201910871"
                    },
                    {
                        "body": "Out of curiosity: are there any pointers to such security practices (documentation)? ",
                        "user": "gramalingam",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-08-02T17:14:09Z",
                        "url": "https://github.com/onnx/onnx/issues/3991#issuecomment-1203004167"
                    },
                    {
                        "body": "@gramalingam do you mean is there any reason to do the patch ?\r\n\r\nMy main reason is that it should not be allowed by default [(from the docs)](https://github.com/onnx/onnx/blob/main/docs/ExternalData.md#external_data-field) as it also may affect the security of the some application or user.\r\n\r\nAbout the security practices in patch: \r\nhttps://owasp.org/www-community/attacks/Path_Traversal\r\n\r\nI would say it would be sure better to have some chrooted env while loading the model, but it would be hard to implement in cross-platform way, so this should be enough as long as the clean_relative_path() has no bugs. \r\n\r\n\r\n",
                        "user": "jnovikov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-08-02T19:16:33Z",
                        "url": "https://github.com/onnx/onnx/issues/3991#issuecomment-1203115641"
                    }
                ],
                "pull_request": null
            }
        ],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 6,
        "num_security_issue_and_pull": 6,
        "security_issues_created_after_policy": [
            {
                "url": "https://github.com/onnx/onnx/pull/4544",
                "title": "Bump protobuf from 3.16.0 to 3.18.3",
                "labels": [
                    "run release CIs",
                    "dependencies",
                    "vulnerability"
                ],
                "user": "jcwchen",
                "issue_author_association": "MEMBER",
                "number": 4544,
                "id": 1385119286,
                "state": "closed",
                "project_created_at": "2022-09-25T18:22:08Z",
                "closed_at": "2022-10-20T17:18:02Z",
                "body": "### Description\r\nBump protobuf from 3.16.0 to 3.18.3 and the minimum supported Protobuf version is also bumped.\r\n\r\n### Motivation and Context\r\nMotivated by https://github.com/onnx/onnx/pull/4541, but this PR includes more necessary updates.",
                "comments": [
                    {
                        "body": "When this is ready, is it something that would be back ported to the current 1.12 onnx release or would it wait for some future release (ie 1.13)?",
                        "user": "cjvolzka",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-09-28T16:03:11Z",
                        "url": "https://github.com/onnx/onnx/pull/4544#issuecomment-1261128279"
                    },
                    {
                        "body": "> When this is ready, is it something that would be back ported to the current 1.12 onnx release or would it wait for some future release (ie 1.13)?\r\n\r\nGood question. ONNX 1.13 release will probably happen this Nov. or Dec so I would say it will only be included in future release instead of a patch release for current 1.12. However, for now I am even not sure whether this PR will be included in next 1.13 since this PR will upgrade ONNX's minimum supported version of Python Protobuf (3.12.2 -> 3.20.0). I will need more time to investigate whether it is OK for other ONNX related tools. May I understand your demand? (Is it also because of this issue ~https://github.com/onnx/onnx/security/dependabot/4~ [GHSA-8gq9-2x98-w8hf](https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-8gq9-2x98-w8hf)?) ",
                        "user": "jcwchen",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-09-28T16:15:17Z",
                        "url": "https://github.com/onnx/onnx/pull/4544#issuecomment-1261142929"
                    },
                    {
                        "body": "@jcwchen I can't seem to access the link you provided. It's related to https://github.com/onnx/onnx/issues/4545 which references https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-8gq9-2x98-w8hf. \r\n\r\nBasically anyone who pulls in onnx and runs a dependency scanner is going to trip up on this. For our case onnx-mlir -> onnx -> protobuf. ",
                        "user": "cjvolzka",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-09-30T01:02:37Z",
                        "url": "https://github.com/onnx/onnx/pull/4544#issuecomment-1262986119"
                    },
                    {
                        "body": "> @jcwchen I can't seem to access the link you provided. It's related to https://github.com/onnx/onnx/issues/4545 which references [GHSA-8gq9-2x98-w8hf](https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-8gq9-2x98-w8hf).\r\n\r\nYes, thank you for providing the valid reference and that is the one I was talking about. I think it's good to have, but let me announce it for a while and see whether anyone has a concern about the upgrade. I will let you know when the decision is made. Thank you for waiting.\r\n",
                        "user": "jcwchen",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-09-30T01:11:25Z",
                        "url": "https://github.com/onnx/onnx/pull/4544#issuecomment-1262990468"
                    },
                    {
                        "body": "@cjvolzka FYI ONNX has bumped its used Protobuf version from 3.16.0 to 3.18.3. Thanks for waiting.",
                        "user": "jcwchen",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-10-20T17:20:35Z",
                        "url": "https://github.com/onnx/onnx/pull/4544#issuecomment-1285899349"
                    },
                    {
                        "body": "@p-wysocki can we make sure that this PR will come in ONNX 1.13 release? Since it's merged, it appears that this will be the case, just wanting to make sure. Thanks.",
                        "user": "AlexandreEichenberger",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-10-20T18:25:42Z",
                        "url": "https://github.com/onnx/onnx/pull/4544#issuecomment-1285968844"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/onnx/onnx/pulls/4544",
                    "merged_at": "2022-10-20T17:18:02Z"
                }
            },
            {
                "url": "https://github.com/onnx/onnx/pull/4470",
                "title": "Use filesystem to load filename to prevent encoding issues on Windows",
                "labels": [
                    "run release CIs",
                    "vulnerability"
                ],
                "user": "jcwchen",
                "issue_author_association": "MEMBER",
                "number": 4470,
                "id": 1351042488,
                "state": "closed",
                "project_created_at": "2022-08-25T15:00:41Z",
                "closed_at": "2022-09-12T20:39:56Z",
                "body": "### Description\r\n- On Windows, use filesystem to load filename to prevent encoding issues (e.g., Chinese locale).\r\n- Extend existing path functions to accept std::wstring as well.\r\n- Add comments for requiring C++17 or higher for Windows.\r\n\r\n### Motivation and Context\r\nFollow-up work of https://github.com/onnx/onnx/pull/4400. Here is another security issue when loading external tensors on Windows:\r\nOn Linux, a path string is either encoded by Unicode(UTF-16), or a multiple byte encoding like GB18030/ISO-8859-1/, and usually it is not UTF-8.  As there are so many encodings, usually we need to convert the string to UTF-16 first and process it with wchar_t. Otherwise, when you search the char \\, you may accidently misclassify a half of a Chinese character to \\. (It can happen in other encodings too). On Linux, the same thing could happen too, but we could claim on Linux we dont support locales other than xxx.UTF-8. But for Windows, we need to handle other encodings. Using filesystem could be a solution.",
                "comments": [
                    {
                        "body": "cc @onnx/sig-archinfra-approvers, @snnn: this PR is ready for review. Thanks!",
                        "user": "jcwchen",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-08-26T16:34:13Z",
                        "url": "https://github.com/onnx/onnx/pull/4470#issuecomment-1228702754"
                    },
                    {
                        "body": "@snnn Thank you for the reviews. I think I should solve all of them. Please take another round of review. Meanwhile, I will try to validate this PR and https://github.com/onnx/onnx/pull/4400 in ORT and see whether there is any issue in advance.\r\n\r\ncc @postrational IIRC, you mentioned you are interested in this topic in our last operator-sig meeting. Feel free to review. Thank you!",
                        "user": "jcwchen",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-09-09T18:50:26Z",
                        "url": "https://github.com/onnx/onnx/pull/4470#issuecomment-1242347909"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/onnx/onnx/pulls/4470",
                    "merged_at": "2022-09-12T20:39:56Z"
                }
            },
            {
                "url": "https://github.com/onnx/onnx/pull/4413",
                "title": "Add comment to make sure vsnprintf usage is secure",
                "labels": [
                    "run release CIs",
                    "vulnerability"
                ],
                "user": "jcwchen",
                "issue_author_association": "MEMBER",
                "number": 4413,
                "id": 1329303303,
                "state": "closed",
                "project_created_at": "2022-08-05T00:24:47Z",
                "closed_at": "2022-08-11T02:50:26Z",
                "body": "**Description**\r\n~Add an assert to make sure the quantity is reasonable for vsnprintf.~ Add comments about why current vsnprintf is fine without vulnerability issue.\r\n\r\n**Motivation and Context**\r\nTo resolve potential vulnerability issue for vsnprintf: Potentially vulnerable format argument for printf style function. The printf type functions format argument does not appear to be hard-coded. Never place user data in the format argument as an attacker can influence a buffer overflow through the format string itself.\r\n",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/onnx/onnx/pulls/4413",
                    "merged_at": "2022-08-11T02:50:26Z"
                }
            },
            {
                "url": "https://github.com/onnx/onnx/pull/4400",
                "title": "Do not allow to read tensor's external_data outside the model directory",
                "labels": [
                    "run release CIs",
                    "utility",
                    "vulnerability"
                ],
                "user": "jnovikov",
                "issue_author_association": "CONTRIBUTOR",
                "number": 4400,
                "id": 1325018901,
                "state": "closed",
                "project_created_at": "2022-08-01T21:48:20Z",
                "closed_at": "2022-08-10T15:35:50Z",
                "body": "Signed-off-by: jnovikov <johnnovikov0@gmail.com>\r\n\r\nThis PR fixes the vulnerability that allows to read tensor_data outside the model directory.\r\n\r\nThe logic behind the PR is to first normalize the relative_path inside the tensor and then check that path has no '../' suffix.\r\nNormalization code is based on go-lang path.Clean() but simplified to work correctly with the relative_paths only. \r\nProvided tests should cover most of the cases.\r\n\r\nPlease note that 'optimal' solution would be to use boost::filesystem or c++17 filesystem to get the absolute path file and resolve possible symlink problems, but AFAIK the project target is C++11 and the boost is not used at the project. \r\n\r\nfixes #3991",
                "comments": [],
                "pull_request": {
                    "url": "https://api.github.com/repos/onnx/onnx/pulls/4400",
                    "merged_at": "2022-08-10T15:35:50Z"
                }
            },
            {
                "url": "https://github.com/onnx/onnx/pull/4377",
                "title": "Use fully qualified pathname when loading DLL to prevent security vulnerability",
                "labels": [
                    "vulnerability"
                ],
                "user": "jcwchen",
                "issue_author_association": "MEMBER",
                "number": 4377,
                "id": 1317428934,
                "state": "closed",
                "project_created_at": "2022-07-25T22:07:43Z",
                "closed_at": "2022-08-04T14:33:56Z",
                "body": "**Description**\r\nTo prevent security vulnerability, we should use fully qualified pathname when loading DLL.\r\n\r\n**Motivation and Context**\r\nSecurity vulnerability: The LoadLibrary*() family of functions are used to dynamically load a DLL into your\r\nprogram. Most versions of the Windows operating system search the current directory first\r\nwhen attempting to load files. If you do not specify a fully qualified pathname when loading\r\na Windows dynamic load library (DLL), the loader will attempt to locate the library in the\r\ncurrent directory. If there is a malicious library located in the current directory, it will be\r\nloaded instead of the intended library.\r\n",
                "comments": [
                    {
                        "body": "Can an approved accept this PR as it is a potential vulnerability. Thanks",
                        "user": "AlexandreEichenberger",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-07-28T15:18:14Z",
                        "url": "https://github.com/onnx/onnx/pull/4377#issuecomment-1198298710"
                    },
                    {
                        "body": "cc @onnx/sig-archinfra-approvers PTAL. Thanks!",
                        "user": "jcwchen",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-07-28T15:20:12Z",
                        "url": "https://github.com/onnx/onnx/pull/4377#issuecomment-1198300992"
                    },
                    {
                        "body": "> LGTM, not sure if the default `LOAD_LIBRARY_SEARCH_DEFAULT_DIRS` is still needed as a fully qualified path is used. But maybe its used for something else... your call.\r\n\r\nThanks for catching this. `LOAD_WITH_ALTERED_SEARCH_PATH` seems more accurate for absolute path and so I will use it instead.",
                        "user": "jcwchen",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2022-07-28T15:56:16Z",
                        "url": "https://github.com/onnx/onnx/pull/4377#issuecomment-1198340445"
                    }
                ],
                "pull_request": {
                    "url": "https://api.github.com/repos/onnx/onnx/pulls/4377",
                    "merged_at": "2022-08-04T14:33:56Z"
                }
            },
            {
                "url": "https://github.com/onnx/onnx/issues/3991",
                "title": "The onnx runtime allow to load the external_data from the file outside the folder",
                "labels": [
                    "enhancement",
                    "vulnerability"
                ],
                "user": "jnovikov",
                "issue_author_association": "CONTRIBUTOR",
                "number": 3991,
                "id": 1125277391,
                "state": "closed",
                "project_created_at": "2022-02-06T18:21:58Z",
                "closed_at": "2022-08-10T15:35:51Z",
                "body": "The external_data field of the tensor proto can have a path to the file which is outside the model current directory or user provided directory, for example \"../../../etc/passwd\". \r\n\r\nThere is no validation on this in this function: https://github.com/onnx/onnx/blob/96516aecd4c110b0ac57eba08ac236ebf7205728/onnx/checker.cc#L129\r\n\r\nThe python library have the _sanitize_path function which has some basic restrictions but it doesn't work when you use the default onnxruntime package to do the model execution.\r\n\r\nI can provide POC and create a patch by request. \r\n\r\n",
                "comments": [
                    {
                        "body": "@jnovikov please send a PR to fix this.",
                        "user": "garymm",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-02-23T19:31:08Z",
                        "url": "https://github.com/onnx/onnx/issues/3991#issuecomment-1049138014"
                    },
                    {
                        "body": "@garymm @jcwchen I've sent a PR to fix, pls review. ",
                        "user": "jnovikov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-08-02T01:26:05Z",
                        "url": "https://github.com/onnx/onnx/issues/3991#issuecomment-1201910871"
                    },
                    {
                        "body": "Out of curiosity: are there any pointers to such security practices (documentation)? ",
                        "user": "gramalingam",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-08-02T17:14:09Z",
                        "url": "https://github.com/onnx/onnx/issues/3991#issuecomment-1203004167"
                    },
                    {
                        "body": "@gramalingam do you mean is there any reason to do the patch ?\r\n\r\nMy main reason is that it should not be allowed by default [(from the docs)](https://github.com/onnx/onnx/blob/main/docs/ExternalData.md#external_data-field) as it also may affect the security of the some application or user.\r\n\r\nAbout the security practices in patch: \r\nhttps://owasp.org/www-community/attacks/Path_Traversal\r\n\r\nI would say it would be sure better to have some chrooted env while loading the model, but it would be hard to implement in cross-platform way, so this should be enough as long as the clean_relative_path() has no bugs. \r\n\r\n\r\n",
                        "user": "jnovikov",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2022-08-02T19:16:33Z",
                        "url": "https://github.com/onnx/onnx/issues/3991#issuecomment-1203115641"
                    }
                ],
                "pull_request": null
            }
        ],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism",
            "User guideline"
        ],
        "num_noncompliant_security_discuss_issue": 1,
        "num_noncompliant_security_pull": 5,
        "has_generic_policy": true
    },
    {
        "project_name": "codecov/codecov-python",
        "project_url": "https://github.com/codecov/codecov-python",
        "SSF": {
            "date": "2024-10-30T01:05:31+07:00",
            "repo": {
                "name": "github.com/codecov/codecov-python",
                "commit": "e553e93ed1404095acaf9a8bc3ef239675d3b88e"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.2,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'master'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "0 out of 28 merged PRs checked by a CI test -- score normalized to 0",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 8,
                    "reason": "Found 21/24 approved changesets -- score normalized to 8",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: NaNoGenMo contributor org/company found, ultrajson contributor org/company found, freelancer up for hire contributor org/company found, pywikibot contributor org/company found, summerofcode contributor org/company found, codecov contributor org/company found, python-pillow contributor org/company found, awesomeWM contributor org/company found, NaPoGenMo contributor org/company found, citybikes contributor org/company found, deadsetbit contributor org/company found, zlib-ng contributor org/company found, Vimjas contributor org/company found, moremoban contributor org/company found, WahKazoo contributor org/company found, pylast contributor org/company found, pytest-dev contributor org/company found, python-twitter-tools contributor org/company found, Nuitka contributor org/company found, django contributor org/company found, unitedstates contributor org/company found, python-humanize contributor org/company found, flake8-implicit-str-concat contributor org/company found, py2many contributor org/company found, fatiando contributor org/company found, helsinki-python contributor org/company found, yourlabs contributor org/company found, neomake contributor org/company found, BesutKode contributor org/company found, Blosc contributor org/company found, termcolor contributor org/company found, gsocindonesia contributor org/company found, editorconfig contributor org/company found, snxd contributor org/company found, wikimedia contributor org/company found, TruthfulTechnology contributor org/company found, PyCQA contributor org/company found, coala contributor org/company found, loklak contributor org/company found, jazzband contributor org/company found, truthfultechnology contributor org/company found, whyaretheflagsup contributor org/company found, mobbler contributor org/company found, sandiegopython contributor org/company found, endoflife-date contributor org/company found, franklin-ai contributor org/company found, whissip contributor org/company found, python-attrs contributor org/company found, MediumCendekia contributor org/company found, fossasia contributor org/company found, python contributor org/company found, psf contributor org/company found, cycle148hki contributor org/company found, nordsoftware contributor org/company found, testbed contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 55 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: .github/dependabot.yml:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": [
                        "Warn: Repository is archived."
                    ],
                    "score": 0,
                    "reason": "project is archived",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build-test.yml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/codecov/codecov-python/build-test.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/build-test.yml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/codecov/codecov-python/build-test.yml/master?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/build-test.yml:30",
                        "Warn: pipCommand not pinned by hash: .github/workflows/build-test.yml:31",
                        "Info:   0 out of   2 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   2 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 28 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/codecov/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/codecov/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/codecov/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/codecov/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/build-test.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/codecov/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "# Codecov Responsible Disclosure Policy\n\nData security is a top priority for Codecov, and Codecov believes that working with skilled security researchers can identify weaknesses in any technology.\n\nIf you believe youve found a security vulnerability in Codecovs service, please notify us; we will work with you to resolve the issue promptly.\n\nEven though we don't have a bug bounty program, we will ensure that your findings gets passed along to the security team for remediation if youve found a security vulnerability in Codecovs service.\n\n## Disclosure Policy\n\n- If you believe youve discovered a potential vulnerability, please let us know by emailing us at security@codecov.io . We will acknowledge your email within five business days.\n- Provide us with a reasonable amount of time to resolve the issue before disclosing it to the public or a third party. We aim to resolve critical issues within five business days of disclosure.\n- Make a good faith effort to avoid violating privacy, destroying data, or interrupting or degrading the Codecov service. Please only interact with accounts you own or for which you have explicit permission from the account holder.\n\n## Exclusions\n\nWhile researching, wed like you to refrain from:\n\n- Distributed Denial of Service (DDoS)\n- Spamming\n- Social engineering or phishing of Codecov employees or contractors\n- Any attacks against Codecovs physical property or data centers\n- Thank you for helping to keep Codecov and our users safe!\n\n## Changes\n\nWe may revise these guidelines from time to time. The most current version of the guidelines will be available at https://codecov.io/security\n\n## Contact\n\nCodecov is always open to feedback, questions, and suggestions. If you would like to talk to us, please feel free to email us at security@codecov.io, and our PGP key is at https://codecov.io/.well-known/security.txt.\n",
        "project_all_labels": [
            "bug",
            "dependencies",
            "duplicate",
            "enhancement",
            "hacktoberfest-accepted",
            "help wanted",
            "invalid",
            "patched & pending review",
            "question",
            "wontfix"
        ],
        "README_content": " Deprecation Notice \n\nThis uploader is being deprecated by the Codecov team. We recommend migrating to our [new uploader](https://docs.codecov.com/docs/codecov-uploader) as soon as possible to prevent any lapses in coverage. [The new uploader is open source](https://github.com/codecov/uploader), and we highly encourage submitting Issues and Pull Requests.\n\nYou can visit our [migration guide](https://docs.codecov.com/docs/deprecated-uploader-migration-guide#python-uploader) for help moving to our new uploader, and our blog post to learn more about our [deprecation plan](https://about.codecov.io/blog/codecov-uploader-deprecation-plan/)\n\n**On February 1, 2022 this uploader will be completely deprecated and will no longer be able to upload coverage to Codecov.**\n\n# Codecov Global Python Uploader\n\n[![codecov.io](https://codecov.io/github/codecov/codecov-python/coverage.svg?branch=master)](https://codecov.io/github/codecov/codecov-python)\n![PyPI](https://img.shields.io/pypi/v/codecov)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fcodecov%2Fcodecov-python.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fcodecov%2Fcodecov-python?ref=badge_shield)\n=======\n| [Support][1] | [Documentation][2] | [Community Boards][3] | [Twitter][4] |\n| ------------ | ------------------ | --------------------- | ------------ |\n\nFind coverage reports for all the [languages below](#languages), gather them and submit them to Codecov.\n\n## Codecov Features\n- Reports are **automatically** combined with no extra setup. Each build is stored separately and combined.\n- Multiple languages are supported in a single upload and repository.\n- *Optionally* stores environment variables per build.\n\n\n## Usage\n\n```sh\npip install --user codecov && codecov -t <the-repository-upload-token>\n```\nor\n```sh\nconda install -c conda-forge codecov && codecov -t <the-repository-upload-token>\n```\n> `--user` argument not needed for Python projects. [See example here](https://github.com/codecov/example-python).\n\n## Languages\n> [Python](https://github.com/codecov/example-python), [C#/.net](https://github.com/codecov/example-csharp), [Java](https://github.com/codecov/example-java), [Node/Javascript/Coffee](https://github.com/codecov/example-node),\n> [C/C++](https://github.com/codecov/example-c), [D](https://github.com/codecov/example-d), [Go](https://github.com/codecov/example-go), [Groovy](https://github.com/codecov/example-groovy), [Kotlin](https://github.com/codecov/example-kotlin),\n> [PHP](https://github.com/codecov/example-php), [R](https://github.com/codecov/example-r), [Scala](https://github.com/codecov/example-scala), [Xtern](https://github.com/codecov/example-xtend), [Xcode](https://github.com/codecov/example-xcode), [Lua](https://github.com/codecov/example-lua) and more...\n\n## Using `tox`?\n\nCodecov can be set up in your `tox.ini`.\n\nJust please make sure to pass all the necessary environment variables through:\n\n```\n[testenv]\npassenv = TOXENV CI TRAVIS TRAVIS_* CODECOV_*\ndeps = codecov>=1.4.0\ncommands = codecov -e TOXENV\n```\n> See all the environment variables for other CI providers [here](https://github.com/codecov/codecov-python/blob/master/codecov/__init__.py#L254-L468)\n\n\n## Configuration\n\n> Below are the most commonly used settings.\n\n| Argument |   Environment   |                                                                    Description                                                                     |\n| -------- | --------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `-t`     | `CODECOV_TOKEN` | Private repo token for uploading                                                                                                                   |\n| `-e`     | `CODECOV_ENV`   | List of config vars to store for the build  |\n| `-F`     |      | Flag this upload to group coverage reports. Ex. `unittests` or `integration`  |\n\n```yaml\n# public repository on Travis CI\ninstall:\n  - pip install --user codecov\n# or\n  - conda install -c conda-forge codecov\nafter_success:\n  - codecov\n```\n\n```yaml\n# private repository on Travis CI\ninstall:\n  - pip install codecov\n# or\n  - conda install -c conda-forge codecov\nafter_success:\n  - codecov -t the-repository-upload-token\n```\n\n\n## CI Providers\n|                       Company                         |                                                                                     Supported                                                                                      |  Token Required  |\n| ----------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------- |\n| [AppVeyor](https://www.appveyor.com/)                 | Yes [![Build status](https://ci.appveyor.com/api/projects/status/sw18lsj7786bw806/branch/master?svg=true)](https://ci.appveyor.com/project/stevepeak/codecov-python/branch/master) | Private only     |\n| [Bamboo](https://www.atlassian.com/software/bamboo)   | `coming soon`                                                                                                                                                                      |                  |\n| [Buildbot](https://buildbot.net/)                     | `coming soon` [buildbot/buildbot#1671](https://github.com/buildbot/buildbot/pull/1671)                                                                                             |                  |\n| [CircleCI](https://circleci.com/)                     | Yes                                                                                                                                                                                | Private only     |\n| [Codeship](https://codeship.com/)                     | Yes                                                                                                                                                                                | Public & Private |\n| [Drone.io](https://drone.io/)                         | Yes                                                                                                                                                                                | Public & Private |\n| [GitHub Actions](https://github.com/features/actions) | Yes [![Build status](https://github.com/codecov/codecov-python/workflows/Python%20package/badge.svg?branch=master)](https://github.com/codecov/codecov-python/actions?query=workflow%3A%22Python+package%22)                                                                                        | Public & Private |\n| [Gitlab CI](https://about.gitlab.com/gitlab-ci/)      | Yes                                                                                                                                                                                | Public & Private |\n| [Jenkins](https://jenkins-ci.org/)                    | Yes                                                                                                                                                                                | Public & Private |\n| [Magnum CI](https://magnum-ci.com/)                   | Yes                                                                                                                                                                                | Public & Private |\n| [Semaphore](https://semaphoreci.com/)                 | Yes                                                                                                                                                                                | Public & Private |\n| [Shippable](https://www.shippable.com/)               | Yes                                                                                                                                                                                | Public & Private |\n| [Solano Labs](https://www.solanolabs.com/)            | `coming soon`                                                                                                                                                                      |                  |\n| [Travis CI](https://travis-ci.org/)                   | Yes [![Build Status](https://secure.travis-ci.org/codecov/codecov-python.svg?branch=master)](https://travis-ci.org/codecov/codecov-python)                                         | Private only     |\n| [Wercker](http://wercker.com/)                        | Yes                                                                                                                                                                                | Public & Private |\n| [Cirrus CI](https://cirrus-ci.org/)                   | Yes                                                                                                                                                                                | Private only     |\n| Git / Mercurial                                       | Yes (as a fallback)                                                                                                                                                                | Public & Private |\n\n\n## Troubleshooting\n\nIf you're seeing an **HTTP 400 error when uploading reports to S3**, make sure you've updated to at least version 2.1.3.\n\n\n\n[1]: https://codecov.io/support/\n[2]: https://docs.codecov.io/\n[3]: https://community.codecov.io/\n[4]: https://twitter.com/codecov\n\n## Copyright\n\n> Copyright 2014-2022 codecov\n\n\n## License\n[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fcodecov%2Fcodecov-python.svg?type=large)](https://app.fossa.com/projects/git%2Bgithub.com%2Fcodecov%2Fcodecov-python?ref=badge_large)\n",
        "num_commits": 669,
        "project_age_days": 3737,
        "project_created_at": "2014-08-06",
        "latest_updated_at": "2024-10-21",
        "latest_pushed_at": "2023-04-18",
        "num_contributors": 50,
        "num_pull": 185,
        "num_issues": 340,
        "num_opening_issue": 23,
        "project_size(kB)": 683,
        "num_stargazers": 185,
        "num_watchers": 185,
        "num_forks": 139,
        "num_subscribers": 21,
        "SecurityPolicy_created_at": "2022-08-18 14:27:11",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "e9302a976838072ff674754ad80a55a593b98917",
                "url": "https://github.com/codecov/.github/commit/e9302a976838072ff674754ad80a55a593b98917",
                "date": "2022-08-18 14:27:11"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism",
            "User guideline",
            "User guideline",
            "Information on maintainer"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "apache/age",
        "project_url": "https://github.com/apache/age",
        "SSF": {
            "date": "2024-10-29T20:57:40+07:00",
            "repo": {
                "name": "github.com/apache/age",
                "commit": "c75d9e477e2f83016a7a144291d2c15038cf229f"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 6.0,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'release/PG14/1.5.0'",
                        "Warn: branch protection not enabled for branch 'release/PG13/1.5.0'",
                        "Warn: branch protection not enabled for branch 'release/PG12/1.5.0'",
                        "Warn: branch protection not enabled for branch 'release/PG11/1.5.0'",
                        "Warn: branch protection not enabled for branch 'release/PG15/1.5.0'",
                        "Warn: branch protection not enabled for branch 'release/PG16/1.5.0'",
                        "Warn: branch protection not enabled for branch 'release/PG15/1.4.0'",
                        "Warn: branch protection not enabled for branch 'release/PG14/1.4.0'",
                        "Warn: branch protection not enabled for branch 'release/PG13/1.4.0'",
                        "Warn: branch protection not enabled for branch 'release/PG12/1.4.0'",
                        "Warn: branch protection not enabled for branch 'release/PG11/1.4.0'",
                        "Warn: branch protection not enabled for branch 'release/PG11/1.3.0'",
                        "Warn: branch protection not enabled for branch 'release/PG12/1.3.0'",
                        "Warn: branch protection not enabled for branch 'release/PG13/1.3.0'",
                        "Warn: branch protection not enabled for branch 'release/PG12/1.1.1'",
                        "Warn: branch protection not enabled for branch 'release/PG11/1.2.0'",
                        "Warn: branch protection not enabled for branch 'release/PG12/1.1.0'",
                        "Warn: branch protection not enabled for branch 'release/1.1.0'",
                        "Warn: branch protection not enabled for branch 'release/1.0.0'",
                        "Warn: branch protection not enabled for branch 'release/0.6.0'",
                        "Info: 'allow deletion' disabled on branch 'master'",
                        "Info: 'force pushes' disabled on branch 'master'",
                        "Info: required approving review count is 2 on branch 'master'",
                        "Warn: codeowners review is not required on branch 'master'",
                        "Warn: no status checks found to merge onto branch 'master'",
                        "Info: PRs are required in order to make changes on branch 'master'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "30 out of 30 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "all changesets reviewed",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: SuperBois contributor org/company found, Asteramind contributor org/company found, bitnine contributor org/company found, agedb contributor org/company found, ewostech contributor org/company found, naver contributor org/company found, bitnine global contributor org/company found, apache contributor org/company found, o2o contributor org/company found, cmc global contributor org/company found, sktelecom contributor org/company found, BitnineGlobal contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 12 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: Dependabot: :0"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: Apache License 2.0: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "15 commit(s) and 4 issue activity found in the last 90 days -- score normalized to 10",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Warn: no GitHub/GitLab publishing workflow detected."
                    ],
                    "score": -1,
                    "reason": "packaging workflow not detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/go-driver.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/go-driver.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/go-driver.yml:28: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/go-driver.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/installcheck.yaml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/installcheck.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/installcheck.yaml:38: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/installcheck.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/jdbc-driver.yaml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/jdbc-driver.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/jdbc-driver.yaml:21: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/jdbc-driver.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/labeler.yml:13: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/labeler.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/labeler.yml:18: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/labeler.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/nodejs-driver.yaml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/nodejs-driver.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/nodejs-driver.yaml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/nodejs-driver.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-driver.yaml:19: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/python-driver.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python-driver.yaml:25: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/python-driver.yaml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/stale.yaml:10: update your workflow using https://app.stepsecurity.io/secureworkflow/apache/age/stale.yaml/master?enable=pin",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile:20",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile:37: pin your Docker image by updating postgres:16 to postgres:16@sha256:91f464e7ba0ad91a106c94cff079fb4384139291b8c0502fd36989cf2c788bbb",
                        "Warn: containerImage not pinned by hash: docker/Dockerfile.dev:20: pin your Docker image by updating postgres:16 to postgres:16@sha256:91f464e7ba0ad91a106c94cff079fb4384139291b8c0502fd36989cf2c788bbb",
                        "Warn: npmCommand not pinned by hash: .github/workflows/nodejs-driver.yaml:31",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python-driver.yaml:32",
                        "Info:   0 out of  13 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   3 containerImage dependencies pinned",
                        "Info:   1 out of   1 goCommand dependencies pinned",
                        "Info:   0 out of   1 npmCommand dependencies pinned",
                        "Info:   0 out of   1 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Warn: 0 commits out of 30 are checked with a SAST tool"
                    ],
                    "score": 0,
                    "reason": "SAST tool is not run on all commits -- score normalized to 0",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/apache/.github/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/apache/.github/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/apache/.github/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/apache/.github/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": [
                        "Warn: release artifact PG14/v1.5.0-rc0 not signed: https://api.github.com/repos/apache/age/releases/136532607",
                        "Warn: release artifact PG13/v1.5.0-rc0 not signed: https://api.github.com/repos/apache/age/releases/136547864",
                        "Warn: release artifact PG12/v1.5.0-rc0 not signed: https://api.github.com/repos/apache/age/releases/136555687",
                        "Warn: release artifact PG11/v1.5.0-rc0 not signed: https://api.github.com/repos/apache/age/releases/136579067",
                        "Warn: release artifact PG15/v1.5.0-rc0 not signed: https://api.github.com/repos/apache/age/releases/136406973",
                        "Warn: release artifact PG14/v1.5.0-rc0 does not have provenance: https://api.github.com/repos/apache/age/releases/136532607",
                        "Warn: release artifact PG13/v1.5.0-rc0 does not have provenance: https://api.github.com/repos/apache/age/releases/136547864",
                        "Warn: release artifact PG12/v1.5.0-rc0 does not have provenance: https://api.github.com/repos/apache/age/releases/136555687",
                        "Warn: release artifact PG11/v1.5.0-rc0 does not have provenance: https://api.github.com/repos/apache/age/releases/136579067",
                        "Warn: release artifact PG15/v1.5.0-rc0 does not have provenance: https://api.github.com/repos/apache/age/releases/136406973"
                    ],
                    "score": 0,
                    "reason": "Project has not signed or included provenance with any releases.",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Info: jobLevel 'contents' permission set to 'read': .github/workflows/labeler.yml:8",
                        "Warn: no topLevel permission defined: .github/workflows/go-driver.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/installcheck.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/jdbc-driver.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/labeler.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/nodejs-driver.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/python-driver.yaml:1",
                        "Warn: no topLevel permission defined: .github/workflows/stale.yaml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/apache/.github/contents/.github/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\nThis is a project of the [Apache Software Foundation](https://apache.org) and follows the ASF [vulnerability handling process](https://apache.org/security/#vulnerability-handling).\n\n## Reporting a Vulnerability\n\nTo report a new vulnerability you have discovered please follow the [ASF vulnerability reporting process](https://apache.org/security/#reporting-a-vulnerability).\n",
        "project_all_labels": [
            "0.2.0",
            "0.3.0",
            "0.4.0",
            "0.5.0",
            "0.6.0",
            "0.7.0",
            "1.0.0",
            "1.1.0",
            "algorithm",
            "API",
            "bolt protocol",
            "branching",
            "browser",
            "bug",
            "c",
            "CentOS",
            "coding standards",
            "conversion",
            "create",
            "critical bug",
            "cypher",
            "Debian",
            "debugging",
            "delete",
            "dependencies",
            "detection",
            "directed network",
            "distributed",
            "docker",
            "documentation",
            "driver",
            "duplicate",
            "enhancement",
            "ETL",
            "extension",
            "feature request",
            "fixed",
            "fortran",
            "GDBMS",
            "golang",
            "good first issue",
            "graph",
            "graph analysis",
            "graph visualization",
            "graphql",
            "help wanted",
            "high availability",
            "hooks",
            "hybrid queries",
            "invalid",
            "java",
            "label inheritance",
            "licensing",
            "linux",
            "load balancing",
            "macos",
            "mariadb",
            "master",
            "match",
            "merge",
            "migration",
            "monitoring",
            "mysql",
            "nodejs",
            "not critical bug",
            "Onboarding",
            "opencypher",
            "optimizer",
            "override-stale",
            "packaging",
            "parser",
            "performance",
            "PG11",
            "PG12",
            "PG13",
            "PG14",
            "PG15",
            "PG16",
            "plugin",
            "postgreSQL",
            "priority",
            "python",
            "query",
            "question",
            "release",
            "remove",
            "replication",
            "RHEL-8",
            "RHEL-9",
            "RPM",
            "security",
            "set",
            "sharding",
            "sql",
            "Stale",
            "swift",
            "testing",
            "To be Closed",
            "tool",
            "Ubuntu",
            "update",
            "upgrade",
            "viewer",
            "vle",
            "windows",
            "wontfix"
        ],
        "README_content": "<br>\n\n<p align=\"center\">\n     <img src=\"https://age.apache.org/age-manual/master/_static/logo.png\" width=\"30%\" height=\"30%\">\n</p>\n<br>\n\n<h3 align=\"center\">\n    <a href=\"https://age.apache.org/age-manual/master/_static/logo.png\" target=\"_blank\">\n        <img src=\"https://age.apache.org/age-manual/master/_static/logo.png\" height=\"25\" height=\"30% alt=\"Apache AGE style=\"margin: 0 0 -3px 0\">\n    </a>\n    <a href=\"https://age.apache.org/age-manual/master/_static/logo.png\" target=\"_blank\">\n    </a>\n     is a leading multi-model graph database </h3>\n     \n</h3>\n\n<h3 align=\"center\">Graph Processing & Analytics for Relational Databases</h3>\n\n<br>\n\n\n</br>\n\n\n\n<p align=\"center\">                                                                                                    \n  <a href=\"https://github.com/apache/age/blob/master/LICENSE\">\n    <img src=\"https://img.shields.io/github/license/apache/age\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://github.com/apache/age/releases\">\n    <img src=\"https://img.shields.io/badge/Release-v1.5.0-FFA500?labelColor=gray&style=flat&link=https://github.com/apache/age/releases\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://www.postgresql.org/docs/16/index.html\">\n    <img src=\"https://img.shields.io/badge/Version-Postgresql 16-00008B?labelColor=gray&style=flat&link=https://www.postgresql.org/docs/16/index.html\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://github.com/apache/age/issues\">\n    <img src=\"https://img.shields.io/github/issues/apache/age\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://github.com/apache/age/network/members\">\n    <img src=\"https://img.shields.io/github/forks/apache/age\"/>\n  </a>\n  &nbsp;\n  <a href=\"https://github.com/apache/age/stargazers\">\n    <img src=\"https://img.shields.io/github/stars/apache/age\"/>\n  </a>\n\n</p>\n\n<br>\n\n\n<h2><img height=\"30\" src=\"/img/AGE.png\">&nbsp;&nbsp;What is Apache AGE?</h2>\n\n[Apache AGE](https://age.apache.org/#) is an extension for PostgreSQL that enables users to leverage a graph database on top of the existing relational databases. AGE is an acronym for A Graph Extension and is inspired by Bitnine's AgensGraph, a multi-model database fork of PostgreSQL. The basic principle of the project is to create a single storage that handles both the relational and graph data model so that the users can use the standard ANSI SQL along with openCypher, one of the most popular graph query languages today. There is a strong need for cohesive, easy-to-implement multi-model databases. As an extension of PostgreSQL, AGE supports all the functionalities and features of PostgreSQL while also offering a graph model to boot.\n</br>\n</br>\n</br>\n\n<p align=\"center\">\n<img src=\"/img/age-01.png\" width=\"80%\" height=\"80%\">\n</p>\n\n</br>\n\n\n<h2><img height=\"30\" src=\"/img/tick.svg\">&nbsp;&nbsp;Overview</h2>\n\nApache AGE is :\n\n- **Powerful**: adds graph database support to the already popular PostgreSQL database: PostgreSQL is used by organizations including Apple, Spotify, and NASA.\n- **Flexible**: allows you to perform openCypher queries, which makes complex queries much easier to write. It also enables querying multiple graphs at the same time.\n- **Intelligent**: allows you to perform graph queries that are the basis for many next-level web services such as fraud detection, master data management, product recommendations, identity and relationship management, experience personalization, knowledge management, and more.\n\n<h2><img height=\"30\" src=\"/img/features.svg\">&nbsp;&nbsp;Features</h2>\n</br>\n</br>\n\n<p align=\"center\">\n<img src=\"/img/age-03.png\" width=\"80%\" height=\"80%\">\n</p>\n</br>\n\n- **Cypher Query**: supports graph query language\n- **Hybrid Querying**: enables SQL and/or Cypher\n- **Querying**: enables multiple graphs\n- **Hierarchical**: graph label organization\n- **Property Indexes**: on both vertices(nodes) and edges\n- **Full PostgreSQL**: supports PG features\n\n\n\n<h2><img height=\"30\" src=\"/img/documentation.svg\">&nbsp;&nbsp;Documentation</h2>\n\nRefer to our latest [Apache AGE documentation](https://age.apache.org/age-manual/master/index.html) to learn about installation, features, built-in functions, and  Cypher queries.\n\n\n\n<h2><img height=\"30\" src=\"/img/installation.svg\">&nbsp;&nbsp;Pre-Installation</h2>\n\nInstall the following essential libraries according to each OS. Building AGE from the source depends on the following Linux libraries (Ubuntu package names shown below):\n\n- **CentOS**\n```bash\nyum install gcc glibc glib-common readline readline-devel zlib zlib-devel flex bison\n```\n- **Fedora**\n```bash\ndnf install gcc glibc bison flex readline readline-devel zlib zlib-devel\n```\n- **Ubuntu**\n```bash\nsudo apt-get install build-essential libreadline-dev zlib1g-dev flex bison\n```\n\n<h2><img height=\"30\" src=\"/img/installation.svg\">&nbsp;&nbsp;Installation</h2>\n\nApache AGE is intended to be simple to install and run. It can be installed with Docker and other traditional ways. \n\n<h4><a><img width=\"20\" src=\"/img/pg.svg\"></a>\n&nbsp;Install PostgreSQL\n</h4>\n\nYou will need to install an AGE compatible version of Postgres<a>, for now AGE supports Postgres 11, 12, 13, 14, 15 & 16. Supporting the latest versions is on AGE roadmap.\n\n<h4>\n&nbsp;Installation via Package Manager\n</h4>\n\nYou can use a <a href=\"https://www.postgresql.org/download/\">package management </a> that your OS provides to download PostgreSQL.\n\n<br>\n\n```bash\nsudo apt install postgresql\n\n```\n<h4>\n&nbsp;Installation From Source Code\n</h4>\n\nYou can <a href=\"https://www.postgresql.org/ftp/source/\"> download the Postgres </a> source code and install your own instance of Postgres. You can read instructions on how to install from source code for different versions on the <a href=\"https://www.postgresql.org/docs/16/installation.html\">official Postgres Website.</a>\n\n\n\n<h4><img width=\"20\" src=\"/img/tux.svg\"><img width=\"20\" src=\"/img/apple.svg\"> &nbsp;Install AGE on Linux and MacOS\n</h4>\n\nClone the <a href=\"https://github.com/apache/age\">github repository</a> or download the <a href=\"https://github.com/apache/age/releases\">download an official release.\n</a>\nRun the pg_config utility and check the version of PostgreSQL. Currently, only PostgreSQL versions 11, 12, 13, 14, 15 & 16 are supported. If you have any other version of Postgres, you will need to install PostgreSQL version 11, 12, 13, 14, 15, or 16.\n<br>\n    \n```bash\npg_config\n```\nRun the following command in the source code directory of Apache AGE to build and install the extension.  \n     \n```bash\nmake install\n```\n     \nIf the path to your Postgres installation is not in the PATH variable, add the path in the arguments:\n```bash\nmake PG_CONFIG=/path/to/postgres/bin/pg_config install\n```\n\n\n<h4></a><img width=\"30\" src=\"/img/docker.svg\"></a>\n&nbsp;Run using Docker\n</h4>\n\n<h5> Get the docker image </h5>\n\n```bash\ndocker pull apache/age\n\n```\n<h5> Create AGE docker container </h5>\n\n```bash\ndocker run \\\n    --name age  \\\n    -p 5455:5432 \\\n    -e POSTGRES_USER=postgresUser \\\n    -e POSTGRES_PASSWORD=postgresPW \\\n    -e POSTGRES_DB=postgresDB \\\n    -d \\\n    apache/age\n```\n\n<h5> Enter PostgreSQL's psql: </h5>\n\n```bash\ndocker exec -it age psql -d postgresDB -U postgresUser\n```\n\n\n\n<h2><img height=\"20\" src=\"/img/contents.svg\">&nbsp;&nbsp;Post Installation</h2>\n\nFor every connection of AGE you start, you will need to load the AGE extension.\n\n```bash\nCREATE EXTENSION age;\n```\n```bash\nLOAD 'age';\n```\n```bash\nSET search_path = ag_catalog, \"$user\", public;\n```\n\n\n\n<h2><img height=\"20\" src=\"/img/contents.svg\">&nbsp;&nbsp;Quick Start</h2>\n\nTo create a graph, use the create_graph function located in the ag_catalog namespace.\n\n```bash\nSELECT create_graph('graph_name');\n```\n\nTo create a single vertex with label and properties, use the CREATE clause.\n\n```bash\nSELECT * \nFROM cypher('graph_name', $$\n    CREATE (:label {property:\"Node A\"})\n$$) as (v agtype);\n```\n\n```bash\nSELECT * \nFROM cypher('graph_name', $$\n    CREATE (:label {property:\"Node B\"})\n$$) as (v agtype);\n```\n\nTo create an edge between two nodes and set its properties:\n\n```bash\nSELECT * \nFROM cypher('graph_name', $$\n    MATCH (a:label), (b:label)\n    WHERE a.property = 'Node A' AND b.property = 'Node B'\n    CREATE (a)-[e:RELTYPE {property:a.property + '<->' + b.property}]->(b)\n    RETURN e\n$$) as (e agtype);\n```\n\nAnd to query the connected nodes:\n\n```\nSELECT * from cypher('graph_name', $$\n        MATCH (V)-[R]-(V2)\n        RETURN V,R,V2\n$$) as (V agtype, R agtype, V2 agtype);\n```\n\n<h2><img height=\"20\" src=\"/img/gettingstarted.svg\">&nbsp;&nbsp;Language Specific Drivers</h2>\n\nStarting with Apache AGE is very simple. You can easily select your platform and incorporate the relevant SDK into your code.\n</br>\n</br>\n\n<p align=\"center\">\n<img src=\"/img/age-02.png\" width=\"80%\" height=\"80%\">\n</p>\n\n\n<h4>Built-in</h4>\n\n- [Go driver](./drivers/golang)\n- [Java driver](./drivers/jdbc)\n- [NodeJs driver](./drivers/nodejs)\n- [Python driver](./drivers/python)\n\n<h4>Community-driven Driver</h4>\n\n- [Apache AGE Rust Driver](https://github.com/Dzordzu/rust-apache-age.git)\n- [Apache AGE .NET Driver](https://github.com/Allison-E/pg-age)\n\n<h2><img height=\"20\" src=\"/img/visualization.svg\">&nbsp;&nbsp;Graph Visualization Tool for AGE</h2>\n\n\nApache AGE Viewer is a user interface for Apache AGE that provides visualization and exploration of data.\nThis web visualization tool allows users to enter complex graph queries and explore the results in graph and table forms.\nApache AGE Viewer is enhanced to proceed with extensive graph data and discover insights through various graph algorithms.\nApache AGE Viewer will become a graph data administration and development platform for Apache AGE to support multiple relational databases: <https://github.com/apache/age-viewer>.\n\n**This is a visualization tool.**\nAfter installing AGE Extension, you may use this tool to get access to the visualization features.\n\n\n![Viewer gdb, and graph](/img/agce.gif)\n\n\n<h2><img height=\"20\" src=\"/img/videos.png\">&nbsp;&nbsp;Video Links</h2>\n\nYou can also get help from these videos. \n\n- Install on [Windows](https://www.youtube.com/watch?v=ddk8VX8Hm-I&list=PLGp3huJbWNDjgwP7s99Q-9_w1vxpjNHXG)\n- Install on [MacOS](https://www.youtube.com/watch?v=0-qMwpDh0CA)\n\n\n\n<h2><img height=\"20\" src=\"/img/community.svg\">&nbsp;&nbsp;Contributing</h2>\n\nYou can improve ongoing efforts or initiate new ones by sending pull requests to [this repository](https://github.com/apache/age).\nAlso, you can learn from the code review process, how to merge pull requests, and from code style compliance to documentation by visiting the [Apache AGE official site - Developer Guidelines](https://age.apache.org/contribution/guide).\nSend all your comments and inquiries to the user mailing list, users@age.apache.org.\n",
        "num_commits": 759,
        "project_age_days": 1581,
        "project_created_at": "2020-07-01",
        "latest_updated_at": "2024-10-27",
        "latest_pushed_at": "2024-09-27",
        "num_contributors": 85,
        "num_pull": 1313,
        "num_issues": 2042,
        "num_opening_issue": 153,
        "project_size(kB)": 47637,
        "num_stargazers": 3096,
        "num_watchers": 3096,
        "num_forks": 409,
        "num_subscribers": 67,
        "SecurityPolicy_created_at": "2021-07-19 11:31:44",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "c5e16821126392a9613ee5def9d1cce56a1f64bf",
                "url": "https://github.com/apache/.github/commit/c5e16821126392a9613ee5def9d1cce56a1f64bf",
                "date": "2021-07-19 11:31:44"
            }
        ],
        "project_security_labels": [
            "security"
        ],
        "security_issues": [
            {
                "url": "https://github.com/apache/age/issues/441",
                "title": "Ensure that the Dependencies of each Driver are Up-to-Date and Secure ",
                "labels": [
                    "driver",
                    "security"
                ],
                "user": "eyab",
                "issue_author_association": "MEMBER",
                "number": 441,
                "id": 1513044178,
                "state": "open",
                "project_created_at": "2022-12-28T18:13:48Z",
                "closed_at": null,
                "body": null,
                "comments": [
                    {
                        "body": "Hi, I am the new Operations Manager Steve from Vancouver Team.",
                        "user": "Steves452",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-10T19:16:03Z",
                        "url": "https://github.com/apache/age/issues/441#issuecomment-1377730917"
                    },
                    {
                        "body": "Hi, I am the new Operations Manager Jayden from Vancouver Team.",
                        "user": "JYage",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-10T19:19:42Z",
                        "url": "https://github.com/apache/age/issues/441#issuecomment-1377735163"
                    },
                    {
                        "body": "Hi. Looking to get started on this.",
                        "user": "aru-d-at",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-12T16:06:41Z",
                        "url": "https://github.com/apache/age/issues/441#issuecomment-1380627613"
                    },
                    {
                        "body": "Looking forward to study more about this project and contribute.",
                        "user": "Hasan-Iqtedar",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-04-09T17:30:18Z",
                        "url": "https://github.com/apache/age/issues/441#issuecomment-1501176609"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/age/issues/440",
                "title": "Check the Go Driver for Security Issues",
                "labels": [
                    "good first issue",
                    "driver",
                    "security"
                ],
                "user": "eyab",
                "issue_author_association": "MEMBER",
                "number": 440,
                "id": 1513043516,
                "state": "open",
                "project_created_at": "2022-12-28T18:12:35Z",
                "closed_at": null,
                "body": null,
                "comments": [
                    {
                        "body": "Hi, I am the new Operations Manager Steve from Vancouver Team.",
                        "user": "Steves452",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-10T19:15:59Z",
                        "url": "https://github.com/apache/age/issues/440#issuecomment-1377730842"
                    },
                    {
                        "body": "Hi, I am the new Operations Manager Jayden from Vancouver Team.",
                        "user": "JYage",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-10T19:19:39Z",
                        "url": "https://github.com/apache/age/issues/440#issuecomment-1377735109"
                    },
                    {
                        "body": "Hi! Will be working on this.",
                        "user": "aru-d-at",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-12T16:06:00Z",
                        "url": "https://github.com/apache/age/issues/440#issuecomment-1380625785"
                    },
                    {
                        "body": "Looking forward to study more about this project and contribute.",
                        "user": "Hasan-Iqtedar",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-04-09T17:30:09Z",
                        "url": "https://github.com/apache/age/issues/440#issuecomment-1501176582"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/age/issues/439",
                "title": "Check the Python Driver for Security Issues",
                "labels": [
                    "python",
                    "driver",
                    "security"
                ],
                "user": "eyab",
                "issue_author_association": "MEMBER",
                "number": 439,
                "id": 1513043213,
                "state": "open",
                "project_created_at": "2022-12-28T18:12:05Z",
                "closed_at": null,
                "body": null,
                "comments": [
                    {
                        "body": "Hi, I am the new Operations Manager Steve from Vancouver Team.",
                        "user": "Steves452",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-10T19:15:28Z",
                        "url": "https://github.com/apache/age/issues/439#issuecomment-1377730145"
                    },
                    {
                        "body": "Hi, I am the new Operations Manager Jayden from Vancouver Team.",
                        "user": "JYage",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-10T19:19:27Z",
                        "url": "https://github.com/apache/age/issues/439#issuecomment-1377734879"
                    },
                    {
                        "body": "Hi! I will be working on this. Any resources would be useful.",
                        "user": "aru-d-at",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-12T16:05:42Z",
                        "url": "https://github.com/apache/age/issues/439#issuecomment-1380625039"
                    },
                    {
                        "body": "Looking forward to study more about this project and contribute.",
                        "user": "Hasan-Iqtedar",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-04-09T17:30:01Z",
                        "url": "https://github.com/apache/age/issues/439#issuecomment-1501176562"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/age/issues/438",
                "title": "Check the Java Driver for Security Issues",
                "labels": [
                    "good first issue",
                    "java",
                    "driver",
                    "security"
                ],
                "user": "eyab",
                "issue_author_association": "MEMBER",
                "number": 438,
                "id": 1513042732,
                "state": "open",
                "project_created_at": "2022-12-28T18:11:23Z",
                "closed_at": null,
                "body": null,
                "comments": [
                    {
                        "body": "Hi, I am the new Operations Manager Steve from Vancouver Team.",
                        "user": "Steves452",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-10T19:15:23Z",
                        "url": "https://github.com/apache/age/issues/438#issuecomment-1377730072"
                    },
                    {
                        "body": "Hi, I am the new Operations Manager Jayden from Vancouver Team.",
                        "user": "JYage",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-10T19:19:23Z",
                        "url": "https://github.com/apache/age/issues/438#issuecomment-1377734797"
                    },
                    {
                        "body": "@dehowef Hi, I am assuming the procedure for finding these security issues are specific for each Language driver? Or is there a protocol to follow?",
                        "user": "aru-d-at",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-12T16:05:17Z",
                        "url": "https://github.com/apache/age/issues/438#issuecomment-1380623882"
                    },
                    {
                        "body": "@aru-d-at There is no defined protocol to follow yet. A good thing to do would be to go over general good security practice and see if it is implemented in the drivers",
                        "user": "dehowef",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-17T06:02:28Z",
                        "url": "https://github.com/apache/age/issues/438#issuecomment-1384874408"
                    },
                    {
                        "body": "Looking forward to study more about this project and contribute.",
                        "user": "Hasan-Iqtedar",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-04-09T17:29:52Z",
                        "url": "https://github.com/apache/age/issues/438#issuecomment-1501176522"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/age/issues/437",
                "title": "Check the NodeJs Driver for Security Issues",
                "labels": [
                    "good first issue",
                    "nodejs",
                    "driver",
                    "security"
                ],
                "user": "eyab",
                "issue_author_association": "MEMBER",
                "number": 437,
                "id": 1513041699,
                "state": "open",
                "project_created_at": "2022-12-28T18:09:41Z",
                "closed_at": null,
                "body": null,
                "comments": [
                    {
                        "body": "Hi, I am the new Operations Manager Steve from Vancouver Team. ",
                        "user": "Steves452",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-09T19:16:46Z",
                        "url": "https://github.com/apache/age/issues/437#issuecomment-1376156578"
                    },
                    {
                        "body": "Hi, I am the new Operations Manager Jayden from Vancouver Team.",
                        "user": "JYage",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-09T19:18:48Z",
                        "url": "https://github.com/apache/age/issues/437#issuecomment-1376159234"
                    },
                    {
                        "body": "Hi, I am the Intern Arunabh who will tackle the issue.",
                        "user": "aru-d-at",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-11T15:46:18Z",
                        "url": "https://github.com/apache/age/issues/437#issuecomment-1378991744"
                    },
                    {
                        "body": "Looking forward to study more about this project and contribute.",
                        "user": "Hasan-Iqtedar",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-03-25T13:08:15Z",
                        "url": "https://github.com/apache/age/issues/437#issuecomment-1483819900"
                    },
                    {
                        "body": "Hello, I'm Hammad Saleem, I'm excited/eager to start with this project",
                        "user": "hammadsaleemm",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-03-26T09:04:59Z",
                        "url": "https://github.com/apache/age/issues/437#issuecomment-1484037826"
                    }
                ],
                "pull_request": null
            }
        ],
        "SecurityPolicy_reporting_mechanism": "external",
        "num_security_issues_after_policy": 5,
        "num_security_issue_and_pull": 5,
        "security_issues_created_after_policy": [
            {
                "url": "https://github.com/apache/age/issues/441",
                "title": "Ensure that the Dependencies of each Driver are Up-to-Date and Secure ",
                "labels": [
                    "driver",
                    "security"
                ],
                "user": "eyab",
                "issue_author_association": "MEMBER",
                "number": 441,
                "id": 1513044178,
                "state": "open",
                "project_created_at": "2022-12-28T18:13:48Z",
                "closed_at": null,
                "body": null,
                "comments": [
                    {
                        "body": "Hi, I am the new Operations Manager Steve from Vancouver Team.",
                        "user": "Steves452",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-10T19:16:03Z",
                        "url": "https://github.com/apache/age/issues/441#issuecomment-1377730917"
                    },
                    {
                        "body": "Hi, I am the new Operations Manager Jayden from Vancouver Team.",
                        "user": "JYage",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-10T19:19:42Z",
                        "url": "https://github.com/apache/age/issues/441#issuecomment-1377735163"
                    },
                    {
                        "body": "Hi. Looking to get started on this.",
                        "user": "aru-d-at",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-12T16:06:41Z",
                        "url": "https://github.com/apache/age/issues/441#issuecomment-1380627613"
                    },
                    {
                        "body": "Looking forward to study more about this project and contribute.",
                        "user": "Hasan-Iqtedar",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-04-09T17:30:18Z",
                        "url": "https://github.com/apache/age/issues/441#issuecomment-1501176609"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/age/issues/440",
                "title": "Check the Go Driver for Security Issues",
                "labels": [
                    "good first issue",
                    "driver",
                    "security"
                ],
                "user": "eyab",
                "issue_author_association": "MEMBER",
                "number": 440,
                "id": 1513043516,
                "state": "open",
                "project_created_at": "2022-12-28T18:12:35Z",
                "closed_at": null,
                "body": null,
                "comments": [
                    {
                        "body": "Hi, I am the new Operations Manager Steve from Vancouver Team.",
                        "user": "Steves452",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-10T19:15:59Z",
                        "url": "https://github.com/apache/age/issues/440#issuecomment-1377730842"
                    },
                    {
                        "body": "Hi, I am the new Operations Manager Jayden from Vancouver Team.",
                        "user": "JYage",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-10T19:19:39Z",
                        "url": "https://github.com/apache/age/issues/440#issuecomment-1377735109"
                    },
                    {
                        "body": "Hi! Will be working on this.",
                        "user": "aru-d-at",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-12T16:06:00Z",
                        "url": "https://github.com/apache/age/issues/440#issuecomment-1380625785"
                    },
                    {
                        "body": "Looking forward to study more about this project and contribute.",
                        "user": "Hasan-Iqtedar",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-04-09T17:30:09Z",
                        "url": "https://github.com/apache/age/issues/440#issuecomment-1501176582"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/age/issues/439",
                "title": "Check the Python Driver for Security Issues",
                "labels": [
                    "python",
                    "driver",
                    "security"
                ],
                "user": "eyab",
                "issue_author_association": "MEMBER",
                "number": 439,
                "id": 1513043213,
                "state": "open",
                "project_created_at": "2022-12-28T18:12:05Z",
                "closed_at": null,
                "body": null,
                "comments": [
                    {
                        "body": "Hi, I am the new Operations Manager Steve from Vancouver Team.",
                        "user": "Steves452",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-10T19:15:28Z",
                        "url": "https://github.com/apache/age/issues/439#issuecomment-1377730145"
                    },
                    {
                        "body": "Hi, I am the new Operations Manager Jayden from Vancouver Team.",
                        "user": "JYage",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-10T19:19:27Z",
                        "url": "https://github.com/apache/age/issues/439#issuecomment-1377734879"
                    },
                    {
                        "body": "Hi! I will be working on this. Any resources would be useful.",
                        "user": "aru-d-at",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-12T16:05:42Z",
                        "url": "https://github.com/apache/age/issues/439#issuecomment-1380625039"
                    },
                    {
                        "body": "Looking forward to study more about this project and contribute.",
                        "user": "Hasan-Iqtedar",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-04-09T17:30:01Z",
                        "url": "https://github.com/apache/age/issues/439#issuecomment-1501176562"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/age/issues/438",
                "title": "Check the Java Driver for Security Issues",
                "labels": [
                    "good first issue",
                    "java",
                    "driver",
                    "security"
                ],
                "user": "eyab",
                "issue_author_association": "MEMBER",
                "number": 438,
                "id": 1513042732,
                "state": "open",
                "project_created_at": "2022-12-28T18:11:23Z",
                "closed_at": null,
                "body": null,
                "comments": [
                    {
                        "body": "Hi, I am the new Operations Manager Steve from Vancouver Team.",
                        "user": "Steves452",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-10T19:15:23Z",
                        "url": "https://github.com/apache/age/issues/438#issuecomment-1377730072"
                    },
                    {
                        "body": "Hi, I am the new Operations Manager Jayden from Vancouver Team.",
                        "user": "JYage",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-10T19:19:23Z",
                        "url": "https://github.com/apache/age/issues/438#issuecomment-1377734797"
                    },
                    {
                        "body": "@dehowef Hi, I am assuming the procedure for finding these security issues are specific for each Language driver? Or is there a protocol to follow?",
                        "user": "aru-d-at",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-12T16:05:17Z",
                        "url": "https://github.com/apache/age/issues/438#issuecomment-1380623882"
                    },
                    {
                        "body": "@aru-d-at There is no defined protocol to follow yet. A good thing to do would be to go over general good security practice and see if it is implemented in the drivers",
                        "user": "dehowef",
                        "issue_author_association": "MEMBER",
                        "project_created_at": "2023-01-17T06:02:28Z",
                        "url": "https://github.com/apache/age/issues/438#issuecomment-1384874408"
                    },
                    {
                        "body": "Looking forward to study more about this project and contribute.",
                        "user": "Hasan-Iqtedar",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-04-09T17:29:52Z",
                        "url": "https://github.com/apache/age/issues/438#issuecomment-1501176522"
                    }
                ],
                "pull_request": null
            },
            {
                "url": "https://github.com/apache/age/issues/437",
                "title": "Check the NodeJs Driver for Security Issues",
                "labels": [
                    "good first issue",
                    "nodejs",
                    "driver",
                    "security"
                ],
                "user": "eyab",
                "issue_author_association": "MEMBER",
                "number": 437,
                "id": 1513041699,
                "state": "open",
                "project_created_at": "2022-12-28T18:09:41Z",
                "closed_at": null,
                "body": null,
                "comments": [
                    {
                        "body": "Hi, I am the new Operations Manager Steve from Vancouver Team. ",
                        "user": "Steves452",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-01-09T19:16:46Z",
                        "url": "https://github.com/apache/age/issues/437#issuecomment-1376156578"
                    },
                    {
                        "body": "Hi, I am the new Operations Manager Jayden from Vancouver Team.",
                        "user": "JYage",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-09T19:18:48Z",
                        "url": "https://github.com/apache/age/issues/437#issuecomment-1376159234"
                    },
                    {
                        "body": "Hi, I am the Intern Arunabh who will tackle the issue.",
                        "user": "aru-d-at",
                        "issue_author_association": "CONTRIBUTOR",
                        "project_created_at": "2023-01-11T15:46:18Z",
                        "url": "https://github.com/apache/age/issues/437#issuecomment-1378991744"
                    },
                    {
                        "body": "Looking forward to study more about this project and contribute.",
                        "user": "Hasan-Iqtedar",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-03-25T13:08:15Z",
                        "url": "https://github.com/apache/age/issues/437#issuecomment-1483819900"
                    },
                    {
                        "body": "Hello, I'm Hammad Saleem, I'm excited/eager to start with this project",
                        "user": "hammadsaleemm",
                        "issue_author_association": "NONE",
                        "project_created_at": "2023-03-26T09:04:59Z",
                        "url": "https://github.com/apache/age/issues/437#issuecomment-1484037826"
                    }
                ],
                "pull_request": null
            }
        ],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism"
        ],
        "num_noncompliant_security_discuss_issue": 5,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    },
    {
        "project_name": "personnummer/python",
        "project_url": "https://github.com/personnummer/python",
        "SSF": {
            "date": "2024-10-30T01:14:10+07:00",
            "repo": {
                "name": "github.com/personnummer/python",
                "commit": "618f999fb77ef173e5d74c5ac03d15005d412489"
            },
            "scorecard": {
                "version": "5.0.0",
                "commit": "ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4"
            },
            "score": 5.9,
            "checks": [
                {
                    "details": null,
                    "score": 10,
                    "reason": "no binaries found in the repo",
                    "name": "Binary-Artifacts",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#binary-artifacts",
                        "short": "Determines if the project has generated executable (binary) artifacts in the source repository."
                    }
                },
                {
                    "details": [
                        "Warn: branch protection not enabled for branch 'master'"
                    ],
                    "score": 0,
                    "reason": "branch protection not enabled on development/release branches",
                    "name": "Branch-Protection",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#branch-protection",
                        "short": "Determines if the default and release branches are protected with GitHub's branch protection settings."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "19 out of 19 merged PRs checked by a CI test -- score normalized to 10",
                    "name": "CI-Tests",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#ci-tests",
                        "short": "Determines if the project runs tests before pull requests are merged."
                    }
                },
                {
                    "details": null,
                    "score": 0,
                    "reason": "no effort to earn an OpenSSF best practices badge detected",
                    "name": "CII-Best-Practices",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#cii-best-practices",
                        "short": "Determines if the project has an OpenSSF (formerly CII) Best Practices Badge."
                    }
                },
                {
                    "details": null,
                    "score": 1,
                    "reason": "Found 3/18 approved changesets -- score normalized to 1",
                    "name": "Code-Review",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#code-review",
                        "short": "Determines if the project requires human code review before pull requests (aka merge requests) are merged."
                    }
                },
                {
                    "details": [
                        "Info: alsterverse contributor org/company found, nko3 contributor org/company found, skillkit contributor org/company found, ylletjs contributor org/company found, swedishtechevents contributor org/company found, northphp contributor org/company found, mend contributor org/company found, coderwall-24PullRequestsParticipant contributor org/company found, Scouterna contributor org/company found, t12t contributor org/company found, github-beta contributor org/company found, supermetrics contributor org/company found, personnummer contributor org/company found, stfturist contributor org/company found, pinefile contributor org/company found, organisationsnummer contributor org/company found, wp-papi contributor org/company found, Keeward contributor org/company found, "
                    ],
                    "score": 10,
                    "reason": "project has 18 contributing companies or organizations",
                    "name": "Contributors",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#contributors",
                        "short": "Determines if the project has a set of contributors from multiple organizations (e.g., companies)."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "no dangerous workflow patterns detected",
                    "name": "Dangerous-Workflow",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dangerous-workflow",
                        "short": "Determines if the project's GitHub Action workflows avoid dangerous patterns."
                    }
                },
                {
                    "details": [
                        "Info: detected update tool: RenovateBot: .github/renovate.json:1"
                    ],
                    "score": 10,
                    "reason": "update tool detected",
                    "name": "Dependency-Update-Tool",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#dependency-update-tool",
                        "short": "Determines if the project uses a dependency update tool."
                    }
                },
                {
                    "details": [
                        "Warn: no fuzzer integrations found"
                    ],
                    "score": 0,
                    "reason": "project is not fuzzed",
                    "name": "Fuzzing",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#fuzzing",
                        "short": "Determines if the project uses fuzzing."
                    }
                },
                {
                    "details": [
                        "Info: project has a license file: LICENSE:0",
                        "Info: FSF or OSI recognized license: MIT License: LICENSE:0"
                    ],
                    "score": 10,
                    "reason": "license file detected",
                    "name": "License",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#license",
                        "short": "Determines if the project has defined a license."
                    }
                },
                {
                    "details": null,
                    "score": 3,
                    "reason": "4 commit(s) and 0 issue activity found in the last 90 days -- score normalized to 3",
                    "name": "Maintained",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#maintained",
                        "short": "Determines if the project is \"actively maintained\"."
                    }
                },
                {
                    "details": [
                        "Info: Project packages its releases by way of GitHub Actions.: .github/workflows/publish.yml:6"
                    ],
                    "score": 10,
                    "reason": "packaging workflow detected",
                    "name": "Packaging",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#packaging",
                        "short": "Determines if the project is published as a package that others can easily download, install, easily update, and uninstall."
                    }
                },
                {
                    "details": [
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:41: update your workflow using https://app.stepsecurity.io/secureworkflow/personnummer/python/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:48: update your workflow using https://app.stepsecurity.io/secureworkflow/personnummer/python/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/codeql-analysis.yml:62: update your workflow using https://app.stepsecurity.io/secureworkflow/personnummer/python/codeql-analysis.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/publish.yml:10: update your workflow using https://app.stepsecurity.io/secureworkflow/personnummer/python/publish.yml/master?enable=pin",
                        "Warn: third-party GitHubAction not pinned by hash: .github/workflows/publish.yml:15: update your workflow using https://app.stepsecurity.io/secureworkflow/personnummer/python/publish.yml/master?enable=pin",
                        "Warn: GitHub-owned GitHubAction not pinned by hash: .github/workflows/python.yml:22: update your workflow using https://app.stepsecurity.io/secureworkflow/personnummer/python/python.yml/master?enable=pin",
                        "Warn: pipCommand not pinned by hash: .github/workflows/publish.yml:14",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python.yml:27",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python.yml:28",
                        "Warn: pipCommand not pinned by hash: .github/workflows/python.yml:31",
                        "Info:   2 out of   7 GitHub-owned GitHubAction dependencies pinned",
                        "Info:   0 out of   1 third-party GitHubAction dependencies pinned",
                        "Info:   0 out of   4 pipCommand dependencies pinned"
                    ],
                    "score": 0,
                    "reason": "dependency not pinned by hash detected -- score normalized to 0",
                    "name": "Pinned-Dependencies",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#pinned-dependencies",
                        "short": "Determines if the project has declared and pinned the dependencies of its build process."
                    }
                },
                {
                    "details": [
                        "Info: SAST configuration detected: CodeQL",
                        "Info: all commits (28) are checked with a SAST tool"
                    ],
                    "score": 10,
                    "reason": "SAST tool is run on all commits",
                    "name": "SAST",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#sast",
                        "short": "Determines if the project uses static code analysis."
                    }
                },
                {
                    "details": [
                        "Info: security policy file detected: github.com/personnummer/.github/SECURITY.md:1",
                        "Info: Found linked content: github.com/personnummer/.github/SECURITY.md:1",
                        "Info: Found disclosure, vulnerability, and/or timelines in security policy: github.com/personnummer/.github/SECURITY.md:1",
                        "Info: Found text in security policy: github.com/personnummer/.github/SECURITY.md:1"
                    ],
                    "score": 10,
                    "reason": "security policy file detected",
                    "name": "Security-Policy",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#security-policy",
                        "short": "Determines if the project has published a security policy."
                    }
                },
                {
                    "details": null,
                    "score": -1,
                    "reason": "no releases found",
                    "name": "Signed-Releases",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#signed-releases",
                        "short": "Determines if the project cryptographically signs release artifacts."
                    }
                },
                {
                    "details": [
                        "Warn: no topLevel permission defined: .github/workflows/codeql-analysis.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/publish.yml:1",
                        "Warn: no topLevel permission defined: .github/workflows/python.yml:1",
                        "Info: no jobLevel write permissions found"
                    ],
                    "score": 0,
                    "reason": "detected GitHub workflow tokens with excessive permissions",
                    "name": "Token-Permissions",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#token-permissions",
                        "short": "Determines if the project's workflows follow the principle of least privilege."
                    }
                },
                {
                    "details": null,
                    "score": 10,
                    "reason": "0 existing vulnerabilities detected",
                    "name": "Vulnerabilities",
                    "documentation": {
                        "url": "https://github.com/ossf/scorecard/blob/ea7e27ed41b76ab879c862fa0ca4cc9c61764ee4/docs/checks.md#vulnerabilities",
                        "short": "Determines if the project has open, known unfixed vulnerabilities."
                    }
                }
            ],
            "metadata": null
        },
        "SecurityPolicy_url_endpoint": "https://api.github.com/repos/personnummer/.github/contents/SECURITY.md",
        "SecurityPolicy_content": "# Security Policy\n\n## Reporting a Vulnerability\n\nBest way to report a vulnerability is to send an email to `security@personnummer.dev`.\nMake the subject `<project> vulnerability` and give a description (and if possible a reproducible example) on the vulnerability.\n\nSecurity issues will be patched on high priority basis, and we try to give the users of the module an alert of a required update as soon as it have been patched, vulnerabilities will be made public within 15 days after a fix is implemented.\n\n## Bug bounties\n\nAs of right now, we offer no bounties for vulnerability reporting.\n",
        "project_all_labels": [
            "bug",
            "dependencies",
            "discussion",
            "duplicate",
            "enhancement",
            "github_actions",
            "good first issue",
            "help wanted",
            "invalid",
            "question",
            "wontfix"
        ],
        "README_content": "# personnummer [![Build Status](https://github.com/personnummer/python/workflows/test/badge.svg)](https://github.com/personnummer/python/actions)\n\nValidate Swedish personal identity numbers. Version 3+ only supports Python 3.\n\n## Installation\n\n```\npip install personnummer\n```\n\nor\n\n```\npip3 install personnummer\n```\n\n## Examples\n\n- All examples that uses `personnummer.Personnumer([params])`, can be replaced with `personnummer.parse([params])`.\n\n### Validation\n\n```python\nfrom personnummer import personnummer\n\npersonnummer.valid(\"8507099805\")\n# => True\n\npersonnummer.valid(\"198507099805\")\n# => True\n```\n\n### Format\n\n```python\nfrom personnummer import personnummer\n\n# Short format\npn = personnummer.Personnummer(8507099805)\npn.format()\n# => '850709-9805'\n\n# Long format\npn = personnummer.Personnummer('8507099805')\npn.format(True)\n# => '198507099805'\n```\n\n### Get Date\n_New in version 3.2.0_\n\n```python\nfrom personnummer import personnummer\n\npn = personnummer.Personnummer('19121212+1212')\npn.get_date()\n# => datetime.date(1912, 12, 12)\n```\n\n### Get Age\n\n```python\nfrom personnummer import personnummer\n\npn = personnummer.Personnummer(\"19121212+1212\")\npn.get_age()\n# => 106\n```\n\nSee [personnummer/tests/test_personnummer.py](personnummer/tests/test_personnummer.py) for more examples.\n\n## License\n\nMIT\n",
        "num_commits": 173,
        "project_age_days": 2565,
        "project_created_at": "2017-10-21",
        "latest_updated_at": "2024-10-24",
        "latest_pushed_at": "2024-10-24",
        "num_contributors": 13,
        "num_pull": 67,
        "num_issues": 78,
        "num_opening_issue": 1,
        "project_size(kB)": 124,
        "num_stargazers": 12,
        "num_watchers": 12,
        "num_forks": 14,
        "num_subscribers": 5,
        "SecurityPolicy_created_at": "2020-04-21 08:37:11",
        "SecurityPolicy_commit_history": [
            {
                "commit_id": "4e5e22e32fe240ff8d40b083b9581858c2f333de",
                "url": "https://github.com/personnummer/.github/commit/4e5e22e32fe240ff8d40b083b9581858c2f333de",
                "date": "2020-04-21 08:37:11"
            }
        ],
        "project_security_labels": [],
        "security_issues": [],
        "SecurityPolicy_reporting_mechanism": "email",
        "num_security_issues_after_policy": 0,
        "num_security_issue_and_pull": 0,
        "security_issues_created_after_policy": [],
        "SecurityPolicy_content_category": [
            "Generic policy",
            "Reporting mechanism",
            "User guideline"
        ],
        "num_noncompliant_security_discuss_issue": 0,
        "num_noncompliant_security_pull": 0,
        "has_generic_policy": true
    }
]